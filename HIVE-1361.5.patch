Index: eclipse-templates/.classpath._hbase
===================================================================
--- eclipse-templates/.classpath._hbase	(revision 0)
+++ eclipse-templates/.classpath._hbase	(revision 0)
@@ -0,0 +1,59 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<classpath>
+	<classpathentry exported="true" kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/hadoop-@HADOOPVER@-core.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/hadoop-@HADOOPVER@-test.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@SERVLETAPIJAR@"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@JETTYJAR@"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-@HADOOPVER@/lib/@JETTYUTILJAR@"/>
+	<classpathentry exported="true" kind="lib" path="cli/lib/jline-0.9.94.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/json.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/asm-3.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-cli-2.0-SNAPSHOT.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-codec-1.3.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-lang-2.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-api-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/derby.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jdo2-api-2.3-SNAPSHOT.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-core-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-enhancer-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-rdbms-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libfb303.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libthrift.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/log4j-1.2.15.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-runtime-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="testlibs/junit-3.8.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-0.20.3.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-0.20.3-test.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/zookeeper-3.2.2.jar"/>
+	<classpathentry kind="src" path="build/ql/gen-java"/>
+	<classpathentry kind="src" path="build/contrib/test/src"/>
+	<classpathentry kind="src" path="build/ql/test/src"/>
+	<classpathentry kind="src" path="cli/src/java"/>
+	<classpathentry kind="src" path="common/src/java"/>
+	<classpathentry kind="src" path="contrib/src/java"/>
+	<classpathentry kind="src" path="contrib/src/test"/>
+	<classpathentry kind="src" path="metastore/src/gen-javabean"/>
+	<classpathentry kind="src" path="metastore/src/java"/>
+	<classpathentry kind="src" path="metastore/src/model"/>
+	<classpathentry kind="src" path="metastore/src/test"/>
+	<classpathentry kind="src" path="ql/src/gen-javabean"/>
+	<classpathentry kind="src" path="ql/src/java"/>
+	<classpathentry kind="src" path="ql/src/test"/>
+	<classpathentry kind="src" path="serde/src/gen-java"/>
+	<classpathentry kind="src" path="serde/src/java"/>
+	<classpathentry kind="src" path="serde/src/test"/>
+	<classpathentry kind="src" path="service/src/gen-javabean"/>
+	<classpathentry kind="src" path="service/src/java"/>
+	<classpathentry kind="src" path="service/src/test"/>
+	<classpathentry kind="src" path="jdbc/src/java"/>
+	<classpathentry kind="src" path="jdbc/src/test"/>
+	<classpathentry kind="src" path="shims/src/@HADOOPVERPREF@/java"/>
+	<classpathentry kind="src" path="shims/src/common/java"/>
+	<classpathentry kind="src" path="hbase-handler/src/java"/>
+    <classpathentry kind="src" path="hwi/src/java"/>
+	<classpathentry kind="src" path="hwi/src/test"/>
+    <classpathentry kind="output" path="build/eclipse-classes"/>
+</classpath>
Index: eclipse-templates/TestHBaseCliDriver.launchtemplate
===================================================================
--- eclipse-templates/TestHBaseCliDriver.launchtemplate	(revision 0)
+++ eclipse-templates/TestHBaseCliDriver.launchtemplate	(revision 0)
@@ -0,0 +1,26 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<launchConfiguration type="org.eclipse.jdt.junit.launchconfig">
+  <booleanAttribute key="org.eclipse.debug.core.appendEnvironmentVariables" value="false"/>
+  <mapAttribute key="org.eclipse.debug.core.environmentVariables">
+    <mapEntry key="JAVA_HOME" value="${system_property:java.home}"/>
+    <mapEntry key="HADOOP_HOME" value="${workspace_loc:@PROJECT@}/build/hadoopcore/hadoop-@HADOOPVER@"/>
+  </mapAttribute>
+  <stringAttribute key="org.eclipse.jdt.junit.CONTAINER" value=""/>
+  <booleanAttribute key="org.eclipse.jdt.junit.KEEPRUNNING_ATTR" value="false"/>
+  <stringAttribute key="org.eclipse.jdt.junit.TESTNAME" value=""/>
+  <stringAttribute key="org.eclipse.jdt.junit.TEST_KIND" value="org.eclipse.jdt.junit.loader.junit3"/>
+  <listAttribute key="org.eclipse.jdt.launching.CLASSPATH">
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry containerPath=&quot;org.eclipse.jdt.launching.JRE_CONTAINER&quot; javaProject=&quot;@PROJECT@&quot; path=&quot;1&quot; type=&quot;4&quot;/&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/metastore/hive-model-0.6.0.jar&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/metastore/src/model&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/build/hadoopcore/hadoop-@HADOOPVER@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/data/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry id=&quot;org.eclipse.jdt.launching.classpathentry.defaultClasspath&quot;&gt;&#10;&lt;memento exportedEntriesOnly=&quot;false&quot; project=&quot;@PROJECT@&quot;/&gt;&#10;&lt;/runtimeClasspathEntry&gt;&#10;"/>
+    <listEntry value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;runtimeClasspathEntry internalArchive=&quot;/@PROJECT@/conf&quot; path=&quot;3&quot; type=&quot;2&quot;/&gt;&#10;"/>
+  </listAttribute>
+  <booleanAttribute key="org.eclipse.jdt.launching.DEFAULT_CLASSPATH" value="false"/>
+  <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.apache.hadoop.hive.cli.TestHBaseCliDriver"/>
+  <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="@PROJECT@"/>
+  <stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS" value="-Dhive.root.logger=INFO,console -Dtest.tmp.dir=&quot;${workspace_loc:@PROJECT@}/build/ql/tmp&quot; -Dbuild.dir=&quot;${workspace_loc:@PROJECT@}/build/ql&quot; -Dbuild.dir.hive=&quot;${workspace_loc:@PROJECT@}/build&quot; -Dversion=&quot;@HIVE_VERSION@&quot;"/>
+  <stringAttribute key="org.eclipse.jdt.launching.WORKING_DIRECTORY" value="${workspace_loc:@PROJECT@}/ql"/>
+</launchConfiguration>
Index: .classpath._hbase
===================================================================
--- .classpath._hbase	(revision 0)
+++ .classpath._hbase	(revision 0)
@@ -0,0 +1,59 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<classpath>
+	<classpathentry exported="true" kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-0.20.0/hadoop-0.20.0-core.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-0.20.0/hadoop-0.20.0-test.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-0.20.0/lib/servlet-api-2.5-6.1.14.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-0.20.0/lib/jetty-6.1.14.jar"/>
+	<classpathentry exported="true" kind="lib" path="build/hadoopcore/hadoop-0.20.0/lib/jetty-util-6.1.14.jar"/>
+	<classpathentry exported="true" kind="lib" path="cli/lib/jline-0.9.94.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/json.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/asm-3.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-cli-2.0-SNAPSHOT.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-codec-1.3.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-lang-2.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/commons-logging-api-1.0.4.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/derby.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/jdo2-api-2.3-SNAPSHOT.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-core-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-enhancer-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/datanucleus-rdbms-1.1.2.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libfb303.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/libthrift.jar"/>
+	<classpathentry exported="true" kind="lib" path="lib/log4j-1.2.15.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="ql/lib/antlr-runtime-3.0.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="testlibs/junit-3.8.1.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-0.20.3.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/hbase-0.20.3-test.jar"/>
+	<classpathentry exported="true" kind="lib" path="stats/lib/zookeeper-3.2.2.jar"/>
+	<classpathentry kind="src" path="build/ql/gen-java"/>
+	<classpathentry kind="src" path="build/contrib/test/src"/>
+	<classpathentry kind="src" path="build/ql/test/src"/>
+	<classpathentry kind="src" path="cli/src/java"/>
+	<classpathentry kind="src" path="common/src/java"/>
+	<classpathentry kind="src" path="contrib/src/java"/>
+	<classpathentry kind="src" path="contrib/src/test"/>
+	<classpathentry kind="src" path="metastore/src/gen-javabean"/>
+	<classpathentry kind="src" path="metastore/src/java"/>
+	<classpathentry kind="src" path="metastore/src/model"/>
+	<classpathentry kind="src" path="metastore/src/test"/>
+	<classpathentry kind="src" path="ql/src/gen-javabean"/>
+	<classpathentry kind="src" path="ql/src/java"/>
+	<classpathentry kind="src" path="ql/src/test"/>
+	<classpathentry kind="src" path="serde/src/gen-java"/>
+	<classpathentry kind="src" path="serde/src/java"/>
+	<classpathentry kind="src" path="serde/src/test"/>
+	<classpathentry kind="src" path="service/src/gen-javabean"/>
+	<classpathentry kind="src" path="service/src/java"/>
+	<classpathentry kind="src" path="service/src/test"/>
+	<classpathentry kind="src" path="jdbc/src/java"/>
+	<classpathentry kind="src" path="jdbc/src/test"/>
+	<classpathentry kind="src" path="shims/src/0.20/java"/>
+	<classpathentry kind="src" path="shims/src/common/java"/>
+	<classpathentry kind="src" path="hbase-handler/src/java"/>
+    <classpathentry kind="src" path="hwi/src/java"/>
+	<classpathentry kind="src" path="hwi/src/test"/>
+    <classpathentry kind="output" path="build/eclipse-classes"/>
+</classpath>
Index: conf/hive-default.xml
===================================================================
--- conf/hive-default.xml	(revision 1000592)
+++ conf/hive-default.xml	(working copy)
@@ -613,6 +613,30 @@
 </property>
 
 <property>
+  <name>hive.stats.dbclass</name>
+  <value>jdbc:derby</value>
+  <description>The default database that stores temporary hive statistics.</description>
+</property>
+
+<property>
+  <name>hive.stats.autogather</name>
+  <value>true</value>
+  <description>A flag to gather statistics automatically during the INSERT OVERWRITE command.</description>
+</property>
+
+<property>
+  <name>hive.stats.jdbcdriver</name>
+  <value>org.apache.derby.jdbc.EmbeddedDriver</value>
+  <description>The JDBC driver for the database that stores temporary hive statistics.</description>
+</property>
+
+<property>
+  <name>hive.stats.dbconnectionstring</name>
+  <value>jdbc:derby:;databaseName=TempStatsStore;create=true</value>
+  <description>The default connection string for the database that stores temporary hive statistics.</description>
+</property>
+
+<property>
   <name>hive.support.concurrency</name>
   <value>false</value>
   <description>Whether hive supports concurrency or not. A zookeeper instance must be up and running for the default hive lock manager to support read-write locks.</description>
Index: hbase-handler/src/test/results/hbase_stats.q.out
===================================================================
--- hbase-handler/src/test/results/hbase_stats.q.out	(revision 0)
+++ hbase-handler/src/test/results/hbase_stats.q.out	(revision 0)
@@ -0,0 +1,130 @@
+PREHOOK: query: analyze table src compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@src
+POSTHOOK: query: analyze table src compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@src
+PREHOOK: query: desc extended src
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended src
+POSTHOOK: type: DESCTABLE
+key	string	default
+value	string	default
+	 	 
+Detailed Table Information	Table(tableName:src, dbName:default, owner:null, createTime:1284419348, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/src, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), partitionKeys:[], parameters:{numPartitions=0, numFiles=1, transient_lastDdlTime=1284419360, numRows=500, totalSize=5812}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	
+PREHOOK: query: analyze table srcpart partition(ds='2008-04-08', hr=11) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: query: analyze table srcpart partition(ds='2008-04-08', hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@srcpart
+POSTHOOK: Output: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: query: analyze table srcpart partition(ds='2008-04-08', hr=12) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: query: analyze table srcpart partition(ds='2008-04-08', hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@srcpart
+POSTHOOK: Output: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: query: desc extended srcpart partition(ds='2008-04-08', hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended srcpart partition(ds='2008-04-08', hr=11)
+POSTHOOK: type: DESCTABLE
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Partition Information	Partition(values:[2008-04-08, 11], dbName:default, tableName:srcpart, createTime:1284419340, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/srcpart/ds=2008-04-08/hr=11, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), parameters:{numFiles=1, transient_lastDdlTime=1284419365, numRows=500, totalSize=5812})	
+PREHOOK: query: desc extended srcpart partition(ds='2008-04-08', hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended srcpart partition(ds='2008-04-08', hr=12)
+POSTHOOK: type: DESCTABLE
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Partition Information	Partition(values:[2008-04-08, 12], dbName:default, tableName:srcpart, createTime:1284419342, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/srcpart/ds=2008-04-08/hr=12, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), parameters:{numFiles=1, transient_lastDdlTime=1284419371, numRows=500, totalSize=5812})	
+PREHOOK: query: desc extended srcpart
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended srcpart
+POSTHOOK: type: DESCTABLE
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Table Information	Table(tableName:srcpart, dbName:default, owner:null, createTime:1284419338, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/srcpart, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:hr, type:string, comment:null)], parameters:{numPartitions=2, numFiles=2, transient_lastDdlTime=1284419371, numRows=1000, totalSize=11624}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	
+PREHOOK: query: create table hbase_part like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table hbase_part like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@hbase_part
+PREHOOK: query: insert overwrite table hbase_part partition (ds='2010-04-08', hr = '11') select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@hbase_part@ds=2010-04-08/hr=11
+POSTHOOK: query: insert overwrite table hbase_part partition (ds='2010-04-08', hr = '11') select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@hbase_part@ds=2010-04-08/hr=11
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: insert overwrite table hbase_part partition (ds='2010-04-08', hr = '12') select key, value from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@hbase_part@ds=2010-04-08/hr=12
+POSTHOOK: query: insert overwrite table hbase_part partition (ds='2010-04-08', hr = '12') select key, value from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@hbase_part@ds=2010-04-08/hr=12
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended hbase_part
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended hbase_part
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Table Information	Table(tableName:hbase_part, dbName:default, owner:null, createTime:1284419371, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/hbase_part, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), partitionKeys:[FieldSchema(name:ds, type:string, comment:null), FieldSchema(name:hr, type:string, comment:null)], parameters:{numPartitions=4, EXTERNAL=FALSE, numFiles=4, transient_lastDdlTime=1284419382, numRows=2000, totalSize=23248}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	
+PREHOOK: query: desc extended hbase_part partition (ds='2010-04-08', hr = '11')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended hbase_part partition (ds='2010-04-08', hr = '11')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Partition Information	Partition(values:[2010-04-08, 11], dbName:default, tableName:hbase_part, createTime:1284419377, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/hbase_part/ds=2010-04-08/hr=11, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), parameters:{numFiles=1, transient_lastDdlTime=1284419377, numRows=500, totalSize=5812})	
+PREHOOK: query: desc extended hbase_part partition (ds='2010-04-08', hr = '12')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended hbase_part partition (ds='2010-04-08', hr = '12')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=11).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: hbase_part PARTITION(ds=2010-04-08,hr=12).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+key	string	default
+value	string	default
+ds	string	
+hr	string	
+	 	 
+Detailed Partition Information	Partition(values:[2010-04-08, 12], dbName:default, tableName:hbase_part, createTime:1284419382, lastAccessTime:0, sd:StorageDescriptor(cols:[FieldSchema(name:key, type:string, comment:default), FieldSchema(name:value, type:string, comment:default)], location:pfile:/data/users/nzhang/work/784/apache-hive/build/hbase-handler/test/data/warehouse/hbase_part/ds=2010-04-08/hr=12, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}), parameters:{numFiles=1, transient_lastDdlTime=1284419382, numRows=500, totalSize=5812})	
Index: hbase-handler/src/test/queries/hbase_stats.q
===================================================================
--- hbase-handler/src/test/queries/hbase_stats.q	(revision 0)
+++ hbase-handler/src/test/queries/hbase_stats.q	(revision 0)
@@ -0,0 +1,23 @@
+set datanucleus.cache.collections=false;
+
+set hive.stats.dbclass=hbase;
+analyze table src compute statistics;
+
+desc extended src;
+
+analyze table srcpart partition(ds='2008-04-08', hr=11) compute statistics;
+analyze table srcpart partition(ds='2008-04-08', hr=12) compute statistics;
+
+desc extended srcpart partition(ds='2008-04-08', hr=11);
+desc extended srcpart partition(ds='2008-04-08', hr=12);
+desc extended srcpart;
+
+create table hbase_part like srcpart;
+
+insert overwrite table hbase_part partition (ds='2010-04-08', hr = '11') select key, value from src;
+insert overwrite table hbase_part partition (ds='2010-04-08', hr = '12') select key, value from src;
+
+desc extended hbase_part;
+desc extended hbase_part partition (ds='2010-04-08', hr = '11');
+desc extended hbase_part partition (ds='2010-04-08', hr = '12');
+
Index: hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsSetupConstants.java
===================================================================
--- hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsSetupConstants.java	(revision 0)
+++ hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsSetupConstants.java	(revision 0)
@@ -0,0 +1,11 @@
+package org.apache.hadoop.hive.hbase;
+
+public final class HBaseStatsSetupConstants {
+
+  public static final String PART_STAT_TABLE_NAME = "PARTITION_STAT_TBL";
+  
+  public static final String PART_STAT_ROW_COUNT_COLUMN_NAME = "ROW_COUNT";
+  
+  public static final String PART_STAT_ROW_COUNT_COLUMN_FAMILY = "ROW_COUNT_FAMILY";
+
+}
Index: hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java
===================================================================
--- hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java	(revision 0)
+++ hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsPublisher.java	(revision 0)
@@ -0,0 +1,140 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.hbase;
+
+import java.io.IOException;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.HColumnDescriptor;
+import org.apache.hadoop.hbase.HTableDescriptor;
+import org.apache.hadoop.hbase.client.Get;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Put;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.RowLock;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hive.ql.stats.*;
+
+/**
+ * A class that implements the StatsPublisher interface through HBase.
+ */
+public class HBaseStatsPublisher implements StatsPublisher {
+
+  private HTable htable;
+  private byte[] rowCountFamily, rowCountColumn;
+  private final Log LOG = LogFactory.getLog(this.getClass().getName());
+
+  /**
+   * Does the necessary HBase initializations.
+   */
+  public boolean connect(Configuration hiveconf) {
+
+    try {
+      HBaseConfiguration hbaseConf = new HBaseConfiguration(hiveconf);
+      HBaseAdmin hbase = new HBaseAdmin(hbaseConf);
+      rowCountFamily = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_FAMILY);
+      rowCountColumn = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME);
+      htable = new HTable(HBaseStatsSetupConstants.PART_STAT_TABLE_NAME);
+      // for performance reason, defer update until the closeConnection
+      htable.setAutoFlush(false);
+    } catch (IOException e) {
+      LOG.error("Error during HBase connection. " + e);
+      return false;
+    }
+
+    return true;
+  }
+
+  /**
+   * Writes temporary statistics into HBase;
+   */
+  public boolean publishStat(String rowID, String key, String value) {
+
+    if (key != StatsSetupConst.ROW_COUNT) {
+      LOG.warn("Warning. Invalid statistic. Currently " +
+      "row count is the only supported statistic");
+      return false;
+    }
+
+    // Write in HBase
+    try {
+      Get get = new Get(Bytes.toBytes(rowID));
+      Result result = htable.get(get);
+      int val = Integer.parseInt(value);
+      int oldVal = 0;
+      if (!result.isEmpty()) {
+        oldVal = Integer.parseInt(Bytes.toString(result.getValue(rowCountFamily, rowCountColumn)));
+      }
+      if (oldVal < val) {
+        Put row = new Put(Bytes.toBytes(rowID));
+        row.add(rowCountFamily, rowCountColumn, Bytes.toBytes(Integer.toString(val)));
+        htable.put(row);
+      }
+      return true;
+
+    } catch (IOException e) {
+      LOG.error("Error during publishing statistics. " + e);
+      return false;
+    }
+  }
+
+  public boolean closeConnection() {
+    // batch update
+    try {
+      htable.flushCommits();
+      return true;
+    } catch (IOException e) {
+      LOG.error("Cannot commit changes in stats publishing.", e);
+      return false;
+    }
+  }
+
+
+  /**
+   * Does the necessary HBase initializations.
+   */
+  public boolean init(Configuration hiveconf) {
+    try {
+      HBaseConfiguration hbaseConf = new HBaseConfiguration(hiveconf);
+      HBaseAdmin hbase = new HBaseAdmin(hbaseConf);
+
+      rowCountFamily = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_FAMILY);
+      rowCountColumn = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME);
+
+      // Creating table if not exists
+      if (!hbase.tableExists(HBaseStatsSetupConstants.PART_STAT_TABLE_NAME)) {
+        HTableDescriptor table = new HTableDescriptor(HBaseStatsSetupConstants.PART_STAT_TABLE_NAME);
+
+        HColumnDescriptor rowCount = new HColumnDescriptor(rowCountFamily);
+        table.addFamily(rowCount);
+
+        hbase.createTable(table);
+      }
+    } catch (IOException e) {
+      LOG.error("Error during HBase initialization. " + e);
+      return false;
+    }
+
+    return true;
+  }  
+}
Index: hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java
===================================================================
--- hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java	(revision 0)
+++ hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStatsAggregator.java	(revision 0)
@@ -0,0 +1,147 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.hbase;
+
+import java.io.IOException;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Iterator;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HBaseConfiguration;
+import org.apache.hadoop.hbase.client.HBaseAdmin;
+import org.apache.hadoop.hbase.client.HTable;
+import org.apache.hadoop.hbase.client.Delete;
+import org.apache.hadoop.hbase.client.Result;
+import org.apache.hadoop.hbase.client.Get;
+import org.apache.hadoop.hbase.client.Scan;
+import org.apache.hadoop.hbase.filter.PrefixFilter;
+import org.apache.hadoop.hbase.client.ResultScanner;
+import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hive.ql.stats.StatsAggregator;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
+
+
+/**
+ * A class that implements the StatsAggregator interface through HBase.
+ */
+public class HBaseStatsAggregator implements StatsAggregator {
+
+  private HTable htable;
+  private byte[] rowCountFamily, rowCountColumn;
+  private final Log LOG = LogFactory.getLog(this.getClass().getName());
+
+  /**
+   * Does the necessary HBase initializations.
+   */
+  public boolean connect(Configuration hiveconf) {
+
+    try {
+      HBaseConfiguration hbaseConf = new HBaseConfiguration(hiveconf);
+      HBaseAdmin hbase = new HBaseAdmin(hbaseConf);
+
+      rowCountFamily = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_FAMILY);
+      rowCountColumn = Bytes.toBytes(HBaseStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME);
+      htable = new HTable(HBaseStatsSetupConstants.PART_STAT_TABLE_NAME);
+
+      return true;
+    } catch (IOException e) {
+      LOG.error("Error during HBase connection. ", e);
+      return false;
+    }    
+  }
+
+  /**
+   * Aggregates temporary stats from HBase;
+   */
+  public String aggregateStats(String rowID, String key) {
+
+    if (key != StatsSetupConst.ROW_COUNT) {
+      LOG.warn("Warning. Invalid statistic. Currently " +
+      "row count is the only supported statistic");
+      return null;
+    }
+
+    int retValue = 0;
+    try {
+      Scan scan = new Scan();
+      scan.addColumn(rowCountFamily, rowCountColumn);
+      // Filter the row by its ID
+      // The complete key is "tableName/PartSpecs/jobID/taskID"
+      // This is a prefix filter, the prefix is "tableName/PartSpecs/JobID", i.e. the taskID is ignored
+      // In SQL, this is equivalent to "Select * FROM tableName where ID LIKE 'tableName/PartSpecs/JobID%';"
+      PrefixFilter filter = new PrefixFilter(Bytes.toBytes(rowID));
+      scan.setFilter(filter);
+      ResultScanner scanner = htable.getScanner(scan);
+      ArrayList<Delete> toDelete = new ArrayList<Delete>();
+      for (Result result: scanner) {
+        retValue += Integer.parseInt(Bytes.toString(result.getValue(rowCountFamily, rowCountColumn)));
+
+        /* Automatic Cleaning:
+          IMPORTANT: Since we publish and aggregate only 1 value (1 column) which is the row count, it
+          is valid to delete the row after aggregation (automatic cleaning) because we know that there is no
+          other values to aggregate.
+          If ;in the future; other values are aggregated and published, then we cannot do cleaning except
+          when we are sure that all values are aggregated, or we can separate the implementation of cleaning
+          through a separate method which the developer has to call it manually in the code.
+         */
+        Delete delete = new Delete(result.getRow()); 
+        toDelete.add(delete);
+      }
+      htable.delete(toDelete); 
+      
+      return Integer.toString(retValue);
+    } catch (IOException e) {
+      LOG.error("Error during publishing aggregation. ", e);
+      return null;
+    }
+  }
+
+  public boolean closeConnection() {
+    return true;
+  }
+
+  public boolean cleanUp(String rowID) {
+    try {
+      Scan scan = new Scan();
+      // Filter the row by its ID
+      // The complete key is "tableName/PartSpecs/jobID/taskID"
+      // This is a prefix filter, the prefix is "JobID"
+      // In SQL, this is equivalent to "Select * FROM tableName where ID LIKE 'JobID%';"
+      PrefixFilter filter = new PrefixFilter(Bytes.toBytes(rowID));
+      scan.setFilter(filter);
+      ResultScanner scanner = htable.getScanner(scan);
+      ArrayList<Delete> toDelete = new ArrayList<Delete>();
+      for (Result result: scanner) {
+        Delete delete = new Delete(result.getRow()); 
+        toDelete.add(delete);
+      }
+      htable.delete(toDelete); 
+      return true;
+    }
+    catch (IOException e) {
+      LOG.error("Error during publishing aggregation. ", e);
+      return false;
+    }
+  }
+  
+}
\ No newline at end of file
Index: build-common.xml
===================================================================
--- build-common.xml	(revision 1000592)
+++ build-common.xml	(working copy)
@@ -411,7 +411,7 @@
       <jvmarg value="-Xdebug"/>
       <jvmarg value="-Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=y"/> -->
       <env key="HADOOP_HOME" value="${hadoop.root}"/>
-      <env key="HADOOP_CLASSPATH" value="${test.src.data.dir}/conf"/>
+      <env key="HADOOP_CLASSPATH" value="${test.src.data.dir}/conf,file://${build.dir.hive}/dist/lib/derby.jar"/> 
       <env key="TZ" value="US/Pacific"/>
       <sysproperty key="test.output.overwrite" value="${overwrite}"/>
       <sysproperty key="test.service.standalone.server" value="${standalone}"/>
Index: common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
===================================================================
--- common/src/java/org/apache/hadoop/hive/conf/HiveConf.java	(revision 1000592)
+++ common/src/java/org/apache/hadoop/hive/conf/HiveConf.java	(working copy)
@@ -273,6 +273,16 @@
     HIVEOPTSORTMERGEBUCKETMAPJOIN("hive.optimize.bucketmapjoin.sortedmerge", false), // try to use sorted merge bucket map join
     HIVEOPTREDUCEDEDUPLICATION("hive.optimize.reducededuplication", true),
 
+    // Statistics
+    HIVESTATSAUTOGATHER("hive.stats.autogather", true),
+    HIVESTATSDBCLASS("hive.stats.dbclass",
+        "jdbc:derby"), // other options are jdbc:mysql and hbase as defined in StatsSetupConst.java
+    HIVESTATSJDBCDRIVER("hive.stats.jdbcdriver",
+        "org.apache.derby.jdbc.EmbeddedDriver"), // JDBC driver specific to the dbclass
+    HIVESTATSDBCONNECTIONSTRING("hive.stats.dbconnectionstring",
+        "jdbc:derby:;databaseName=TempStatsStore;create=true"), // automatically create database
+
+    // Concurrency
     HIVE_SUPPORT_CONCURRENCY("hive.support.concurrency", false),
     HIVE_LOCK_MANAGER("hive.lock.manager", "org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager"),
     HIVE_LOCK_NUMRETRIES("hive.lock.numretries", 100),
Index: contrib/src/test/results/clientpositive/serde_typedbytes.q.out_0.17
===================================================================
--- contrib/src/test/results/clientpositive/serde_typedbytes.q.out_0.17	(revision 1000592)
+++ contrib/src/test/results/clientpositive/serde_typedbytes.q.out_0.17	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -81,14 +82,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-49-51_382_4622644744961849025/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-23_012_2807368536394496642/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -101,9 +102,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-49-51_382_4622644744961849025/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-23_012_2807368536394496642/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -156,11 +160,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-49-55_144_6013603357651059081/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-29_017_3216076138782477108/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-49-55_144_6013603357651059081/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-29_017_3216076138782477108/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: contrib/src/test/results/clientpositive/serde_typedbytes4.q.out
===================================================================
--- contrib/src/test/results/clientpositive/serde_typedbytes4.q.out	(revision 1000592)
+++ contrib/src/test/results/clientpositive/serde_typedbytes4.q.out	(working copy)
@@ -37,6 +37,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -106,7 +107,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(cast(src.key as tinyint), src.value) ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.TypedBytesSerDe'
@@ -138,11 +142,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-09_481_4318057970138533652/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-53_257_7808701437859103855/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-09_481_4318057970138533652/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-53_257_7808701437859103855/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: contrib/src/test/results/clientpositive/serde_typedbytes2.q.out_0.17
===================================================================
--- contrib/src/test/results/clientpositive/serde_typedbytes2.q.out_0.17	(revision 1000592)
+++ contrib/src/test/results/clientpositive/serde_typedbytes2.q.out_0.17	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -74,14 +75,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-49-55_937_7140028317305724106/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-30_294_3842816236457000176/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -94,9 +95,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-49-55_937_7140028317305724106/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-30_294_3842816236457000176/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -149,11 +153,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-49-59_721_4278833815354712355/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-37_008_2602885333879790669/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-49-59_721_4278833815354712355/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-37_008_2602885333879790669/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: contrib/src/test/results/clientpositive/serde_typedbytes3.q.out_0.17
===================================================================
--- contrib/src/test/results/clientpositive/serde_typedbytes3.q.out_0.17	(revision 1000592)
+++ contrib/src/test/results/clientpositive/serde_typedbytes3.q.out_0.17	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -74,14 +75,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-50-00_556_4571111651009453839/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-38_316_2452507055215036685/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -94,9 +95,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-50-00_556_4571111651009453839/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-38_316_2452507055215036685/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -149,11 +153,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-04_450_584756664375230434/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-45_553_1148648718205896873/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-04_450_584756664375230434/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-18-45_553_1148648718205896873/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: contrib/src/test/results/clientpositive/serde_typedbytes5.q.out_0.17
===================================================================
--- contrib/src/test/results/clientpositive/serde_typedbytes5.q.out_0.17	(revision 1000592)
+++ contrib/src/test/results/clientpositive/serde_typedbytes5.q.out_0.17	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -81,14 +82,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-50-10_331_8861291796416981703/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-54_560_6676989742688424228/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -101,9 +102,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/njain/hive3/hive3/build/contrib/scratchdir/hive_2010-08-18_09-50-10_331_8861291796416981703/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/contrib/scratchdir/hive_2010-09-21_10-18-54_560_6676989742688424228/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -156,11 +160,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-14_244_548053753581897872/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-19-01_812_3935015144770510266/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-18_09-50-14_244_548053753581897872/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_10-19-01_812_3935015144770510266/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/union_ppr.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union_ppr.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/union_ppr.q.out_0.17	(revision 0)
@@ -0,0 +1,612 @@
+PREHOOK: query: EXPLAIN EXTENDED 
+SELECT * FROM (
+  SELECT X.* FROM SRCPART X WHERE X.key < 100
+  UNION ALL
+  SELECT Y.* FROM SRCPART Y WHERE Y.key < 100
+) A
+WHERE A.ds = '2008-04-08'
+SORT BY A.key
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN EXTENDED 
+SELECT * FROM (
+  SELECT X.* FROM SRCPART X WHERE X.key < 100
+  UNION ALL
+  SELECT Y.* FROM SRCPART Y WHERE Y.key < 100
+) A
+WHERE A.ds = '2008-04-08'
+SORT BY A.key
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_TABREF SRCPART X)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF X))) (TOK_WHERE (< (. (TOK_TABLE_OR_COL X) key) 100)))) (TOK_QUERY (TOK_FROM (TOK_TABREF SRCPART Y)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF Y))) (TOK_WHERE (< (. (TOK_TABLE_OR_COL Y) key) 100))))) A)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (= (. (TOK_TABLE_OR_COL A) ds) '2008-04-08')) (TOK_SORTBY (TOK_TABSORTCOLNAMEASC (. (TOK_TABLE_OR_COL A) key)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        null-subquery1:a-subquery1:x 
+          TableScan
+            alias: x
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: ((key < 100) and (ds = '2008-04-08'))
+                  type: boolean
+              Filter Operator
+                isSamplingPred: false
+                predicate:
+                    expr: (key < 100)
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                        expr: ds
+                        type: string
+                        expr: hr
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  Union
+                    Filter Operator
+                      isSamplingPred: false
+                      predicate:
+                          expr: (_col2 = '2008-04-08')
+                          type: boolean
+                      Select Operator
+                        expressions:
+                              expr: _col0
+                              type: string
+                              expr: _col1
+                              type: string
+                              expr: _col2
+                              type: string
+                              expr: _col3
+                              type: string
+                        outputColumnNames: _col0, _col1, _col2, _col3
+                        Reduce Output Operator
+                          key expressions:
+                                expr: _col0
+                                type: string
+                          sort order: +
+                          tag: -1
+                          value expressions:
+                                expr: _col0
+                                type: string
+                                expr: _col1
+                                type: string
+                                expr: _col2
+                                type: string
+                                expr: _col3
+                                type: string
+        null-subquery2:a-subquery2:y 
+          TableScan
+            alias: y
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: ((key < 100) and (ds = '2008-04-08'))
+                  type: boolean
+              Filter Operator
+                isSamplingPred: false
+                predicate:
+                    expr: (key < 100)
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                        expr: ds
+                        type: string
+                        expr: hr
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  Union
+                    Filter Operator
+                      isSamplingPred: false
+                      predicate:
+                          expr: (_col2 = '2008-04-08')
+                          type: boolean
+                      Select Operator
+                        expressions:
+                              expr: _col0
+                              type: string
+                              expr: _col1
+                              type: string
+                              expr: _col2
+                              type: string
+                              expr: _col3
+                              type: string
+                        outputColumnNames: _col0, _col1, _col2, _col3
+                        Reduce Output Operator
+                          key expressions:
+                                expr: _col0
+                                type: string
+                          sort order: +
+                          tag: -1
+                          value expressions:
+                                expr: _col0
+                                type: string
+                                expr: _col1
+                                type: string
+                                expr: _col2
+                                type: string
+                                expr: _col3
+                                type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+          Partition
+            base file name: hr=11
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 11
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+          Partition
+            base file name: hr=12
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            directory: file:/tmp/nzhang/hive_2010-09-15_17-41-50_990_3853346514414187930/-ext-10001
+            NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-41-50_990_3853346514414187930/-ext-10001/
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                properties:
+                  columns _col0,_col1,_col2,_col3
+                  columns.types string:string:string:string
+                  serialization.format 1
+            TotalFiles: 1
+            GatherStats: false
+            MultiFileSpray: false
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: SELECT * FROM (
+  SELECT X.* FROM SRCPART X WHERE X.key < 100
+  UNION ALL
+  SELECT Y.* FROM SRCPART Y WHERE Y.key < 100
+) A
+WHERE A.ds = '2008-04-08'
+SORT BY A.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-51_133_3284198983915968569/-mr-10000
+POSTHOOK: query: SELECT * FROM (
+  SELECT X.* FROM SRCPART X WHERE X.key < 100
+  UNION ALL
+  SELECT Y.* FROM SRCPART Y WHERE Y.key < 100
+) A
+WHERE A.ds = '2008-04-08'
+SORT BY A.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-51_133_3284198983915968569/-mr-10000
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	11
+0	val_0	2008-04-08	12
+0	val_0	2008-04-08	12
+0	val_0	2008-04-08	12
+0	val_0	2008-04-08	12
+0	val_0	2008-04-08	12
+0	val_0	2008-04-08	12
+10	val_10	2008-04-08	12
+10	val_10	2008-04-08	12
+10	val_10	2008-04-08	11
+10	val_10	2008-04-08	11
+11	val_11	2008-04-08	11
+11	val_11	2008-04-08	11
+11	val_11	2008-04-08	12
+11	val_11	2008-04-08	12
+12	val_12	2008-04-08	12
+12	val_12	2008-04-08	12
+12	val_12	2008-04-08	12
+12	val_12	2008-04-08	12
+12	val_12	2008-04-08	11
+12	val_12	2008-04-08	11
+12	val_12	2008-04-08	11
+12	val_12	2008-04-08	11
+15	val_15	2008-04-08	11
+15	val_15	2008-04-08	11
+15	val_15	2008-04-08	11
+15	val_15	2008-04-08	11
+15	val_15	2008-04-08	12
+15	val_15	2008-04-08	12
+15	val_15	2008-04-08	12
+15	val_15	2008-04-08	12
+17	val_17	2008-04-08	12
+17	val_17	2008-04-08	12
+17	val_17	2008-04-08	11
+17	val_17	2008-04-08	11
+18	val_18	2008-04-08	11
+18	val_18	2008-04-08	11
+18	val_18	2008-04-08	11
+18	val_18	2008-04-08	11
+18	val_18	2008-04-08	12
+18	val_18	2008-04-08	12
+18	val_18	2008-04-08	12
+18	val_18	2008-04-08	12
+19	val_19	2008-04-08	12
+19	val_19	2008-04-08	12
+19	val_19	2008-04-08	11
+19	val_19	2008-04-08	11
+2	val_2	2008-04-08	11
+2	val_2	2008-04-08	11
+2	val_2	2008-04-08	12
+2	val_2	2008-04-08	12
+20	val_20	2008-04-08	12
+20	val_20	2008-04-08	12
+20	val_20	2008-04-08	11
+20	val_20	2008-04-08	11
+24	val_24	2008-04-08	11
+24	val_24	2008-04-08	11
+24	val_24	2008-04-08	11
+24	val_24	2008-04-08	11
+24	val_24	2008-04-08	12
+24	val_24	2008-04-08	12
+24	val_24	2008-04-08	12
+24	val_24	2008-04-08	12
+26	val_26	2008-04-08	12
+26	val_26	2008-04-08	12
+26	val_26	2008-04-08	12
+26	val_26	2008-04-08	12
+26	val_26	2008-04-08	11
+26	val_26	2008-04-08	11
+26	val_26	2008-04-08	11
+26	val_26	2008-04-08	11
+27	val_27	2008-04-08	11
+27	val_27	2008-04-08	11
+27	val_27	2008-04-08	12
+27	val_27	2008-04-08	12
+28	val_28	2008-04-08	12
+28	val_28	2008-04-08	12
+28	val_28	2008-04-08	11
+28	val_28	2008-04-08	11
+30	val_30	2008-04-08	11
+30	val_30	2008-04-08	11
+30	val_30	2008-04-08	12
+30	val_30	2008-04-08	12
+33	val_33	2008-04-08	12
+33	val_33	2008-04-08	12
+33	val_33	2008-04-08	11
+33	val_33	2008-04-08	11
+34	val_34	2008-04-08	11
+34	val_34	2008-04-08	11
+34	val_34	2008-04-08	12
+34	val_34	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	12
+35	val_35	2008-04-08	11
+35	val_35	2008-04-08	11
+35	val_35	2008-04-08	11
+35	val_35	2008-04-08	11
+35	val_35	2008-04-08	11
+35	val_35	2008-04-08	11
+37	val_37	2008-04-08	11
+37	val_37	2008-04-08	11
+37	val_37	2008-04-08	11
+37	val_37	2008-04-08	11
+37	val_37	2008-04-08	12
+37	val_37	2008-04-08	12
+37	val_37	2008-04-08	12
+37	val_37	2008-04-08	12
+4	val_4	2008-04-08	12
+4	val_4	2008-04-08	12
+4	val_4	2008-04-08	11
+4	val_4	2008-04-08	11
+41	val_41	2008-04-08	11
+41	val_41	2008-04-08	11
+41	val_41	2008-04-08	12
+41	val_41	2008-04-08	12
+42	val_42	2008-04-08	12
+42	val_42	2008-04-08	12
+42	val_42	2008-04-08	12
+42	val_42	2008-04-08	12
+42	val_42	2008-04-08	11
+42	val_42	2008-04-08	11
+42	val_42	2008-04-08	11
+42	val_42	2008-04-08	11
+43	val_43	2008-04-08	11
+43	val_43	2008-04-08	11
+43	val_43	2008-04-08	12
+43	val_43	2008-04-08	12
+44	val_44	2008-04-08	12
+44	val_44	2008-04-08	12
+44	val_44	2008-04-08	11
+44	val_44	2008-04-08	11
+47	val_47	2008-04-08	11
+47	val_47	2008-04-08	11
+47	val_47	2008-04-08	12
+47	val_47	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	12
+5	val_5	2008-04-08	11
+5	val_5	2008-04-08	11
+5	val_5	2008-04-08	11
+5	val_5	2008-04-08	11
+5	val_5	2008-04-08	11
+5	val_5	2008-04-08	11
+51	val_51	2008-04-08	11
+51	val_51	2008-04-08	11
+51	val_51	2008-04-08	11
+51	val_51	2008-04-08	11
+51	val_51	2008-04-08	12
+51	val_51	2008-04-08	12
+51	val_51	2008-04-08	12
+51	val_51	2008-04-08	12
+53	val_53	2008-04-08	12
+53	val_53	2008-04-08	12
+53	val_53	2008-04-08	11
+53	val_53	2008-04-08	11
+54	val_54	2008-04-08	11
+54	val_54	2008-04-08	11
+54	val_54	2008-04-08	12
+54	val_54	2008-04-08	12
+57	val_57	2008-04-08	12
+57	val_57	2008-04-08	12
+57	val_57	2008-04-08	11
+57	val_57	2008-04-08	11
+58	val_58	2008-04-08	11
+58	val_58	2008-04-08	11
+58	val_58	2008-04-08	11
+58	val_58	2008-04-08	11
+58	val_58	2008-04-08	12
+58	val_58	2008-04-08	12
+58	val_58	2008-04-08	12
+58	val_58	2008-04-08	12
+64	val_64	2008-04-08	12
+64	val_64	2008-04-08	12
+64	val_64	2008-04-08	11
+64	val_64	2008-04-08	11
+65	val_65	2008-04-08	11
+65	val_65	2008-04-08	11
+65	val_65	2008-04-08	12
+65	val_65	2008-04-08	12
+66	val_66	2008-04-08	12
+66	val_66	2008-04-08	12
+66	val_66	2008-04-08	11
+66	val_66	2008-04-08	11
+67	val_67	2008-04-08	11
+67	val_67	2008-04-08	11
+67	val_67	2008-04-08	11
+67	val_67	2008-04-08	11
+67	val_67	2008-04-08	12
+67	val_67	2008-04-08	12
+67	val_67	2008-04-08	12
+67	val_67	2008-04-08	12
+69	val_69	2008-04-08	12
+69	val_69	2008-04-08	12
+69	val_69	2008-04-08	11
+69	val_69	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	11
+70	val_70	2008-04-08	12
+70	val_70	2008-04-08	12
+70	val_70	2008-04-08	12
+70	val_70	2008-04-08	12
+70	val_70	2008-04-08	12
+70	val_70	2008-04-08	12
+72	val_72	2008-04-08	12
+72	val_72	2008-04-08	12
+72	val_72	2008-04-08	12
+72	val_72	2008-04-08	12
+72	val_72	2008-04-08	11
+72	val_72	2008-04-08	11
+72	val_72	2008-04-08	11
+72	val_72	2008-04-08	11
+74	val_74	2008-04-08	11
+74	val_74	2008-04-08	11
+74	val_74	2008-04-08	12
+74	val_74	2008-04-08	12
+76	val_76	2008-04-08	12
+76	val_76	2008-04-08	12
+76	val_76	2008-04-08	12
+76	val_76	2008-04-08	12
+76	val_76	2008-04-08	11
+76	val_76	2008-04-08	11
+76	val_76	2008-04-08	11
+76	val_76	2008-04-08	11
+77	val_77	2008-04-08	11
+77	val_77	2008-04-08	11
+77	val_77	2008-04-08	12
+77	val_77	2008-04-08	12
+78	val_78	2008-04-08	12
+78	val_78	2008-04-08	12
+78	val_78	2008-04-08	11
+78	val_78	2008-04-08	11
+8	val_8	2008-04-08	11
+8	val_8	2008-04-08	11
+8	val_8	2008-04-08	12
+8	val_8	2008-04-08	12
+80	val_80	2008-04-08	12
+80	val_80	2008-04-08	12
+80	val_80	2008-04-08	11
+80	val_80	2008-04-08	11
+82	val_82	2008-04-08	11
+82	val_82	2008-04-08	11
+82	val_82	2008-04-08	12
+82	val_82	2008-04-08	12
+83	val_83	2008-04-08	12
+83	val_83	2008-04-08	12
+83	val_83	2008-04-08	12
+83	val_83	2008-04-08	12
+83	val_83	2008-04-08	11
+83	val_83	2008-04-08	11
+83	val_83	2008-04-08	11
+83	val_83	2008-04-08	11
+84	val_84	2008-04-08	11
+84	val_84	2008-04-08	11
+84	val_84	2008-04-08	11
+84	val_84	2008-04-08	11
+84	val_84	2008-04-08	12
+84	val_84	2008-04-08	12
+84	val_84	2008-04-08	12
+84	val_84	2008-04-08	12
+85	val_85	2008-04-08	12
+85	val_85	2008-04-08	12
+85	val_85	2008-04-08	11
+85	val_85	2008-04-08	11
+86	val_86	2008-04-08	11
+86	val_86	2008-04-08	11
+86	val_86	2008-04-08	12
+86	val_86	2008-04-08	12
+87	val_87	2008-04-08	12
+87	val_87	2008-04-08	12
+87	val_87	2008-04-08	11
+87	val_87	2008-04-08	11
+9	val_9	2008-04-08	11
+9	val_9	2008-04-08	11
+9	val_9	2008-04-08	12
+9	val_9	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	12
+90	val_90	2008-04-08	11
+90	val_90	2008-04-08	11
+90	val_90	2008-04-08	11
+90	val_90	2008-04-08	11
+90	val_90	2008-04-08	11
+90	val_90	2008-04-08	11
+92	val_92	2008-04-08	11
+92	val_92	2008-04-08	11
+92	val_92	2008-04-08	12
+92	val_92	2008-04-08	12
+95	val_95	2008-04-08	12
+95	val_95	2008-04-08	12
+95	val_95	2008-04-08	12
+95	val_95	2008-04-08	12
+95	val_95	2008-04-08	11
+95	val_95	2008-04-08	11
+95	val_95	2008-04-08	11
+95	val_95	2008-04-08	11
+96	val_96	2008-04-08	11
+96	val_96	2008-04-08	11
+96	val_96	2008-04-08	12
+96	val_96	2008-04-08	12
+97	val_97	2008-04-08	12
+97	val_97	2008-04-08	12
+97	val_97	2008-04-08	12
+97	val_97	2008-04-08	12
+97	val_97	2008-04-08	11
+97	val_97	2008-04-08	11
+97	val_97	2008-04-08	11
+97	val_97	2008-04-08	11
+98	val_98	2008-04-08	11
+98	val_98	2008-04-08	11
+98	val_98	2008-04-08	11
+98	val_98	2008-04-08	11
+98	val_98	2008-04-08	12
+98	val_98	2008-04-08	12
+98	val_98	2008-04-08	12
+98	val_98	2008-04-08	12
Index: ql/src/test/results/clientpositive/merge4.q.out
===================================================================
--- ql/src/test/results/clientpositive/merge4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge4.q.out	(working copy)
@@ -14,10 +14,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -52,14 +53,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: nzhang_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-51_321_4342271261883953579/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-33_418_8321844712406551860/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -75,9 +76,12 @@
               name: nzhang_part
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-51_321_4342271261883953579/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-33_418_8321844712406551860/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -106,12 +110,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-02_504_6924515535764392544/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-27-45_749_6761468726494270601/-mr-10000
 POSTHOOK: query: select * from nzhang_part
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-02_504_6924515535764392544/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-27-45_749_6761468726494270601/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1131,10 +1135,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -1167,14 +1172,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: nzhang_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-44-03_589_2316123978849728483/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-46_548_4926136843884722397/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -1190,9 +1195,12 @@
               name: nzhang_part
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-44-03_589_2316123978849728483/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-46_548_4926136843884722397/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -1223,12 +1231,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-13_644_4054388057551943925/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-27-57_876_3323265609012860875/-mr-10000
 POSTHOOK: query: select * from nzhang_part
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-13_644_4054388057551943925/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-27-57_876_3323265609012860875/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -2760,12 +2768,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2801,7 +2810,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-15_16-44-14_463_7249270881536354004/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_00-27-58_682_6033422304556905840/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -2820,7 +2829,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part
-        file:/tmp/nzhang/hive_2010-09-15_16-44-14_463_7249270881536354004/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-21_00-27-58_682_6033422304556905840/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -2840,14 +2849,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-44-14_463_7249270881536354004/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-58_682_6033422304556905840/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -2863,9 +2872,12 @@
               name: nzhang_part
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-44-14_463_7249270881536354004/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-27-58_682_6033422304556905840/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -2875,7 +2887,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: nzhang_part
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:s-subquery2:src 
@@ -2935,14 +2947,14 @@
 POSTHOOK: Output: default@nzhang_part@ds=2010-08-15/hr=file,
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 PREHOOK: query: show partitions nzhang_part
@@ -2951,14 +2963,14 @@
 POSTHOOK: type: SHOWPARTITIONS
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 ds=2010-08-15/hr=11
@@ -2967,21 +2979,21 @@
 PREHOOK: query: select * from nzhang_part where hr = 'file,'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=file,
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-35_568_3765164280240692375/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-28-20_480_4738957703179155628/-mr-10000
 POSTHOOK: query: select * from nzhang_part where hr = 'file,'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=file,
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-44-35_568_3765164280240692375/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-28-20_480_4738957703179155628/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 1	1	2010-08-15	file,
Index: ql/src/test/results/clientpositive/join6.q.out
===================================================================
--- ql/src/test/results/clientpositive/join6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join6.q.out	(working copy)
@@ -39,6 +39,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -169,7 +170,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -209,11 +213,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-17-04_195_8961200433327227077/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-50_077_9159182815856110050/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-17-04_195_8961200433327227077/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-50_077_9159182815856110050/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/union19.q.out
===================================================================
--- ql/src/test/results/clientpositive/union19.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union19.q.out	(working copy)
@@ -31,10 +31,12 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-3 depends on stages: Stage-2, Stage-4
+  Stage-3 depends on stages: Stage-2, Stage-6
   Stage-0 depends on stages: Stage-3
+  Stage-4 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-3
-  Stage-4 is a root stage
+  Stage-5 depends on stages: Stage-1
+  Stage-6 is a root stage
 
 STAGE PLANS:
   Stage: Stage-2
@@ -80,7 +82,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-40-25_638_6209859465363547113/10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-19-07_762_5076204664112453958/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -127,7 +129,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
-        file:/tmp/jssarma/hive_2010-07-21_13-40-25_638_6209859465363547113/10005 
+        file:/tmp/nzhang/hive_2010-09-14_18-19-07_762_5076204664112453958/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -210,6 +212,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-4
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -220,7 +225,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-4
+  Stage: Stage-5
+    Stats-Aggr Operator
+
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -267,11 +275,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-33_529_5679096718849362367/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-23_211_5795126073345644412/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-33_529_5679096718849362367/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-23_211_5795126073345644412/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
@@ -590,11 +598,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-36_079_8511341470250811242/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-26_789_6983596924823083129/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-36_079_8511341470250811242/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-26_789_6983596924823083129/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input32.q.out
===================================================================
--- ql/src/test/results/clientpositive/input32.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input32.q.out	(working copy)
@@ -22,6 +22,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -79,7 +80,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tst_dest32
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table dest32
 select count(1) from srcbucket
 PREHOOK: type: QUERY
@@ -94,10 +98,10 @@
 PREHOOK: query: select * from tst_dest32
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tst_dest32
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-54_520_2654638815572437304/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-34_990_3499360845984372062/-mr-10000
 POSTHOOK: query: select * from tst_dest32
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tst_dest32
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-54_520_2654638815572437304/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-34_990_3499360845984372062/-mr-10000
 POSTHOOK: Lineage: tst_dest32.a EXPRESSION [(srcbucket)srcbucket.null, ]
 1000
Index: ql/src/test/results/clientpositive/union4.q.out
===================================================================
--- ql/src/test/results/clientpositive/union4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union4.q.out	(working copy)
@@ -26,12 +26,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -77,7 +78,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-17_23-00-26_802_8395517398034899124/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_18-21-17_342_7247960984302090021/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -101,7 +102,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/nzhang/hive_2010-08-17_23-00-26_802_8395517398034899124/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-21-17_342_7247960984302090021/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -126,14 +127,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-26_802_8395517398034899124/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-21-17_342_7247960984302090021/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -146,9 +147,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-26_802_8395517398034899124/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-21-17_342_7247960984302090021/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -158,7 +162,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -218,11 +222,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-00-41_917_5299368229202949539/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-21-35_055_5141984508295950666/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-00-41_917_5299368229202949539/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-21-35_055_5141984508295950666/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src)s2.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/groupby9.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby9.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -87,7 +89,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-25-41_473_5912399545173757449/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-55_657_8040013815774414670/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -144,9 +146,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-25-41_473_5912399545173757449/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-55_657_8040013815774414670/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -212,7 +217,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, SRC.value, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key, SRC.value
@@ -235,11 +243,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-25-49_248_6786053973649103964/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-12_444_3597512065913999700/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-25-49_248_6786053973649103964/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-12_444_3597512065913999700/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -557,11 +565,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-25-49_307_6015579282653689221/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-12_904_392417491226802946/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-25-49_307_6015579282653689221/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-12_904_392417491226802946/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out_0.17	(working copy)
@@ -55,10 +55,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -67,6 +68,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -107,8 +109,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -118,15 +121,16 @@
                             columns.types string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                             name bucketmapjoin_tmp_result
                             serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1280426527
+                            transient_lastDdlTime 1284589129
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: bucketmapjoin_tmp_result
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -138,6 +142,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -183,8 +188,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -194,21 +200,22 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1280426527
+                                  transient_lastDdlTime 1284589129
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -220,12 +227,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280426526
+              transient_lastDdlTime 1284589127
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -237,31 +244,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426526
+                transient_lastDdlTime 1284589127
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002
-          destination: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -271,20 +278,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426527
+                transient_lastDdlTime 1284589129
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -300,9 +311,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002 [pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -313,12 +324,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280426527
+              transient_lastDdlTime 1284589129
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -329,12 +340,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426527
+                transient_lastDdlTime 1284589129
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -343,7 +354,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-07_971_4336731564238806806/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-49_922_3590451947670375929/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -354,15 +365,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280426527
+                  transient_lastDdlTime 1284589129
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
Index: ql/src/test/results/clientpositive/input11.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input11.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input11.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-25_294_797296808123008532/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-11_684_7662212828448945841/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -79,9 +80,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-25_294_797296808123008532/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-11_684_7662212828448945841/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -120,11 +124,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-29_902_5761587040502015571/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-18_320_3335098694914168047/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-29_902_5761587040502015571/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-18_320_3335098694914168047/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 86	val_86
Index: ql/src/test/results/clientpositive/groupby_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby_ppr.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -31,6 +32,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -61,10 +63,10 @@
                     tag: -1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
       Path -> Partition:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -78,13 +80,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474268
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -95,17 +97,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474268
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -119,13 +121,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474268
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -136,13 +138,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474268
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -178,8 +180,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-36_841_252670956800781040/-ext-10000
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-21-09_050_5882001718557065950/-ext-10000
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-21-09_050_5882001718557065950/-ext-10000/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -189,22 +192,23 @@
                       columns.types string:int:string
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                       name dest1
                       serialization.ddl struct dest1 { string key, i32 c1, string c2}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      transient_lastDdlTime 1281475356
+                      transient_lastDdlTime 1284506469
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
                 TotalFiles: 1
+                GatherStats: true
                 MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-36_841_252670956800781040/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-21-09_050_5882001718557065950/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -214,17 +218,21 @@
                 columns.types string:int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string key, i32 c1, string c2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281475356
+                transient_lastDdlTime 1284506469
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-36_841_252670956800781040/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-21-09_050_5882001718557065950/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-21-09_050_5882001718557065950/-ext-10000/
 
+
 PREHOOK: query: FROM srcpart src
 INSERT OVERWRITE TABLE dest1 
 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) 
@@ -249,11 +257,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-22-39_769_6433162077995600386/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-21-17_301_3824290419944310976/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-22-39_769_6433162077995600386/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-21-17_301_3824290419944310976/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(srcpart)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(srcpart)src.FieldSchema(name:key, type:string, comment:default), (srcpart)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample8.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample8.q.out	(working copy)
@@ -31,6 +31,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -56,6 +57,7 @@
         t 
           TableScan
             alias: t
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -76,12 +78,12 @@
                         type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [t, s]
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [t]
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [t]
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [t]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [t, s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [t]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [t]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [t]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -95,13 +97,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430361
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -112,17 +114,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430361
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -136,13 +138,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430361
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -153,17 +155,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430361
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -177,13 +179,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430361
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -194,17 +196,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430361
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -218,13 +220,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430361
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -235,13 +237,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430361
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -273,7 +275,7 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-mr-10002
+                directory: file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-mr-10002
                 NumFilesPerFileSink: 1
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -283,12 +285,13 @@
                       columns.types string,string,string,string
                       escape.delim \
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -313,9 +316,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-mr-10002 [file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-mr-10002 [file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-mr-10002]
       Path -> Partition:
-        file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -336,8 +339,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_621_3276461109795788096/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-33_114_8195541114406860965/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -346,6 +350,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -364,7 +369,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_812_3396467032413618864/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-33_385_7295722553925021004/-mr-10000
 POSTHOOK: query: SELECT s.key, s.value
 FROM srcpart TABLESAMPLE (BUCKET 1 OUT OF 1 ON key) s
 JOIN srcpart TABLESAMPLE (BUCKET 1 OUT OF 10 ON key) t
@@ -376,7 +381,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_13-30-40_812_3396467032413618864/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-33_385_7295722553925021004/-mr-10000
 0	val_0
 0	val_0
 0	val_0
Index: ql/src/test/results/clientpositive/join29.q.out
===================================================================
--- ql/src/test/results/clientpositive/join29.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join29.q.out	(working copy)
@@ -20,12 +20,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,7 +88,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-17_22-54-18_745_3735170774347695260/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-39-23_363_5550537730462856534/-mr-10002 
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -138,11 +139,11 @@
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            file:/tmp/nzhang/hive_2010-08-17_22-54-18_745_3735170774347695260/-mr-10004 
+            file:/tmp/nzhang/hive_2010-09-14_16-39-23_363_5550537730462856534/-mr-10004 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            file:/tmp/nzhang/hive_2010-08-17_22-54-18_745_3735170774347695260/-mr-10004 
+            file:/tmp/nzhang/hive_2010-09-14_16-39-23_363_5550537730462856534/-mr-10004 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -191,14 +192,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-18_745_3735170774347695260/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-39-23_363_5550537730462856534/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -211,9 +212,12 @@
               name: dest_j1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-18_745_3735170774347695260/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-39-23_363_5550537730462856534/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -223,7 +227,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         subq1:x 
@@ -302,11 +306,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-54-30_633_9036208287661562782/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-36_282_980898119383375655/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-54-30_633_9036208287661562782/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-36_282_980898119383375655/-mr-10000
 POSTHOOK: Lineage: dest_j1.cnt1 EXPRESSION [(src1)x.null, ]
 POSTHOOK: Lineage: dest_j1.cnt2 EXPRESSION [(src)y.null, ]
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/transform_ppr2.q.out
===================================================================
--- ql/src/test/results/clientpositive/transform_ppr2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/transform_ppr2.q.out	(working copy)
@@ -32,6 +32,7 @@
         tmap:src 
           TableScan
             alias: src
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -79,10 +80,10 @@
                             type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -96,13 +97,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453630
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -113,17 +114,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453630
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -137,13 +138,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453630
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -154,13 +155,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453630
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -181,8 +182,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-33_000_2820489435038834397/10001
+                directory: file:/tmp/nzhang/hive_2010-09-15_17-09-57_137_3472461582427948800/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-09-57_137_3472461582427948800/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -191,6 +193,7 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -209,7 +212,7 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-33_475_6899535769120373197/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-57_241_6172961698186584468/-mr-10000
 POSTHOOK: query: FROM (
   FROM srcpart src
   SELECT TRANSFORM(src.ds, src.key, src.value)
@@ -221,7 +224,7 @@
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-33_475_6899535769120373197/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-57_241_6172961698186584468/-mr-10000
 0	val_0
 0	val_0
 0	val_0
Index: ql/src/test/results/clientpositive/notable_alias1.q.out
===================================================================
--- ql/src/test/results/clientpositive/notable_alias1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/notable_alias1.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -106,7 +107,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT '1234', key, count(1) WHERE src.key < 100 group by key
 PREHOOK: type: QUERY
@@ -123,11 +127,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-22-17_250_654170917197184025/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-42_121_5828123472930756203/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-22-17_250_654170917197184025/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-42_121_5828123472930756203/-mr-10000
 POSTHOOK: Lineage: dest1.dummy SIMPLE []
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.null, ]
Index: ql/src/test/results/clientpositive/join1.q.out
===================================================================
--- ql/src/test/results/clientpositive/join1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join1.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -94,7 +95,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key)
 INSERT OVERWRITE TABLE dest_j1 SELECT src1.key, src2.value
 PREHOOK: type: QUERY
@@ -110,11 +114,11 @@
 PREHOOK: query: SELECT dest_j1.* FROM dest_j1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-26-58_363_544510040941465358/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_13-48-35_405_4416987253533563393/-mr-10000
 POSTHOOK: query: SELECT dest_j1.* FROM dest_j1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-26-58_363_544510040941465358/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_13-48-35_405_4416987253533563393/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/bucketmapjoin2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin2.q.out_0.17	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -130,8 +132,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -141,15 +144,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282940394
+                          transient_lastDdlTime 1284588659
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -161,6 +165,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -204,8 +209,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -215,29 +221,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282940394
+                                  transient_lastDdlTime 1284588659
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -249,12 +256,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940389
+              transient_lastDdlTime 1284588654
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -266,31 +273,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940389
+                transient_lastDdlTime 1284588654
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -300,20 +307,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940394
+                transient_lastDdlTime 1284588659
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -329,9 +340,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -342,12 +353,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940394
+              transient_lastDdlTime 1284588659
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -358,12 +369,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940394
+                transient_lastDdlTime 1284588659
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -372,7 +383,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-54_261_3709163670151055576/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-10-59_454_1005932006596386685/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -383,15 +394,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940394
+                  transient_lastDdlTime 1284588659
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -417,11 +429,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-03_719_6665293727490387231/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-10_478_6335362899255626856/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-03_719_6665293727490387231/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-10_478_6335362899255626856/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part_2)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -470,11 +482,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-18_384_3865621339601729806/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-33_023_5222597184607368145/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-18_384_3865621339601729806/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-33_023_5222597184607368145/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -513,14 +525,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-24_983_6691574317220546085/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-43_360_4826747035882193604/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-24_983_6691574317220546085/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-11-43_360_4826747035882193604/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -563,10 +575,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -575,6 +588,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -618,8 +632,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -629,15 +644,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 0
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940418
+                              totalSize 0
+                              transient_lastDdlTime 1284588692
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -649,6 +669,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -682,8 +703,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -693,29 +715,34 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 0
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940418
+                              totalSize 0
+                              transient_lastDdlTime 1284588692
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -729,13 +756,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940392
+              transient_lastDdlTime 1284588657
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -747,32 +774,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940392
+                transient_lastDdlTime 1284588657
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -782,20 +809,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 0
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940418
+                totalSize 0
+                transient_lastDdlTime 1284588692
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -811,9 +846,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -824,12 +859,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 0
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940418
+              totalSize 0
+              transient_lastDdlTime 1284588692
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -840,12 +879,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 0
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940418
+                totalSize 0
+                transient_lastDdlTime 1284588692
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -854,7 +897,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-20-28_849_1096973413691523770/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-11-48_799_2470186467399886741/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -865,15 +908,20 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 0
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940418
+                  totalSize 0
+                  transient_lastDdlTime 1284588692
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -911,11 +959,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-37_225_250073906219450831/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-00_123_7343096506282242329/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-37_225_250073906219450831/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-00_123_7343096506282242329/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1000,11 +1048,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-51_635_932709049820822575/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-24_249_6531524068669089635/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-51_635_932709049820822575/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-24_249_6531524068669089635/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1067,14 +1115,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-58_123_3810133318564098124/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-34_549_8994196466129966712/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-20-58_123_3810133318564098124/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-12-34_549_8994196466129966712/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/load_dyn_part13.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part13.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part13.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:07:15 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:14:33 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part13	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part13	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473235          
+	transient_lastDdlTime	1285053273          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -78,6 +78,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -173,7 +174,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part13
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part13 partition (ds="2010-03-03", hr) 
 select * from (
    select key, value, '22'
@@ -216,12 +220,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part13@ds=2010-03-03/hr=22
 PREHOOK: Input: default@nzhang_part13@ds=2010-03-03/hr=33
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-07-18_377_2550771221773064356/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-14-42_233_3307312463750788413/-mr-10000
 POSTHOOK: query: select * from nzhang_part13 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part13@ds=2010-03-03/hr=22
 POSTHOOK: Input: default@nzhang_part13@ds=2010-03-03/hr=33
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-07-18_377_2550771221773064356/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-14-42_233_3307312463750788413/-mr-10000
 POSTHOOK: Lineage: nzhang_part13 PARTITION(ds=2010-03-03,hr=22).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part13 PARTITION(ds=2010-03-03,hr=22).value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part13 PARTITION(ds=2010-03-03,hr=33).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input6.q.out
===================================================================
--- ql/src/test/results/clientpositive/input6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input6.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -52,14 +53,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-05_506_395010164537868834/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-22_961_7505255459402308117/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -72,9 +73,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-05_506_395010164537868834/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-22_961_7505255459402308117/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -100,10 +104,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-09_213_7887186973737481836/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-28_717_6428564753345154099/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-09_213_7887186973737481836/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-28_717_6428564753345154099/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/stats8.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats8.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats8.q.out	(revision 0)
@@ -0,0 +1,796 @@
+PREHOOK: query: create table analyze_srcpart like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table analyze_srcpart like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@analyze_srcpart
+PREHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-08') (TOK_PARTVAL hr 11))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:36 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056765          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:12:25 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	EXTERNAL            	FALSE               
+	numFiles            	1                   
+	transient_lastDdlTime	1285056765          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-08') (TOK_PARTVAL hr 12))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:37 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056772          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-09') (TOK_PARTVAL hr 11))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:37 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056778          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-09') (TOK_PARTVAL hr 12))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:38 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056785          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds, hr) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds, hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds) (TOK_PARTVAL hr))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds, hr) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds, hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:36 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056793          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:37 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056793          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:37 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056793          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:38 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056793          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:12:25 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	4                   
+	EXTERNAL            	FALSE               
+	numFiles            	4                   
+	transient_lastDdlTime	1285056793          
+	numRows             	2000                
+	totalSize           	23248               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/union_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/union_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union_ppr.q.out	(working copy)
@@ -30,6 +30,7 @@
         null-subquery1:a-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -86,6 +87,7 @@
         null-subquery2:a-subquery2:y 
           TableScan
             alias: y
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -141,10 +143,10 @@
                                 type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -158,13 +160,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266455284
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -175,17 +177,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266455284
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -199,13 +201,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266455284
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -216,13 +218,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266455284
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -231,8 +233,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_17-08-08_275_3527875092444717132/10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_17-41-50_990_3853346514414187930/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-41-50_990_3853346514414187930/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -241,6 +244,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -258,7 +262,7 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_17-08-09_971_7493737717907439251/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-51_133_3284198983915968569/-mr-10000
 POSTHOOK: query: SELECT * FROM (
   SELECT X.* FROM SRCPART X WHERE X.key < 100
   UNION ALL
@@ -269,7 +273,7 @@
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_17-08-09_971_7493737717907439251/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-51_133_3284198983915968569/-mr-10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
Index: ql/src/test/results/clientpositive/join32.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join32.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join32.q.out_0.17	(working copy)
@@ -19,20 +19,22 @@
   (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_TABREF src1 x) (TOK_TABREF src y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key))) (TOK_TABREF srcpart z) (and (and (= (. (TOK_TABLE_OR_COL x) value) (. (TOK_TABLE_OR_COL z) value)) (= (. (TOK_TABLE_OR_COL z) ds) '2008-04-08')) (= (. (TOK_TABLE_OR_COL z) hr) 11)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest_j1)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST x z))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL z) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL y) value)))))
 
 STAGE DEPENDENCIES:
-  Stage-5 is a root stage
-  Stage-1 depends on stages: Stage-5
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-6 is a root stage
+  Stage-1 depends on stages: Stage-6
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
-  Stage: Stage-5
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
         y 
           TableScan
             alias: y
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -48,7 +50,7 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003
+                directory: file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003
                 NumFilesPerFileSink: 1
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -58,6 +60,7 @@
                       columns.types string,string,string
                       escape.delim \
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -69,6 +72,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -84,7 +88,7 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003
+                    directory: file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -94,12 +98,13 @@
                           columns.types string,string,string
                           escape.delim \
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/src [y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [y]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -110,12 +115,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940176
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -126,12 +131,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940176
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -139,7 +144,7 @@
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003 
           Select Operator
             expressions:
                   expr: _col0
@@ -182,8 +187,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -193,15 +199,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                           name dest_j1
                           serialization.ddl struct dest_j1 { string key, string value, string val2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282942331
+                          transient_lastDdlTime 1284591472
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest_j1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -213,6 +220,7 @@
             z 
               TableScan
                 alias: z
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -261,8 +269,9 @@
                             File Output Operator
                               compressed: false
                               GlobalTableId: 1
-                              directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002
+                              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002
                               NumFilesPerFileSink: 1
+                              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000/
                               table:
                                   input format: org.apache.hadoop.mapred.TextInputFormat
                                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -272,21 +281,22 @@
                                     columns.types string:string:string
                                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                    location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                     name dest_j1
                                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                                     serialization.format 1
                                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                    transient_lastDdlTime 1282942331
+                                    transient_lastDdlTime 1284591472
                                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                   name: dest_j1
                               TotalFiles: 1
+                              GatherStats: true
                               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003 [file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003]
+        file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003 [file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003]
       Path -> Partition:
-        file:/tmp/jsichi/hive_2010-08-27_13-52-11_902_9082359192091349153/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-15_15-57-52_346_7488000421787097635/-mr-10003 
           Partition
             base file name: -mr-10003
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -303,21 +313,21 @@
                 columns.types string,string,string
                 escape.delim \
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -327,20 +337,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942331
+                transient_lastDdlTime 1284591472
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -356,9 +370,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -369,12 +383,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282942331
+              transient_lastDdlTime 1284591472
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -385,12 +399,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942331
+                transient_lastDdlTime 1284591472
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -399,7 +413,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-52-11_902_9082359192091349153/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-57-52_346_7488000421787097635/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -410,15 +424,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282942331
+                  transient_lastDdlTime 1284591472
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -446,11 +461,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-52-18_581_2705301025151045736/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-02_431_2007407577007366266/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-52-18_581_2705301025151045736/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-02_431_2007407577007366266/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby4.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby4.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -58,7 +59,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-32_718_1164929876386853266/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-15-29_592_716698340137236338/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -100,7 +101,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT substr(src.key,1,1) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -115,11 +119,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-41_552_1485173365513617364/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-39_750_3083045586040754583/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-41_552_1485173365513617364/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-39_750_3083045586040754583/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/input_part7.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part7.q.out	(working copy)
@@ -28,6 +28,7 @@
         null-subquery1:a-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -79,6 +80,7 @@
         null-subquery2:a-subquery2:y 
           TableScan
             alias: y
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -129,10 +131,10 @@
                               type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [null-subquery1:a-subquery1:x, null-subquery2:a-subquery2:y]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -146,13 +148,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450846
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -163,17 +165,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450846
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -187,13 +189,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450846
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -204,13 +206,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450846
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -219,8 +221,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-10_179_5710430684753314987/10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_16-34-50_348_7354540351576895226/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-34-50_348_7354540351576895226/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -229,6 +232,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -245,7 +249,7 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-10_984_3284366749196522713/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-50_554_5346969636819272886/-mr-10000
 POSTHOOK: query: SELECT * FROM (
   SELECT X.* FROM SRCPART X WHERE X.ds = '2008-04-08' and X.key < 100
   UNION ALL
@@ -255,7 +259,7 @@
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-10_984_3284366749196522713/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-50_554_5346969636819272886/-mr-10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
Index: ql/src/test/results/clientpositive/join26.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join26.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join26.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -83,8 +85,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -94,15 +97,16 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282942261
+                                transient_lastDdlTime 1284591372
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -117,6 +121,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -153,8 +158,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -164,19 +170,21 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282942261
+                              transient_lastDdlTime 1284591372
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -213,8 +221,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -224,21 +233,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282942261
+                              transient_lastDdlTime 1284591372
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -252,13 +262,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940169
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -269,32 +279,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940169
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -304,20 +314,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942261
+                transient_lastDdlTime 1284591372
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -333,9 +347,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -346,12 +360,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282942261
+              transient_lastDdlTime 1284591372
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -362,12 +376,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942261
+                transient_lastDdlTime 1284591372
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -376,7 +390,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-01_567_5222040103440600396/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-12_069_5973804308287672711/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -387,15 +401,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282942261
+                  transient_lastDdlTime 1284591372
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -423,11 +438,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-51-06_513_4212370621532341209/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-19_848_3270685861338388650/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-51-06_513_4212370621532341209/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-19_848_3270685861338388650/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin5.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin5.q.out	(working copy)
@@ -115,10 +115,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -127,6 +128,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -160,8 +162,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -171,15 +174,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282861954
+                          transient_lastDdlTime 1284505182
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -191,6 +195,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -224,8 +229,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -235,36 +241,37 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861954
+                              transient_lastDdlTime 1284505182
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket20.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket21.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -278,13 +285,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861946
+              transient_lastDdlTime 1284505168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -296,17 +303,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861946
+                transient_lastDdlTime 1284505168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -320,13 +327,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861946
+              transient_lastDdlTime 1284505168
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -338,32 +345,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861946
+                transient_lastDdlTime 1284505168
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -373,24 +380,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861954
+                transient_lastDdlTime 1284505182
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -401,21 +412,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861954
+                    transient_lastDdlTime 1284505182
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-32-34_867_8897207649119511130/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-59-42_577_2707452756229867945/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -426,12 +438,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861954
+              transient_lastDdlTime 1284505182
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -442,12 +454,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861954
+                transient_lastDdlTime 1284505182
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -477,11 +489,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-45_477_2732155281688232597/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-00_607_4363184705399797060/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-45_477_2732155281688232597/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-00_607_4363184705399797060/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -532,11 +544,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-02_299_7650145598922104246/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-27_785_1420877540768328899/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-02_299_7650145598922104246/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-27_785_1420877540768328899/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -575,14 +587,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-08_714_273114286204001219/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-38_053_810358526331057404/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-08_714_273114286204001219/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-38_053_810358526331057404/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -625,10 +637,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -637,6 +650,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -670,8 +684,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -681,15 +696,20 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
+                          numFiles 1
+                          numPartitions 0
+                          numRows 928
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282861982
+                          totalSize 17966
+                          transient_lastDdlTime 1284505227
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -701,6 +721,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -734,8 +755,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -745,32 +767,37 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 928
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861982
+                              totalSize 17966
+                              transient_lastDdlTime 1284505227
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -784,13 +811,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861951
+              transient_lastDdlTime 1284505177
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -802,17 +829,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861951
+                transient_lastDdlTime 1284505177
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -826,13 +853,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861951
+              transient_lastDdlTime 1284505177
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -844,32 +871,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861951
+                transient_lastDdlTime 1284505177
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -879,24 +906,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 928
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861982
+                totalSize 17966
+                transient_lastDdlTime 1284505227
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -907,21 +942,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 928
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861982
+                    totalSize 17966
+                    transient_lastDdlTime 1284505227
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-33-12_002_3382885953507765100/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-00-43_036_8977672461532956091/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -932,12 +972,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 928
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861982
+              totalSize 17966
+              transient_lastDdlTime 1284505227
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -948,12 +992,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 928
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861982
+                totalSize 17966
+                transient_lastDdlTime 1284505227
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -995,11 +1043,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-20_762_1076908082223859177/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-56_352_1173075773351651295/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-20_762_1076908082223859177/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-00-56_352_1173075773351651295/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1086,11 +1134,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-35_187_1026481808950583465/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-19_467_5081261362458339468/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-35_187_1026481808950583465/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-19_467_5081261362458339468/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1153,14 +1201,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-41_619_7453774123022828869/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-29_267_3333079687141827583/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-33-41_619_7453774123022828869/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-29_267_3333079687141827583/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/join_map_ppr.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join_map_ppr.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join_map_ppr.q.out_0.17	(working copy)
@@ -22,10 +22,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -34,6 +35,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -84,8 +86,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -95,15 +98,16 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282942493
+                              transient_lastDdlTime 1284591716
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -118,6 +122,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -163,8 +168,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -174,19 +180,21 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282942493
+                                transient_lastDdlTime 1284591716
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -232,8 +240,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -243,21 +252,22 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282942493
+                                transient_lastDdlTime 1284591716
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -271,13 +281,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940169
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -288,32 +298,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940169
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -323,20 +333,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942493
+                transient_lastDdlTime 1284591716
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -352,9 +366,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -365,12 +379,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282942493
+              transient_lastDdlTime 1284591716
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -381,12 +395,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942493
+                transient_lastDdlTime 1284591716
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -395,7 +409,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-54-53_592_3911100532884895712/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-01-56_481_4412478241472228156/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -406,17 +420,19 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282942493
+                  transient_lastDdlTime 1284591716
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1
 SELECT /*+ MAPJOIN(x,y) */ x.key, z.value, y.value
 FROM src1 x JOIN src y ON (x.key = y.key) 
@@ -443,11 +459,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-54-58_494_5115558967305748352/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-02-04_045_4968164727064072138/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-54-58_494_5115558967305748352/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-02-04_045_4968164727064072138/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
@@ -628,10 +644,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -640,6 +657,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -690,8 +708,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -701,15 +720,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
+                              numFiles 1
+                              numPartitions 0
+                              numRows 107
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282942498
+                              totalSize 2125
+                              transient_lastDdlTime 1284591723
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -724,6 +748,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -769,8 +794,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -780,19 +806,25 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
+                                numFiles 1
+                                numPartitions 0
+                                numRows 107
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282942498
+                                totalSize 2125
+                                transient_lastDdlTime 1284591723
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -838,8 +870,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -849,21 +882,26 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
+                                numFiles 1
+                                numPartitions 0
+                                numRows 107
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282942498
+                                totalSize 2125
+                                transient_lastDdlTime 1284591723
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -877,13 +915,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940169
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -894,32 +932,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940169
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -929,20 +967,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
+                numFiles 1
+                numPartitions 0
+                numRows 107
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942498
+                totalSize 2125
+                transient_lastDdlTime 1284591723
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -958,9 +1004,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -971,12 +1017,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
+              numFiles 1
+              numPartitions 0
+              numRows 107
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282942498
+              totalSize 2125
+              transient_lastDdlTime 1284591723
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -987,12 +1037,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
+                numFiles 1
+                numPartitions 0
+                numRows 107
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282942498
+                totalSize 2125
+                transient_lastDdlTime 1284591723
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -1001,7 +1055,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-55-08_718_8637784932212434358/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-02-19_898_5143372157054162049/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1012,17 +1066,23 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
+                  numFiles 1
+                  numPartitions 0
+                  numRows 107
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282942498
+                  totalSize 2125
+                  transient_lastDdlTime 1284591723
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1
 SELECT /*+ MAPJOIN(x,y) */ x.key, z.value, y.value
 FROM src1_copy x JOIN src_copy y ON (x.key = y.key) 
@@ -1056,11 +1116,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-55-13_614_5667132009357094218/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-02-27_479_8406623522580965515/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-55-13_614_5667132009357094218/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-02-27_479_8406623522580965515/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1_copy)x.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/union6.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union6.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/union6.q.out_0.17	(working copy)
@@ -26,12 +26,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -77,7 +78,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-42-01_703_4701345677859889091/10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-41-07_808_9220991775473325843/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -94,7 +95,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-42-01_703_4701345677859889091/10004 
+        file:/tmp/nzhang/hive_2010-09-15_17-41-07_808_9220991775473325843/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -112,14 +113,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-42-01_703_4701345677859889091/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-41-07_808_9220991775473325843/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -132,9 +133,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-42-01_703_4701345677859889091/10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-41-07_808_9220991775473325843/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -157,7 +161,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -199,11 +203,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key, x.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-42-11_839_6864063023544125357/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-26_153_6524787488397952247/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key, x.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-42-11_839_6864063023544125357/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-41-26_153_6524787488397952247/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
 	
Index: ql/src/test/results/clientpositive/bucketmapjoin5.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin5.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin5.q.out_0.17	(working copy)
@@ -115,10 +115,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -127,6 +128,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -160,8 +162,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -171,15 +174,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282940624
+                          transient_lastDdlTime 1284588998
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -191,6 +195,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -224,8 +229,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -235,36 +241,37 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940624
+                              transient_lastDdlTime 1284588998
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket20.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket21.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -278,13 +285,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940615
+              transient_lastDdlTime 1284588991
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -296,17 +303,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940615
+                transient_lastDdlTime 1284588991
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -320,13 +327,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940615
+              transient_lastDdlTime 1284588991
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -338,32 +345,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940615
+                transient_lastDdlTime 1284588991
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -373,20 +380,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940624
+                transient_lastDdlTime 1284588998
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -402,9 +413,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -415,12 +426,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940624
+              transient_lastDdlTime 1284588998
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -431,12 +442,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940624
+                transient_lastDdlTime 1284588998
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -445,7 +456,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-44_048_3362814336824214960/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-16-38_942_8385463192674322586/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -456,15 +467,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940624
+                  transient_lastDdlTime 1284588998
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -492,11 +504,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-59_410_2642286914558110313/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-00_637_2860793514903079414/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-59_410_2642286914558110313/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-00_637_2860793514903079414/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -547,11 +559,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-22_309_7849202608320032551/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-34_090_8083163216169583974/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-22_309_7849202608320032551/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-34_090_8083163216169583974/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -590,14 +602,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-28_909_4705323531161455782/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-44_539_449743994957151759/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-28_909_4705323531161455782/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-17-44_539_449743994957151759/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -640,10 +652,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -652,6 +665,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -685,8 +699,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -696,15 +711,20 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
+                          numFiles 1
+                          numPartitions 0
+                          numRows 928
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282940662
+                          totalSize 17966
+                          transient_lastDdlTime 1284589054
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -716,6 +736,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -749,8 +770,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -760,32 +782,37 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 928
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940662
+                              totalSize 17966
+                              transient_lastDdlTime 1284589054
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt], ds=2008-04-09/srcbucket22.txt=[srcbucket20.txt], ds=2008-04-09/srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -799,13 +826,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940621
+              transient_lastDdlTime 1284588996
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -817,17 +844,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940621
+                transient_lastDdlTime 1284588996
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -841,13 +868,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940621
+              transient_lastDdlTime 1284588996
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -859,32 +886,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940621
+                transient_lastDdlTime 1284588996
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -894,20 +921,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 928
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940662
+                totalSize 17966
+                transient_lastDdlTime 1284589054
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -923,9 +958,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -936,12 +971,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 928
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940662
+              totalSize 17966
+              transient_lastDdlTime 1284589054
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -952,12 +991,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 928
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940662
+                totalSize 17966
+                transient_lastDdlTime 1284589054
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -966,7 +1009,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-24-32_579_4665962759304448485/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-17-49_609_5876978711324607283/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -977,15 +1020,20 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 928
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940662
+                  totalSize 17966
+                  transient_lastDdlTime 1284589054
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -1025,11 +1073,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-42_813_2027159015867580639/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-05_009_5351558109048554781/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-24-42_813_2027159015867580639/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-05_009_5351558109048554781/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1116,11 +1164,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-25-00_186_4050824185643389015/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-30_093_7214598033311727717/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-25-00_186_4050824185643389015/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-30_093_7214598033311727717/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1183,14 +1231,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-25-06_933_2760601759923284738/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-40_416_1423510925520953155/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-25-06_933_2760601759923284738/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-18-40_416_1423510925520953155/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/load_dyn_part2.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part2.q.out	(working copy)
@@ -24,15 +24,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Thu Sep 16 06:29:10 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:15:26 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part_bucket	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part_bucket	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284643750          
+	transient_lastDdlTime	1285053326          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -57,6 +57,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -119,7 +120,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part_bucket
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part_bucket partition (ds='2010-03-23', hr) select key, value, hr from srcpart where ds is not null and hr is not null
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
@@ -151,11 +155,11 @@
 PREHOOK: query: select * from nzhang_part_bucket where ds='2010-03-23' and hr='11' order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part_bucket@ds=2010-03-23/hr=11
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_06-29-15_480_2279252070002045703/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-43_033_6451736056187260668/-mr-10000
 POSTHOOK: query: select * from nzhang_part_bucket where ds='2010-03-23' and hr='11' order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part_bucket@ds=2010-03-23/hr=11
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_06-29-15_480_2279252070002045703/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-43_033_6451736056187260668/-mr-10000
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1163,11 +1167,11 @@
 PREHOOK: query: select * from nzhang_part_bucket where ds='2010-03-23' and hr='12' order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part_bucket@ds=2010-03-23/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_06-29-19_109_7906798640956023956/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-49_936_54145232361564185/-mr-10000
 POSTHOOK: query: select * from nzhang_part_bucket where ds='2010-03-23' and hr='12' order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part_bucket@ds=2010-03-23/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_06-29-19_109_7906798640956023956/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-49_936_54145232361564185/-mr-10000
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part_bucket PARTITION(ds=2010-03-23,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby7_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby7_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby7_map.q.out	(working copy)
@@ -24,8 +24,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -128,9 +130,12 @@
               name: dest1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-28_805_567019798040414438/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-17-44_148_5547939144307537663/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -186,7 +191,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -208,11 +216,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-38_546_5348321121685877555/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-57_997_7209819666869325866/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-38_546_5348321121685877555/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-57_997_7209819666869325866/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -529,11 +537,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-38_609_8222314999786102004/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-58_462_8744984340537397657/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-38_609_8222314999786102004/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-58_462_8744984340537397657/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join35.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join35.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join35.q.out_0.17	(working copy)
@@ -28,12 +28,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -42,6 +43,7 @@
         null-subquery1:subq1-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -80,9 +82,9 @@
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -93,12 +95,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -109,12 +111,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -138,7 +140,7 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10002
+              directory: file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10002
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -148,12 +150,13 @@
                     columns.types string,bigint
                     escape.delim \
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10002 
           Union
             Common Join Operator
               condition map:
@@ -197,8 +200,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -208,17 +212,18 @@
                             columns.types string:string:int
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                             name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1280084740
+                            transient_lastDdlTime 1284591513
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10004 
           Union
             Common Join Operator
               condition map:
@@ -262,8 +267,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -273,15 +279,16 @@
                             columns.types string:string:int
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                             name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1280084740
+                            transient_lastDdlTime 1284591513
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -293,6 +300,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -335,8 +343,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -346,22 +355,23 @@
                                 columns.types string:string:int
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1280084740
+                                transient_lastDdlTime 1284591513
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10002 [file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10002]
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10004 [file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10004]
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10002 [file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10004 [file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10004]
       Path -> Partition:
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -377,7 +387,7 @@
                 columns _col0,_col1
                 columns.types string,bigint
                 escape.delim \
-        file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10004 
           Partition
             base file name: -mr-10004
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -394,21 +404,21 @@
                 columns.types string,bigint
                 escape.delim \
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -418,20 +428,24 @@
                 columns.types string:string:int
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280084740
+                transient_lastDdlTime 1284591513
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10001
 
   Stage: Stage-3
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000/
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -447,9 +461,9 @@
                     type: int
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10003 
           Partition
             base file name: -ext-10003
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -460,12 +474,12 @@
               columns.types string:string:int
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, i32 val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280084740
+              transient_lastDdlTime 1284591513
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -476,12 +490,12 @@
                 columns.types string:string:int
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280084740
+                transient_lastDdlTime 1284591513
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -490,7 +504,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-40_758_5061664908968766431/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-33_276_1170775167092707494/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -501,23 +515,25 @@
                   columns.types string:string:int
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280084740
+                  transient_lastDdlTime 1284591513
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:subq1-subquery2:x1 
           TableScan
             alias: x1
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -556,9 +572,9 @@
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -569,12 +585,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -585,12 +601,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -614,7 +630,7 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/jssarma/hive_2010-07-25_12-05-40_758_5061664908968766431/-mr-10004
+              directory: file:/tmp/nzhang/hive_2010-09-15_15-58-33_276_1170775167092707494/-mr-10004
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -624,6 +640,7 @@
                     columns.types string,bigint
                     escape.delim \
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
 
@@ -657,11 +674,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-05-51_262_6569271114416709764/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-53_620_443243080288264497/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-05-51_262_6569271114416709764/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-53_620_443243080288264497/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)x.null, (src)x1.null, ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join29.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join29.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join29.q.out_0.17	(working copy)
@@ -20,12 +20,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,7 +88,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-32-59_660_3940646832112023058/10002 
+        file:/tmp/nzhang/hive_2010-09-15_15-56-48_781_6190155030135598307/-mr-10002 
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -138,11 +139,11 @@
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            file:/tmp/jssarma/hive_2010-07-21_11-32-59_660_3940646832112023058/10004 
+            file:/tmp/nzhang/hive_2010-09-15_15-56-48_781_6190155030135598307/-mr-10004 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            file:/tmp/jssarma/hive_2010-07-21_11-32-59_660_3940646832112023058/10004 
+            file:/tmp/nzhang/hive_2010-09-15_15-56-48_781_6190155030135598307/-mr-10004 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -191,14 +192,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-32-59_660_3940646832112023058/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-48_781_6190155030135598307/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -211,9 +212,12 @@
               name: dest_j1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-32-59_660_3940646832112023058/10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-48_781_6190155030135598307/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -238,7 +242,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         subq1:x 
@@ -317,11 +321,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-08_454_5846290866810953063/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-57-02_171_3968415237561428855/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-08_454_5846290866810953063/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-57-02_171_3968415237561428855/-mr-10000
 POSTHOOK: Lineage: dest_j1.cnt1 EXPRESSION [(src1)x.null, ]
 POSTHOOK: Lineage: dest_j1.cnt2 EXPRESSION [(src)y.null, ]
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/stats3.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats3.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats3.q.out	(revision 0)
@@ -0,0 +1,181 @@
+PREHOOK: query: drop table hive_test_src
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table hive_test_src
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table hive_test_dst
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table hive_test_dst
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table hive_test_src ( col1 string ) stored as textfile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table hive_test_src ( col1 string ) stored as textfile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@hive_test_src
+PREHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/test.dat' overwrite into table hive_test_src
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@hive_test_src
+PREHOOK: query: create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@hive_test_dst
+PREHOOK: query: insert overwrite table hive_test_dst partition ( pcol1='test_part', pCol2='test_Part') select col1 from hive_test_src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_src
+PREHOOK: Output: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: query: insert overwrite table hive_test_dst partition ( pcol1='test_part', pCol2='test_Part') select col1 from hive_test_src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_src
+POSTHOOK: Output: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_Part'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-48_741_4666382027997974463/-mr-10000
+POSTHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_Part'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-48_741_4666382027997974463/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+1	test_part	test_Part
+2	test_part	test_Part
+3	test_part	test_Part
+4	test_part	test_Part
+5	test_part	test_Part
+6	test_part	test_Part
+PREHOOK: query: select count(1) from hive_test_dst
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-49_252_7452474459995369471/-mr-10000
+POSTHOOK: query: select count(1) from hive_test_dst
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-49_252_7452474459995369471/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+6
+PREHOOK: query: insert overwrite table hive_test_dst partition ( pCol1='test_part', pcol2='test_Part') select col1 from hive_test_src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_src
+PREHOOK: Output: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: query: insert overwrite table hive_test_dst partition ( pCol1='test_part', pcol2='test_Part') select col1 from hive_test_src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_src
+POSTHOOK: Output: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+PREHOOK: type: QUERY
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-58_576_6980096604094616479/-mr-10000
+POSTHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+POSTHOOK: type: QUERY
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-58_576_6980096604094616479/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: select count(1) from hive_test_dst
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-58_626_4368103866978336718/-mr-10000
+POSTHOOK: query: select count(1) from hive_test_dst
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-10-58_626_4368103866978336718/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+6
+PREHOOK: query: select * from hive_test_dst where pcol1='test_part'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-02_419_7815117641043388974/-mr-10000
+POSTHOOK: query: select * from hive_test_dst where pcol1='test_part'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@hive_test_dst@pcol1=test_part/pcol2=test_Part
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-02_419_7815117641043388974/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+1	test_part	test_Part
+2	test_part	test_Part
+3	test_part	test_Part
+4	test_part	test_Part
+5	test_part	test_Part
+6	test_part	test_Part
+PREHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+PREHOOK: type: QUERY
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-02_947_2022421415266096272/-mr-10000
+POSTHOOK: query: select * from hive_test_dst where pcol1='test_part' and pcol2='test_part'
+POSTHOOK: type: QUERY
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-02_947_2022421415266096272/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: select * from hive_test_dst where pcol1='test_Part'
+PREHOOK: type: QUERY
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-03_001_4419154579807959228/-mr-10000
+POSTHOOK: query: select * from hive_test_dst where pcol1='test_Part'
+POSTHOOK: type: QUERY
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-03_001_4419154579807959228/-mr-10000
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: describe extended hive_test_dst
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended hive_test_dst
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+col_name            	data_type           	comment             
+	 	 
+col1                	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+pcol1               	string              	None                
+pcol2               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:10:42 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/hive_test_dst	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056658          
+	numRows             	6                   
+	totalSize           	171                 
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.SequenceFileInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: drop table hive_test_src
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@hive_test_src
+PREHOOK: Output: default@hive_test_src
+POSTHOOK: query: drop table hive_test_src
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@hive_test_src
+POSTHOOK: Output: default@hive_test_src
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+PREHOOK: query: drop table hive_test_dst
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@hive_test_dst
+PREHOOK: Output: default@hive_test_dst
+POSTHOOK: query: drop table hive_test_dst
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@hive_test_dst
+POSTHOOK: Output: default@hive_test_dst
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
+POSTHOOK: Lineage: hive_test_dst PARTITION(pcol1=test_part,pcol2=test_Part).col1 SIMPLE [(hive_test_src)hive_test_src.FieldSchema(name:col1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/merge3.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/merge3.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge3.q.out_0.17	(working copy)
@@ -66,6 +66,7 @@
         merge_src 
           TableScan
             alias: merge_src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -76,8 +77,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -86,12 +88,13 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src [merge_src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src [merge_src]
       Path -> Partition:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src 
           Partition
             base file name: merge_src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -102,12 +105,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src
               name merge_src
               serialization.ddl struct merge_src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284354277
+              transient_lastDdlTime 1284593000
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -118,12 +121,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src
                 name merge_src
                 serialization.ddl struct merge_src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354277
+                transient_lastDdlTime 1284593000
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src
             name: merge_src
@@ -135,15 +138,15 @@
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002
-          destination: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10001
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10001
 
   Stage: Stage-0
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10001
-          destination: pfile:///data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src2
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10001
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src2
 
   Stage: Stage-5
       Create Table Operator:
@@ -159,7 +162,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -173,9 +176,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002 [pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -196,7 +199,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-04-48_507_309142649354797380/-ext-10001
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-30_684_4127937283493175514/-ext-10001
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -206,6 +209,7 @@
                   columns.types string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -225,11 +229,11 @@
 PREHOOK: query: select * from merge_src2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-04_739_2492541155495503385/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-23-42_185_8009073830887608610/-mr-10000
 POSTHOOK: query: select * from merge_src2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-04_739_2492541155495503385/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-23-42_185_8009073830887608610/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -2263,6 +2267,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2271,6 +2276,7 @@
         merge_src_part 
           TableScan
             alias: merge_src_part
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2293,8 +2299,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-06_435_7440177713183186553/-ext-10000
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-42_982_981124947923300348/-ext-10000
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-42_982_981124947923300348/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2305,23 +2312,28 @@
                           columns.types string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                           name merge_src_part2
+                          numFiles 4
+                          numPartitions 2
+                          numRows 2000
                           partition_columns ds
                           serialization.ddl struct merge_src_part2 { string key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1284354306
+                          totalSize 23248
+                          transient_lastDdlTime 1284593022
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: merge_src_part2
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [merge_src_part]
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [merge_src_part]
       Path -> Partition:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2334,13 +2346,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284354277
+              totalSize 23248
+              transient_lastDdlTime 1284593010
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2351,17 +2367,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354277
+                totalSize 23248
+                transient_lastDdlTime 1284593010
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2374,13 +2394,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284354277
+              totalSize 23248
+              transient_lastDdlTime 1284593010
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2391,13 +2415,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354277
+                totalSize 23248
+                transient_lastDdlTime 1284593010
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
@@ -2408,7 +2436,7 @@
           partition:
             ds 
           replace: true
-          source: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-06_435_7440177713183186553/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-42_982_981124947923300348/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2419,18 +2447,26 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354306
+                totalSize 23248
+                transient_lastDdlTime 1284593022
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
-          tmp directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-06_435_7440177713183186553/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-42_982_981124947923300348/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-42_982_981124947923300348/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table merge_src_part2 partition(ds)
 select key, value, ds from merge_src_part
 where ds is not null
@@ -2471,12 +2507,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-08
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-09
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-18_730_5937319765835193571/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-23-53_664_4636083482223443296/-mr-10000
 POSTHOOK: query: select * from merge_src_part2 where ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-08
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-09
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-18_730_5937319765835193571/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-23-53_664_4636083482223443296/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -4538,6 +4574,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -4546,6 +4583,7 @@
         s:merge_src_part 
           TableScan
             alias: merge_src_part
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -4580,10 +4618,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [s:merge_src_part]
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [s:merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [s:merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [s:merge_src_part]
       Path -> Partition:
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4596,13 +4634,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284354277
+              totalSize 23248
+              transient_lastDdlTime 1284593010
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4613,17 +4655,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354277
+                totalSize 23248
+                transient_lastDdlTime 1284593010
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
-        pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4636,13 +4682,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284354277
+              totalSize 23248
+              transient_lastDdlTime 1284593010
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4653,13 +4703,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354277
+                totalSize 23248
+                transient_lastDdlTime 1284593010
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
@@ -4677,8 +4731,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-23_976_5247091504121728913/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-56_309_165900465239876610/-ext-10000
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-56_309_165900465239876610/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -4689,16 +4744,21 @@
                     columns.types string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                     name merge_src_part2
+                    numFiles 4
+                    numPartitions 2
+                    numRows 2000
                     partition_columns ds
                     serialization.ddl struct merge_src_part2 { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1284354323
+                    totalSize 23248
+                    transient_lastDdlTime 1284593036
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: merge_src_part2
               TotalFiles: 1
+              GatherStats: true
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -4707,7 +4767,7 @@
           partition:
             ds 
           replace: true
-          source: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-23_976_5247091504121728913/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-56_309_165900465239876610/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -4718,18 +4778,26 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284354323
+                totalSize 23248
+                transient_lastDdlTime 1284593036
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
-          tmp directory: pfile:/data/users/nzhang/reviews/2/apache-hive/build/ql/scratchdir/hive_2010-09-12_22-05-23_976_5247091504121728913/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-56_309_165900465239876610/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-56_309_165900465239876610/-ext-10000/
 
+
 PREHOOK: query: from (select * from merge_src_part where ds is not null distribute by ds) s
 insert overwrite table merge_src_part2 partition(ds)
 select key, value, ds
@@ -4778,12 +4846,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-08
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-09
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-37_206_1580798592522074568/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-07_279_6517902631936476088/-mr-10000
 POSTHOOK: query: select * from merge_src_part2 where ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-08
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-09
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-12_22-05-37_206_1580798592522074568/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-07_279_6517902631936476088/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/combine3.q.out
===================================================================
--- ql/src/test/results/clientpositive/combine3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/combine3.q.out	(working copy)
@@ -62,12 +62,15 @@
 Partition Value:    	[2010-08-03, 00]    	 
 Database:           	default             	 
 Table:              	combine_3_srcpart_seq_rc	 
-CreateTime:         	Tue Sep 14 08:10:04 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:25:54 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=00	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477004          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050355          
+	numRows             	500                 
+	totalSize           	15250               
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -103,12 +106,15 @@
 Partition Value:    	[2010-08-03, 001]   	 
 Database:           	default             	 
 Table:              	combine_3_srcpart_seq_rc	 
-CreateTime:         	Tue Sep 14 08:10:07 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:26:02 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine_3_srcpart_seq_rc/ds=2010-08-03/hr=001	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477007          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050362          
+	numRows             	500                 
+	totalSize           	2076                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe	 
@@ -125,12 +131,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@combine_3_srcpart_seq_rc@ds=2010-08-03/hr=00
 PREHOOK: Input: default@combine_3_srcpart_seq_rc@ds=2010-08-03/hr=001
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-10-07_563_6249036471530626320/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-26-03_040_1636466126220724204/-mr-10000
 POSTHOOK: query: select key, value, ds, hr from combine_3_srcpart_seq_rc where ds="2010-08-03" order by key, hr limit 30
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@combine_3_srcpart_seq_rc@ds=2010-08-03/hr=00
 POSTHOOK: Input: default@combine_3_srcpart_seq_rc@ds=2010-08-03/hr=001
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-10-07_563_6249036471530626320/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-26-03_040_1636466126220724204/-mr-10000
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=001).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=001).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=00).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -234,12 +240,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@combine_3_srcpart_seq_rc_bucket@ds=1
 PREHOOK: Input: default@combine_3_srcpart_seq_rc_bucket@ds=11
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-10-16_242_8416235865630529186/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-26-23_545_2451540426039382986/-mr-10000
 POSTHOOK: query: select key, ds from combine_3_srcpart_seq_rc_bucket tablesample (bucket 1 out of 2) s where ds = '1' or ds= '11' order by key, ds limit 30
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@combine_3_srcpart_seq_rc_bucket@ds=1
 POSTHOOK: Input: default@combine_3_srcpart_seq_rc_bucket@ds=11
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-10-16_242_8416235865630529186/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-26-23_545_2451540426039382986/-mr-10000
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=001).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=001).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: combine_3_srcpart_seq_rc PARTITION(ds=2010-08-03,hr=00).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join33.q.out
===================================================================
--- ql/src/test/results/clientpositive/join33.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join33.q.out	(working copy)
@@ -19,17 +19,19 @@
   (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_TABREF src1 x) (TOK_TABREF src y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key))) (TOK_TABREF srcpart z) (and (and (= (. (TOK_TABLE_OR_COL x) value) (. (TOK_TABLE_OR_COL z) value)) (= (. (TOK_TABLE_OR_COL z) ds) '2008-04-08')) (= (. (TOK_TABLE_OR_COL z) hr) 11)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest_j1)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST x))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL z) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL y) value)))))
 
 STAGE DEPENDENCIES:
-  Stage-2 is a root stage
-  Stage-1 depends on stages: Stage-2
+  Stage-3 is a root stage
+  Stage-1 depends on stages: Stage-3
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
-  Stage: Stage-2
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
         y 
           TableScan
             alias: y
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -45,7 +47,7 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002
+                directory: file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002
                 NumFilesPerFileSink: 1
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -55,6 +57,7 @@
                       columns.types string,string,string
                       escape.delim \
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -66,6 +69,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -81,7 +85,7 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002
+                    directory: file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -91,12 +95,13 @@
                           columns.types string,string,string
                           escape.delim \
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [y]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -107,12 +112,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -123,12 +128,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -136,7 +141,7 @@
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -163,6 +168,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -192,10 +198,10 @@
                           type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002 [file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002 [file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-49_528_2718740905898829882/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-39_182_1358797628502389193/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -211,7 +217,7 @@
                 columns _col0,_col1,_col5
                 columns.types string,string,string
                 escape.delim \
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -225,13 +231,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -242,13 +248,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -273,8 +279,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-49_528_2718740905898829882/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-39_182_1358797628502389193/-ext-10000
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-39_182_1358797628502389193/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -284,22 +291,23 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282863589
+                    transient_lastDdlTime 1284507639
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: true
               MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-49_528_2718740905898829882/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-39_182_1358797628502389193/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -309,17 +317,21 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863589
+                transient_lastDdlTime 1284507639
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-49_528_2718740905898829882/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-39_182_1358797628502389193/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-39_182_1358797628502389193/-ext-10000/
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1
 SELECT /*+ MAPJOIN(x) */ x.key, z.value, y.value
 FROM src1 x JOIN src y ON (x.key = y.key) 
@@ -344,11 +356,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-59-56_099_6500613120945442582/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-49_500_7236030535168569116/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-59-56_099_6500613120945442582/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-49_500_7236030535168569116/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_part2.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part2.q.out	(working copy)
@@ -23,14 +23,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -39,6 +41,7 @@
         srcpart 
           TableScan
             alias: srcpart
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -69,8 +72,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -80,15 +84,16 @@
                           columns.types int:string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282110794
+                          transient_lastDdlTime 1284507245
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
             Filter Operator
               isSamplingPred: false
@@ -120,8 +125,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 2
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10002/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -131,22 +137,23 @@
                           columns.types int:string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                           name dest2
                           serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282110794
+                          transient_lastDdlTime 1284507245
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest2
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -160,13 +167,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -177,17 +184,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -201,13 +208,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -218,32 +225,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -253,24 +260,28 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110794
+                transient_lastDdlTime 1284507245
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10001
 
   Stage: Stage-3
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10000/
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -281,21 +292,22 @@
                     columns.types int:string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110794
+                    transient_lastDdlTime 1284507245
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10004 
           Partition
             base file name: -ext-10004
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -306,12 +318,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110794
+              transient_lastDdlTime 1284507245
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -322,31 +334,31 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110794
+                transient_lastDdlTime 1284507245
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10002
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10002
 
   Stage: Stage-1
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10002
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10002
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -356,24 +368,28 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                 name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110794
+                transient_lastDdlTime 1284507245
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10003
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10003
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10002/
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10002
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10002
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -384,21 +400,22 @@
                     columns.types int:string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                     name dest2
                     serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110794
+                    transient_lastDdlTime 1284507245
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest2
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-14_757_6735987898850844788/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-05_844_956399580779269887/-ext-10005 
           Partition
             base file name: -ext-10005
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -409,12 +426,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
               name dest2
               serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110794
+              transient_lastDdlTime 1284507245
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -425,12 +442,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                 name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110794
+                transient_lastDdlTime 1284507245
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
             name: dest2
@@ -463,11 +480,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-27_392_8817642032424654753/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-20_758_7838543748238866974/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-27_392_8817642032424654753/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-20_758_7838543748238866974/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -563,11 +580,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-30_790_3814132887064625641/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-24_310_1078458348357753515/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-30_790_3814132887064625641/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-24_310_1078458348357753515/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input38.q.out
===================================================================
--- ql/src/test/results/clientpositive/input38.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input38.q.out	(working copy)
@@ -24,10 +24,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -68,14 +69,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-48_505_281957867109136522/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-30-15_451_6033211784807069966/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -88,9 +89,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-48_505_281957867109136522/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-30-15_451_6033211784807069966/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -124,11 +128,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-52_359_6901631517799281464/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-21_896_7350116915883019392/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-52_359_6901631517799281464/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-21_896_7350116915883019392/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238	3	7
Index: ql/src/test/results/clientpositive/udf_reflect.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/udf_reflect.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/udf_reflect.q.out_0.17	(revision 0)
@@ -0,0 +1,150 @@
+PREHOOK: query: DESCRIBE FUNCTION reflect
+PREHOOK: type: DESCFUNCTION
+POSTHOOK: query: DESCRIBE FUNCTION reflect
+POSTHOOK: type: DESCFUNCTION
+reflect(class,method[,arg1[,arg2..]]) calls method with reflection
+PREHOOK: query: DESCRIBE FUNCTION EXTENDED reflect
+PREHOOK: type: DESCFUNCTION
+POSTHOOK: query: DESCRIBE FUNCTION EXTENDED reflect
+POSTHOOK: type: DESCFUNCTION
+reflect(class,method[,arg1[,arg2..]]) calls method with reflection
+Use this UDF to call Java methods by matching the argument signature
+
+PREHOOK: query: EXPLAIN EXTENDED
+SELECT reflect("java.lang.String", "valueOf", 1),
+       reflect("java.lang.String", "isEmpty"),
+       reflect("java.lang.Math", "max", 2, 3),
+       reflect("java.lang.Math", "min", 2, 3),
+       reflect("java.lang.Math", "round", 2.5),
+       reflect("java.lang.Math", "exp", 1.0),
+       reflect("java.lang.Math", "floor", 1.9)
+FROM src LIMIT 1
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN EXTENDED
+SELECT reflect("java.lang.String", "valueOf", 1),
+       reflect("java.lang.String", "isEmpty"),
+       reflect("java.lang.Math", "max", 2, 3),
+       reflect("java.lang.Math", "min", 2, 3),
+       reflect("java.lang.Math", "round", 2.5),
+       reflect("java.lang.Math", "exp", 1.0),
+       reflect("java.lang.Math", "floor", 1.9)
+FROM src LIMIT 1
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.String" "valueOf" 1)) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.String" "isEmpty")) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.Math" "max" 2 3)) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.Math" "min" 2 3)) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.Math" "round" 2.5)) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.Math" "exp" 1.0)) (TOK_SELEXPR (TOK_FUNCTION reflect "java.lang.Math" "floor" 1.9))) (TOK_LIMIT 1)))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: reflect('java.lang.String','valueOf',1)
+                    type: string
+                    expr: reflect('java.lang.String','isEmpty')
+                    type: string
+                    expr: reflect('java.lang.Math','max',2,3)
+                    type: string
+                    expr: reflect('java.lang.Math','min',2,3)
+                    type: string
+                    expr: reflect('java.lang.Math','round',2.5)
+                    type: string
+                    expr: reflect('java.lang.Math','exp',1.0)
+                    type: string
+                    expr: reflect('java.lang.Math','floor',1.9)
+                    type: string
+              outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
+              Limit
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 0
+                  directory: file:/tmp/nzhang/hive_2010-09-15_17-26-36_357_6265400288274412023/-ext-10001
+                  NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-26-36_357_6265400288274412023/-ext-10001/
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      properties:
+                        columns _col0,_col1,_col2,_col3,_col4,_col5,_col6
+                        columns.types string:string:string:string:string:string:string
+                        serialization.format 1
+                  TotalFiles: 1
+                  GatherStats: false
+                  MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
+          Partition
+            base file name: src
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588338
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588338
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: src
+            name: src
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: 1
+
+
+PREHOOK: query: SELECT reflect("java.lang.String", "valueOf", 1),
+       reflect("java.lang.String", "isEmpty"),
+       reflect("java.lang.Math", "max", 2, 3),
+       reflect("java.lang.Math", "min", 2, 3),
+       reflect("java.lang.Math", "round", 2.5),
+       reflect("java.lang.Math", "exp", 1.0),
+       reflect("java.lang.Math", "floor", 1.9)
+FROM src LIMIT 1
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-36_401_5084178290925314023/-mr-10000
+POSTHOOK: query: SELECT reflect("java.lang.String", "valueOf", 1),
+       reflect("java.lang.String", "isEmpty"),
+       reflect("java.lang.Math", "max", 2, 3),
+       reflect("java.lang.Math", "min", 2, 3),
+       reflect("java.lang.Math", "round", 2.5),
+       reflect("java.lang.Math", "exp", 1.0),
+       reflect("java.lang.Math", "floor", 1.9)
+FROM src LIMIT 1
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-36_401_5084178290925314023/-mr-10000
+1	true	3	2	3	2.7182818284590455	1.0
Index: ql/src/test/results/clientpositive/mapreduce5.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce5.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -96,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 SELECT src.key as c1, CAST(src.key / 10 AS INT) as c2, CAST(src.key % 10 AS INT) as c3, src.value as c4
@@ -120,11 +124,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-22-57_596_1267379481706176084/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-35_392_2576146699023530567/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-22-57_596_1267379481706176084/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-35_392_2576146699023530567/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby3_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby3_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby3_noskew.q.out	(working copy)
@@ -35,6 +35,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -130,7 +131,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT
   sum(substr(src.value,5)),
@@ -171,11 +175,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-47_426_1452039016187035932/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-28_241_6736826911531146786/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-47_426_1452039016187035932/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-28_241_6736826911531146786/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby4_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby4_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby4_map.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -72,7 +73,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT count(1)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -85,10 +89,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-48_861_249696756658161235/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-47_965_3140661049905924445/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-48_861_249696756658161235/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-47_965_3140661049905924445/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.null, ]
 500
Index: ql/src/test/results/clientpositive/input35.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input35.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input35.q.out_0.17	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-46_935_1376343678250380802/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-46-55_593_945131753291175603/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-46_935_1376343678250380802/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-46-55_593_945131753291175603/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -144,11 +148,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-50_834_8263388023937488503/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-01_769_8251877580992520144/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-50_834_8263388023937488503/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-01_769_8251877580992520144/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/router_join_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/router_join_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/router_join_ppr.q.out	(working copy)
@@ -30,6 +30,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -47,6 +48,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -70,13 +72,13 @@
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +89,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -103,16 +105,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -126,13 +128,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -143,17 +145,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -167,13 +169,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -184,17 +186,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -208,13 +210,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284969304
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -225,17 +227,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284969304
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -249,13 +251,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284969304
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -266,13 +268,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284969304
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -307,8 +309,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-27-58_740_7654580536117070815/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-50_688_106540346366790271/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-50_688_106540346366790271/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -317,6 +320,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -337,7 +341,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-27-58_900_249160347924848000/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-50_947_802261129610359633/-mr-10000
 POSTHOOK: query: FROM 
   src a
  RIGHT OUTER JOIN 
@@ -351,7 +355,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-27-58_900_249160347924848000/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-50_947_802261129610359633/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -396,6 +400,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -423,6 +428,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -444,11 +450,11 @@
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -459,12 +465,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -475,16 +481,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -498,13 +504,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -515,17 +521,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -539,13 +545,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -556,13 +562,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -594,8 +600,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-28-03_530_5511408924303498423/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-57_385_2674297394224351134/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-57_385_2674297394224351134/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -604,6 +611,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -622,7 +630,7 @@
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-03_693_6030547893373702709/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-57_611_4105748427653678426/-mr-10000
 POSTHOOK: query: FROM 
   srcpart a
  RIGHT OUTER JOIN 
@@ -634,7 +642,7 @@
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-03_693_6030547893373702709/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-57_611_4105748427653678426/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -679,6 +687,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -696,6 +705,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -719,11 +729,11 @@
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -734,12 +744,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -750,16 +760,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -773,13 +783,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -790,17 +800,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -814,13 +824,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -831,13 +841,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -869,8 +879,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-28-08_327_7225187921961050710/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-46-02_838_923926967854761420/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-46-02_838_923926967854761420/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -879,6 +890,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -897,7 +909,7 @@
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-08_481_2074258607919607662/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-03_067_3649694556490015216/-mr-10000
 POSTHOOK: query: FROM 
   src a
  RIGHT OUTER JOIN 
@@ -909,7 +921,7 @@
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-08_481_2074258607919607662/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-03_067_3649694556490015216/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -954,6 +966,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -973,6 +986,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -994,13 +1008,13 @@
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1011,12 +1025,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1027,16 +1041,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1050,13 +1064,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1067,17 +1081,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1091,13 +1105,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1108,17 +1122,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1132,13 +1146,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1149,17 +1163,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1173,13 +1187,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1190,13 +1204,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1228,8 +1242,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-28-13_124_7639159324445029873/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-46-08_350_5034131631880076580/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-46-08_350_5034131631880076580/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1238,6 +1253,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -1258,7 +1274,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-13_297_1158788927411509004/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-08_600_74533087762223962/-mr-10000
 POSTHOOK: query: FROM 
   srcpart a
  RIGHT OUTER JOIN 
@@ -1272,7 +1288,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-28-13_297_1158788927411509004/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-08_600_74533087762223962/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
Index: ql/src/test/results/clientpositive/join7.q.out
===================================================================
--- ql/src/test/results/clientpositive/join7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join7.q.out	(working copy)
@@ -49,6 +49,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -225,7 +226,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -277,11 +281,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-17-07_518_5772529591765100751/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-58_936_1523026899455151688/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-17-07_518_5772529591765100751/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-58_936_1523026899455151688/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input7.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input7.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input7.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-13-30_523_1580378905234533343/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-36_438_8424471613012423906/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-13-30_523_1580378905234533343/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-36_438_8424471613012423906/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -112,11 +116,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-13-34_944_8840990517743539064/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-42_567_5263488535834090497/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-13-34_944_8840990517743539064/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-42_567_5263488535834090497/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 NULL	238
Index: ql/src/test/results/clientpositive/groupby7_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby7_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby7_map_skew.q.out	(working copy)
@@ -25,9 +25,11 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-5 depends on stages: Stage-4
-  Stage-1 depends on stages: Stage-5
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-6 depends on stages: Stage-5
+  Stage-1 depends on stages: Stage-6
+  Stage-7 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -106,7 +108,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-15_482_4437449743430298375/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-00_200_2425264639686556770/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -163,9 +165,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-15_482_4437449743430298375/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-00_200_2425264639686556770/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -195,10 +200,10 @@
                 input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-5
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-15_482_4437449743430298375/10006 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-00_200_2425264639686556770/-mr-10006 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -254,7 +259,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-7
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -276,11 +284,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-32_559_9038776760459612990/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-21_775_6919978381667314926/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-32_559_9038776760459612990/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-21_775_6919978381667314926/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -597,11 +605,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-32_618_4459940117692588721/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-22_250_5639917931903539486/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-32_618_4459940117692588721/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-22_250_5639917931903539486/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out_0.17	(working copy)
@@ -60,10 +60,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -72,6 +73,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -105,8 +107,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -116,15 +119,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1280426534
+                          transient_lastDdlTime 1284589134
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -136,6 +140,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -169,8 +174,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -180,21 +186,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1280426534
+                              transient_lastDdlTime 1284589134
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -206,12 +213,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280426530
+              transient_lastDdlTime 1284589132
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -223,31 +230,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426530
+                transient_lastDdlTime 1284589132
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002
-          destination: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -257,20 +264,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426534
+                transient_lastDdlTime 1284589134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -286,9 +297,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002 [pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -299,12 +310,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280426534
+              transient_lastDdlTime 1284589134
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -315,12 +326,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280426534
+                transient_lastDdlTime 1284589134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -329,7 +340,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-02-14_630_2201972795156035816/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-55_006_6965947439009092774/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -340,15 +351,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280426534
+                  transient_lastDdlTime 1284589134
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
Index: ql/src/test/results/clientpositive/input33.q.out
===================================================================
--- ql/src/test/results/clientpositive/input33.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input33.q.out	(working copy)
@@ -35,6 +35,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -111,7 +112,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   MAP src.key, src.key
@@ -145,11 +149,11 @@
 PREHOOK: query: SELECT * FROM dest1 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-33_943_1300959345773184923/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-43_192_703407910376694731/-mr-10000
 POSTHOOK: query: SELECT * FROM dest1 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-33_943_1300959345773184923/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-43_192_703407910376694731/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 1	105_105
Index: ql/src/test/results/clientpositive/groupby8_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby8_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby8_noskew.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -83,7 +85,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-40_930_2650271257621427493/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-36_874_4018574469529585954/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -140,9 +142,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-40_930_2650271257621427493/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-36_874_4018574469529585954/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -198,7 +203,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -220,11 +228,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-54_007_8899137116766039226/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-53_559_1612069899469209557/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-54_007_8899137116766039226/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-53_559_1612069899469209557/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -541,11 +549,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-54_077_6203538463439207284/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-53_978_3131301998051508911/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-54_077_6203538463439207284/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-53_978_3131301998051508911/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input38.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input38.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input38.q.out_0.17	(working copy)
@@ -24,10 +24,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -68,14 +69,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-28-12_445_5695557680495519967/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-47-16_382_605262879981204470/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -88,9 +89,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-28-12_445_5695557680495519967/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-47-16_382_605262879981204470/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -137,11 +141,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-28-15_024_5142138661614792399/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-23_612_8341635543604548420/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-28-15_024_5142138661614792399/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-23_612_8341635543604548420/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238	3	7
Index: ql/src/test/results/clientpositive/binary_output_format.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/binary_output_format.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/binary_output_format.q.out_0.17	(working copy)
@@ -54,10 +54,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -66,6 +67,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -88,8 +90,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
@@ -99,22 +102,23 @@
                         columns.types string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                        location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                         name dest1
                         serialization.ddl struct dest1 { string mydata}
                         serialization.format 1
                         serialization.last.column.takes.rest true
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1280083027
+                        transient_lastDdlTime 1284588394
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -125,12 +129,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -141,31 +145,31 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
@@ -175,21 +179,25 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string mydata}
                 serialization.format 1
                 serialization.last.column.takes.rest true
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280083027
+                transient_lastDdlTime 1284588394
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -201,9 +209,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -214,13 +222,13 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { string mydata}
               serialization.format 1
               serialization.last.column.takes.rest true
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280083027
+              transient_lastDdlTime 1284588394
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -231,13 +239,13 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string mydata}
                 serialization.format 1
                 serialization.last.column.takes.rest true
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280083027
+                transient_lastDdlTime 1284588394
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -246,7 +254,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-37-07_143_545511266047909547/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-06-34_157_3907187975100374432/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -257,16 +265,17 @@
                   columns.types string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { string mydata}
                   serialization.format 1
                   serialization.last.column.takes.rest true
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280083027
+                  transient_lastDdlTime 1284588394
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -303,12 +312,12 @@
 SELECT * FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-37-10_119_5660806743258606681/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-06-40_207_5146800440661796390/-mr-10000
 POSTHOOK: query: -- Test the result
 SELECT * FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-37-10_119_5660806743258606681/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-06-40_207_5146800440661796390/-mr-10000
 POSTHOOK: Lineage: dest1.mydata SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
 86	val_86
Index: ql/src/test/results/clientpositive/lineage1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/lineage1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/lineage1.q.out_0.17	(working copy)
@@ -34,12 +34,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -101,7 +102,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-27_14-01-08_880_5138753499787161938/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_16-09-58_498_3134069552714183715/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -125,7 +126,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_l1
-        file:/tmp/jsichi/hive_2010-08-27_14-01-08_880_5138753499787161938/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-15_16-09-58_498_3134069552714183715/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -150,14 +151,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_l1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_14-01-08_880_5138753499787161938/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-09-58_498_3134069552714183715/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -170,9 +171,12 @@
               name: dest_l1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_14-01-08_880_5138753499787161938/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-09-58_498_3134069552714183715/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -195,7 +199,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_l1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:j-subquery2:p2 
Index: ql/src/test/results/clientpositive/bucket1.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucket1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucket1.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -45,9 +47,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -58,12 +60,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -74,12 +76,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -95,8 +97,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-06_147_3859020501578469948/10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-02_223_4269812662234645087/-ext-10000
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-02_223_4269812662234645087/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -107,22 +110,23 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket1_1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket1_1
                     name bucket1_1
                     serialization.ddl struct bucket1_1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279735746
+                    transient_lastDdlTime 1284504602
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket1_1
               TotalFiles: 1
+              GatherStats: true
               MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-06_147_3859020501578469948/10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-02_223_4269812662234645087/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -133,17 +137,21 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket1_1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket1_1
                 name bucket1_1
                 serialization.ddl struct bucket1_1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735746
+                transient_lastDdlTime 1284504602
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket1_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-06_147_3859020501578469948/10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-02_223_4269812662234645087/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-02_223_4269812662234645087/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket1_1
 select * from src
 PREHOOK: type: QUERY
@@ -159,11 +167,11 @@
 PREHOOK: query: select * from bucket1_1 order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket1_1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-08_981_1141988062127111870/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-08_787_7479988112336189751/-mr-10000
 POSTHOOK: query: select * from bucket1_1 order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket1_1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-08_981_1141988062127111870/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-08_787_7479988112336189751/-mr-10000
 POSTHOOK: Lineage: bucket1_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket1_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/input42.q.out
===================================================================
--- ql/src/test/results/clientpositive/input42.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input42.q.out	(working copy)
@@ -18,6 +18,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -58,10 +59,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -75,13 +76,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -92,17 +93,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -116,13 +117,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -133,13 +134,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -148,8 +149,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-31_405_4243138583283237901/10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_16-31-46_306_6759001800020639664/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-31-46_306_6759001800020639664/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -158,6 +160,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -169,12 +172,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-31_807_794964127606193747/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-46_471_3626631269117516580/-mr-10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-31_807_794964127606193747/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-46_471_3626631269117516580/-mr-10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
@@ -1195,6 +1198,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1235,10 +1239,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1252,13 +1256,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1269,17 +1273,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1293,13 +1297,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1310,13 +1314,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1325,8 +1329,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-36_856_3062883207280337374/10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_16-31-51_225_5785806232660897565/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-31-51_225_5785806232660897565/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1335,6 +1340,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -1346,12 +1352,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-37_367_2107452731635635539/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-51_399_7044069682356924165/-mr-10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' and key < 200 order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-37_367_2107452731635635539/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-51_399_7044069682356924165/-mr-10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
@@ -1750,6 +1756,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1785,10 +1792,10 @@
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1802,13 +1809,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1819,17 +1826,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1843,13 +1850,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450628
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1860,13 +1867,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450628
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1875,8 +1882,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-42_857_9108360631480411334/10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_16-31-56_098_8749861367604146831/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-31-56_098_8749861367604146831/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1885,6 +1893,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -1896,12 +1905,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-43_229_6660183930342483682/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-56_272_1291625234860137249/-mr-10000
 POSTHOOK: query: select * from srcpart a where a.ds='2008-04-08' and rand(100) < 0.1 order by a.key, a.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-50-43_229_6660183930342483682/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-56_272_1291625234860137249/-mr-10000
 113	val_113	2008-04-08	11
 113	val_113	2008-04-08	12
 118	val_118	2008-04-08	11
Index: ql/src/test/results/clientpositive/groupby1_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1_map.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -94,7 +95,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -108,11 +112,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-15_817_9056145041729904750/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-44_564_8321546219919797444/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-15_817_9056145041729904750/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-44_564_8321546219919797444/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/load_dyn_part8.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part8.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:14:42 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:22:30 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part8	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part8	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473682          
+	transient_lastDdlTime	1285053750          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -66,7 +66,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -75,6 +77,7 @@
         srcpart 
           TableScan
             alias: srcpart
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -94,8 +97,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10000
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10000
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -106,16 +110,17 @@
                         columns.types string:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part8
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part8
                         name nzhang_part8
                         partition_columns ds/hr
                         serialization.ddl struct nzhang_part8 { string key, string value}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1284473682
+                        transient_lastDdlTime 1285053750
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: nzhang_part8
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
             Filter Operator
               isSamplingPred: false
@@ -134,8 +139,10 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 2
-                  directory: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10002
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10002
                   NumFilesPerFileSink: 1
+                  Static Partition Specification: ds=2008-12-31/
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10002/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -146,25 +153,26 @@
                         columns.types string:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part8
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part8
                         name nzhang_part8
                         partition_columns ds/hr
                         serialization.ddl struct nzhang_part8 { string key, string value}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1284473682
+                        transient_lastDdlTime 1285053750
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: nzhang_part8
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [srcpart]
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [srcpart]
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
       Path -> Partition:
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -178,13 +186,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284473678
+              transient_lastDdlTime 1285049300
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -195,17 +203,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473678
+                transient_lastDdlTime 1285049300
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -219,13 +227,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284473678
+              transient_lastDdlTime 1285049300
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -236,17 +244,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473678
+                transient_lastDdlTime 1285049300
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -260,13 +268,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284473678
+              transient_lastDdlTime 1285049300
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -277,17 +285,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473678
+                transient_lastDdlTime 1285049300
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -301,13 +309,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284473678
+              transient_lastDdlTime 1285049300
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -318,13 +326,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473678
+                transient_lastDdlTime 1285049300
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -336,7 +344,7 @@
             ds 
             hr 
           replace: true
-          source: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -347,17 +355,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part8
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part8
                 name nzhang_part8
                 partition_columns ds/hr
                 serialization.ddl struct nzhang_part8 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473682
+                transient_lastDdlTime 1285053750
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part8
-          tmp directory: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10001
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10000/
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -365,7 +377,7 @@
             ds 2008-12-31
             hr 
           replace: true
-          source: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10002
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10002
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -376,18 +388,22 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part8
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part8
                 name nzhang_part8
                 partition_columns ds/hr
                 serialization.ddl struct nzhang_part8 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284473682
+                transient_lastDdlTime 1285053750
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part8
-          tmp directory: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-14-42_202_4241678664810185333/-ext-10003
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10003
 
+  Stage: Stage-4
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-22-30_626_3614055251733750528/-ext-10002/
 
+
 PREHOOK: query: from srcpart
 insert overwrite table nzhang_part8 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
 insert overwrite table nzhang_part8 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
@@ -438,14 +454,14 @@
 PREHOOK: Input: default@nzhang_part8@ds=2008-04-08/hr=12
 PREHOOK: Input: default@nzhang_part8@ds=2008-12-31/hr=11
 PREHOOK: Input: default@nzhang_part8@ds=2008-12-31/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-14-47_080_4674138694548640892/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-42_722_1686154939137108359/-mr-10000
 POSTHOOK: query: select * from nzhang_part8 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part8@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part8@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@nzhang_part8@ds=2008-12-31/hr=11
 POSTHOOK: Input: default@nzhang_part8@ds=2008-12-31/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-14-47_080_4674138694548640892/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-42_722_1686154939137108359/-mr-10000
 POSTHOOK: Lineage: nzhang_part8 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part8 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part8 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample9.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample9.q.out	(working copy)
@@ -20,6 +20,7 @@
         s:a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -47,8 +48,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 0
-                      directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-27-34_917_490221468766104547/10001
+                      directory: file:/tmp/nzhang/hive_2010-09-14_17-25-46_949_6966788619794916428/-ext-10001
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-46_949_6966788619794916428/-ext-10001/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -57,12 +59,13 @@
                             columns.types int:string
                             serialization.format 1
                       TotalFiles: 1
+                      GatherStats: false
                       MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s:a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s:a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -74,12 +77,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452853
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -91,12 +94,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452853
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -110,12 +113,12 @@
 FROM (SELECT a.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) a) s
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-27-35_233_6622042744082355796/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-47_211_4954933153324523917/-mr-10000
 POSTHOOK: query: SELECT s.*
 FROM (SELECT a.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) a) s
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-27-35_233_6622042744082355796/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-47_211_4954933153324523917/-mr-10000
 474	val_475
 62	val_63
 468	val_469
Index: ql/src/test/results/clientpositive/quote1.q.out
===================================================================
--- ql/src/test/results/clientpositive/quote1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/quote1.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-42_799_6150966690031866092/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-37_754_2432298277175258919/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -81,9 +82,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-42_799_6150966690031866092/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-37_754_2432298277175258919/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -158,11 +162,11 @@
 PREHOOK: query: SELECT `int`.`location`, `int`.`type`, `int`.`table` FROM dest1 `int` WHERE `int`.`table` = '2008-04-08'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1@table=2008-04-08
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-46_708_8988651619968569066/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-19-44_273_5740940772723274466/-mr-10000
 POSTHOOK: query: SELECT `int`.`location`, `int`.`type`, `int`.`table` FROM dest1 `int` WHERE `int`.`table` = '2008-04-08'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1@table=2008-04-08
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-46_708_8988651619968569066/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-19-44_273_5740940772723274466/-mr-10000
 POSTHOOK: Lineage: dest1 PARTITION(table=2008-04-08).location EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(table=2008-04-08).type SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238	2008-04-08
Index: ql/src/test/results/clientpositive/notable_alias2.q.out
===================================================================
--- ql/src/test/results/clientpositive/notable_alias2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/notable_alias2.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -106,7 +107,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT '1234', src.key, count(1) WHERE key < 100 group by src.key
 PREHOOK: type: QUERY
@@ -123,11 +127,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-23-19_191_7981155394027438130/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-50_818_5788376518261161162/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-23-19_191_7981155394027438130/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-50_818_5788376518261161162/-mr-10000
 POSTHOOK: Lineage: dest1.dummy SIMPLE []
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.null, ]
Index: ql/src/test/results/clientpositive/join2.q.out
===================================================================
--- ql/src/test/results/clientpositive/join2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join2.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -142,7 +143,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j2
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key) JOIN src src3 ON (src1.key + src2.key = src3.key)
 INSERT OVERWRITE TABLE dest_j2 SELECT src1.key, src3.value
 PREHOOK: type: QUERY
@@ -158,11 +162,11 @@
 PREHOOK: query: SELECT dest_j2.* FROM dest_j2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j2
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-27-08_358_4973287120185382423/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-37-49_730_3869022116910097771/-mr-10000
 POSTHOOK: query: SELECT dest_j2.* FROM dest_j2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j2
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-27-08_358_4973287120185382423/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-37-49_730_3869022116910097771/-mr-10000
 POSTHOOK: Lineage: dest_j2.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j2.value SIMPLE [(src)src3.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out
===================================================================
--- ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/columnarserde_create_shortcut.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -76,7 +77,10 @@
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: columnarserde_create_shortcut
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src_thrift
 INSERT OVERWRITE TABLE columnarserde_create_shortcut SELECT src_thrift.lint, src_thrift.lstring, src_thrift.mstringstring, src_thrift.aint, src_thrift.astring DISTRIBUTE BY 1
 PREHOOK: type: QUERY
@@ -95,11 +99,11 @@
 PREHOOK: query: SELECT columnarserde_create_shortcut.* FROM columnarserde_create_shortcut DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@columnarserde_create_shortcut
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-43_710_70657971241231541/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-36_108_8409199986184348363/-mr-10000
 POSTHOOK: query: SELECT columnarserde_create_shortcut.* FROM columnarserde_create_shortcut DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@columnarserde_create_shortcut
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-43_710_70657971241231541/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-36_108_8409199986184348363/-mr-10000
 POSTHOOK: Lineage: columnarserde_create_shortcut.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -119,11 +123,11 @@
 PREHOOK: query: SELECT columnarserde_create_shortcut.a[0], columnarserde_create_shortcut.b[0], columnarserde_create_shortcut.c['key2'], columnarserde_create_shortcut.d, columnarserde_create_shortcut.e FROM columnarserde_create_shortcut DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@columnarserde_create_shortcut
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-46_074_7710287368838036826/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-39_691_5606542646725803617/-mr-10000
 POSTHOOK: query: SELECT columnarserde_create_shortcut.a[0], columnarserde_create_shortcut.b[0], columnarserde_create_shortcut.c['key2'], columnarserde_create_shortcut.d, columnarserde_create_shortcut.e FROM columnarserde_create_shortcut DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@columnarserde_create_shortcut
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-46_074_7710287368838036826/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-39_691_5606542646725803617/-mr-10000
 POSTHOOK: Lineage: columnarserde_create_shortcut.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -185,11 +189,11 @@
 PREHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 PREHOOK: type: QUERY
 PREHOOK: Input: default@columnshortcuttable
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-50_786_1069232517788942548/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-50_492_1201536824580029819/-mr-10000
 POSTHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@columnshortcuttable
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-50_786_1069232517788942548/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-50_492_1201536824580029819/-mr-10000
 POSTHOOK: Lineage: columnarserde_create_shortcut.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -225,11 +229,11 @@
 PREHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 PREHOOK: type: QUERY
 PREHOOK: Input: default@columnshortcuttable
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-50_931_2866711447002937633/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-51_053_7536543525937925493/-mr-10000
 POSTHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@columnshortcuttable
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-50_931_2866711447002937633/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-51_053_7536543525937925493/-mr-10000
 POSTHOOK: Lineage: columnarserde_create_shortcut.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -265,11 +269,11 @@
 PREHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 PREHOOK: type: QUERY
 PREHOOK: Input: default@columnshortcuttable
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-51_106_8133207443946864890/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-51_605_3764283101735008865/-mr-10000
 POSTHOOK: query: SELECT columnShortcutTable.* FROM columnShortcutTable
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@columnshortcuttable
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-51_106_8133207443946864890/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-24-51_605_3764283101735008865/-mr-10000
 POSTHOOK: Lineage: columnarserde_create_shortcut.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: columnarserde_create_shortcut.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/stats0.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/stats0.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/stats0.q.out_0.17	(revision 0)
@@ -0,0 +1,2964 @@
+PREHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_non_partitioned
+PREHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_non_partitioned)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-06_840_1835363986061290605/-ext-10000
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-06_840_1835363986061290605/-ext-10000/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      bucket_count -1
+                      columns key,value
+                      columns.types string:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                      name stats_non_partitioned
+                      serialization.ddl struct stats_non_partitioned { string key, string value}
+                      serialization.format 1
+                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      transient_lastDdlTime 1285085466
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_non_partitioned
+                TotalFiles: 1
+                GatherStats: true
+                MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
+          Partition
+            base file name: src
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285078277
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285078277
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: src
+            name: src
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-06_840_1835363986061290605/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285085466
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-06_840_1835363986061290605/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-06_840_1835363986061290605/-ext-10000/
+
+
+PREHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended stats_non_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended stats_non_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 09:11:06 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285085472          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: select * from stats_non_partitioned
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-12_649_6027155150115308122/-mr-10000
+POSTHOOK: query: select * from stats_non_partitioned
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-12_649_6027155150115308122/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238
+86	val_86
+311	val_311
+27	val_27
+165	val_165
+409	val_409
+255	val_255
+278	val_278
+98	val_98
+484	val_484
+265	val_265
+193	val_193
+401	val_401
+150	val_150
+273	val_273
+224	val_224
+369	val_369
+66	val_66
+128	val_128
+213	val_213
+146	val_146
+406	val_406
+429	val_429
+374	val_374
+152	val_152
+469	val_469
+145	val_145
+495	val_495
+37	val_37
+327	val_327
+281	val_281
+277	val_277
+209	val_209
+15	val_15
+82	val_82
+403	val_403
+166	val_166
+417	val_417
+430	val_430
+252	val_252
+292	val_292
+219	val_219
+287	val_287
+153	val_153
+193	val_193
+338	val_338
+446	val_446
+459	val_459
+394	val_394
+237	val_237
+482	val_482
+174	val_174
+413	val_413
+494	val_494
+207	val_207
+199	val_199
+466	val_466
+208	val_208
+174	val_174
+399	val_399
+396	val_396
+247	val_247
+417	val_417
+489	val_489
+162	val_162
+377	val_377
+397	val_397
+309	val_309
+365	val_365
+266	val_266
+439	val_439
+342	val_342
+367	val_367
+325	val_325
+167	val_167
+195	val_195
+475	val_475
+17	val_17
+113	val_113
+155	val_155
+203	val_203
+339	val_339
+0	val_0
+455	val_455
+128	val_128
+311	val_311
+316	val_316
+57	val_57
+302	val_302
+205	val_205
+149	val_149
+438	val_438
+345	val_345
+129	val_129
+170	val_170
+20	val_20
+489	val_489
+157	val_157
+378	val_378
+221	val_221
+92	val_92
+111	val_111
+47	val_47
+72	val_72
+4	val_4
+280	val_280
+35	val_35
+427	val_427
+277	val_277
+208	val_208
+356	val_356
+399	val_399
+169	val_169
+382	val_382
+498	val_498
+125	val_125
+386	val_386
+437	val_437
+469	val_469
+192	val_192
+286	val_286
+187	val_187
+176	val_176
+54	val_54
+459	val_459
+51	val_51
+138	val_138
+103	val_103
+239	val_239
+213	val_213
+216	val_216
+430	val_430
+278	val_278
+176	val_176
+289	val_289
+221	val_221
+65	val_65
+318	val_318
+332	val_332
+311	val_311
+275	val_275
+137	val_137
+241	val_241
+83	val_83
+333	val_333
+180	val_180
+284	val_284
+12	val_12
+230	val_230
+181	val_181
+67	val_67
+260	val_260
+404	val_404
+384	val_384
+489	val_489
+353	val_353
+373	val_373
+272	val_272
+138	val_138
+217	val_217
+84	val_84
+348	val_348
+466	val_466
+58	val_58
+8	val_8
+411	val_411
+230	val_230
+208	val_208
+348	val_348
+24	val_24
+463	val_463
+431	val_431
+179	val_179
+172	val_172
+42	val_42
+129	val_129
+158	val_158
+119	val_119
+496	val_496
+0	val_0
+322	val_322
+197	val_197
+468	val_468
+393	val_393
+454	val_454
+100	val_100
+298	val_298
+199	val_199
+191	val_191
+418	val_418
+96	val_96
+26	val_26
+165	val_165
+327	val_327
+230	val_230
+205	val_205
+120	val_120
+131	val_131
+51	val_51
+404	val_404
+43	val_43
+436	val_436
+156	val_156
+469	val_469
+468	val_468
+308	val_308
+95	val_95
+196	val_196
+288	val_288
+481	val_481
+457	val_457
+98	val_98
+282	val_282
+197	val_197
+187	val_187
+318	val_318
+318	val_318
+409	val_409
+470	val_470
+137	val_137
+369	val_369
+316	val_316
+169	val_169
+413	val_413
+85	val_85
+77	val_77
+0	val_0
+490	val_490
+87	val_87
+364	val_364
+179	val_179
+118	val_118
+134	val_134
+395	val_395
+282	val_282
+138	val_138
+238	val_238
+419	val_419
+15	val_15
+118	val_118
+72	val_72
+90	val_90
+307	val_307
+19	val_19
+435	val_435
+10	val_10
+277	val_277
+273	val_273
+306	val_306
+224	val_224
+309	val_309
+389	val_389
+327	val_327
+242	val_242
+369	val_369
+392	val_392
+272	val_272
+331	val_331
+401	val_401
+242	val_242
+452	val_452
+177	val_177
+226	val_226
+5	val_5
+497	val_497
+402	val_402
+396	val_396
+317	val_317
+395	val_395
+58	val_58
+35	val_35
+336	val_336
+95	val_95
+11	val_11
+168	val_168
+34	val_34
+229	val_229
+233	val_233
+143	val_143
+472	val_472
+322	val_322
+498	val_498
+160	val_160
+195	val_195
+42	val_42
+321	val_321
+430	val_430
+119	val_119
+489	val_489
+458	val_458
+78	val_78
+76	val_76
+41	val_41
+223	val_223
+492	val_492
+149	val_149
+449	val_449
+218	val_218
+228	val_228
+138	val_138
+453	val_453
+30	val_30
+209	val_209
+64	val_64
+468	val_468
+76	val_76
+74	val_74
+342	val_342
+69	val_69
+230	val_230
+33	val_33
+368	val_368
+103	val_103
+296	val_296
+113	val_113
+216	val_216
+367	val_367
+344	val_344
+167	val_167
+274	val_274
+219	val_219
+239	val_239
+485	val_485
+116	val_116
+223	val_223
+256	val_256
+263	val_263
+70	val_70
+487	val_487
+480	val_480
+401	val_401
+288	val_288
+191	val_191
+5	val_5
+244	val_244
+438	val_438
+128	val_128
+467	val_467
+432	val_432
+202	val_202
+316	val_316
+229	val_229
+469	val_469
+463	val_463
+280	val_280
+2	val_2
+35	val_35
+283	val_283
+331	val_331
+235	val_235
+80	val_80
+44	val_44
+193	val_193
+321	val_321
+335	val_335
+104	val_104
+466	val_466
+366	val_366
+175	val_175
+403	val_403
+483	val_483
+53	val_53
+105	val_105
+257	val_257
+406	val_406
+409	val_409
+190	val_190
+406	val_406
+401	val_401
+114	val_114
+258	val_258
+90	val_90
+203	val_203
+262	val_262
+348	val_348
+424	val_424
+12	val_12
+396	val_396
+201	val_201
+217	val_217
+164	val_164
+431	val_431
+454	val_454
+478	val_478
+298	val_298
+125	val_125
+431	val_431
+164	val_164
+424	val_424
+187	val_187
+382	val_382
+5	val_5
+70	val_70
+397	val_397
+480	val_480
+291	val_291
+24	val_24
+351	val_351
+255	val_255
+104	val_104
+70	val_70
+163	val_163
+438	val_438
+119	val_119
+414	val_414
+200	val_200
+491	val_491
+237	val_237
+439	val_439
+360	val_360
+248	val_248
+479	val_479
+305	val_305
+417	val_417
+199	val_199
+444	val_444
+120	val_120
+429	val_429
+169	val_169
+443	val_443
+323	val_323
+325	val_325
+277	val_277
+230	val_230
+478	val_478
+178	val_178
+468	val_468
+310	val_310
+317	val_317
+333	val_333
+493	val_493
+460	val_460
+207	val_207
+249	val_249
+265	val_265
+480	val_480
+83	val_83
+136	val_136
+353	val_353
+172	val_172
+214	val_214
+462	val_462
+233	val_233
+406	val_406
+133	val_133
+175	val_175
+189	val_189
+454	val_454
+375	val_375
+401	val_401
+421	val_421
+407	val_407
+384	val_384
+256	val_256
+26	val_26
+134	val_134
+67	val_67
+384	val_384
+379	val_379
+18	val_18
+462	val_462
+492	val_492
+100	val_100
+298	val_298
+9	val_9
+341	val_341
+498	val_498
+146	val_146
+458	val_458
+362	val_362
+186	val_186
+285	val_285
+348	val_348
+167	val_167
+18	val_18
+273	val_273
+183	val_183
+281	val_281
+344	val_344
+97	val_97
+469	val_469
+315	val_315
+84	val_84
+28	val_28
+37	val_37
+448	val_448
+152	val_152
+348	val_348
+307	val_307
+194	val_194
+414	val_414
+477	val_477
+222	val_222
+126	val_126
+90	val_90
+169	val_169
+403	val_403
+400	val_400
+200	val_200
+97	val_97
+PREHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_partitioned (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_partitioned
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_partitioned
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+
+PREHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions stats_partitioned
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions stats_partitioned
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ds=1
+PREHOOK: query: select * from stats_partitioned where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_partitioned@ds=1
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-19_976_7851207089927129714/-mr-10000
+POSTHOOK: query: select * from stats_partitioned where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_partitioned@ds=1
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-19_976_7851207089927129714/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	1
+86	val_86	1
+311	val_311	1
+27	val_27	1
+165	val_165	1
+409	val_409	1
+255	val_255	1
+278	val_278	1
+98	val_98	1
+484	val_484	1
+265	val_265	1
+193	val_193	1
+401	val_401	1
+150	val_150	1
+273	val_273	1
+224	val_224	1
+369	val_369	1
+66	val_66	1
+128	val_128	1
+213	val_213	1
+146	val_146	1
+406	val_406	1
+429	val_429	1
+374	val_374	1
+152	val_152	1
+469	val_469	1
+145	val_145	1
+495	val_495	1
+37	val_37	1
+327	val_327	1
+281	val_281	1
+277	val_277	1
+209	val_209	1
+15	val_15	1
+82	val_82	1
+403	val_403	1
+166	val_166	1
+417	val_417	1
+430	val_430	1
+252	val_252	1
+292	val_292	1
+219	val_219	1
+287	val_287	1
+153	val_153	1
+193	val_193	1
+338	val_338	1
+446	val_446	1
+459	val_459	1
+394	val_394	1
+237	val_237	1
+482	val_482	1
+174	val_174	1
+413	val_413	1
+494	val_494	1
+207	val_207	1
+199	val_199	1
+466	val_466	1
+208	val_208	1
+174	val_174	1
+399	val_399	1
+396	val_396	1
+247	val_247	1
+417	val_417	1
+489	val_489	1
+162	val_162	1
+377	val_377	1
+397	val_397	1
+309	val_309	1
+365	val_365	1
+266	val_266	1
+439	val_439	1
+342	val_342	1
+367	val_367	1
+325	val_325	1
+167	val_167	1
+195	val_195	1
+475	val_475	1
+17	val_17	1
+113	val_113	1
+155	val_155	1
+203	val_203	1
+339	val_339	1
+0	val_0	1
+455	val_455	1
+128	val_128	1
+311	val_311	1
+316	val_316	1
+57	val_57	1
+302	val_302	1
+205	val_205	1
+149	val_149	1
+438	val_438	1
+345	val_345	1
+129	val_129	1
+170	val_170	1
+20	val_20	1
+489	val_489	1
+157	val_157	1
+378	val_378	1
+221	val_221	1
+92	val_92	1
+111	val_111	1
+47	val_47	1
+72	val_72	1
+4	val_4	1
+280	val_280	1
+35	val_35	1
+427	val_427	1
+277	val_277	1
+208	val_208	1
+356	val_356	1
+399	val_399	1
+169	val_169	1
+382	val_382	1
+498	val_498	1
+125	val_125	1
+386	val_386	1
+437	val_437	1
+469	val_469	1
+192	val_192	1
+286	val_286	1
+187	val_187	1
+176	val_176	1
+54	val_54	1
+459	val_459	1
+51	val_51	1
+138	val_138	1
+103	val_103	1
+239	val_239	1
+213	val_213	1
+216	val_216	1
+430	val_430	1
+278	val_278	1
+176	val_176	1
+289	val_289	1
+221	val_221	1
+65	val_65	1
+318	val_318	1
+332	val_332	1
+311	val_311	1
+275	val_275	1
+137	val_137	1
+241	val_241	1
+83	val_83	1
+333	val_333	1
+180	val_180	1
+284	val_284	1
+12	val_12	1
+230	val_230	1
+181	val_181	1
+67	val_67	1
+260	val_260	1
+404	val_404	1
+384	val_384	1
+489	val_489	1
+353	val_353	1
+373	val_373	1
+272	val_272	1
+138	val_138	1
+217	val_217	1
+84	val_84	1
+348	val_348	1
+466	val_466	1
+58	val_58	1
+8	val_8	1
+411	val_411	1
+230	val_230	1
+208	val_208	1
+348	val_348	1
+24	val_24	1
+463	val_463	1
+431	val_431	1
+179	val_179	1
+172	val_172	1
+42	val_42	1
+129	val_129	1
+158	val_158	1
+119	val_119	1
+496	val_496	1
+0	val_0	1
+322	val_322	1
+197	val_197	1
+468	val_468	1
+393	val_393	1
+454	val_454	1
+100	val_100	1
+298	val_298	1
+199	val_199	1
+191	val_191	1
+418	val_418	1
+96	val_96	1
+26	val_26	1
+165	val_165	1
+327	val_327	1
+230	val_230	1
+205	val_205	1
+120	val_120	1
+131	val_131	1
+51	val_51	1
+404	val_404	1
+43	val_43	1
+436	val_436	1
+156	val_156	1
+469	val_469	1
+468	val_468	1
+308	val_308	1
+95	val_95	1
+196	val_196	1
+288	val_288	1
+481	val_481	1
+457	val_457	1
+98	val_98	1
+282	val_282	1
+197	val_197	1
+187	val_187	1
+318	val_318	1
+318	val_318	1
+409	val_409	1
+470	val_470	1
+137	val_137	1
+369	val_369	1
+316	val_316	1
+169	val_169	1
+413	val_413	1
+85	val_85	1
+77	val_77	1
+0	val_0	1
+490	val_490	1
+87	val_87	1
+364	val_364	1
+179	val_179	1
+118	val_118	1
+134	val_134	1
+395	val_395	1
+282	val_282	1
+138	val_138	1
+238	val_238	1
+419	val_419	1
+15	val_15	1
+118	val_118	1
+72	val_72	1
+90	val_90	1
+307	val_307	1
+19	val_19	1
+435	val_435	1
+10	val_10	1
+277	val_277	1
+273	val_273	1
+306	val_306	1
+224	val_224	1
+309	val_309	1
+389	val_389	1
+327	val_327	1
+242	val_242	1
+369	val_369	1
+392	val_392	1
+272	val_272	1
+331	val_331	1
+401	val_401	1
+242	val_242	1
+452	val_452	1
+177	val_177	1
+226	val_226	1
+5	val_5	1
+497	val_497	1
+402	val_402	1
+396	val_396	1
+317	val_317	1
+395	val_395	1
+58	val_58	1
+35	val_35	1
+336	val_336	1
+95	val_95	1
+11	val_11	1
+168	val_168	1
+34	val_34	1
+229	val_229	1
+233	val_233	1
+143	val_143	1
+472	val_472	1
+322	val_322	1
+498	val_498	1
+160	val_160	1
+195	val_195	1
+42	val_42	1
+321	val_321	1
+430	val_430	1
+119	val_119	1
+489	val_489	1
+458	val_458	1
+78	val_78	1
+76	val_76	1
+41	val_41	1
+223	val_223	1
+492	val_492	1
+149	val_149	1
+449	val_449	1
+218	val_218	1
+228	val_228	1
+138	val_138	1
+453	val_453	1
+30	val_30	1
+209	val_209	1
+64	val_64	1
+468	val_468	1
+76	val_76	1
+74	val_74	1
+342	val_342	1
+69	val_69	1
+230	val_230	1
+33	val_33	1
+368	val_368	1
+103	val_103	1
+296	val_296	1
+113	val_113	1
+216	val_216	1
+367	val_367	1
+344	val_344	1
+167	val_167	1
+274	val_274	1
+219	val_219	1
+239	val_239	1
+485	val_485	1
+116	val_116	1
+223	val_223	1
+256	val_256	1
+263	val_263	1
+70	val_70	1
+487	val_487	1
+480	val_480	1
+401	val_401	1
+288	val_288	1
+191	val_191	1
+5	val_5	1
+244	val_244	1
+438	val_438	1
+128	val_128	1
+467	val_467	1
+432	val_432	1
+202	val_202	1
+316	val_316	1
+229	val_229	1
+469	val_469	1
+463	val_463	1
+280	val_280	1
+2	val_2	1
+35	val_35	1
+283	val_283	1
+331	val_331	1
+235	val_235	1
+80	val_80	1
+44	val_44	1
+193	val_193	1
+321	val_321	1
+335	val_335	1
+104	val_104	1
+466	val_466	1
+366	val_366	1
+175	val_175	1
+403	val_403	1
+483	val_483	1
+53	val_53	1
+105	val_105	1
+257	val_257	1
+406	val_406	1
+409	val_409	1
+190	val_190	1
+406	val_406	1
+401	val_401	1
+114	val_114	1
+258	val_258	1
+90	val_90	1
+203	val_203	1
+262	val_262	1
+348	val_348	1
+424	val_424	1
+12	val_12	1
+396	val_396	1
+201	val_201	1
+217	val_217	1
+164	val_164	1
+431	val_431	1
+454	val_454	1
+478	val_478	1
+298	val_298	1
+125	val_125	1
+431	val_431	1
+164	val_164	1
+424	val_424	1
+187	val_187	1
+382	val_382	1
+5	val_5	1
+70	val_70	1
+397	val_397	1
+480	val_480	1
+291	val_291	1
+24	val_24	1
+351	val_351	1
+255	val_255	1
+104	val_104	1
+70	val_70	1
+163	val_163	1
+438	val_438	1
+119	val_119	1
+414	val_414	1
+200	val_200	1
+491	val_491	1
+237	val_237	1
+439	val_439	1
+360	val_360	1
+248	val_248	1
+479	val_479	1
+305	val_305	1
+417	val_417	1
+199	val_199	1
+444	val_444	1
+120	val_120	1
+429	val_429	1
+169	val_169	1
+443	val_443	1
+323	val_323	1
+325	val_325	1
+277	val_277	1
+230	val_230	1
+478	val_478	1
+178	val_178	1
+468	val_468	1
+310	val_310	1
+317	val_317	1
+333	val_333	1
+493	val_493	1
+460	val_460	1
+207	val_207	1
+249	val_249	1
+265	val_265	1
+480	val_480	1
+83	val_83	1
+136	val_136	1
+353	val_353	1
+172	val_172	1
+214	val_214	1
+462	val_462	1
+233	val_233	1
+406	val_406	1
+133	val_133	1
+175	val_175	1
+189	val_189	1
+454	val_454	1
+375	val_375	1
+401	val_401	1
+421	val_421	1
+407	val_407	1
+384	val_384	1
+256	val_256	1
+26	val_26	1
+134	val_134	1
+67	val_67	1
+384	val_384	1
+379	val_379	1
+18	val_18	1
+462	val_462	1
+492	val_492	1
+100	val_100	1
+298	val_298	1
+9	val_9	1
+341	val_341	1
+498	val_498	1
+146	val_146	1
+458	val_458	1
+362	val_362	1
+186	val_186	1
+285	val_285	1
+348	val_348	1
+167	val_167	1
+18	val_18	1
+273	val_273	1
+183	val_183	1
+281	val_281	1
+344	val_344	1
+97	val_97	1
+469	val_469	1
+315	val_315	1
+84	val_84	1
+28	val_28	1
+37	val_37	1
+448	val_448	1
+152	val_152	1
+348	val_348	1
+307	val_307	1
+194	val_194	1
+414	val_414	1
+477	val_477	1
+222	val_222	1
+126	val_126	1
+90	val_90	1
+169	val_169	1
+403	val_403	1
+400	val_400	1
+200	val_200	1
+97	val_97	1
+PREHOOK: query: describe extended stats_partitioned partition (ds='1')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned partition (ds='1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[1]                 	 
+Database:           	default             	 
+Table:              	stats_partitioned   	 
+CreateTime:         	Tue Sep 21 09:11:19 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned/ds=1	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085479          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended stats_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 09:11:13 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285085479          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: drop table stats_non_partitioned
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: drop table stats_non_partitioned
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: drop table stats_partitioned
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@stats_partitioned
+PREHOOK: Output: default@stats_partitioned
+POSTHOOK: query: drop table stats_partitioned
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@stats_partitioned
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_non_partitioned)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10000/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      bucket_count -1
+                      columns key,value
+                      columns.types string:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                      name stats_non_partitioned
+                      serialization.ddl struct stats_non_partitioned { string key, string value}
+                      serialization.format 1
+                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      transient_lastDdlTime 1285085481
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_non_partitioned
+                TotalFiles: 1
+                GatherStats: true
+                MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
+          Partition
+            base file name: src
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285078277
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285078277
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: src
+            name: src
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285085481
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002 
+            Reduce Output Operator
+              sort order: 
+              Map-reduce partition columns:
+                    expr: rand()
+                    type: double
+              tag: -1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+              name stats_non_partitioned
+              serialization.ddl struct stats_non_partitioned { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285085481
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285085481
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+            name: stats_non_partitioned
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-21_472_4089733993661017246/-ext-10000
+            NumFilesPerFileSink: 1
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                properties:
+                  bucket_count -1
+                  columns key,value
+                  columns.types string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                  name stats_non_partitioned
+                  serialization.ddl struct stats_non_partitioned { string key, string value}
+                  serialization.format 1
+                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  transient_lastDdlTime 1285085481
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: stats_non_partitioned
+            TotalFiles: 1
+            GatherStats: false
+            MultiFileSpray: false
+
+
+PREHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended stats_non_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended stats_non_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 09:11:21 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285085487          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: select * from stats_non_partitioned
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-27_337_7652349977128217172/-mr-10000
+POSTHOOK: query: select * from stats_non_partitioned
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-27_337_7652349977128217172/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238
+86	val_86
+311	val_311
+27	val_27
+165	val_165
+409	val_409
+255	val_255
+278	val_278
+98	val_98
+484	val_484
+265	val_265
+193	val_193
+401	val_401
+150	val_150
+273	val_273
+224	val_224
+369	val_369
+66	val_66
+128	val_128
+213	val_213
+146	val_146
+406	val_406
+429	val_429
+374	val_374
+152	val_152
+469	val_469
+145	val_145
+495	val_495
+37	val_37
+327	val_327
+281	val_281
+277	val_277
+209	val_209
+15	val_15
+82	val_82
+403	val_403
+166	val_166
+417	val_417
+430	val_430
+252	val_252
+292	val_292
+219	val_219
+287	val_287
+153	val_153
+193	val_193
+338	val_338
+446	val_446
+459	val_459
+394	val_394
+237	val_237
+482	val_482
+174	val_174
+413	val_413
+494	val_494
+207	val_207
+199	val_199
+466	val_466
+208	val_208
+174	val_174
+399	val_399
+396	val_396
+247	val_247
+417	val_417
+489	val_489
+162	val_162
+377	val_377
+397	val_397
+309	val_309
+365	val_365
+266	val_266
+439	val_439
+342	val_342
+367	val_367
+325	val_325
+167	val_167
+195	val_195
+475	val_475
+17	val_17
+113	val_113
+155	val_155
+203	val_203
+339	val_339
+0	val_0
+455	val_455
+128	val_128
+311	val_311
+316	val_316
+57	val_57
+302	val_302
+205	val_205
+149	val_149
+438	val_438
+345	val_345
+129	val_129
+170	val_170
+20	val_20
+489	val_489
+157	val_157
+378	val_378
+221	val_221
+92	val_92
+111	val_111
+47	val_47
+72	val_72
+4	val_4
+280	val_280
+35	val_35
+427	val_427
+277	val_277
+208	val_208
+356	val_356
+399	val_399
+169	val_169
+382	val_382
+498	val_498
+125	val_125
+386	val_386
+437	val_437
+469	val_469
+192	val_192
+286	val_286
+187	val_187
+176	val_176
+54	val_54
+459	val_459
+51	val_51
+138	val_138
+103	val_103
+239	val_239
+213	val_213
+216	val_216
+430	val_430
+278	val_278
+176	val_176
+289	val_289
+221	val_221
+65	val_65
+318	val_318
+332	val_332
+311	val_311
+275	val_275
+137	val_137
+241	val_241
+83	val_83
+333	val_333
+180	val_180
+284	val_284
+12	val_12
+230	val_230
+181	val_181
+67	val_67
+260	val_260
+404	val_404
+384	val_384
+489	val_489
+353	val_353
+373	val_373
+272	val_272
+138	val_138
+217	val_217
+84	val_84
+348	val_348
+466	val_466
+58	val_58
+8	val_8
+411	val_411
+230	val_230
+208	val_208
+348	val_348
+24	val_24
+463	val_463
+431	val_431
+179	val_179
+172	val_172
+42	val_42
+129	val_129
+158	val_158
+119	val_119
+496	val_496
+0	val_0
+322	val_322
+197	val_197
+468	val_468
+393	val_393
+454	val_454
+100	val_100
+298	val_298
+199	val_199
+191	val_191
+418	val_418
+96	val_96
+26	val_26
+165	val_165
+327	val_327
+230	val_230
+205	val_205
+120	val_120
+131	val_131
+51	val_51
+404	val_404
+43	val_43
+436	val_436
+156	val_156
+469	val_469
+468	val_468
+308	val_308
+95	val_95
+196	val_196
+288	val_288
+481	val_481
+457	val_457
+98	val_98
+282	val_282
+197	val_197
+187	val_187
+318	val_318
+318	val_318
+409	val_409
+470	val_470
+137	val_137
+369	val_369
+316	val_316
+169	val_169
+413	val_413
+85	val_85
+77	val_77
+0	val_0
+490	val_490
+87	val_87
+364	val_364
+179	val_179
+118	val_118
+134	val_134
+395	val_395
+282	val_282
+138	val_138
+238	val_238
+419	val_419
+15	val_15
+118	val_118
+72	val_72
+90	val_90
+307	val_307
+19	val_19
+435	val_435
+10	val_10
+277	val_277
+273	val_273
+306	val_306
+224	val_224
+309	val_309
+389	val_389
+327	val_327
+242	val_242
+369	val_369
+392	val_392
+272	val_272
+331	val_331
+401	val_401
+242	val_242
+452	val_452
+177	val_177
+226	val_226
+5	val_5
+497	val_497
+402	val_402
+396	val_396
+317	val_317
+395	val_395
+58	val_58
+35	val_35
+336	val_336
+95	val_95
+11	val_11
+168	val_168
+34	val_34
+229	val_229
+233	val_233
+143	val_143
+472	val_472
+322	val_322
+498	val_498
+160	val_160
+195	val_195
+42	val_42
+321	val_321
+430	val_430
+119	val_119
+489	val_489
+458	val_458
+78	val_78
+76	val_76
+41	val_41
+223	val_223
+492	val_492
+149	val_149
+449	val_449
+218	val_218
+228	val_228
+138	val_138
+453	val_453
+30	val_30
+209	val_209
+64	val_64
+468	val_468
+76	val_76
+74	val_74
+342	val_342
+69	val_69
+230	val_230
+33	val_33
+368	val_368
+103	val_103
+296	val_296
+113	val_113
+216	val_216
+367	val_367
+344	val_344
+167	val_167
+274	val_274
+219	val_219
+239	val_239
+485	val_485
+116	val_116
+223	val_223
+256	val_256
+263	val_263
+70	val_70
+487	val_487
+480	val_480
+401	val_401
+288	val_288
+191	val_191
+5	val_5
+244	val_244
+438	val_438
+128	val_128
+467	val_467
+432	val_432
+202	val_202
+316	val_316
+229	val_229
+469	val_469
+463	val_463
+280	val_280
+2	val_2
+35	val_35
+283	val_283
+331	val_331
+235	val_235
+80	val_80
+44	val_44
+193	val_193
+321	val_321
+335	val_335
+104	val_104
+466	val_466
+366	val_366
+175	val_175
+403	val_403
+483	val_483
+53	val_53
+105	val_105
+257	val_257
+406	val_406
+409	val_409
+190	val_190
+406	val_406
+401	val_401
+114	val_114
+258	val_258
+90	val_90
+203	val_203
+262	val_262
+348	val_348
+424	val_424
+12	val_12
+396	val_396
+201	val_201
+217	val_217
+164	val_164
+431	val_431
+454	val_454
+478	val_478
+298	val_298
+125	val_125
+431	val_431
+164	val_164
+424	val_424
+187	val_187
+382	val_382
+5	val_5
+70	val_70
+397	val_397
+480	val_480
+291	val_291
+24	val_24
+351	val_351
+255	val_255
+104	val_104
+70	val_70
+163	val_163
+438	val_438
+119	val_119
+414	val_414
+200	val_200
+491	val_491
+237	val_237
+439	val_439
+360	val_360
+248	val_248
+479	val_479
+305	val_305
+417	val_417
+199	val_199
+444	val_444
+120	val_120
+429	val_429
+169	val_169
+443	val_443
+323	val_323
+325	val_325
+277	val_277
+230	val_230
+478	val_478
+178	val_178
+468	val_468
+310	val_310
+317	val_317
+333	val_333
+493	val_493
+460	val_460
+207	val_207
+249	val_249
+265	val_265
+480	val_480
+83	val_83
+136	val_136
+353	val_353
+172	val_172
+214	val_214
+462	val_462
+233	val_233
+406	val_406
+133	val_133
+175	val_175
+189	val_189
+454	val_454
+375	val_375
+401	val_401
+421	val_421
+407	val_407
+384	val_384
+256	val_256
+26	val_26
+134	val_134
+67	val_67
+384	val_384
+379	val_379
+18	val_18
+462	val_462
+492	val_492
+100	val_100
+298	val_298
+9	val_9
+341	val_341
+498	val_498
+146	val_146
+458	val_458
+362	val_362
+186	val_186
+285	val_285
+348	val_348
+167	val_167
+18	val_18
+273	val_273
+183	val_183
+281	val_281
+344	val_344
+97	val_97
+469	val_469
+315	val_315
+84	val_84
+28	val_28
+37	val_37
+448	val_448
+152	val_152
+348	val_348
+307	val_307
+194	val_194
+414	val_414
+477	val_477
+222	val_222
+126	val_126
+90	val_90
+169	val_169
+403	val_403
+400	val_400
+200	val_200
+97	val_97
+PREHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_partitioned (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_partitioned
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-28_161_8333975378740305237/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_partitioned
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_09-11-28_161_8333975378740305237/-ext-10002 
+            Reduce Output Operator
+              sort order: 
+              Map-reduce partition columns:
+                    expr: rand()
+                    type: double
+              tag: -1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: stats_partitioned
+
+
+PREHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions stats_partitioned
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions stats_partitioned
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ds=1
+PREHOOK: query: select * from stats_partitioned where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_partitioned@ds=1
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-34_423_3084919034796072200/-mr-10000
+POSTHOOK: query: select * from stats_partitioned where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_partitioned@ds=1
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-11-34_423_3084919034796072200/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	1
+86	val_86	1
+311	val_311	1
+27	val_27	1
+165	val_165	1
+409	val_409	1
+255	val_255	1
+278	val_278	1
+98	val_98	1
+484	val_484	1
+265	val_265	1
+193	val_193	1
+401	val_401	1
+150	val_150	1
+273	val_273	1
+224	val_224	1
+369	val_369	1
+66	val_66	1
+128	val_128	1
+213	val_213	1
+146	val_146	1
+406	val_406	1
+429	val_429	1
+374	val_374	1
+152	val_152	1
+469	val_469	1
+145	val_145	1
+495	val_495	1
+37	val_37	1
+327	val_327	1
+281	val_281	1
+277	val_277	1
+209	val_209	1
+15	val_15	1
+82	val_82	1
+403	val_403	1
+166	val_166	1
+417	val_417	1
+430	val_430	1
+252	val_252	1
+292	val_292	1
+219	val_219	1
+287	val_287	1
+153	val_153	1
+193	val_193	1
+338	val_338	1
+446	val_446	1
+459	val_459	1
+394	val_394	1
+237	val_237	1
+482	val_482	1
+174	val_174	1
+413	val_413	1
+494	val_494	1
+207	val_207	1
+199	val_199	1
+466	val_466	1
+208	val_208	1
+174	val_174	1
+399	val_399	1
+396	val_396	1
+247	val_247	1
+417	val_417	1
+489	val_489	1
+162	val_162	1
+377	val_377	1
+397	val_397	1
+309	val_309	1
+365	val_365	1
+266	val_266	1
+439	val_439	1
+342	val_342	1
+367	val_367	1
+325	val_325	1
+167	val_167	1
+195	val_195	1
+475	val_475	1
+17	val_17	1
+113	val_113	1
+155	val_155	1
+203	val_203	1
+339	val_339	1
+0	val_0	1
+455	val_455	1
+128	val_128	1
+311	val_311	1
+316	val_316	1
+57	val_57	1
+302	val_302	1
+205	val_205	1
+149	val_149	1
+438	val_438	1
+345	val_345	1
+129	val_129	1
+170	val_170	1
+20	val_20	1
+489	val_489	1
+157	val_157	1
+378	val_378	1
+221	val_221	1
+92	val_92	1
+111	val_111	1
+47	val_47	1
+72	val_72	1
+4	val_4	1
+280	val_280	1
+35	val_35	1
+427	val_427	1
+277	val_277	1
+208	val_208	1
+356	val_356	1
+399	val_399	1
+169	val_169	1
+382	val_382	1
+498	val_498	1
+125	val_125	1
+386	val_386	1
+437	val_437	1
+469	val_469	1
+192	val_192	1
+286	val_286	1
+187	val_187	1
+176	val_176	1
+54	val_54	1
+459	val_459	1
+51	val_51	1
+138	val_138	1
+103	val_103	1
+239	val_239	1
+213	val_213	1
+216	val_216	1
+430	val_430	1
+278	val_278	1
+176	val_176	1
+289	val_289	1
+221	val_221	1
+65	val_65	1
+318	val_318	1
+332	val_332	1
+311	val_311	1
+275	val_275	1
+137	val_137	1
+241	val_241	1
+83	val_83	1
+333	val_333	1
+180	val_180	1
+284	val_284	1
+12	val_12	1
+230	val_230	1
+181	val_181	1
+67	val_67	1
+260	val_260	1
+404	val_404	1
+384	val_384	1
+489	val_489	1
+353	val_353	1
+373	val_373	1
+272	val_272	1
+138	val_138	1
+217	val_217	1
+84	val_84	1
+348	val_348	1
+466	val_466	1
+58	val_58	1
+8	val_8	1
+411	val_411	1
+230	val_230	1
+208	val_208	1
+348	val_348	1
+24	val_24	1
+463	val_463	1
+431	val_431	1
+179	val_179	1
+172	val_172	1
+42	val_42	1
+129	val_129	1
+158	val_158	1
+119	val_119	1
+496	val_496	1
+0	val_0	1
+322	val_322	1
+197	val_197	1
+468	val_468	1
+393	val_393	1
+454	val_454	1
+100	val_100	1
+298	val_298	1
+199	val_199	1
+191	val_191	1
+418	val_418	1
+96	val_96	1
+26	val_26	1
+165	val_165	1
+327	val_327	1
+230	val_230	1
+205	val_205	1
+120	val_120	1
+131	val_131	1
+51	val_51	1
+404	val_404	1
+43	val_43	1
+436	val_436	1
+156	val_156	1
+469	val_469	1
+468	val_468	1
+308	val_308	1
+95	val_95	1
+196	val_196	1
+288	val_288	1
+481	val_481	1
+457	val_457	1
+98	val_98	1
+282	val_282	1
+197	val_197	1
+187	val_187	1
+318	val_318	1
+318	val_318	1
+409	val_409	1
+470	val_470	1
+137	val_137	1
+369	val_369	1
+316	val_316	1
+169	val_169	1
+413	val_413	1
+85	val_85	1
+77	val_77	1
+0	val_0	1
+490	val_490	1
+87	val_87	1
+364	val_364	1
+179	val_179	1
+118	val_118	1
+134	val_134	1
+395	val_395	1
+282	val_282	1
+138	val_138	1
+238	val_238	1
+419	val_419	1
+15	val_15	1
+118	val_118	1
+72	val_72	1
+90	val_90	1
+307	val_307	1
+19	val_19	1
+435	val_435	1
+10	val_10	1
+277	val_277	1
+273	val_273	1
+306	val_306	1
+224	val_224	1
+309	val_309	1
+389	val_389	1
+327	val_327	1
+242	val_242	1
+369	val_369	1
+392	val_392	1
+272	val_272	1
+331	val_331	1
+401	val_401	1
+242	val_242	1
+452	val_452	1
+177	val_177	1
+226	val_226	1
+5	val_5	1
+497	val_497	1
+402	val_402	1
+396	val_396	1
+317	val_317	1
+395	val_395	1
+58	val_58	1
+35	val_35	1
+336	val_336	1
+95	val_95	1
+11	val_11	1
+168	val_168	1
+34	val_34	1
+229	val_229	1
+233	val_233	1
+143	val_143	1
+472	val_472	1
+322	val_322	1
+498	val_498	1
+160	val_160	1
+195	val_195	1
+42	val_42	1
+321	val_321	1
+430	val_430	1
+119	val_119	1
+489	val_489	1
+458	val_458	1
+78	val_78	1
+76	val_76	1
+41	val_41	1
+223	val_223	1
+492	val_492	1
+149	val_149	1
+449	val_449	1
+218	val_218	1
+228	val_228	1
+138	val_138	1
+453	val_453	1
+30	val_30	1
+209	val_209	1
+64	val_64	1
+468	val_468	1
+76	val_76	1
+74	val_74	1
+342	val_342	1
+69	val_69	1
+230	val_230	1
+33	val_33	1
+368	val_368	1
+103	val_103	1
+296	val_296	1
+113	val_113	1
+216	val_216	1
+367	val_367	1
+344	val_344	1
+167	val_167	1
+274	val_274	1
+219	val_219	1
+239	val_239	1
+485	val_485	1
+116	val_116	1
+223	val_223	1
+256	val_256	1
+263	val_263	1
+70	val_70	1
+487	val_487	1
+480	val_480	1
+401	val_401	1
+288	val_288	1
+191	val_191	1
+5	val_5	1
+244	val_244	1
+438	val_438	1
+128	val_128	1
+467	val_467	1
+432	val_432	1
+202	val_202	1
+316	val_316	1
+229	val_229	1
+469	val_469	1
+463	val_463	1
+280	val_280	1
+2	val_2	1
+35	val_35	1
+283	val_283	1
+331	val_331	1
+235	val_235	1
+80	val_80	1
+44	val_44	1
+193	val_193	1
+321	val_321	1
+335	val_335	1
+104	val_104	1
+466	val_466	1
+366	val_366	1
+175	val_175	1
+403	val_403	1
+483	val_483	1
+53	val_53	1
+105	val_105	1
+257	val_257	1
+406	val_406	1
+409	val_409	1
+190	val_190	1
+406	val_406	1
+401	val_401	1
+114	val_114	1
+258	val_258	1
+90	val_90	1
+203	val_203	1
+262	val_262	1
+348	val_348	1
+424	val_424	1
+12	val_12	1
+396	val_396	1
+201	val_201	1
+217	val_217	1
+164	val_164	1
+431	val_431	1
+454	val_454	1
+478	val_478	1
+298	val_298	1
+125	val_125	1
+431	val_431	1
+164	val_164	1
+424	val_424	1
+187	val_187	1
+382	val_382	1
+5	val_5	1
+70	val_70	1
+397	val_397	1
+480	val_480	1
+291	val_291	1
+24	val_24	1
+351	val_351	1
+255	val_255	1
+104	val_104	1
+70	val_70	1
+163	val_163	1
+438	val_438	1
+119	val_119	1
+414	val_414	1
+200	val_200	1
+491	val_491	1
+237	val_237	1
+439	val_439	1
+360	val_360	1
+248	val_248	1
+479	val_479	1
+305	val_305	1
+417	val_417	1
+199	val_199	1
+444	val_444	1
+120	val_120	1
+429	val_429	1
+169	val_169	1
+443	val_443	1
+323	val_323	1
+325	val_325	1
+277	val_277	1
+230	val_230	1
+478	val_478	1
+178	val_178	1
+468	val_468	1
+310	val_310	1
+317	val_317	1
+333	val_333	1
+493	val_493	1
+460	val_460	1
+207	val_207	1
+249	val_249	1
+265	val_265	1
+480	val_480	1
+83	val_83	1
+136	val_136	1
+353	val_353	1
+172	val_172	1
+214	val_214	1
+462	val_462	1
+233	val_233	1
+406	val_406	1
+133	val_133	1
+175	val_175	1
+189	val_189	1
+454	val_454	1
+375	val_375	1
+401	val_401	1
+421	val_421	1
+407	val_407	1
+384	val_384	1
+256	val_256	1
+26	val_26	1
+134	val_134	1
+67	val_67	1
+384	val_384	1
+379	val_379	1
+18	val_18	1
+462	val_462	1
+492	val_492	1
+100	val_100	1
+298	val_298	1
+9	val_9	1
+341	val_341	1
+498	val_498	1
+146	val_146	1
+458	val_458	1
+362	val_362	1
+186	val_186	1
+285	val_285	1
+348	val_348	1
+167	val_167	1
+18	val_18	1
+273	val_273	1
+183	val_183	1
+281	val_281	1
+344	val_344	1
+97	val_97	1
+469	val_469	1
+315	val_315	1
+84	val_84	1
+28	val_28	1
+37	val_37	1
+448	val_448	1
+152	val_152	1
+348	val_348	1
+307	val_307	1
+194	val_194	1
+414	val_414	1
+477	val_477	1
+222	val_222	1
+126	val_126	1
+90	val_90	1
+169	val_169	1
+403	val_403	1
+400	val_400	1
+200	val_200	1
+97	val_97	1
+PREHOOK: query: describe extended stats_partitioned partition (ds='1')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned partition (ds='1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[1]                 	 
+Database:           	default             	 
+Table:              	stats_partitioned   	 
+CreateTime:         	Tue Sep 21 09:11:33 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned/ds=1	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085494          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended stats_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 09:11:28 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285085494          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/load_dyn_part14.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part14.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part14.q.out	(working copy)
@@ -20,15 +20,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:07:49 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:14:43 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part14	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part14	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284473269          
+	transient_lastDdlTime	1285053283          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -66,13 +66,14 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6, Stage-7
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7, Stage-8
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
   Stage-7 is a root stage
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -110,7 +111,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/thiruvel/hive_2010-09-14_07-07-49_374_8339491885099239815/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_00-14-44_080_840579455257940486/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -127,7 +128,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part14
-        file:/tmp/thiruvel/hive_2010-09-14_07-07-49_374_8339491885099239815/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-21_00-14-44_080_840579455257940486/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -144,7 +145,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part14
-        file:/tmp/thiruvel/hive_2010-09-14_07-07-49_374_8339491885099239815/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-21_00-14-44_080_840579455257940486/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -162,14 +163,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part14
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-07-49_374_8339491885099239815/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-14-44_080_840579455257940486/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -184,9 +185,12 @@
               name: nzhang_part14
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-07-49_374_8339491885099239815/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-14-44_080_840579455257940486/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -196,7 +200,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: nzhang_part14
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:t-subquery2:src 
@@ -228,7 +232,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery1:t-subquery1-subquery1:src 
@@ -298,13 +302,13 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part14@value= 
 PREHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-08-01_813_1027212280998565647/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-06_708_7234512413045849371/-mr-10000
 POSTHOOK: query: select * from nzhang_part14 where value <> 'a'
 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part14@value= 
 POSTHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-08-01_813_1027212280998565647/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-15-06_708_7234512413045849371/-mr-10000
 POSTHOOK: Lineage: nzhang_part14 PARTITION(value= ).key EXPRESSION []
 POSTHOOK: Lineage: nzhang_part14 PARTITION(value=__HIVE_DEFAULT_PARTITION__).key EXPRESSION []
 k1	__HIVE_DEFAULT_PARTITION__
Index: ql/src/test/results/clientpositive/input7.q.out
===================================================================
--- ql/src/test/results/clientpositive/input7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input7.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-52_995_892471705852031186/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-29_771_7561754217677684022/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-52_995_892471705852031186/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-29_771_7561754217677684022/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -99,11 +103,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-56_769_2532023178691399118/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-35_981_8611592653456547806/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-56_769_2532023178691399118/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-35_981_8611592653456547806/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 NULL	238
Index: ql/src/test/results/clientpositive/stats9.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats9.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats9.q.out	(revision 0)
@@ -0,0 +1,89 @@
+PREHOOK: query: create table analyze_srcbucket like srcbucket
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table analyze_srcbucket like srcbucket
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@analyze_srcbucket
+PREHOOK: query: insert overwrite table analyze_srcbucket select * from srcbucket
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket
+PREHOOK: Output: default@analyze_srcbucket
+POSTHOOK: query: insert overwrite table analyze_srcbucket select * from srcbucket
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket
+POSTHOOK: Output: default@analyze_srcbucket
+POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: explain analyze table analyze_srcbucket compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcbucket compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcbucket))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcbucket 
+          TableScan
+            alias: analyze_srcbucket
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcbucket compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcbucket
+PREHOOK: Output: default@analyze_srcbucket
+POSTHOOK: query: analyze table analyze_srcbucket compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcbucket
+POSTHOOK: Output: default@analyze_srcbucket
+POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: describe extended analyze_srcbucket
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcbucket
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcbucket.key SIMPLE [(srcbucket)srcbucket.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: analyze_srcbucket.value SIMPLE [(srcbucket)srcbucket.FieldSchema(name:value, type:string, comment:null), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:13:15 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcbucket	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	EXTERNAL            	FALSE               
+	numFiles            	1                   
+	transient_lastDdlTime	1285056808          
+	numRows             	1000                
+	totalSize           	11603               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	2                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/groupby5_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby5_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby5_map_skew.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -76,7 +77,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT sum(src.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -89,10 +93,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-03_646_1852490662220439836/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-33_383_4385266538141302612/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-03_646_1852490662220439836/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-33_383_4385266538141302612/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 130091
Index: ql/src/test/results/clientpositive/groupby_map_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby_map_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby_map_ppr.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -31,6 +32,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -78,10 +80,10 @@
                             type: double
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src]
       Path -> Partition:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -95,13 +97,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474268
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -112,17 +114,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474268
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -136,13 +138,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474268
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -153,13 +155,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474268
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -195,8 +197,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-28_485_4662596155020790948/-ext-10000
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-20-51_289_8761202816854339436/-ext-10000
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-20-51_289_8761202816854339436/-ext-10000/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -206,22 +209,23 @@
                       columns.types string:int:string
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                       name dest1
                       serialization.ddl struct dest1 { string key, i32 c1, string c2}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      transient_lastDdlTime 1281475348
+                      transient_lastDdlTime 1284506451
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
                 TotalFiles: 1
+                GatherStats: true
                 MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-28_485_4662596155020790948/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-20-51_289_8761202816854339436/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -231,17 +235,21 @@
                 columns.types string:int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string key, i32 c1, string c2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281475348
+                transient_lastDdlTime 1284506451
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-22-28_485_4662596155020790948/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-20-51_289_8761202816854339436/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-20-51_289_8761202816854339436/-ext-10000/
 
+
 PREHOOK: query: FROM srcpart src
 INSERT OVERWRITE TABLE dest1 
 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) 
@@ -266,11 +274,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-22-31_394_4995738244078952055/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-58_916_635029702540877766/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-22-31_394_4995738244078952055/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-20-58_916_635029702540877766/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(srcpart)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(srcpart)src.FieldSchema(name:key, type:string, comment:default), (srcpart)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby5.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby5.q.out	(working copy)
@@ -22,6 +22,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -69,7 +70,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-49_005_2289581797986974703/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-16-05_756_422253425726749240/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -125,7 +126,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest1 
 SELECT src.key, sum(substr(src.value,5)) 
 FROM src
@@ -145,11 +149,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-57_505_8639659723124514323/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-16_036_6260975271152662340/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-57_505_8639659723124514323/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-16_036_6260975271152662340/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/sample6.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample6.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample6.q.out_0.17	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -30,6 +31,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -50,8 +52,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -61,21 +64,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1280085952
+                          transient_lastDdlTime 1284594138
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +91,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -104,31 +108,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -138,20 +142,24 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085952
+                transient_lastDdlTime 1284594138
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -165,9 +173,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -178,12 +186,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280085952
+              transient_lastDdlTime 1284594138
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -194,12 +202,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085952
+                transient_lastDdlTime 1284594138
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -208,7 +216,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-52_186_3157231182322687780/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-18_686_1706660273087818718/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -219,15 +227,16 @@
                   columns.types int:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280085952
+                  transient_lastDdlTime 1284594138
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -246,11 +255,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-55_336_7091683219503570256/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-27_048_367400550230713544/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-55_336_7091683219503570256/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-27_048_367400550230713544/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 468	val_469
@@ -524,6 +533,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -556,9 +566,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
           Partition
             base file name: srcbucket1.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -570,12 +580,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -587,12 +597,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -601,8 +611,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-25-55_582_7165177909491540451/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-27_819_5123800734939130757/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-27_819_5123800734939130757/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -611,6 +622,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -622,12 +634,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-55_759_3472807197075770512/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-28_033_583743085629276146/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 4 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-55_759_3472807197075770512/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-28_033_583743085629276146/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 3	val_4
@@ -891,6 +903,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -923,9 +936,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -937,12 +950,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -954,12 +967,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -968,8 +981,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-25-58_300_3758020696633496326/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-31_778_2915860691893204239/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-31_778_2915860691893204239/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -978,6 +992,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -989,12 +1004,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-58_471_2646849319725353487/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-31_961_3599719768909989913/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-58_471_2646849319725353487/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-31_961_3599719768909989913/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -1512,6 +1527,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1544,9 +1560,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1558,12 +1574,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1575,12 +1591,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -1589,8 +1605,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-26-01_013_4050660666796364037/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-36_095_6189313761818547184/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-36_095_6189313761818547184/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1599,6 +1616,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -1610,12 +1628,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-01_082_9188204284444338479/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-36_141_7053656018349385163/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-01_082_9188204284444338479/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-36_141_7053656018349385163/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -1976,6 +1994,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2008,9 +2027,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2022,12 +2041,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2039,12 +2058,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -2053,8 +2072,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-26-03_632_3598741012744525781/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-41_002_772694042204264910/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-41_002_772694042204264910/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2063,6 +2083,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2074,12 +2095,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-03_702_9132739866161120811/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-41_049_5489113407957139786/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 2 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-03_702_9132739866161120811/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-41_049_5489113407957139786/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 1	val_2
@@ -2426,6 +2447,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2458,10 +2480,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
           Partition
             base file name: srcbucket20.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2473,12 +2495,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588337
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2490,16 +2512,16 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588337
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
           Partition
             base file name: srcbucket22.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2511,12 +2533,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588337
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2528,12 +2550,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588337
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2542,8 +2564,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-26-06_209_3310903741276971307/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-45_903_7296358938053708434/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-45_903_7296358938053708434/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2552,6 +2575,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2563,12 +2587,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-06_679_1761695012341202622/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-46_498_8057360059853751924/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-06_679_1761695012341202622/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-46_498_8057360059853751924/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -2715,6 +2739,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2747,9 +2772,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
           Partition
             base file name: srcbucket21.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2761,12 +2786,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588337
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2778,12 +2803,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588337
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2792,8 +2817,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-26-09_584_1080977776732961084/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-51_862_7173463593635604688/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-51_862_7173463593635604688/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2802,6 +2828,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2813,12 +2840,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-09_846_163307172377614317/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-52_178_8970377829137698540/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 2 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-09_846_163307172377614317/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-52_178_8970377829137698540/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 5	val_5
@@ -2888,6 +2915,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2924,8 +2952,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/jssarma/hive_2010-07-25_12-26-12_552_493736512331555139/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-15_16-42-56_107_5485989908363705924/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_16-42-56_107_5485989908363705924/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2934,6 +2963,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2945,11 +2975,11 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@empty_bucket
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-12_620_3471282047092165712/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-56_152_2312559691257337711/-mr-10000
 POSTHOOK: query: SELECT s.* FROM empty_bucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@empty_bucket
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-12_620_3471282047092165712/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-56_152_2312559691257337711/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/input11_limit.q.out
===================================================================
--- ql/src/test/results/clientpositive/input11_limit.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input11_limit.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -78,7 +79,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT src.key, src.value WHERE src.key < 100 LIMIT 10
 PREHOOK: type: QUERY
@@ -94,11 +98,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-34_850_8424044685558477447/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-34_699_86964705078646062/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-34_850_8424044685558477447/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-34_699_86964705078646062/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 86	val_86
Index: ql/src/test/results/clientpositive/rand_partitionpruner2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/rand_partitionpruner2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/rand_partitionpruner2.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -51,8 +53,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -62,22 +65,23 @@
                         columns.types string:string:string:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                         name tmptable
                         serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1282158160
+                        transient_lastDdlTime 1284593881
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -91,13 +95,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -108,17 +112,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -132,13 +136,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -149,32 +153,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -184,20 +188,24 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                 name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282158160
+                transient_lastDdlTime 1284593881
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -215,9 +223,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -228,12 +236,12 @@
               columns.types string:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
               name tmptable
               serialization.ddl struct tmptable { string key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282158160
+              transient_lastDdlTime 1284593881
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -244,12 +252,12 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                 name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282158160
+                transient_lastDdlTime 1284593881
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
             name: tmptable
@@ -258,7 +266,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-40_956_6636539774212878518/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-38-01_046_5567640707812928309/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -269,15 +277,16 @@
                   columns.types string:string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                   name tmptable
                   serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282158160
+                  transient_lastDdlTime 1284593881
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -300,11 +309,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-50_605_6158244388640362996/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-38-12_942_8552996669145051375/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-50_605_6158244388640362996/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-38-12_942_8552996669145051375/-mr-10000
 POSTHOOK: Lineage: tmptable.ds SIMPLE [(srcpart)a.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.hr SIMPLE [(srcpart)a.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.key SIMPLE [(srcpart)a.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/load_dyn_part3.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part3.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:10:45 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:15:58 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part3	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part3	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473445          
+	transient_lastDdlTime	1285053358          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -62,6 +62,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -111,7 +112,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part3
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part3 partition (ds, hr) select key, value, ds, hr from srcpart where ds is not null and hr is not null
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
@@ -142,14 +146,14 @@
 PREHOOK: Input: default@nzhang_part3@ds=2008-04-08/hr=12
 PREHOOK: Input: default@nzhang_part3@ds=2008-04-09/hr=11
 PREHOOK: Input: default@nzhang_part3@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-10-49_463_1113383905913320380/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-09_172_3608646943207982864/-mr-10000
 POSTHOOK: query: select * from nzhang_part3 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part3@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part3@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@nzhang_part3@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@nzhang_part3@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-10-49_463_1113383905913320380/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-09_172_3608646943207982864/-mr-10000
 POSTHOOK: Lineage: nzhang_part3 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part3 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part3 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample4.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample4.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -52,8 +54,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -63,21 +66,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282111175
+                          transient_lastDdlTime 1284510262
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -89,12 +93,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110630
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -106,31 +110,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110630
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -140,24 +144,28 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111175
+                transient_lastDdlTime 1284510262
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -168,21 +176,22 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111175
+                    transient_lastDdlTime 1284510262
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-35_266_1447395205504426904/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-22_823_2600373229446067176/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -193,12 +202,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111175
+              transient_lastDdlTime 1284510262
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -209,12 +218,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111175
+                transient_lastDdlTime 1284510262
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -235,11 +244,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-39_291_5283897258050057893/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-28_726_8098117195006938273/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-39_291_5283897258050057893/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-28_726_8098117195006938273/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 474	val_475
Index: ql/src/test/results/clientpositive/join25.q.out
===================================================================
--- ql/src/test/results/clientpositive/join25.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join25.q.out	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-52_704_8772985366163326052/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-36_073_5985571747516774307/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-52_704_8772985366163326052/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-36_073_5985571747516774307/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -188,11 +192,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-56_988_6826737012115531394/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-38-43_960_1122058681238312225/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-56_988_6826737012115531394/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-38-43_960_1122058681238312225/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/stats4.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats4.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats4.q.out	(revision 0)
@@ -0,0 +1,2599 @@
+PREHOOK: query: show partitions srcpart
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions srcpart
+POSTHOOK: type: SHOWPARTITIONS
+ds=2008-04-08/hr=11
+ds=2008-04-08/hr=12
+ds=2008-04-09/hr=11
+ds=2008-04-09/hr=12
+PREHOOK: query: drop table nzhang_part1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table nzhang_part1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table nzhang_part2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table nzhang_part2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table if not exists nzhang_part1 like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table if not exists nzhang_part1 like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@nzhang_part1
+PREHOOK: query: create table if not exists nzhang_part2 like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table if not exists nzhang_part2 like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@nzhang_part2
+PREHOOK: query: explain
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB nzhang_part1 (TOK_PARTSPEC (TOK_PARTVAL ds) (TOK_PARTVAL hr)))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL ds)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (<= (TOK_TABLE_OR_COL ds) '2008-04-08'))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB nzhang_part2 (TOK_PARTSPEC (TOK_PARTVAL ds '2008-12-31') (TOK_PARTVAL hr)))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (> (TOK_TABLE_OR_COL ds) '2008-04-08'))))
+
+STAGE DEPENDENCIES:
+  Stage-2 is a root stage
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
+  Stage-4
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
+
+STAGE PLANS:
+  Stage: Stage-2
+    Map Reduce
+      Alias -> Map Operator Tree:
+        srcpart 
+          TableScan
+            alias: srcpart
+            Filter Operator
+              predicate:
+                  expr: (ds <= '2008-04-08')
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                      expr: ds
+                      type: string
+                      expr: hr
+                      type: string
+                outputColumnNames: _col0, _col1, _col2, _col3
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: nzhang_part1
+            Filter Operator
+              predicate:
+                  expr: (ds > '2008-04-08')
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                      expr: hr
+                      type: string
+                outputColumnNames: _col0, _col1, _col2
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 2
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: nzhang_part2
+
+  Stage: Stage-6
+    Conditional Operator
+
+  Stage: Stage-5
+    Move Operator
+      files:
+          hdfs directory: true
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-11-04_741_3724891305932718079/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 
+            hr 
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: nzhang_part1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-11-04_741_3724891305932718079/-ext-10004 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: nzhang_part1
+
+  Stage: Stage-10
+    Conditional Operator
+
+  Stage: Stage-9
+    Move Operator
+      files:
+          hdfs directory: true
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-11-04_741_3724891305932718079/-ext-10002
+
+  Stage: Stage-1
+    Move Operator
+      tables:
+          partition:
+            ds 2008-12-31
+            hr 
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: nzhang_part2
+
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-11-04_741_3724891305932718079/-ext-10005 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: nzhang_part2
+
+
+PREHOOK: query: from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@nzhang_part1@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@nzhang_part1@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@nzhang_part2@ds=2008-12-31/hr=11
+POSTHOOK: Output: default@nzhang_part2@ds=2008-12-31/hr=12
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions nzhang_part1
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions nzhang_part1
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ds=2008-04-08/hr=11
+ds=2008-04-08/hr=12
+PREHOOK: query: show partitions nzhang_part2
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions nzhang_part2
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ds=2008-12-31/hr=11
+ds=2008-12-31/hr=12
+PREHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
+PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-21_462_8751318034647954787/-mr-10000
+POSTHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-21_462_8751318034647954787/-mr-10000
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	2008-04-08	11
+86	val_86	2008-04-08	11
+311	val_311	2008-04-08	11
+27	val_27	2008-04-08	11
+165	val_165	2008-04-08	11
+409	val_409	2008-04-08	11
+255	val_255	2008-04-08	11
+278	val_278	2008-04-08	11
+98	val_98	2008-04-08	11
+484	val_484	2008-04-08	11
+265	val_265	2008-04-08	11
+193	val_193	2008-04-08	11
+401	val_401	2008-04-08	11
+150	val_150	2008-04-08	11
+273	val_273	2008-04-08	11
+224	val_224	2008-04-08	11
+369	val_369	2008-04-08	11
+66	val_66	2008-04-08	11
+128	val_128	2008-04-08	11
+213	val_213	2008-04-08	11
+146	val_146	2008-04-08	11
+406	val_406	2008-04-08	11
+429	val_429	2008-04-08	11
+374	val_374	2008-04-08	11
+152	val_152	2008-04-08	11
+469	val_469	2008-04-08	11
+145	val_145	2008-04-08	11
+495	val_495	2008-04-08	11
+37	val_37	2008-04-08	11
+327	val_327	2008-04-08	11
+281	val_281	2008-04-08	11
+277	val_277	2008-04-08	11
+209	val_209	2008-04-08	11
+15	val_15	2008-04-08	11
+82	val_82	2008-04-08	11
+403	val_403	2008-04-08	11
+166	val_166	2008-04-08	11
+417	val_417	2008-04-08	11
+430	val_430	2008-04-08	11
+252	val_252	2008-04-08	11
+292	val_292	2008-04-08	11
+219	val_219	2008-04-08	11
+287	val_287	2008-04-08	11
+153	val_153	2008-04-08	11
+193	val_193	2008-04-08	11
+338	val_338	2008-04-08	11
+446	val_446	2008-04-08	11
+459	val_459	2008-04-08	11
+394	val_394	2008-04-08	11
+237	val_237	2008-04-08	11
+482	val_482	2008-04-08	11
+174	val_174	2008-04-08	11
+413	val_413	2008-04-08	11
+494	val_494	2008-04-08	11
+207	val_207	2008-04-08	11
+199	val_199	2008-04-08	11
+466	val_466	2008-04-08	11
+208	val_208	2008-04-08	11
+174	val_174	2008-04-08	11
+399	val_399	2008-04-08	11
+396	val_396	2008-04-08	11
+247	val_247	2008-04-08	11
+417	val_417	2008-04-08	11
+489	val_489	2008-04-08	11
+162	val_162	2008-04-08	11
+377	val_377	2008-04-08	11
+397	val_397	2008-04-08	11
+309	val_309	2008-04-08	11
+365	val_365	2008-04-08	11
+266	val_266	2008-04-08	11
+439	val_439	2008-04-08	11
+342	val_342	2008-04-08	11
+367	val_367	2008-04-08	11
+325	val_325	2008-04-08	11
+167	val_167	2008-04-08	11
+195	val_195	2008-04-08	11
+475	val_475	2008-04-08	11
+17	val_17	2008-04-08	11
+113	val_113	2008-04-08	11
+155	val_155	2008-04-08	11
+203	val_203	2008-04-08	11
+339	val_339	2008-04-08	11
+0	val_0	2008-04-08	11
+455	val_455	2008-04-08	11
+128	val_128	2008-04-08	11
+311	val_311	2008-04-08	11
+316	val_316	2008-04-08	11
+57	val_57	2008-04-08	11
+302	val_302	2008-04-08	11
+205	val_205	2008-04-08	11
+149	val_149	2008-04-08	11
+438	val_438	2008-04-08	11
+345	val_345	2008-04-08	11
+129	val_129	2008-04-08	11
+170	val_170	2008-04-08	11
+20	val_20	2008-04-08	11
+489	val_489	2008-04-08	11
+157	val_157	2008-04-08	11
+378	val_378	2008-04-08	11
+221	val_221	2008-04-08	11
+92	val_92	2008-04-08	11
+111	val_111	2008-04-08	11
+47	val_47	2008-04-08	11
+72	val_72	2008-04-08	11
+4	val_4	2008-04-08	11
+280	val_280	2008-04-08	11
+35	val_35	2008-04-08	11
+427	val_427	2008-04-08	11
+277	val_277	2008-04-08	11
+208	val_208	2008-04-08	11
+356	val_356	2008-04-08	11
+399	val_399	2008-04-08	11
+169	val_169	2008-04-08	11
+382	val_382	2008-04-08	11
+498	val_498	2008-04-08	11
+125	val_125	2008-04-08	11
+386	val_386	2008-04-08	11
+437	val_437	2008-04-08	11
+469	val_469	2008-04-08	11
+192	val_192	2008-04-08	11
+286	val_286	2008-04-08	11
+187	val_187	2008-04-08	11
+176	val_176	2008-04-08	11
+54	val_54	2008-04-08	11
+459	val_459	2008-04-08	11
+51	val_51	2008-04-08	11
+138	val_138	2008-04-08	11
+103	val_103	2008-04-08	11
+239	val_239	2008-04-08	11
+213	val_213	2008-04-08	11
+216	val_216	2008-04-08	11
+430	val_430	2008-04-08	11
+278	val_278	2008-04-08	11
+176	val_176	2008-04-08	11
+289	val_289	2008-04-08	11
+221	val_221	2008-04-08	11
+65	val_65	2008-04-08	11
+318	val_318	2008-04-08	11
+332	val_332	2008-04-08	11
+311	val_311	2008-04-08	11
+275	val_275	2008-04-08	11
+137	val_137	2008-04-08	11
+241	val_241	2008-04-08	11
+83	val_83	2008-04-08	11
+333	val_333	2008-04-08	11
+180	val_180	2008-04-08	11
+284	val_284	2008-04-08	11
+12	val_12	2008-04-08	11
+230	val_230	2008-04-08	11
+181	val_181	2008-04-08	11
+67	val_67	2008-04-08	11
+260	val_260	2008-04-08	11
+404	val_404	2008-04-08	11
+384	val_384	2008-04-08	11
+489	val_489	2008-04-08	11
+353	val_353	2008-04-08	11
+373	val_373	2008-04-08	11
+272	val_272	2008-04-08	11
+138	val_138	2008-04-08	11
+217	val_217	2008-04-08	11
+84	val_84	2008-04-08	11
+348	val_348	2008-04-08	11
+466	val_466	2008-04-08	11
+58	val_58	2008-04-08	11
+8	val_8	2008-04-08	11
+411	val_411	2008-04-08	11
+230	val_230	2008-04-08	11
+208	val_208	2008-04-08	11
+348	val_348	2008-04-08	11
+24	val_24	2008-04-08	11
+463	val_463	2008-04-08	11
+431	val_431	2008-04-08	11
+179	val_179	2008-04-08	11
+172	val_172	2008-04-08	11
+42	val_42	2008-04-08	11
+129	val_129	2008-04-08	11
+158	val_158	2008-04-08	11
+119	val_119	2008-04-08	11
+496	val_496	2008-04-08	11
+0	val_0	2008-04-08	11
+322	val_322	2008-04-08	11
+197	val_197	2008-04-08	11
+468	val_468	2008-04-08	11
+393	val_393	2008-04-08	11
+454	val_454	2008-04-08	11
+100	val_100	2008-04-08	11
+298	val_298	2008-04-08	11
+199	val_199	2008-04-08	11
+191	val_191	2008-04-08	11
+418	val_418	2008-04-08	11
+96	val_96	2008-04-08	11
+26	val_26	2008-04-08	11
+165	val_165	2008-04-08	11
+327	val_327	2008-04-08	11
+230	val_230	2008-04-08	11
+205	val_205	2008-04-08	11
+120	val_120	2008-04-08	11
+131	val_131	2008-04-08	11
+51	val_51	2008-04-08	11
+404	val_404	2008-04-08	11
+43	val_43	2008-04-08	11
+436	val_436	2008-04-08	11
+156	val_156	2008-04-08	11
+469	val_469	2008-04-08	11
+468	val_468	2008-04-08	11
+308	val_308	2008-04-08	11
+95	val_95	2008-04-08	11
+196	val_196	2008-04-08	11
+288	val_288	2008-04-08	11
+481	val_481	2008-04-08	11
+457	val_457	2008-04-08	11
+98	val_98	2008-04-08	11
+282	val_282	2008-04-08	11
+197	val_197	2008-04-08	11
+187	val_187	2008-04-08	11
+318	val_318	2008-04-08	11
+318	val_318	2008-04-08	11
+409	val_409	2008-04-08	11
+470	val_470	2008-04-08	11
+137	val_137	2008-04-08	11
+369	val_369	2008-04-08	11
+316	val_316	2008-04-08	11
+169	val_169	2008-04-08	11
+413	val_413	2008-04-08	11
+85	val_85	2008-04-08	11
+77	val_77	2008-04-08	11
+0	val_0	2008-04-08	11
+490	val_490	2008-04-08	11
+87	val_87	2008-04-08	11
+364	val_364	2008-04-08	11
+179	val_179	2008-04-08	11
+118	val_118	2008-04-08	11
+134	val_134	2008-04-08	11
+395	val_395	2008-04-08	11
+282	val_282	2008-04-08	11
+138	val_138	2008-04-08	11
+238	val_238	2008-04-08	11
+419	val_419	2008-04-08	11
+15	val_15	2008-04-08	11
+118	val_118	2008-04-08	11
+72	val_72	2008-04-08	11
+90	val_90	2008-04-08	11
+307	val_307	2008-04-08	11
+19	val_19	2008-04-08	11
+435	val_435	2008-04-08	11
+10	val_10	2008-04-08	11
+277	val_277	2008-04-08	11
+273	val_273	2008-04-08	11
+306	val_306	2008-04-08	11
+224	val_224	2008-04-08	11
+309	val_309	2008-04-08	11
+389	val_389	2008-04-08	11
+327	val_327	2008-04-08	11
+242	val_242	2008-04-08	11
+369	val_369	2008-04-08	11
+392	val_392	2008-04-08	11
+272	val_272	2008-04-08	11
+331	val_331	2008-04-08	11
+401	val_401	2008-04-08	11
+242	val_242	2008-04-08	11
+452	val_452	2008-04-08	11
+177	val_177	2008-04-08	11
+226	val_226	2008-04-08	11
+5	val_5	2008-04-08	11
+497	val_497	2008-04-08	11
+402	val_402	2008-04-08	11
+396	val_396	2008-04-08	11
+317	val_317	2008-04-08	11
+395	val_395	2008-04-08	11
+58	val_58	2008-04-08	11
+35	val_35	2008-04-08	11
+336	val_336	2008-04-08	11
+95	val_95	2008-04-08	11
+11	val_11	2008-04-08	11
+168	val_168	2008-04-08	11
+34	val_34	2008-04-08	11
+229	val_229	2008-04-08	11
+233	val_233	2008-04-08	11
+143	val_143	2008-04-08	11
+472	val_472	2008-04-08	11
+322	val_322	2008-04-08	11
+498	val_498	2008-04-08	11
+160	val_160	2008-04-08	11
+195	val_195	2008-04-08	11
+42	val_42	2008-04-08	11
+321	val_321	2008-04-08	11
+430	val_430	2008-04-08	11
+119	val_119	2008-04-08	11
+489	val_489	2008-04-08	11
+458	val_458	2008-04-08	11
+78	val_78	2008-04-08	11
+76	val_76	2008-04-08	11
+41	val_41	2008-04-08	11
+223	val_223	2008-04-08	11
+492	val_492	2008-04-08	11
+149	val_149	2008-04-08	11
+449	val_449	2008-04-08	11
+218	val_218	2008-04-08	11
+228	val_228	2008-04-08	11
+138	val_138	2008-04-08	11
+453	val_453	2008-04-08	11
+30	val_30	2008-04-08	11
+209	val_209	2008-04-08	11
+64	val_64	2008-04-08	11
+468	val_468	2008-04-08	11
+76	val_76	2008-04-08	11
+74	val_74	2008-04-08	11
+342	val_342	2008-04-08	11
+69	val_69	2008-04-08	11
+230	val_230	2008-04-08	11
+33	val_33	2008-04-08	11
+368	val_368	2008-04-08	11
+103	val_103	2008-04-08	11
+296	val_296	2008-04-08	11
+113	val_113	2008-04-08	11
+216	val_216	2008-04-08	11
+367	val_367	2008-04-08	11
+344	val_344	2008-04-08	11
+167	val_167	2008-04-08	11
+274	val_274	2008-04-08	11
+219	val_219	2008-04-08	11
+239	val_239	2008-04-08	11
+485	val_485	2008-04-08	11
+116	val_116	2008-04-08	11
+223	val_223	2008-04-08	11
+256	val_256	2008-04-08	11
+263	val_263	2008-04-08	11
+70	val_70	2008-04-08	11
+487	val_487	2008-04-08	11
+480	val_480	2008-04-08	11
+401	val_401	2008-04-08	11
+288	val_288	2008-04-08	11
+191	val_191	2008-04-08	11
+5	val_5	2008-04-08	11
+244	val_244	2008-04-08	11
+438	val_438	2008-04-08	11
+128	val_128	2008-04-08	11
+467	val_467	2008-04-08	11
+432	val_432	2008-04-08	11
+202	val_202	2008-04-08	11
+316	val_316	2008-04-08	11
+229	val_229	2008-04-08	11
+469	val_469	2008-04-08	11
+463	val_463	2008-04-08	11
+280	val_280	2008-04-08	11
+2	val_2	2008-04-08	11
+35	val_35	2008-04-08	11
+283	val_283	2008-04-08	11
+331	val_331	2008-04-08	11
+235	val_235	2008-04-08	11
+80	val_80	2008-04-08	11
+44	val_44	2008-04-08	11
+193	val_193	2008-04-08	11
+321	val_321	2008-04-08	11
+335	val_335	2008-04-08	11
+104	val_104	2008-04-08	11
+466	val_466	2008-04-08	11
+366	val_366	2008-04-08	11
+175	val_175	2008-04-08	11
+403	val_403	2008-04-08	11
+483	val_483	2008-04-08	11
+53	val_53	2008-04-08	11
+105	val_105	2008-04-08	11
+257	val_257	2008-04-08	11
+406	val_406	2008-04-08	11
+409	val_409	2008-04-08	11
+190	val_190	2008-04-08	11
+406	val_406	2008-04-08	11
+401	val_401	2008-04-08	11
+114	val_114	2008-04-08	11
+258	val_258	2008-04-08	11
+90	val_90	2008-04-08	11
+203	val_203	2008-04-08	11
+262	val_262	2008-04-08	11
+348	val_348	2008-04-08	11
+424	val_424	2008-04-08	11
+12	val_12	2008-04-08	11
+396	val_396	2008-04-08	11
+201	val_201	2008-04-08	11
+217	val_217	2008-04-08	11
+164	val_164	2008-04-08	11
+431	val_431	2008-04-08	11
+454	val_454	2008-04-08	11
+478	val_478	2008-04-08	11
+298	val_298	2008-04-08	11
+125	val_125	2008-04-08	11
+431	val_431	2008-04-08	11
+164	val_164	2008-04-08	11
+424	val_424	2008-04-08	11
+187	val_187	2008-04-08	11
+382	val_382	2008-04-08	11
+5	val_5	2008-04-08	11
+70	val_70	2008-04-08	11
+397	val_397	2008-04-08	11
+480	val_480	2008-04-08	11
+291	val_291	2008-04-08	11
+24	val_24	2008-04-08	11
+351	val_351	2008-04-08	11
+255	val_255	2008-04-08	11
+104	val_104	2008-04-08	11
+70	val_70	2008-04-08	11
+163	val_163	2008-04-08	11
+438	val_438	2008-04-08	11
+119	val_119	2008-04-08	11
+414	val_414	2008-04-08	11
+200	val_200	2008-04-08	11
+491	val_491	2008-04-08	11
+237	val_237	2008-04-08	11
+439	val_439	2008-04-08	11
+360	val_360	2008-04-08	11
+248	val_248	2008-04-08	11
+479	val_479	2008-04-08	11
+305	val_305	2008-04-08	11
+417	val_417	2008-04-08	11
+199	val_199	2008-04-08	11
+444	val_444	2008-04-08	11
+120	val_120	2008-04-08	11
+429	val_429	2008-04-08	11
+169	val_169	2008-04-08	11
+443	val_443	2008-04-08	11
+323	val_323	2008-04-08	11
+325	val_325	2008-04-08	11
+277	val_277	2008-04-08	11
+230	val_230	2008-04-08	11
+478	val_478	2008-04-08	11
+178	val_178	2008-04-08	11
+468	val_468	2008-04-08	11
+310	val_310	2008-04-08	11
+317	val_317	2008-04-08	11
+333	val_333	2008-04-08	11
+493	val_493	2008-04-08	11
+460	val_460	2008-04-08	11
+207	val_207	2008-04-08	11
+249	val_249	2008-04-08	11
+265	val_265	2008-04-08	11
+480	val_480	2008-04-08	11
+83	val_83	2008-04-08	11
+136	val_136	2008-04-08	11
+353	val_353	2008-04-08	11
+172	val_172	2008-04-08	11
+214	val_214	2008-04-08	11
+462	val_462	2008-04-08	11
+233	val_233	2008-04-08	11
+406	val_406	2008-04-08	11
+133	val_133	2008-04-08	11
+175	val_175	2008-04-08	11
+189	val_189	2008-04-08	11
+454	val_454	2008-04-08	11
+375	val_375	2008-04-08	11
+401	val_401	2008-04-08	11
+421	val_421	2008-04-08	11
+407	val_407	2008-04-08	11
+384	val_384	2008-04-08	11
+256	val_256	2008-04-08	11
+26	val_26	2008-04-08	11
+134	val_134	2008-04-08	11
+67	val_67	2008-04-08	11
+384	val_384	2008-04-08	11
+379	val_379	2008-04-08	11
+18	val_18	2008-04-08	11
+462	val_462	2008-04-08	11
+492	val_492	2008-04-08	11
+100	val_100	2008-04-08	11
+298	val_298	2008-04-08	11
+9	val_9	2008-04-08	11
+341	val_341	2008-04-08	11
+498	val_498	2008-04-08	11
+146	val_146	2008-04-08	11
+458	val_458	2008-04-08	11
+362	val_362	2008-04-08	11
+186	val_186	2008-04-08	11
+285	val_285	2008-04-08	11
+348	val_348	2008-04-08	11
+167	val_167	2008-04-08	11
+18	val_18	2008-04-08	11
+273	val_273	2008-04-08	11
+183	val_183	2008-04-08	11
+281	val_281	2008-04-08	11
+344	val_344	2008-04-08	11
+97	val_97	2008-04-08	11
+469	val_469	2008-04-08	11
+315	val_315	2008-04-08	11
+84	val_84	2008-04-08	11
+28	val_28	2008-04-08	11
+37	val_37	2008-04-08	11
+448	val_448	2008-04-08	11
+152	val_152	2008-04-08	11
+348	val_348	2008-04-08	11
+307	val_307	2008-04-08	11
+194	val_194	2008-04-08	11
+414	val_414	2008-04-08	11
+477	val_477	2008-04-08	11
+222	val_222	2008-04-08	11
+126	val_126	2008-04-08	11
+90	val_90	2008-04-08	11
+169	val_169	2008-04-08	11
+403	val_403	2008-04-08	11
+400	val_400	2008-04-08	11
+200	val_200	2008-04-08	11
+97	val_97	2008-04-08	11
+238	val_238	2008-04-08	12
+86	val_86	2008-04-08	12
+311	val_311	2008-04-08	12
+27	val_27	2008-04-08	12
+165	val_165	2008-04-08	12
+409	val_409	2008-04-08	12
+255	val_255	2008-04-08	12
+278	val_278	2008-04-08	12
+98	val_98	2008-04-08	12
+484	val_484	2008-04-08	12
+265	val_265	2008-04-08	12
+193	val_193	2008-04-08	12
+401	val_401	2008-04-08	12
+150	val_150	2008-04-08	12
+273	val_273	2008-04-08	12
+224	val_224	2008-04-08	12
+369	val_369	2008-04-08	12
+66	val_66	2008-04-08	12
+128	val_128	2008-04-08	12
+213	val_213	2008-04-08	12
+146	val_146	2008-04-08	12
+406	val_406	2008-04-08	12
+429	val_429	2008-04-08	12
+374	val_374	2008-04-08	12
+152	val_152	2008-04-08	12
+469	val_469	2008-04-08	12
+145	val_145	2008-04-08	12
+495	val_495	2008-04-08	12
+37	val_37	2008-04-08	12
+327	val_327	2008-04-08	12
+281	val_281	2008-04-08	12
+277	val_277	2008-04-08	12
+209	val_209	2008-04-08	12
+15	val_15	2008-04-08	12
+82	val_82	2008-04-08	12
+403	val_403	2008-04-08	12
+166	val_166	2008-04-08	12
+417	val_417	2008-04-08	12
+430	val_430	2008-04-08	12
+252	val_252	2008-04-08	12
+292	val_292	2008-04-08	12
+219	val_219	2008-04-08	12
+287	val_287	2008-04-08	12
+153	val_153	2008-04-08	12
+193	val_193	2008-04-08	12
+338	val_338	2008-04-08	12
+446	val_446	2008-04-08	12
+459	val_459	2008-04-08	12
+394	val_394	2008-04-08	12
+237	val_237	2008-04-08	12
+482	val_482	2008-04-08	12
+174	val_174	2008-04-08	12
+413	val_413	2008-04-08	12
+494	val_494	2008-04-08	12
+207	val_207	2008-04-08	12
+199	val_199	2008-04-08	12
+466	val_466	2008-04-08	12
+208	val_208	2008-04-08	12
+174	val_174	2008-04-08	12
+399	val_399	2008-04-08	12
+396	val_396	2008-04-08	12
+247	val_247	2008-04-08	12
+417	val_417	2008-04-08	12
+489	val_489	2008-04-08	12
+162	val_162	2008-04-08	12
+377	val_377	2008-04-08	12
+397	val_397	2008-04-08	12
+309	val_309	2008-04-08	12
+365	val_365	2008-04-08	12
+266	val_266	2008-04-08	12
+439	val_439	2008-04-08	12
+342	val_342	2008-04-08	12
+367	val_367	2008-04-08	12
+325	val_325	2008-04-08	12
+167	val_167	2008-04-08	12
+195	val_195	2008-04-08	12
+475	val_475	2008-04-08	12
+17	val_17	2008-04-08	12
+113	val_113	2008-04-08	12
+155	val_155	2008-04-08	12
+203	val_203	2008-04-08	12
+339	val_339	2008-04-08	12
+0	val_0	2008-04-08	12
+455	val_455	2008-04-08	12
+128	val_128	2008-04-08	12
+311	val_311	2008-04-08	12
+316	val_316	2008-04-08	12
+57	val_57	2008-04-08	12
+302	val_302	2008-04-08	12
+205	val_205	2008-04-08	12
+149	val_149	2008-04-08	12
+438	val_438	2008-04-08	12
+345	val_345	2008-04-08	12
+129	val_129	2008-04-08	12
+170	val_170	2008-04-08	12
+20	val_20	2008-04-08	12
+489	val_489	2008-04-08	12
+157	val_157	2008-04-08	12
+378	val_378	2008-04-08	12
+221	val_221	2008-04-08	12
+92	val_92	2008-04-08	12
+111	val_111	2008-04-08	12
+47	val_47	2008-04-08	12
+72	val_72	2008-04-08	12
+4	val_4	2008-04-08	12
+280	val_280	2008-04-08	12
+35	val_35	2008-04-08	12
+427	val_427	2008-04-08	12
+277	val_277	2008-04-08	12
+208	val_208	2008-04-08	12
+356	val_356	2008-04-08	12
+399	val_399	2008-04-08	12
+169	val_169	2008-04-08	12
+382	val_382	2008-04-08	12
+498	val_498	2008-04-08	12
+125	val_125	2008-04-08	12
+386	val_386	2008-04-08	12
+437	val_437	2008-04-08	12
+469	val_469	2008-04-08	12
+192	val_192	2008-04-08	12
+286	val_286	2008-04-08	12
+187	val_187	2008-04-08	12
+176	val_176	2008-04-08	12
+54	val_54	2008-04-08	12
+459	val_459	2008-04-08	12
+51	val_51	2008-04-08	12
+138	val_138	2008-04-08	12
+103	val_103	2008-04-08	12
+239	val_239	2008-04-08	12
+213	val_213	2008-04-08	12
+216	val_216	2008-04-08	12
+430	val_430	2008-04-08	12
+278	val_278	2008-04-08	12
+176	val_176	2008-04-08	12
+289	val_289	2008-04-08	12
+221	val_221	2008-04-08	12
+65	val_65	2008-04-08	12
+318	val_318	2008-04-08	12
+332	val_332	2008-04-08	12
+311	val_311	2008-04-08	12
+275	val_275	2008-04-08	12
+137	val_137	2008-04-08	12
+241	val_241	2008-04-08	12
+83	val_83	2008-04-08	12
+333	val_333	2008-04-08	12
+180	val_180	2008-04-08	12
+284	val_284	2008-04-08	12
+12	val_12	2008-04-08	12
+230	val_230	2008-04-08	12
+181	val_181	2008-04-08	12
+67	val_67	2008-04-08	12
+260	val_260	2008-04-08	12
+404	val_404	2008-04-08	12
+384	val_384	2008-04-08	12
+489	val_489	2008-04-08	12
+353	val_353	2008-04-08	12
+373	val_373	2008-04-08	12
+272	val_272	2008-04-08	12
+138	val_138	2008-04-08	12
+217	val_217	2008-04-08	12
+84	val_84	2008-04-08	12
+348	val_348	2008-04-08	12
+466	val_466	2008-04-08	12
+58	val_58	2008-04-08	12
+8	val_8	2008-04-08	12
+411	val_411	2008-04-08	12
+230	val_230	2008-04-08	12
+208	val_208	2008-04-08	12
+348	val_348	2008-04-08	12
+24	val_24	2008-04-08	12
+463	val_463	2008-04-08	12
+431	val_431	2008-04-08	12
+179	val_179	2008-04-08	12
+172	val_172	2008-04-08	12
+42	val_42	2008-04-08	12
+129	val_129	2008-04-08	12
+158	val_158	2008-04-08	12
+119	val_119	2008-04-08	12
+496	val_496	2008-04-08	12
+0	val_0	2008-04-08	12
+322	val_322	2008-04-08	12
+197	val_197	2008-04-08	12
+468	val_468	2008-04-08	12
+393	val_393	2008-04-08	12
+454	val_454	2008-04-08	12
+100	val_100	2008-04-08	12
+298	val_298	2008-04-08	12
+199	val_199	2008-04-08	12
+191	val_191	2008-04-08	12
+418	val_418	2008-04-08	12
+96	val_96	2008-04-08	12
+26	val_26	2008-04-08	12
+165	val_165	2008-04-08	12
+327	val_327	2008-04-08	12
+230	val_230	2008-04-08	12
+205	val_205	2008-04-08	12
+120	val_120	2008-04-08	12
+131	val_131	2008-04-08	12
+51	val_51	2008-04-08	12
+404	val_404	2008-04-08	12
+43	val_43	2008-04-08	12
+436	val_436	2008-04-08	12
+156	val_156	2008-04-08	12
+469	val_469	2008-04-08	12
+468	val_468	2008-04-08	12
+308	val_308	2008-04-08	12
+95	val_95	2008-04-08	12
+196	val_196	2008-04-08	12
+288	val_288	2008-04-08	12
+481	val_481	2008-04-08	12
+457	val_457	2008-04-08	12
+98	val_98	2008-04-08	12
+282	val_282	2008-04-08	12
+197	val_197	2008-04-08	12
+187	val_187	2008-04-08	12
+318	val_318	2008-04-08	12
+318	val_318	2008-04-08	12
+409	val_409	2008-04-08	12
+470	val_470	2008-04-08	12
+137	val_137	2008-04-08	12
+369	val_369	2008-04-08	12
+316	val_316	2008-04-08	12
+169	val_169	2008-04-08	12
+413	val_413	2008-04-08	12
+85	val_85	2008-04-08	12
+77	val_77	2008-04-08	12
+0	val_0	2008-04-08	12
+490	val_490	2008-04-08	12
+87	val_87	2008-04-08	12
+364	val_364	2008-04-08	12
+179	val_179	2008-04-08	12
+118	val_118	2008-04-08	12
+134	val_134	2008-04-08	12
+395	val_395	2008-04-08	12
+282	val_282	2008-04-08	12
+138	val_138	2008-04-08	12
+238	val_238	2008-04-08	12
+419	val_419	2008-04-08	12
+15	val_15	2008-04-08	12
+118	val_118	2008-04-08	12
+72	val_72	2008-04-08	12
+90	val_90	2008-04-08	12
+307	val_307	2008-04-08	12
+19	val_19	2008-04-08	12
+435	val_435	2008-04-08	12
+10	val_10	2008-04-08	12
+277	val_277	2008-04-08	12
+273	val_273	2008-04-08	12
+306	val_306	2008-04-08	12
+224	val_224	2008-04-08	12
+309	val_309	2008-04-08	12
+389	val_389	2008-04-08	12
+327	val_327	2008-04-08	12
+242	val_242	2008-04-08	12
+369	val_369	2008-04-08	12
+392	val_392	2008-04-08	12
+272	val_272	2008-04-08	12
+331	val_331	2008-04-08	12
+401	val_401	2008-04-08	12
+242	val_242	2008-04-08	12
+452	val_452	2008-04-08	12
+177	val_177	2008-04-08	12
+226	val_226	2008-04-08	12
+5	val_5	2008-04-08	12
+497	val_497	2008-04-08	12
+402	val_402	2008-04-08	12
+396	val_396	2008-04-08	12
+317	val_317	2008-04-08	12
+395	val_395	2008-04-08	12
+58	val_58	2008-04-08	12
+35	val_35	2008-04-08	12
+336	val_336	2008-04-08	12
+95	val_95	2008-04-08	12
+11	val_11	2008-04-08	12
+168	val_168	2008-04-08	12
+34	val_34	2008-04-08	12
+229	val_229	2008-04-08	12
+233	val_233	2008-04-08	12
+143	val_143	2008-04-08	12
+472	val_472	2008-04-08	12
+322	val_322	2008-04-08	12
+498	val_498	2008-04-08	12
+160	val_160	2008-04-08	12
+195	val_195	2008-04-08	12
+42	val_42	2008-04-08	12
+321	val_321	2008-04-08	12
+430	val_430	2008-04-08	12
+119	val_119	2008-04-08	12
+489	val_489	2008-04-08	12
+458	val_458	2008-04-08	12
+78	val_78	2008-04-08	12
+76	val_76	2008-04-08	12
+41	val_41	2008-04-08	12
+223	val_223	2008-04-08	12
+492	val_492	2008-04-08	12
+149	val_149	2008-04-08	12
+449	val_449	2008-04-08	12
+218	val_218	2008-04-08	12
+228	val_228	2008-04-08	12
+138	val_138	2008-04-08	12
+453	val_453	2008-04-08	12
+30	val_30	2008-04-08	12
+209	val_209	2008-04-08	12
+64	val_64	2008-04-08	12
+468	val_468	2008-04-08	12
+76	val_76	2008-04-08	12
+74	val_74	2008-04-08	12
+342	val_342	2008-04-08	12
+69	val_69	2008-04-08	12
+230	val_230	2008-04-08	12
+33	val_33	2008-04-08	12
+368	val_368	2008-04-08	12
+103	val_103	2008-04-08	12
+296	val_296	2008-04-08	12
+113	val_113	2008-04-08	12
+216	val_216	2008-04-08	12
+367	val_367	2008-04-08	12
+344	val_344	2008-04-08	12
+167	val_167	2008-04-08	12
+274	val_274	2008-04-08	12
+219	val_219	2008-04-08	12
+239	val_239	2008-04-08	12
+485	val_485	2008-04-08	12
+116	val_116	2008-04-08	12
+223	val_223	2008-04-08	12
+256	val_256	2008-04-08	12
+263	val_263	2008-04-08	12
+70	val_70	2008-04-08	12
+487	val_487	2008-04-08	12
+480	val_480	2008-04-08	12
+401	val_401	2008-04-08	12
+288	val_288	2008-04-08	12
+191	val_191	2008-04-08	12
+5	val_5	2008-04-08	12
+244	val_244	2008-04-08	12
+438	val_438	2008-04-08	12
+128	val_128	2008-04-08	12
+467	val_467	2008-04-08	12
+432	val_432	2008-04-08	12
+202	val_202	2008-04-08	12
+316	val_316	2008-04-08	12
+229	val_229	2008-04-08	12
+469	val_469	2008-04-08	12
+463	val_463	2008-04-08	12
+280	val_280	2008-04-08	12
+2	val_2	2008-04-08	12
+35	val_35	2008-04-08	12
+283	val_283	2008-04-08	12
+331	val_331	2008-04-08	12
+235	val_235	2008-04-08	12
+80	val_80	2008-04-08	12
+44	val_44	2008-04-08	12
+193	val_193	2008-04-08	12
+321	val_321	2008-04-08	12
+335	val_335	2008-04-08	12
+104	val_104	2008-04-08	12
+466	val_466	2008-04-08	12
+366	val_366	2008-04-08	12
+175	val_175	2008-04-08	12
+403	val_403	2008-04-08	12
+483	val_483	2008-04-08	12
+53	val_53	2008-04-08	12
+105	val_105	2008-04-08	12
+257	val_257	2008-04-08	12
+406	val_406	2008-04-08	12
+409	val_409	2008-04-08	12
+190	val_190	2008-04-08	12
+406	val_406	2008-04-08	12
+401	val_401	2008-04-08	12
+114	val_114	2008-04-08	12
+258	val_258	2008-04-08	12
+90	val_90	2008-04-08	12
+203	val_203	2008-04-08	12
+262	val_262	2008-04-08	12
+348	val_348	2008-04-08	12
+424	val_424	2008-04-08	12
+12	val_12	2008-04-08	12
+396	val_396	2008-04-08	12
+201	val_201	2008-04-08	12
+217	val_217	2008-04-08	12
+164	val_164	2008-04-08	12
+431	val_431	2008-04-08	12
+454	val_454	2008-04-08	12
+478	val_478	2008-04-08	12
+298	val_298	2008-04-08	12
+125	val_125	2008-04-08	12
+431	val_431	2008-04-08	12
+164	val_164	2008-04-08	12
+424	val_424	2008-04-08	12
+187	val_187	2008-04-08	12
+382	val_382	2008-04-08	12
+5	val_5	2008-04-08	12
+70	val_70	2008-04-08	12
+397	val_397	2008-04-08	12
+480	val_480	2008-04-08	12
+291	val_291	2008-04-08	12
+24	val_24	2008-04-08	12
+351	val_351	2008-04-08	12
+255	val_255	2008-04-08	12
+104	val_104	2008-04-08	12
+70	val_70	2008-04-08	12
+163	val_163	2008-04-08	12
+438	val_438	2008-04-08	12
+119	val_119	2008-04-08	12
+414	val_414	2008-04-08	12
+200	val_200	2008-04-08	12
+491	val_491	2008-04-08	12
+237	val_237	2008-04-08	12
+439	val_439	2008-04-08	12
+360	val_360	2008-04-08	12
+248	val_248	2008-04-08	12
+479	val_479	2008-04-08	12
+305	val_305	2008-04-08	12
+417	val_417	2008-04-08	12
+199	val_199	2008-04-08	12
+444	val_444	2008-04-08	12
+120	val_120	2008-04-08	12
+429	val_429	2008-04-08	12
+169	val_169	2008-04-08	12
+443	val_443	2008-04-08	12
+323	val_323	2008-04-08	12
+325	val_325	2008-04-08	12
+277	val_277	2008-04-08	12
+230	val_230	2008-04-08	12
+478	val_478	2008-04-08	12
+178	val_178	2008-04-08	12
+468	val_468	2008-04-08	12
+310	val_310	2008-04-08	12
+317	val_317	2008-04-08	12
+333	val_333	2008-04-08	12
+493	val_493	2008-04-08	12
+460	val_460	2008-04-08	12
+207	val_207	2008-04-08	12
+249	val_249	2008-04-08	12
+265	val_265	2008-04-08	12
+480	val_480	2008-04-08	12
+83	val_83	2008-04-08	12
+136	val_136	2008-04-08	12
+353	val_353	2008-04-08	12
+172	val_172	2008-04-08	12
+214	val_214	2008-04-08	12
+462	val_462	2008-04-08	12
+233	val_233	2008-04-08	12
+406	val_406	2008-04-08	12
+133	val_133	2008-04-08	12
+175	val_175	2008-04-08	12
+189	val_189	2008-04-08	12
+454	val_454	2008-04-08	12
+375	val_375	2008-04-08	12
+401	val_401	2008-04-08	12
+421	val_421	2008-04-08	12
+407	val_407	2008-04-08	12
+384	val_384	2008-04-08	12
+256	val_256	2008-04-08	12
+26	val_26	2008-04-08	12
+134	val_134	2008-04-08	12
+67	val_67	2008-04-08	12
+384	val_384	2008-04-08	12
+379	val_379	2008-04-08	12
+18	val_18	2008-04-08	12
+462	val_462	2008-04-08	12
+492	val_492	2008-04-08	12
+100	val_100	2008-04-08	12
+298	val_298	2008-04-08	12
+9	val_9	2008-04-08	12
+341	val_341	2008-04-08	12
+498	val_498	2008-04-08	12
+146	val_146	2008-04-08	12
+458	val_458	2008-04-08	12
+362	val_362	2008-04-08	12
+186	val_186	2008-04-08	12
+285	val_285	2008-04-08	12
+348	val_348	2008-04-08	12
+167	val_167	2008-04-08	12
+18	val_18	2008-04-08	12
+273	val_273	2008-04-08	12
+183	val_183	2008-04-08	12
+281	val_281	2008-04-08	12
+344	val_344	2008-04-08	12
+97	val_97	2008-04-08	12
+469	val_469	2008-04-08	12
+315	val_315	2008-04-08	12
+84	val_84	2008-04-08	12
+28	val_28	2008-04-08	12
+37	val_37	2008-04-08	12
+448	val_448	2008-04-08	12
+152	val_152	2008-04-08	12
+348	val_348	2008-04-08	12
+307	val_307	2008-04-08	12
+194	val_194	2008-04-08	12
+414	val_414	2008-04-08	12
+477	val_477	2008-04-08	12
+222	val_222	2008-04-08	12
+126	val_126	2008-04-08	12
+90	val_90	2008-04-08	12
+169	val_169	2008-04-08	12
+403	val_403	2008-04-08	12
+400	val_400	2008-04-08	12
+200	val_200	2008-04-08	12
+97	val_97	2008-04-08	12
+PREHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
+PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-22_337_917757126992605846/-mr-10000
+POSTHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
+POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-11-22_337_917757126992605846/-mr-10000
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	2008-12-31	11
+86	val_86	2008-12-31	11
+311	val_311	2008-12-31	11
+27	val_27	2008-12-31	11
+165	val_165	2008-12-31	11
+409	val_409	2008-12-31	11
+255	val_255	2008-12-31	11
+278	val_278	2008-12-31	11
+98	val_98	2008-12-31	11
+484	val_484	2008-12-31	11
+265	val_265	2008-12-31	11
+193	val_193	2008-12-31	11
+401	val_401	2008-12-31	11
+150	val_150	2008-12-31	11
+273	val_273	2008-12-31	11
+224	val_224	2008-12-31	11
+369	val_369	2008-12-31	11
+66	val_66	2008-12-31	11
+128	val_128	2008-12-31	11
+213	val_213	2008-12-31	11
+146	val_146	2008-12-31	11
+406	val_406	2008-12-31	11
+429	val_429	2008-12-31	11
+374	val_374	2008-12-31	11
+152	val_152	2008-12-31	11
+469	val_469	2008-12-31	11
+145	val_145	2008-12-31	11
+495	val_495	2008-12-31	11
+37	val_37	2008-12-31	11
+327	val_327	2008-12-31	11
+281	val_281	2008-12-31	11
+277	val_277	2008-12-31	11
+209	val_209	2008-12-31	11
+15	val_15	2008-12-31	11
+82	val_82	2008-12-31	11
+403	val_403	2008-12-31	11
+166	val_166	2008-12-31	11
+417	val_417	2008-12-31	11
+430	val_430	2008-12-31	11
+252	val_252	2008-12-31	11
+292	val_292	2008-12-31	11
+219	val_219	2008-12-31	11
+287	val_287	2008-12-31	11
+153	val_153	2008-12-31	11
+193	val_193	2008-12-31	11
+338	val_338	2008-12-31	11
+446	val_446	2008-12-31	11
+459	val_459	2008-12-31	11
+394	val_394	2008-12-31	11
+237	val_237	2008-12-31	11
+482	val_482	2008-12-31	11
+174	val_174	2008-12-31	11
+413	val_413	2008-12-31	11
+494	val_494	2008-12-31	11
+207	val_207	2008-12-31	11
+199	val_199	2008-12-31	11
+466	val_466	2008-12-31	11
+208	val_208	2008-12-31	11
+174	val_174	2008-12-31	11
+399	val_399	2008-12-31	11
+396	val_396	2008-12-31	11
+247	val_247	2008-12-31	11
+417	val_417	2008-12-31	11
+489	val_489	2008-12-31	11
+162	val_162	2008-12-31	11
+377	val_377	2008-12-31	11
+397	val_397	2008-12-31	11
+309	val_309	2008-12-31	11
+365	val_365	2008-12-31	11
+266	val_266	2008-12-31	11
+439	val_439	2008-12-31	11
+342	val_342	2008-12-31	11
+367	val_367	2008-12-31	11
+325	val_325	2008-12-31	11
+167	val_167	2008-12-31	11
+195	val_195	2008-12-31	11
+475	val_475	2008-12-31	11
+17	val_17	2008-12-31	11
+113	val_113	2008-12-31	11
+155	val_155	2008-12-31	11
+203	val_203	2008-12-31	11
+339	val_339	2008-12-31	11
+0	val_0	2008-12-31	11
+455	val_455	2008-12-31	11
+128	val_128	2008-12-31	11
+311	val_311	2008-12-31	11
+316	val_316	2008-12-31	11
+57	val_57	2008-12-31	11
+302	val_302	2008-12-31	11
+205	val_205	2008-12-31	11
+149	val_149	2008-12-31	11
+438	val_438	2008-12-31	11
+345	val_345	2008-12-31	11
+129	val_129	2008-12-31	11
+170	val_170	2008-12-31	11
+20	val_20	2008-12-31	11
+489	val_489	2008-12-31	11
+157	val_157	2008-12-31	11
+378	val_378	2008-12-31	11
+221	val_221	2008-12-31	11
+92	val_92	2008-12-31	11
+111	val_111	2008-12-31	11
+47	val_47	2008-12-31	11
+72	val_72	2008-12-31	11
+4	val_4	2008-12-31	11
+280	val_280	2008-12-31	11
+35	val_35	2008-12-31	11
+427	val_427	2008-12-31	11
+277	val_277	2008-12-31	11
+208	val_208	2008-12-31	11
+356	val_356	2008-12-31	11
+399	val_399	2008-12-31	11
+169	val_169	2008-12-31	11
+382	val_382	2008-12-31	11
+498	val_498	2008-12-31	11
+125	val_125	2008-12-31	11
+386	val_386	2008-12-31	11
+437	val_437	2008-12-31	11
+469	val_469	2008-12-31	11
+192	val_192	2008-12-31	11
+286	val_286	2008-12-31	11
+187	val_187	2008-12-31	11
+176	val_176	2008-12-31	11
+54	val_54	2008-12-31	11
+459	val_459	2008-12-31	11
+51	val_51	2008-12-31	11
+138	val_138	2008-12-31	11
+103	val_103	2008-12-31	11
+239	val_239	2008-12-31	11
+213	val_213	2008-12-31	11
+216	val_216	2008-12-31	11
+430	val_430	2008-12-31	11
+278	val_278	2008-12-31	11
+176	val_176	2008-12-31	11
+289	val_289	2008-12-31	11
+221	val_221	2008-12-31	11
+65	val_65	2008-12-31	11
+318	val_318	2008-12-31	11
+332	val_332	2008-12-31	11
+311	val_311	2008-12-31	11
+275	val_275	2008-12-31	11
+137	val_137	2008-12-31	11
+241	val_241	2008-12-31	11
+83	val_83	2008-12-31	11
+333	val_333	2008-12-31	11
+180	val_180	2008-12-31	11
+284	val_284	2008-12-31	11
+12	val_12	2008-12-31	11
+230	val_230	2008-12-31	11
+181	val_181	2008-12-31	11
+67	val_67	2008-12-31	11
+260	val_260	2008-12-31	11
+404	val_404	2008-12-31	11
+384	val_384	2008-12-31	11
+489	val_489	2008-12-31	11
+353	val_353	2008-12-31	11
+373	val_373	2008-12-31	11
+272	val_272	2008-12-31	11
+138	val_138	2008-12-31	11
+217	val_217	2008-12-31	11
+84	val_84	2008-12-31	11
+348	val_348	2008-12-31	11
+466	val_466	2008-12-31	11
+58	val_58	2008-12-31	11
+8	val_8	2008-12-31	11
+411	val_411	2008-12-31	11
+230	val_230	2008-12-31	11
+208	val_208	2008-12-31	11
+348	val_348	2008-12-31	11
+24	val_24	2008-12-31	11
+463	val_463	2008-12-31	11
+431	val_431	2008-12-31	11
+179	val_179	2008-12-31	11
+172	val_172	2008-12-31	11
+42	val_42	2008-12-31	11
+129	val_129	2008-12-31	11
+158	val_158	2008-12-31	11
+119	val_119	2008-12-31	11
+496	val_496	2008-12-31	11
+0	val_0	2008-12-31	11
+322	val_322	2008-12-31	11
+197	val_197	2008-12-31	11
+468	val_468	2008-12-31	11
+393	val_393	2008-12-31	11
+454	val_454	2008-12-31	11
+100	val_100	2008-12-31	11
+298	val_298	2008-12-31	11
+199	val_199	2008-12-31	11
+191	val_191	2008-12-31	11
+418	val_418	2008-12-31	11
+96	val_96	2008-12-31	11
+26	val_26	2008-12-31	11
+165	val_165	2008-12-31	11
+327	val_327	2008-12-31	11
+230	val_230	2008-12-31	11
+205	val_205	2008-12-31	11
+120	val_120	2008-12-31	11
+131	val_131	2008-12-31	11
+51	val_51	2008-12-31	11
+404	val_404	2008-12-31	11
+43	val_43	2008-12-31	11
+436	val_436	2008-12-31	11
+156	val_156	2008-12-31	11
+469	val_469	2008-12-31	11
+468	val_468	2008-12-31	11
+308	val_308	2008-12-31	11
+95	val_95	2008-12-31	11
+196	val_196	2008-12-31	11
+288	val_288	2008-12-31	11
+481	val_481	2008-12-31	11
+457	val_457	2008-12-31	11
+98	val_98	2008-12-31	11
+282	val_282	2008-12-31	11
+197	val_197	2008-12-31	11
+187	val_187	2008-12-31	11
+318	val_318	2008-12-31	11
+318	val_318	2008-12-31	11
+409	val_409	2008-12-31	11
+470	val_470	2008-12-31	11
+137	val_137	2008-12-31	11
+369	val_369	2008-12-31	11
+316	val_316	2008-12-31	11
+169	val_169	2008-12-31	11
+413	val_413	2008-12-31	11
+85	val_85	2008-12-31	11
+77	val_77	2008-12-31	11
+0	val_0	2008-12-31	11
+490	val_490	2008-12-31	11
+87	val_87	2008-12-31	11
+364	val_364	2008-12-31	11
+179	val_179	2008-12-31	11
+118	val_118	2008-12-31	11
+134	val_134	2008-12-31	11
+395	val_395	2008-12-31	11
+282	val_282	2008-12-31	11
+138	val_138	2008-12-31	11
+238	val_238	2008-12-31	11
+419	val_419	2008-12-31	11
+15	val_15	2008-12-31	11
+118	val_118	2008-12-31	11
+72	val_72	2008-12-31	11
+90	val_90	2008-12-31	11
+307	val_307	2008-12-31	11
+19	val_19	2008-12-31	11
+435	val_435	2008-12-31	11
+10	val_10	2008-12-31	11
+277	val_277	2008-12-31	11
+273	val_273	2008-12-31	11
+306	val_306	2008-12-31	11
+224	val_224	2008-12-31	11
+309	val_309	2008-12-31	11
+389	val_389	2008-12-31	11
+327	val_327	2008-12-31	11
+242	val_242	2008-12-31	11
+369	val_369	2008-12-31	11
+392	val_392	2008-12-31	11
+272	val_272	2008-12-31	11
+331	val_331	2008-12-31	11
+401	val_401	2008-12-31	11
+242	val_242	2008-12-31	11
+452	val_452	2008-12-31	11
+177	val_177	2008-12-31	11
+226	val_226	2008-12-31	11
+5	val_5	2008-12-31	11
+497	val_497	2008-12-31	11
+402	val_402	2008-12-31	11
+396	val_396	2008-12-31	11
+317	val_317	2008-12-31	11
+395	val_395	2008-12-31	11
+58	val_58	2008-12-31	11
+35	val_35	2008-12-31	11
+336	val_336	2008-12-31	11
+95	val_95	2008-12-31	11
+11	val_11	2008-12-31	11
+168	val_168	2008-12-31	11
+34	val_34	2008-12-31	11
+229	val_229	2008-12-31	11
+233	val_233	2008-12-31	11
+143	val_143	2008-12-31	11
+472	val_472	2008-12-31	11
+322	val_322	2008-12-31	11
+498	val_498	2008-12-31	11
+160	val_160	2008-12-31	11
+195	val_195	2008-12-31	11
+42	val_42	2008-12-31	11
+321	val_321	2008-12-31	11
+430	val_430	2008-12-31	11
+119	val_119	2008-12-31	11
+489	val_489	2008-12-31	11
+458	val_458	2008-12-31	11
+78	val_78	2008-12-31	11
+76	val_76	2008-12-31	11
+41	val_41	2008-12-31	11
+223	val_223	2008-12-31	11
+492	val_492	2008-12-31	11
+149	val_149	2008-12-31	11
+449	val_449	2008-12-31	11
+218	val_218	2008-12-31	11
+228	val_228	2008-12-31	11
+138	val_138	2008-12-31	11
+453	val_453	2008-12-31	11
+30	val_30	2008-12-31	11
+209	val_209	2008-12-31	11
+64	val_64	2008-12-31	11
+468	val_468	2008-12-31	11
+76	val_76	2008-12-31	11
+74	val_74	2008-12-31	11
+342	val_342	2008-12-31	11
+69	val_69	2008-12-31	11
+230	val_230	2008-12-31	11
+33	val_33	2008-12-31	11
+368	val_368	2008-12-31	11
+103	val_103	2008-12-31	11
+296	val_296	2008-12-31	11
+113	val_113	2008-12-31	11
+216	val_216	2008-12-31	11
+367	val_367	2008-12-31	11
+344	val_344	2008-12-31	11
+167	val_167	2008-12-31	11
+274	val_274	2008-12-31	11
+219	val_219	2008-12-31	11
+239	val_239	2008-12-31	11
+485	val_485	2008-12-31	11
+116	val_116	2008-12-31	11
+223	val_223	2008-12-31	11
+256	val_256	2008-12-31	11
+263	val_263	2008-12-31	11
+70	val_70	2008-12-31	11
+487	val_487	2008-12-31	11
+480	val_480	2008-12-31	11
+401	val_401	2008-12-31	11
+288	val_288	2008-12-31	11
+191	val_191	2008-12-31	11
+5	val_5	2008-12-31	11
+244	val_244	2008-12-31	11
+438	val_438	2008-12-31	11
+128	val_128	2008-12-31	11
+467	val_467	2008-12-31	11
+432	val_432	2008-12-31	11
+202	val_202	2008-12-31	11
+316	val_316	2008-12-31	11
+229	val_229	2008-12-31	11
+469	val_469	2008-12-31	11
+463	val_463	2008-12-31	11
+280	val_280	2008-12-31	11
+2	val_2	2008-12-31	11
+35	val_35	2008-12-31	11
+283	val_283	2008-12-31	11
+331	val_331	2008-12-31	11
+235	val_235	2008-12-31	11
+80	val_80	2008-12-31	11
+44	val_44	2008-12-31	11
+193	val_193	2008-12-31	11
+321	val_321	2008-12-31	11
+335	val_335	2008-12-31	11
+104	val_104	2008-12-31	11
+466	val_466	2008-12-31	11
+366	val_366	2008-12-31	11
+175	val_175	2008-12-31	11
+403	val_403	2008-12-31	11
+483	val_483	2008-12-31	11
+53	val_53	2008-12-31	11
+105	val_105	2008-12-31	11
+257	val_257	2008-12-31	11
+406	val_406	2008-12-31	11
+409	val_409	2008-12-31	11
+190	val_190	2008-12-31	11
+406	val_406	2008-12-31	11
+401	val_401	2008-12-31	11
+114	val_114	2008-12-31	11
+258	val_258	2008-12-31	11
+90	val_90	2008-12-31	11
+203	val_203	2008-12-31	11
+262	val_262	2008-12-31	11
+348	val_348	2008-12-31	11
+424	val_424	2008-12-31	11
+12	val_12	2008-12-31	11
+396	val_396	2008-12-31	11
+201	val_201	2008-12-31	11
+217	val_217	2008-12-31	11
+164	val_164	2008-12-31	11
+431	val_431	2008-12-31	11
+454	val_454	2008-12-31	11
+478	val_478	2008-12-31	11
+298	val_298	2008-12-31	11
+125	val_125	2008-12-31	11
+431	val_431	2008-12-31	11
+164	val_164	2008-12-31	11
+424	val_424	2008-12-31	11
+187	val_187	2008-12-31	11
+382	val_382	2008-12-31	11
+5	val_5	2008-12-31	11
+70	val_70	2008-12-31	11
+397	val_397	2008-12-31	11
+480	val_480	2008-12-31	11
+291	val_291	2008-12-31	11
+24	val_24	2008-12-31	11
+351	val_351	2008-12-31	11
+255	val_255	2008-12-31	11
+104	val_104	2008-12-31	11
+70	val_70	2008-12-31	11
+163	val_163	2008-12-31	11
+438	val_438	2008-12-31	11
+119	val_119	2008-12-31	11
+414	val_414	2008-12-31	11
+200	val_200	2008-12-31	11
+491	val_491	2008-12-31	11
+237	val_237	2008-12-31	11
+439	val_439	2008-12-31	11
+360	val_360	2008-12-31	11
+248	val_248	2008-12-31	11
+479	val_479	2008-12-31	11
+305	val_305	2008-12-31	11
+417	val_417	2008-12-31	11
+199	val_199	2008-12-31	11
+444	val_444	2008-12-31	11
+120	val_120	2008-12-31	11
+429	val_429	2008-12-31	11
+169	val_169	2008-12-31	11
+443	val_443	2008-12-31	11
+323	val_323	2008-12-31	11
+325	val_325	2008-12-31	11
+277	val_277	2008-12-31	11
+230	val_230	2008-12-31	11
+478	val_478	2008-12-31	11
+178	val_178	2008-12-31	11
+468	val_468	2008-12-31	11
+310	val_310	2008-12-31	11
+317	val_317	2008-12-31	11
+333	val_333	2008-12-31	11
+493	val_493	2008-12-31	11
+460	val_460	2008-12-31	11
+207	val_207	2008-12-31	11
+249	val_249	2008-12-31	11
+265	val_265	2008-12-31	11
+480	val_480	2008-12-31	11
+83	val_83	2008-12-31	11
+136	val_136	2008-12-31	11
+353	val_353	2008-12-31	11
+172	val_172	2008-12-31	11
+214	val_214	2008-12-31	11
+462	val_462	2008-12-31	11
+233	val_233	2008-12-31	11
+406	val_406	2008-12-31	11
+133	val_133	2008-12-31	11
+175	val_175	2008-12-31	11
+189	val_189	2008-12-31	11
+454	val_454	2008-12-31	11
+375	val_375	2008-12-31	11
+401	val_401	2008-12-31	11
+421	val_421	2008-12-31	11
+407	val_407	2008-12-31	11
+384	val_384	2008-12-31	11
+256	val_256	2008-12-31	11
+26	val_26	2008-12-31	11
+134	val_134	2008-12-31	11
+67	val_67	2008-12-31	11
+384	val_384	2008-12-31	11
+379	val_379	2008-12-31	11
+18	val_18	2008-12-31	11
+462	val_462	2008-12-31	11
+492	val_492	2008-12-31	11
+100	val_100	2008-12-31	11
+298	val_298	2008-12-31	11
+9	val_9	2008-12-31	11
+341	val_341	2008-12-31	11
+498	val_498	2008-12-31	11
+146	val_146	2008-12-31	11
+458	val_458	2008-12-31	11
+362	val_362	2008-12-31	11
+186	val_186	2008-12-31	11
+285	val_285	2008-12-31	11
+348	val_348	2008-12-31	11
+167	val_167	2008-12-31	11
+18	val_18	2008-12-31	11
+273	val_273	2008-12-31	11
+183	val_183	2008-12-31	11
+281	val_281	2008-12-31	11
+344	val_344	2008-12-31	11
+97	val_97	2008-12-31	11
+469	val_469	2008-12-31	11
+315	val_315	2008-12-31	11
+84	val_84	2008-12-31	11
+28	val_28	2008-12-31	11
+37	val_37	2008-12-31	11
+448	val_448	2008-12-31	11
+152	val_152	2008-12-31	11
+348	val_348	2008-12-31	11
+307	val_307	2008-12-31	11
+194	val_194	2008-12-31	11
+414	val_414	2008-12-31	11
+477	val_477	2008-12-31	11
+222	val_222	2008-12-31	11
+126	val_126	2008-12-31	11
+90	val_90	2008-12-31	11
+169	val_169	2008-12-31	11
+403	val_403	2008-12-31	11
+400	val_400	2008-12-31	11
+200	val_200	2008-12-31	11
+97	val_97	2008-12-31	11
+238	val_238	2008-12-31	12
+86	val_86	2008-12-31	12
+311	val_311	2008-12-31	12
+27	val_27	2008-12-31	12
+165	val_165	2008-12-31	12
+409	val_409	2008-12-31	12
+255	val_255	2008-12-31	12
+278	val_278	2008-12-31	12
+98	val_98	2008-12-31	12
+484	val_484	2008-12-31	12
+265	val_265	2008-12-31	12
+193	val_193	2008-12-31	12
+401	val_401	2008-12-31	12
+150	val_150	2008-12-31	12
+273	val_273	2008-12-31	12
+224	val_224	2008-12-31	12
+369	val_369	2008-12-31	12
+66	val_66	2008-12-31	12
+128	val_128	2008-12-31	12
+213	val_213	2008-12-31	12
+146	val_146	2008-12-31	12
+406	val_406	2008-12-31	12
+429	val_429	2008-12-31	12
+374	val_374	2008-12-31	12
+152	val_152	2008-12-31	12
+469	val_469	2008-12-31	12
+145	val_145	2008-12-31	12
+495	val_495	2008-12-31	12
+37	val_37	2008-12-31	12
+327	val_327	2008-12-31	12
+281	val_281	2008-12-31	12
+277	val_277	2008-12-31	12
+209	val_209	2008-12-31	12
+15	val_15	2008-12-31	12
+82	val_82	2008-12-31	12
+403	val_403	2008-12-31	12
+166	val_166	2008-12-31	12
+417	val_417	2008-12-31	12
+430	val_430	2008-12-31	12
+252	val_252	2008-12-31	12
+292	val_292	2008-12-31	12
+219	val_219	2008-12-31	12
+287	val_287	2008-12-31	12
+153	val_153	2008-12-31	12
+193	val_193	2008-12-31	12
+338	val_338	2008-12-31	12
+446	val_446	2008-12-31	12
+459	val_459	2008-12-31	12
+394	val_394	2008-12-31	12
+237	val_237	2008-12-31	12
+482	val_482	2008-12-31	12
+174	val_174	2008-12-31	12
+413	val_413	2008-12-31	12
+494	val_494	2008-12-31	12
+207	val_207	2008-12-31	12
+199	val_199	2008-12-31	12
+466	val_466	2008-12-31	12
+208	val_208	2008-12-31	12
+174	val_174	2008-12-31	12
+399	val_399	2008-12-31	12
+396	val_396	2008-12-31	12
+247	val_247	2008-12-31	12
+417	val_417	2008-12-31	12
+489	val_489	2008-12-31	12
+162	val_162	2008-12-31	12
+377	val_377	2008-12-31	12
+397	val_397	2008-12-31	12
+309	val_309	2008-12-31	12
+365	val_365	2008-12-31	12
+266	val_266	2008-12-31	12
+439	val_439	2008-12-31	12
+342	val_342	2008-12-31	12
+367	val_367	2008-12-31	12
+325	val_325	2008-12-31	12
+167	val_167	2008-12-31	12
+195	val_195	2008-12-31	12
+475	val_475	2008-12-31	12
+17	val_17	2008-12-31	12
+113	val_113	2008-12-31	12
+155	val_155	2008-12-31	12
+203	val_203	2008-12-31	12
+339	val_339	2008-12-31	12
+0	val_0	2008-12-31	12
+455	val_455	2008-12-31	12
+128	val_128	2008-12-31	12
+311	val_311	2008-12-31	12
+316	val_316	2008-12-31	12
+57	val_57	2008-12-31	12
+302	val_302	2008-12-31	12
+205	val_205	2008-12-31	12
+149	val_149	2008-12-31	12
+438	val_438	2008-12-31	12
+345	val_345	2008-12-31	12
+129	val_129	2008-12-31	12
+170	val_170	2008-12-31	12
+20	val_20	2008-12-31	12
+489	val_489	2008-12-31	12
+157	val_157	2008-12-31	12
+378	val_378	2008-12-31	12
+221	val_221	2008-12-31	12
+92	val_92	2008-12-31	12
+111	val_111	2008-12-31	12
+47	val_47	2008-12-31	12
+72	val_72	2008-12-31	12
+4	val_4	2008-12-31	12
+280	val_280	2008-12-31	12
+35	val_35	2008-12-31	12
+427	val_427	2008-12-31	12
+277	val_277	2008-12-31	12
+208	val_208	2008-12-31	12
+356	val_356	2008-12-31	12
+399	val_399	2008-12-31	12
+169	val_169	2008-12-31	12
+382	val_382	2008-12-31	12
+498	val_498	2008-12-31	12
+125	val_125	2008-12-31	12
+386	val_386	2008-12-31	12
+437	val_437	2008-12-31	12
+469	val_469	2008-12-31	12
+192	val_192	2008-12-31	12
+286	val_286	2008-12-31	12
+187	val_187	2008-12-31	12
+176	val_176	2008-12-31	12
+54	val_54	2008-12-31	12
+459	val_459	2008-12-31	12
+51	val_51	2008-12-31	12
+138	val_138	2008-12-31	12
+103	val_103	2008-12-31	12
+239	val_239	2008-12-31	12
+213	val_213	2008-12-31	12
+216	val_216	2008-12-31	12
+430	val_430	2008-12-31	12
+278	val_278	2008-12-31	12
+176	val_176	2008-12-31	12
+289	val_289	2008-12-31	12
+221	val_221	2008-12-31	12
+65	val_65	2008-12-31	12
+318	val_318	2008-12-31	12
+332	val_332	2008-12-31	12
+311	val_311	2008-12-31	12
+275	val_275	2008-12-31	12
+137	val_137	2008-12-31	12
+241	val_241	2008-12-31	12
+83	val_83	2008-12-31	12
+333	val_333	2008-12-31	12
+180	val_180	2008-12-31	12
+284	val_284	2008-12-31	12
+12	val_12	2008-12-31	12
+230	val_230	2008-12-31	12
+181	val_181	2008-12-31	12
+67	val_67	2008-12-31	12
+260	val_260	2008-12-31	12
+404	val_404	2008-12-31	12
+384	val_384	2008-12-31	12
+489	val_489	2008-12-31	12
+353	val_353	2008-12-31	12
+373	val_373	2008-12-31	12
+272	val_272	2008-12-31	12
+138	val_138	2008-12-31	12
+217	val_217	2008-12-31	12
+84	val_84	2008-12-31	12
+348	val_348	2008-12-31	12
+466	val_466	2008-12-31	12
+58	val_58	2008-12-31	12
+8	val_8	2008-12-31	12
+411	val_411	2008-12-31	12
+230	val_230	2008-12-31	12
+208	val_208	2008-12-31	12
+348	val_348	2008-12-31	12
+24	val_24	2008-12-31	12
+463	val_463	2008-12-31	12
+431	val_431	2008-12-31	12
+179	val_179	2008-12-31	12
+172	val_172	2008-12-31	12
+42	val_42	2008-12-31	12
+129	val_129	2008-12-31	12
+158	val_158	2008-12-31	12
+119	val_119	2008-12-31	12
+496	val_496	2008-12-31	12
+0	val_0	2008-12-31	12
+322	val_322	2008-12-31	12
+197	val_197	2008-12-31	12
+468	val_468	2008-12-31	12
+393	val_393	2008-12-31	12
+454	val_454	2008-12-31	12
+100	val_100	2008-12-31	12
+298	val_298	2008-12-31	12
+199	val_199	2008-12-31	12
+191	val_191	2008-12-31	12
+418	val_418	2008-12-31	12
+96	val_96	2008-12-31	12
+26	val_26	2008-12-31	12
+165	val_165	2008-12-31	12
+327	val_327	2008-12-31	12
+230	val_230	2008-12-31	12
+205	val_205	2008-12-31	12
+120	val_120	2008-12-31	12
+131	val_131	2008-12-31	12
+51	val_51	2008-12-31	12
+404	val_404	2008-12-31	12
+43	val_43	2008-12-31	12
+436	val_436	2008-12-31	12
+156	val_156	2008-12-31	12
+469	val_469	2008-12-31	12
+468	val_468	2008-12-31	12
+308	val_308	2008-12-31	12
+95	val_95	2008-12-31	12
+196	val_196	2008-12-31	12
+288	val_288	2008-12-31	12
+481	val_481	2008-12-31	12
+457	val_457	2008-12-31	12
+98	val_98	2008-12-31	12
+282	val_282	2008-12-31	12
+197	val_197	2008-12-31	12
+187	val_187	2008-12-31	12
+318	val_318	2008-12-31	12
+318	val_318	2008-12-31	12
+409	val_409	2008-12-31	12
+470	val_470	2008-12-31	12
+137	val_137	2008-12-31	12
+369	val_369	2008-12-31	12
+316	val_316	2008-12-31	12
+169	val_169	2008-12-31	12
+413	val_413	2008-12-31	12
+85	val_85	2008-12-31	12
+77	val_77	2008-12-31	12
+0	val_0	2008-12-31	12
+490	val_490	2008-12-31	12
+87	val_87	2008-12-31	12
+364	val_364	2008-12-31	12
+179	val_179	2008-12-31	12
+118	val_118	2008-12-31	12
+134	val_134	2008-12-31	12
+395	val_395	2008-12-31	12
+282	val_282	2008-12-31	12
+138	val_138	2008-12-31	12
+238	val_238	2008-12-31	12
+419	val_419	2008-12-31	12
+15	val_15	2008-12-31	12
+118	val_118	2008-12-31	12
+72	val_72	2008-12-31	12
+90	val_90	2008-12-31	12
+307	val_307	2008-12-31	12
+19	val_19	2008-12-31	12
+435	val_435	2008-12-31	12
+10	val_10	2008-12-31	12
+277	val_277	2008-12-31	12
+273	val_273	2008-12-31	12
+306	val_306	2008-12-31	12
+224	val_224	2008-12-31	12
+309	val_309	2008-12-31	12
+389	val_389	2008-12-31	12
+327	val_327	2008-12-31	12
+242	val_242	2008-12-31	12
+369	val_369	2008-12-31	12
+392	val_392	2008-12-31	12
+272	val_272	2008-12-31	12
+331	val_331	2008-12-31	12
+401	val_401	2008-12-31	12
+242	val_242	2008-12-31	12
+452	val_452	2008-12-31	12
+177	val_177	2008-12-31	12
+226	val_226	2008-12-31	12
+5	val_5	2008-12-31	12
+497	val_497	2008-12-31	12
+402	val_402	2008-12-31	12
+396	val_396	2008-12-31	12
+317	val_317	2008-12-31	12
+395	val_395	2008-12-31	12
+58	val_58	2008-12-31	12
+35	val_35	2008-12-31	12
+336	val_336	2008-12-31	12
+95	val_95	2008-12-31	12
+11	val_11	2008-12-31	12
+168	val_168	2008-12-31	12
+34	val_34	2008-12-31	12
+229	val_229	2008-12-31	12
+233	val_233	2008-12-31	12
+143	val_143	2008-12-31	12
+472	val_472	2008-12-31	12
+322	val_322	2008-12-31	12
+498	val_498	2008-12-31	12
+160	val_160	2008-12-31	12
+195	val_195	2008-12-31	12
+42	val_42	2008-12-31	12
+321	val_321	2008-12-31	12
+430	val_430	2008-12-31	12
+119	val_119	2008-12-31	12
+489	val_489	2008-12-31	12
+458	val_458	2008-12-31	12
+78	val_78	2008-12-31	12
+76	val_76	2008-12-31	12
+41	val_41	2008-12-31	12
+223	val_223	2008-12-31	12
+492	val_492	2008-12-31	12
+149	val_149	2008-12-31	12
+449	val_449	2008-12-31	12
+218	val_218	2008-12-31	12
+228	val_228	2008-12-31	12
+138	val_138	2008-12-31	12
+453	val_453	2008-12-31	12
+30	val_30	2008-12-31	12
+209	val_209	2008-12-31	12
+64	val_64	2008-12-31	12
+468	val_468	2008-12-31	12
+76	val_76	2008-12-31	12
+74	val_74	2008-12-31	12
+342	val_342	2008-12-31	12
+69	val_69	2008-12-31	12
+230	val_230	2008-12-31	12
+33	val_33	2008-12-31	12
+368	val_368	2008-12-31	12
+103	val_103	2008-12-31	12
+296	val_296	2008-12-31	12
+113	val_113	2008-12-31	12
+216	val_216	2008-12-31	12
+367	val_367	2008-12-31	12
+344	val_344	2008-12-31	12
+167	val_167	2008-12-31	12
+274	val_274	2008-12-31	12
+219	val_219	2008-12-31	12
+239	val_239	2008-12-31	12
+485	val_485	2008-12-31	12
+116	val_116	2008-12-31	12
+223	val_223	2008-12-31	12
+256	val_256	2008-12-31	12
+263	val_263	2008-12-31	12
+70	val_70	2008-12-31	12
+487	val_487	2008-12-31	12
+480	val_480	2008-12-31	12
+401	val_401	2008-12-31	12
+288	val_288	2008-12-31	12
+191	val_191	2008-12-31	12
+5	val_5	2008-12-31	12
+244	val_244	2008-12-31	12
+438	val_438	2008-12-31	12
+128	val_128	2008-12-31	12
+467	val_467	2008-12-31	12
+432	val_432	2008-12-31	12
+202	val_202	2008-12-31	12
+316	val_316	2008-12-31	12
+229	val_229	2008-12-31	12
+469	val_469	2008-12-31	12
+463	val_463	2008-12-31	12
+280	val_280	2008-12-31	12
+2	val_2	2008-12-31	12
+35	val_35	2008-12-31	12
+283	val_283	2008-12-31	12
+331	val_331	2008-12-31	12
+235	val_235	2008-12-31	12
+80	val_80	2008-12-31	12
+44	val_44	2008-12-31	12
+193	val_193	2008-12-31	12
+321	val_321	2008-12-31	12
+335	val_335	2008-12-31	12
+104	val_104	2008-12-31	12
+466	val_466	2008-12-31	12
+366	val_366	2008-12-31	12
+175	val_175	2008-12-31	12
+403	val_403	2008-12-31	12
+483	val_483	2008-12-31	12
+53	val_53	2008-12-31	12
+105	val_105	2008-12-31	12
+257	val_257	2008-12-31	12
+406	val_406	2008-12-31	12
+409	val_409	2008-12-31	12
+190	val_190	2008-12-31	12
+406	val_406	2008-12-31	12
+401	val_401	2008-12-31	12
+114	val_114	2008-12-31	12
+258	val_258	2008-12-31	12
+90	val_90	2008-12-31	12
+203	val_203	2008-12-31	12
+262	val_262	2008-12-31	12
+348	val_348	2008-12-31	12
+424	val_424	2008-12-31	12
+12	val_12	2008-12-31	12
+396	val_396	2008-12-31	12
+201	val_201	2008-12-31	12
+217	val_217	2008-12-31	12
+164	val_164	2008-12-31	12
+431	val_431	2008-12-31	12
+454	val_454	2008-12-31	12
+478	val_478	2008-12-31	12
+298	val_298	2008-12-31	12
+125	val_125	2008-12-31	12
+431	val_431	2008-12-31	12
+164	val_164	2008-12-31	12
+424	val_424	2008-12-31	12
+187	val_187	2008-12-31	12
+382	val_382	2008-12-31	12
+5	val_5	2008-12-31	12
+70	val_70	2008-12-31	12
+397	val_397	2008-12-31	12
+480	val_480	2008-12-31	12
+291	val_291	2008-12-31	12
+24	val_24	2008-12-31	12
+351	val_351	2008-12-31	12
+255	val_255	2008-12-31	12
+104	val_104	2008-12-31	12
+70	val_70	2008-12-31	12
+163	val_163	2008-12-31	12
+438	val_438	2008-12-31	12
+119	val_119	2008-12-31	12
+414	val_414	2008-12-31	12
+200	val_200	2008-12-31	12
+491	val_491	2008-12-31	12
+237	val_237	2008-12-31	12
+439	val_439	2008-12-31	12
+360	val_360	2008-12-31	12
+248	val_248	2008-12-31	12
+479	val_479	2008-12-31	12
+305	val_305	2008-12-31	12
+417	val_417	2008-12-31	12
+199	val_199	2008-12-31	12
+444	val_444	2008-12-31	12
+120	val_120	2008-12-31	12
+429	val_429	2008-12-31	12
+169	val_169	2008-12-31	12
+443	val_443	2008-12-31	12
+323	val_323	2008-12-31	12
+325	val_325	2008-12-31	12
+277	val_277	2008-12-31	12
+230	val_230	2008-12-31	12
+478	val_478	2008-12-31	12
+178	val_178	2008-12-31	12
+468	val_468	2008-12-31	12
+310	val_310	2008-12-31	12
+317	val_317	2008-12-31	12
+333	val_333	2008-12-31	12
+493	val_493	2008-12-31	12
+460	val_460	2008-12-31	12
+207	val_207	2008-12-31	12
+249	val_249	2008-12-31	12
+265	val_265	2008-12-31	12
+480	val_480	2008-12-31	12
+83	val_83	2008-12-31	12
+136	val_136	2008-12-31	12
+353	val_353	2008-12-31	12
+172	val_172	2008-12-31	12
+214	val_214	2008-12-31	12
+462	val_462	2008-12-31	12
+233	val_233	2008-12-31	12
+406	val_406	2008-12-31	12
+133	val_133	2008-12-31	12
+175	val_175	2008-12-31	12
+189	val_189	2008-12-31	12
+454	val_454	2008-12-31	12
+375	val_375	2008-12-31	12
+401	val_401	2008-12-31	12
+421	val_421	2008-12-31	12
+407	val_407	2008-12-31	12
+384	val_384	2008-12-31	12
+256	val_256	2008-12-31	12
+26	val_26	2008-12-31	12
+134	val_134	2008-12-31	12
+67	val_67	2008-12-31	12
+384	val_384	2008-12-31	12
+379	val_379	2008-12-31	12
+18	val_18	2008-12-31	12
+462	val_462	2008-12-31	12
+492	val_492	2008-12-31	12
+100	val_100	2008-12-31	12
+298	val_298	2008-12-31	12
+9	val_9	2008-12-31	12
+341	val_341	2008-12-31	12
+498	val_498	2008-12-31	12
+146	val_146	2008-12-31	12
+458	val_458	2008-12-31	12
+362	val_362	2008-12-31	12
+186	val_186	2008-12-31	12
+285	val_285	2008-12-31	12
+348	val_348	2008-12-31	12
+167	val_167	2008-12-31	12
+18	val_18	2008-12-31	12
+273	val_273	2008-12-31	12
+183	val_183	2008-12-31	12
+281	val_281	2008-12-31	12
+344	val_344	2008-12-31	12
+97	val_97	2008-12-31	12
+469	val_469	2008-12-31	12
+315	val_315	2008-12-31	12
+84	val_84	2008-12-31	12
+28	val_28	2008-12-31	12
+37	val_37	2008-12-31	12
+448	val_448	2008-12-31	12
+152	val_152	2008-12-31	12
+348	val_348	2008-12-31	12
+307	val_307	2008-12-31	12
+194	val_194	2008-12-31	12
+414	val_414	2008-12-31	12
+477	val_477	2008-12-31	12
+222	val_222	2008-12-31	12
+126	val_126	2008-12-31	12
+90	val_90	2008-12-31	12
+169	val_169	2008-12-31	12
+403	val_403	2008-12-31	12
+400	val_400	2008-12-31	12
+200	val_200	2008-12-31	12
+97	val_97	2008-12-31	12
+PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
+CreateTime:         	Tue Sep 21 01:11:18 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056678          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
+CreateTime:         	Tue Sep 21 01:11:18 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056679          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+CreateTime:         	Tue Sep 21 01:11:20 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2/ds=2008-12-31/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056680          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+CreateTime:         	Tue Sep 21 01:11:20 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2/ds=2008-12-31/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056681          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part1
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:11:04 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285056679          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:11:04 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285056681          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: drop table nzhang_part1
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@nzhang_part1
+PREHOOK: Output: default@nzhang_part1
+POSTHOOK: query: drop table nzhang_part1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@nzhang_part1
+POSTHOOK: Output: default@nzhang_part1
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: drop table nzhang_part2
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@nzhang_part2
+PREHOOK: Output: default@nzhang_part2
+POSTHOOK: query: drop table nzhang_part2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@nzhang_part2
+POSTHOOK: Output: default@nzhang_part2
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/smb_mapjoin_6.q.out
===================================================================
--- ql/src/test/results/clientpositive/smb_mapjoin_6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/smb_mapjoin_6.q.out	(working copy)
@@ -62,6 +62,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -123,7 +124,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: smb_join_results
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table smb_join_results
 select /*+mapjoin(a)*/ * from smb_bucket4_1 a join smb_bucket4_2 b on a.key = b.key
 PREHOOK: type: QUERY
@@ -147,11 +151,11 @@
 PREHOOK: query: select * from smb_join_results order by k1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-43-58_355_4241912694869470636/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-42-55_279_7791327046962948852/-mr-10000
 POSTHOOK: query: select * from smb_join_results order by k1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-43-58_355_4241912694869470636/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-42-55_279_7791327046962948852/-mr-10000
 POSTHOOK: Lineage: smb_bucket4_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_bucket4_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_bucket4_2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1213,11 +1217,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@normal_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-07_386_5215362180353440890/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-08_043_5392784140667926398/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@normal_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-07_386_5215362180353440890/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-08_043_5392784140667926398/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:from deserializer), ]
@@ -1234,11 +1238,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-10_503_5044933337669213788/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-11_731_2929158753603213416/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-10_503_5044933337669213788/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-11_731_2929158753603213416/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:from deserializer), ]
@@ -1278,6 +1282,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -1339,7 +1344,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: smb_join_results
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table smb_join_results
 select /*+mapjoin(b)*/ * from smb_bucket4_1 a join smb_bucket4_2 b on a.key = b.key
 PREHOOK: type: QUERY
@@ -1403,11 +1411,11 @@
 PREHOOK: query: select * from smb_join_results order by k1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-21_789_8349972338199515523/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-31_563_4706124973124003834/-mr-10000
 POSTHOOK: query: select * from smb_join_results order by k1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-21_789_8349972338199515523/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-31_563_4706124973124003834/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:from deserializer), ]
@@ -2493,11 +2501,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@normal_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-30_839_4771778288932582310/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-45_165_8849292789711497460/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@normal_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-30_839_4771778288932582310/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-45_165_8849292789711497460/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
@@ -2526,11 +2534,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-33_938_44080156296442227/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-48_878_3474963241024457613/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-33_938_44080156296442227/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-43-48_878_3474963241024457613/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
@@ -2594,6 +2602,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2659,7 +2668,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: smb_join_results
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table smb_join_results
 select /*+mapjoin(a)*/ * from smb_bucket4_1 a join smb_bucket4_2 b on a.key = b.key where a.key>1000
 PREHOOK: type: QUERY
@@ -2742,6 +2754,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2811,7 +2824,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: smb_join_results
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table smb_join_results
 select /*+mapjoin(b)*/ * from smb_bucket4_1 a join smb_bucket4_2 b on a.key = b.key where a.key>1000
 PREHOOK: type: QUERY
@@ -2977,12 +2993,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_bucket4_1
 PREHOOK: Input: default@smb_bucket4_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-46_257_446569303031962295/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-11_081_2683450931844732628/-mr-10000
 POSTHOOK: query: select /*+mapjoin(b,c)*/ * from smb_bucket4_1 a join smb_bucket4_2 b on a.key = b.key join smb_bucket4_2 c on b.key = c.key where a.key>1000
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_bucket4_1
 POSTHOOK: Input: default@smb_bucket4_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-44-46_257_446569303031962295/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-11_081_2683450931844732628/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:from deserializer), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/union10.q.out
===================================================================
--- ql/src/test/results/clientpositive/union10.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union10.q.out	(working copy)
@@ -28,13 +28,14 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6, Stage-7
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7, Stage-8
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
   Stage-7 is a root stage
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -80,7 +81,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-17_23-00-04_276_3788594933575479321/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_18-16-27_415_2101823753644090814/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -104,7 +105,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/nzhang/hive_2010-08-17_23-00-04_276_3788594933575479321/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-16-27_415_2101823753644090814/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -128,7 +129,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/nzhang/hive_2010-08-17_23-00-04_276_3788594933575479321/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-14_18-16-27_415_2101823753644090814/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -153,14 +154,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-04_276_3788594933575479321/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-16-27_415_2101823753644090814/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -173,9 +174,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-04_276_3788594933575479321/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-16-27_415_2101823753644090814/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -185,7 +189,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery2:unionsrc-subquery1-subquery2:s2 
@@ -225,7 +229,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s3 
@@ -289,11 +293,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-00-22_940_3211558482053780252/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-16-48_462_1984253436535360715/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-00-22_940_3211558482053780252/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-16-48_462_1984253436535360715/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src)s2.null, (src)s3.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/rcfile_null_value.q.out
===================================================================
--- ql/src/test/results/clientpositive/rcfile_null_value.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/rcfile_null_value.q.out	(working copy)
@@ -16,11 +16,11 @@
 PREHOOK: query: SELECT * FROM src1_rc
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src1_rc
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-47_002_2104750496460432907/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-21-57_139_2164061306153672083/-mr-10000
 POSTHOOK: query: SELECT * FROM src1_rc
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src1_rc
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-47_002_2104750496460432907/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-21-57_139_2164061306153672083/-mr-10000
 POSTHOOK: Lineage: src1_rc.key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src1_rc.value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
@@ -93,6 +93,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -223,7 +224,10 @@
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: dest1_rc
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -265,11 +269,11 @@
 PREHOOK: query: SELECT dest1_rc.* FROM dest1_rc
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1_rc
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-50_018_8982453667868960765/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-05_391_6302655231306765287/-mr-10000
 POSTHOOK: query: SELECT dest1_rc.* FROM dest1_rc
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1_rc
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-50_018_8982453667868960765/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-05_391_6302655231306765287/-mr-10000
 POSTHOOK: Lineage: dest1_rc.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1_rc.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1_rc.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/ppd_constant_expr.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/ppd_constant_expr.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/ppd_constant_expr.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -55,14 +56,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: ppd_constant_expr
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-46-27_316_7397975593428086505/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-34-53_763_4256834044204600052/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -75,9 +76,12 @@
               name: ppd_constant_expr
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-46-27_316_7397975593428086505/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-34-53_763_4256834044204600052/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -119,11 +123,11 @@
 PREHOOK: query: SELECT ppd_constant_expr.* FROM ppd_constant_expr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@ppd_constant_expr
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-46-29_875_7776179823012704510/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-35-00_906_8807968777797763609/-mr-10000
 POSTHOOK: query: SELECT ppd_constant_expr.* FROM ppd_constant_expr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@ppd_constant_expr
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-46-29_875_7776179823012704510/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-35-00_906_8807968777797763609/-mr-10000
 POSTHOOK: Lineage: ppd_constant_expr.c1 EXPRESSION []
 POSTHOOK: Lineage: ppd_constant_expr.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: ppd_constant_expr.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/groupby3_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby3_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby3_map_skew.q.out	(working copy)
@@ -36,6 +36,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -119,7 +120,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-23-38_951_8559728103103624706/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-15-08_373_2624482254796238588/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -218,7 +219,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT
   sum(substr(src.value,5)),
@@ -259,11 +263,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-44_381_5135448855404252228/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-19_943_1654924992322441913/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-44_381_5135448855404252228/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-19_943_1654924992322441913/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join34.q.out
===================================================================
--- ql/src/test/results/clientpositive/join34.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join34.q.out	(working copy)
@@ -28,10 +28,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -40,6 +41,7 @@
         null-subquery1:subq1-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -91,8 +93,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -102,19 +105,21 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                   name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282110886
+                                  transient_lastDdlTime 1284507653
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
         null-subquery2:subq1-subquery2:x1 
           TableScan
             alias: x1
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -166,8 +171,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -177,15 +183,16 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                   name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282110886
+                                  transient_lastDdlTime 1284507653
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -197,6 +204,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -230,8 +238,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -241,21 +250,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282110886
+                              transient_lastDdlTime 1284507653
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -266,12 +276,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110633
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -282,31 +292,31 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110633
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -316,24 +326,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110886
+                transient_lastDdlTime 1284507653
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -344,21 +358,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110886
+                    transient_lastDdlTime 1284507653
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-46_555_7665980938656510225/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-53_747_9048108600140235824/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -369,12 +384,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110886
+              transient_lastDdlTime 1284507653
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -385,12 +400,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110886
+                transient_lastDdlTime 1284507653
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -426,11 +441,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-54-50_742_4903058281649790450/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-01_352_8712511675304640347/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-54-50_742_4903058281649790450/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-01_352_8712511675304640347/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)x.FieldSchema(name:value, type:string, comment:default), (src)x1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin1.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin1.q.out	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -137,8 +139,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -148,15 +151,16 @@
                             columns.types string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                             name bucketmapjoin_tmp_result
                             serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282861665
+                            transient_lastDdlTime 1284504734
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: bucketmapjoin_tmp_result
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -168,6 +172,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -213,8 +218,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -224,29 +230,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282861665
+                                  transient_lastDdlTime 1284504734
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket21.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -258,12 +265,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861660
+              transient_lastDdlTime 1284504727
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -275,31 +282,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861660
+                transient_lastDdlTime 1284504727
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -309,24 +316,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861665
+                transient_lastDdlTime 1284504734
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -337,21 +348,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861665
+                    transient_lastDdlTime 1284504734
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-27-45_443_5246531592135492584/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-52-14_568_8446001704480162238/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -362,12 +374,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861665
+              transient_lastDdlTime 1284504734
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -378,12 +390,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861665
+                transient_lastDdlTime 1284504734
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -411,11 +423,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-27-53_775_1430223565708098665/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-26_025_7986849883515222888/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-27-53_775_1430223565708098665/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-26_025_7986849883515222888/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -464,11 +476,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-07_896_8980413570460942198/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-47_328_3277552806566207374/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-07_896_8980413570460942198/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-47_328_3277552806566207374/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -507,14 +519,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-14_304_6082586747306863372/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-57_482_1461425029485724814/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-14_304_6082586747306863372/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-52-57_482_1461425029485724814/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -557,10 +569,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -569,6 +582,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -614,8 +628,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -625,15 +640,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861687
+                              totalSize 8983
+                              transient_lastDdlTime 1284504767
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -645,6 +665,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -685,8 +706,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -696,31 +718,36 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                 name bucketmapjoin_tmp_result
+                                numFiles 1
+                                numPartitions 0
+                                numRows 464
                                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282861687
+                                totalSize 8983
+                                transient_lastDdlTime 1284504767
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: bucketmapjoin_tmp_result
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -734,13 +761,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861661
+              transient_lastDdlTime 1284504727
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -752,32 +779,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861661
+                transient_lastDdlTime 1284504727
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -787,24 +814,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861687
+                totalSize 8983
+                transient_lastDdlTime 1284504767
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -815,21 +850,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 464
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861687
+                    totalSize 8983
+                    transient_lastDdlTime 1284504767
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-28-18_728_7919250035608448387/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-53-02_338_1389292184977084722/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -840,12 +880,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861687
+              totalSize 8983
+              transient_lastDdlTime 1284504767
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -856,12 +900,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861687
+                totalSize 8983
+                transient_lastDdlTime 1284504767
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -901,11 +949,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-27_929_4309708501631568542/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-15_338_4031538421928596147/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-27_929_4309708501631568542/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-15_338_4031538421928596147/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -990,11 +1038,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-43_910_1958177214587769286/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-39_709_5928500906509440912/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-43_910_1958177214587769286/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-39_709_5928500906509440912/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1057,14 +1105,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-50_247_5816889851285149323/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-49_922_7370633857792864325/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-28-50_247_5816889851285149323/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-53-49_922_7370633857792864325/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/input_columnarserde.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_columnarserde.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_columnarserde.q.out	(working copy)
@@ -27,6 +27,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -86,7 +87,10 @@
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: input_columnarserde
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src_thrift
 INSERT OVERWRITE TABLE input_columnarserde SELECT src_thrift.lint, src_thrift.lstring, src_thrift.mstringstring, src_thrift.aint, src_thrift.astring DISTRIBUTE BY 1
 PREHOOK: type: QUERY
@@ -105,11 +109,11 @@
 PREHOOK: query: SELECT input_columnarserde.* FROM input_columnarserde DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@input_columnarserde
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-29-33_249_4936798916691606497/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-58_757_857951464814038304/-mr-10000
 POSTHOOK: query: SELECT input_columnarserde.* FROM input_columnarserde DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@input_columnarserde
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-29-33_249_4936798916691606497/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-58_757_857951464814038304/-mr-10000
 POSTHOOK: Lineage: input_columnarserde.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: input_columnarserde.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: input_columnarserde.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -129,11 +133,11 @@
 PREHOOK: query: SELECT input_columnarserde.a[0], input_columnarserde.b[0], input_columnarserde.c['key2'], input_columnarserde.d, input_columnarserde.e FROM input_columnarserde DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@input_columnarserde
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-29-35_826_902275362669356666/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-02_404_3492935474356171782/-mr-10000
 POSTHOOK: query: SELECT input_columnarserde.a[0], input_columnarserde.b[0], input_columnarserde.c['key2'], input_columnarserde.d, input_columnarserde.e FROM input_columnarserde DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@input_columnarserde
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-29-35_826_902275362669356666/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-02_404_3492935474356171782/-mr-10000
 POSTHOOK: Lineage: input_columnarserde.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: input_columnarserde.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: input_columnarserde.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/groupby10.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby10.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby10.q.out	(working copy)
@@ -35,8 +35,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -95,7 +97,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-22-31_118_2529581520401612430/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-12-47_850_4438080186685603592/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -159,9 +161,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-22-31_118_2529581520401612430/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-12-47_850_4438080186685603592/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -224,7 +229,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM INPUT
 INSERT OVERWRITE TABLE dest1 SELECT INPUT.key, count(substr(INPUT.value,5)), count(distinct substr(INPUT.value,5)) GROUP BY INPUT.key
 INSERT OVERWRITE TABLE dest2 SELECT INPUT.key, sum(substr(INPUT.value,5)), sum(distinct substr(INPUT.value,5))   GROUP BY INPUT.key
@@ -248,11 +256,11 @@
 PREHOOK: query: SELECT * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-39_144_1975011296044036004/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-04_432_5505854178165228004/-mr-10000
 POSTHOOK: query: SELECT * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-39_144_1975011296044036004/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-04_432_5505854178165228004/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(input)input.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.val1 EXPRESSION [(input)input.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.val2 EXPRESSION [(input)input.FieldSchema(name:value, type:string, comment:null), ]
@@ -282,11 +290,11 @@
 PREHOOK: query: SELECT * from dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-39_198_7481470784996277044/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-04_860_4545965166949742953/-mr-10000
 POSTHOOK: query: SELECT * from dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-39_198_7481470784996277044/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-04_860_4545965166949742953/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(input)input.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.val1 EXPRESSION [(input)input.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.val2 EXPRESSION [(input)input.FieldSchema(name:value, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/mapreduce6.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce6.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -96,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 SELECT src.key, CAST(src.key / 10 AS INT) as c2, CAST(src.key % 10 AS INT) as c3, src.value
@@ -120,11 +124,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-19-09_713_3892584664273112770/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-43_918_4177508543694288198/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-19-09_713_3892584664273112770/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-43_918_4177508543694288198/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby1_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1_noskew.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -85,7 +86,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_g1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -99,11 +103,11 @@
 PREHOOK: query: SELECT dest_g1.* FROM dest_g1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_g1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-03_470_6383324562009926228/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-13_384_3634246862771804694/-mr-10000
 POSTHOOK: query: SELECT dest_g1.* FROM dest_g1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_g1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-03_470_6383324562009926228/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-13_384_3634246862771804694/-mr-10000
 POSTHOOK: Lineage: dest_g1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/sample10.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample10.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample10.q.out	(working copy)
@@ -59,6 +59,7 @@
         srcpartbucket 
           TableScan
             alias: srcpartbucket
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -102,12 +103,12 @@
                               type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=11/000000_0 [srcpartbucket]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=12/000000_0 [srcpartbucket]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=11/000000_0 [srcpartbucket]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=12/000000_0 [srcpartbucket]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=11/000000_0 [srcpartbucket]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=12/000000_0 [srcpartbucket]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=11/000000_0 [srcpartbucket]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=12/000000_0 [srcpartbucket]
       Path -> Partition:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=11/000000_0 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=11/000000_0 
           Partition
             base file name: 000000_0
             input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -122,13 +123,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
               name srcpartbucket
+              numFiles 16
+              numPartitions 4
+              numRows 40
               partition_columns ds/hr
               serialization.ddl struct srcpartbucket { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-              transient_lastDdlTime 1281477011
+              totalSize 2748
+              transient_lastDdlTime 1284510224
             serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
           
               input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -140,17 +145,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
                 name srcpartbucket
+                numFiles 16
+                numPartitions 4
+                numRows 40
                 partition_columns ds/hr
                 serialization.ddl struct srcpartbucket { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-                transient_lastDdlTime 1281477011
+                totalSize 2748
+                transient_lastDdlTime 1284510224
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: srcpartbucket
             name: srcpartbucket
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=12/000000_0 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-08/hr=12/000000_0 
           Partition
             base file name: 000000_0
             input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -165,13 +174,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
               name srcpartbucket
+              numFiles 16
+              numPartitions 4
+              numRows 40
               partition_columns ds/hr
               serialization.ddl struct srcpartbucket { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-              transient_lastDdlTime 1281477011
+              totalSize 2748
+              transient_lastDdlTime 1284510224
             serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
           
               input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -183,17 +196,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
                 name srcpartbucket
+                numFiles 16
+                numPartitions 4
+                numRows 40
                 partition_columns ds/hr
                 serialization.ddl struct srcpartbucket { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-                transient_lastDdlTime 1281477011
+                totalSize 2748
+                transient_lastDdlTime 1284510224
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: srcpartbucket
             name: srcpartbucket
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=11/000000_0 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=11/000000_0 
           Partition
             base file name: 000000_0
             input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -208,13 +225,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
               name srcpartbucket
+              numFiles 16
+              numPartitions 4
+              numRows 40
               partition_columns ds/hr
               serialization.ddl struct srcpartbucket { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-              transient_lastDdlTime 1281477011
+              totalSize 2748
+              transient_lastDdlTime 1284510224
             serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
           
               input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -226,17 +247,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
                 name srcpartbucket
+                numFiles 16
+                numPartitions 4
+                numRows 40
                 partition_columns ds/hr
                 serialization.ddl struct srcpartbucket { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-                transient_lastDdlTime 1281477011
+                totalSize 2748
+                transient_lastDdlTime 1284510224
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: srcpartbucket
             name: srcpartbucket
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=12/000000_0 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket/ds=2008-04-09/hr=12/000000_0 
           Partition
             base file name: 000000_0
             input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -251,13 +276,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
               name srcpartbucket
+              numFiles 16
+              numPartitions 4
+              numRows 40
               partition_columns ds/hr
               serialization.ddl struct srcpartbucket { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-              transient_lastDdlTime 1281477011
+              totalSize 2748
+              transient_lastDdlTime 1284510224
             serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
           
               input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
@@ -269,13 +298,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.hive.ql.io.RCFileInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.RCFileOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpartbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpartbucket
                 name srcpartbucket
+                numFiles 16
+                numPartitions 4
+                numRows 40
                 partition_columns ds/hr
                 serialization.ddl struct srcpartbucket { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
-                transient_lastDdlTime 1281477011
+                totalSize 2748
+                transient_lastDdlTime 1284510224
               serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
               name: srcpartbucket
             name: srcpartbucket
@@ -299,8 +332,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/heyongqiang/hive_2010-08-10_14-50-17_401_547402505778789806/-ext-10001
+              directory: file:/tmp/nzhang/hive_2010-09-14_17-23-44_066_3247658907709266665/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-23-44_066_3247658907709266665/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -309,6 +343,7 @@
                     columns.types string:bigint
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -322,14 +357,14 @@
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-17_944_5225178246022163963/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-45_501_8306764459922725508/-mr-10000
 POSTHOOK: query: select ds, count(1) from srcpartbucket tablesample (bucket 1 out of 4 on key) where ds is not null group by ds
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-17_944_5225178246022163963/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-45_501_8306764459922725508/-mr-10000
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -346,14 +381,14 @@
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-21_157_3535171777893500208/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-52_348_396768639774586175/-mr-10000
 POSTHOOK: query: select ds, count(1) from srcpartbucket tablesample (bucket 1 out of 2 on key) where ds is not null group by ds
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-21_157_3535171777893500208/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-52_348_396768639774586175/-mr-10000
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -370,14 +405,14 @@
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-26_154_4895921586339251850/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-02_836_4321753954425997828/-mr-10000
 POSTHOOK: query: select * from srcpartbucket where ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpartbucket@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-50-26_154_4895921586339251850/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-02_836_4321753954425997828/-mr-10000
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: srcpartbucket PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join8.q.out
===================================================================
--- ql/src/test/results/clientpositive/join8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join8.q.out	(working copy)
@@ -39,6 +39,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -173,7 +174,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -213,11 +217,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-20-30_236_4837395214661677322/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-07_014_1922499990883267735/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-20-30_236_4837395214661677322/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-07_014_1922499990883267735/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/rand_partitionpruner1.q.out
===================================================================
--- ql/src/test/results/clientpositive/rand_partitionpruner1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/rand_partitionpruner1.q.out	(working copy)
@@ -18,6 +18,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -33,8 +34,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-27_455_4988263281914631499/10001
+                  directory: file:/tmp/nzhang/hive_2010-09-14_17-19-52_616_4921474467166008696/-ext-10001
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-19-52_616_4921474467166008696/-ext-10001/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -43,12 +45,13 @@
                         columns.types string:string
                         serialization.format 1
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -59,12 +62,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452546
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -75,12 +78,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452546
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -93,11 +96,11 @@
 PREHOOK: query: select * from src where rand(1) < 0.1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-27_673_4814026618120977628/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-19-52_716_1485476896153547687/-mr-10000
 POSTHOOK: query: select * from src where rand(1) < 0.1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-27_673_4814026618120977628/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-19-52_716_1485476896153547687/-mr-10000
 409	val_409
 429	val_429
 209	val_209
Index: ql/src/test/results/clientpositive/groupby1_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1_map_skew.q.out	(working copy)
@@ -16,6 +16,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -72,7 +73,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-09_602_22291236730281531/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-13-54_781_8312436605720387245/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -128,7 +129,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -142,11 +146,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-19_228_2468704690191281915/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-04_746_1589757391854107647/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-19_228_2468704690191281915/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-04_746_1589757391854107647/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/input11.q.out
===================================================================
--- ql/src/test/results/clientpositive/input11.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input11.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-27_687_684902206488383899/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-20_753_2692406317545606269/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -79,9 +80,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-27_687_684902206488383899/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-20_753_2692406317545606269/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -107,11 +111,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-31_531_926487594371102951/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-26_456_2545394700696109733/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-31_531_926487594371102951/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-26_456_2545394700696109733/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 86	val_86
Index: ql/src/test/results/clientpositive/groupby6_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby6_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby6_noskew.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -71,7 +72,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT DISTINCT substr(src.value,5,1)
 PREHOOK: type: QUERY
@@ -86,11 +90,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-12_723_4601281117175548853/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-20_070_3822618529499763976/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-12_723_4601281117175548853/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-20_070_3822618529499763976/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/input34.q.out
===================================================================
--- ql/src/test/results/clientpositive/input34.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input34.q.out	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-01_180_4901293199265245358/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-29-47_532_7242599438455938197/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-01_180_4901293199265245358/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-29-47_532_7242599438455938197/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -131,11 +135,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-04_960_4077678002178946293/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-53_325_8043851611952541282/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-04_960_4077678002178946293/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-53_325_8043851611952541282/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/input12.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input12.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input12.q.out_0.17	(working copy)
@@ -30,18 +30,21 @@
 
 STAGE DEPENDENCIES:
   Stage-3 is a root stage
-  Stage-6 depends on stages: Stage-3 , consists of Stage-5, Stage-4
+  Stage-7 depends on stages: Stage-3 , consists of Stage-6, Stage-5
+  Stage-6
+  Stage-0 depends on stages: Stage-6, Stage-5
+  Stage-4 depends on stages: Stage-0
   Stage-5
-  Stage-0 depends on stages: Stage-5, Stage-4
-  Stage-4
-  Stage-9 depends on stages: Stage-3 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
-  Stage-12 depends on stages: Stage-3 , consists of Stage-11, Stage-10
-  Stage-11
-  Stage-2 depends on stages: Stage-11, Stage-10
+  Stage-11 depends on stages: Stage-3 , consists of Stage-10, Stage-9
   Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
+  Stage-15 depends on stages: Stage-3 , consists of Stage-14, Stage-13
+  Stage-14
+  Stage-2 depends on stages: Stage-14, Stage-13
+  Stage-12 depends on stages: Stage-2
+  Stage-13
 
 STAGE PLANS:
   Stage: Stage-3
@@ -125,14 +128,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest3
 
-  Stage: Stage-6
+  Stage: Stage-7
     Conditional Operator
 
-  Stage: Stage-5
+  Stage: Stage-6
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -145,9 +148,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -170,14 +176,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -189,10 +195,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10007 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10007 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -215,14 +224,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
 
-  Stage: Stage-12
+  Stage: Stage-15
     Conditional Operator
 
-  Stage: Stage-11
+  Stage: Stage-14
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10004
 
   Stage: Stage-2
     Move Operator
@@ -237,10 +246,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest3
 
-  Stage: Stage-10
+  Stage: Stage-12
+    Stats-Aggr Operator
+
+  Stage: Stage-13
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-41_931_5369380083021091529/10008 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-28_159_7424886637215869609/-ext-10008 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -288,11 +300,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_449_7424653031518092836/10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-37_419_4324670001280553754/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_449_7424653031518092836/10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-37_419_4324670001280553754/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -385,11 +397,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_504_847793569669105301/10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-38_022_3197731740628094077/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_504_847793569669105301/10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-38_022_3197731740628094077/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -503,11 +515,11 @@
 PREHOOK: query: SELECT dest3.* FROM dest3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_553_731816401522380914/10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-38_638_3795914837064421728/-mr-10000
 POSTHOOK: query: SELECT dest3.* FROM dest3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-47_553_731816401522380914/10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-38_638_3795914837064421728/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_part1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_part1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part1.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -28,6 +29,7 @@
         srcpart 
           TableScan
             alias: srcpart
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -63,8 +65,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -74,21 +77,22 @@
                             columns.types int:string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                             name dest1
                             serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282157974
+                            transient_lastDdlTime 1284591061
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -102,13 +106,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -119,32 +123,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -154,20 +158,24 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157974
+                transient_lastDdlTime 1284591061
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -185,9 +193,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -198,12 +206,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157974
+              transient_lastDdlTime 1284591061
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -214,12 +222,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157974
+                transient_lastDdlTime 1284591061
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -228,7 +236,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-34_655_270474947223590291/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-01_208_8205417364488146083/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -239,15 +247,16 @@
                   columns.types int:string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282157974
+                  transient_lastDdlTime 1284591061
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -268,11 +277,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-38_951_8671245487867133873/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-07_728_1327545905800819955/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-38_951_8671245487867133873/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-07_728_1327545905800819955/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/union6.q.out
===================================================================
--- ql/src/test/results/clientpositive/union6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union6.q.out	(working copy)
@@ -26,12 +26,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -77,7 +78,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-17_23-00-46_249_3935923739130713155/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_18-21-50_637_3032457585026659835/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -94,7 +95,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: tmptable
-        file:/tmp/nzhang/hive_2010-08-17_23-00-46_249_3935923739130713155/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-21-50_637_3032457585026659835/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -112,14 +113,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-46_249_3935923739130713155/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-21-50_637_3032457585026659835/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -132,9 +133,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_23-00-46_249_3935923739130713155/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-21-50_637_3032457585026659835/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -144,7 +148,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -186,11 +190,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key, x.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-01-01_489_2593025423842842121/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-22-07_181_1811819841284617502/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key, x.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_23-01-01_489_2593025423842842121/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-22-07_181_1811819841284617502/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
 	
Index: ql/src/test/results/clientpositive/union4.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union4.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/union4.q.out_0.17	(working copy)
@@ -26,12 +26,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -77,7 +78,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-41-40_681_7920974237145003540/10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-40-32_822_6218549786107543796/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -101,7 +102,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-41-40_681_7920974237145003540/10004 
+        file:/tmp/nzhang/hive_2010-09-15_17-40-32_822_6218549786107543796/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -126,14 +127,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-41-40_681_7920974237145003540/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-40-32_822_6218549786107543796/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -146,9 +147,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-41-40_681_7920974237145003540/10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-40-32_822_6218549786107543796/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -171,7 +175,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -231,11 +235,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-41-50_925_942224749030960902/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-40-51_601_8347227640439049691/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-41-50_925_942224749030960902/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-40-51_601_8347227640439049691/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src)s2.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/transform_ppr1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/transform_ppr1.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/transform_ppr1.q.out_0.17	(revision 0)
@@ -0,0 +1,469 @@
+PREHOOK: query: EXPLAIN EXTENDED
+FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100 AND tmap.ds = '2008-04-08'
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN EXTENDED
+FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100 AND tmap.ds = '2008-04-08'
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart src)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TRANSFORM (TOK_EXPLIST (. (TOK_TABLE_OR_COL src) ds) (. (TOK_TABLE_OR_COL src) key) (. (TOK_TABLE_OR_COL src) value)) TOK_SERDE TOK_RECORDWRITER '/bin/cat' TOK_SERDE TOK_RECORDREADER (TOK_ALIASLIST ds tkey tvalue)))) (TOK_CLUSTERBY (TOK_TABLE_OR_COL tkey)))) tmap)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL tmap) tkey)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL tmap) tvalue))) (TOK_WHERE (AND (< (. (TOK_TABLE_OR_COL tmap) tkey) 100) (= (. (TOK_TABLE_OR_COL tmap) ds) '2008-04-08')))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        tmap:src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: ds
+                    type: string
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1, _col2
+              Transform Operator
+                command: /bin/cat
+                output info:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      columns _col0,_col1,_col2
+                      columns.types string,string,string
+                      field.delim 9
+                      serialization.format 9
+                Reduce Output Operator
+                  key expressions:
+                        expr: _col1
+                        type: string
+                  sort order: +
+                  Map-reduce partition columns:
+                        expr: _col1
+                        type: string
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                        expr: _col2
+                        type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [tmap:src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+          Partition
+            base file name: hr=11
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 11
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+          Partition
+            base file name: hr=12
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+          Partition
+            base file name: hr=11
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-09
+              hr 11
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+          Partition
+            base file name: hr=12
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-09
+              hr 12
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+      Reduce Operator Tree:
+        Extract
+          Filter Operator
+            isSamplingPred: false
+            predicate:
+                expr: ((_col1 < 100) and (_col0 = '2008-04-08'))
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col1
+                    type: string
+                    expr: _col2
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                directory: file:/tmp/nzhang/hive_2010-09-15_17-09-49_113_6975059842786318267/-ext-10001
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-09-49_113_6975059842786318267/-ext-10001/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      columns _col0,_col1
+                      columns.types string:string
+                      serialization.format 1
+                TotalFiles: 1
+                GatherStats: false
+                MultiFileSpray: false
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100 AND tmap.ds = '2008-04-08'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-49_237_3543567544677490790/-mr-10000
+POSTHOOK: query: FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100 AND tmap.ds = '2008-04-08'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-49_237_3543567544677490790/-mr-10000
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+10	val_10
+10	val_10
+11	val_11
+11	val_11
+12	val_12
+12	val_12
+12	val_12
+12	val_12
+15	val_15
+15	val_15
+15	val_15
+15	val_15
+17	val_17
+17	val_17
+18	val_18
+18	val_18
+18	val_18
+18	val_18
+19	val_19
+19	val_19
+2	val_2
+2	val_2
+20	val_20
+20	val_20
+24	val_24
+24	val_24
+24	val_24
+24	val_24
+26	val_26
+26	val_26
+26	val_26
+26	val_26
+27	val_27
+27	val_27
+28	val_28
+28	val_28
+30	val_30
+30	val_30
+33	val_33
+33	val_33
+34	val_34
+34	val_34
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+37	val_37
+37	val_37
+37	val_37
+37	val_37
+4	val_4
+4	val_4
+41	val_41
+41	val_41
+42	val_42
+42	val_42
+42	val_42
+42	val_42
+43	val_43
+43	val_43
+44	val_44
+44	val_44
+47	val_47
+47	val_47
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+51	val_51
+51	val_51
+51	val_51
+51	val_51
+53	val_53
+53	val_53
+54	val_54
+54	val_54
+57	val_57
+57	val_57
+58	val_58
+58	val_58
+58	val_58
+58	val_58
+64	val_64
+64	val_64
+65	val_65
+65	val_65
+66	val_66
+66	val_66
+67	val_67
+67	val_67
+67	val_67
+67	val_67
+69	val_69
+69	val_69
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+72	val_72
+72	val_72
+72	val_72
+72	val_72
+74	val_74
+74	val_74
+76	val_76
+76	val_76
+76	val_76
+76	val_76
+77	val_77
+77	val_77
+78	val_78
+78	val_78
+8	val_8
+8	val_8
+80	val_80
+80	val_80
+82	val_82
+82	val_82
+83	val_83
+83	val_83
+83	val_83
+83	val_83
+84	val_84
+84	val_84
+84	val_84
+84	val_84
+85	val_85
+85	val_85
+86	val_86
+86	val_86
+87	val_87
+87	val_87
+9	val_9
+9	val_9
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+92	val_92
+92	val_92
+95	val_95
+95	val_95
+95	val_95
+95	val_95
+96	val_96
+96	val_96
+97	val_97
+97	val_97
+97	val_97
+97	val_97
+98	val_98
+98	val_98
+98	val_98
+98	val_98
Index: ql/src/test/results/clientpositive/bucketmapjoin3.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin3.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin3.q.out_0.17	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -140,8 +142,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -151,15 +154,16 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940468
+                              transient_lastDdlTime 1284588766
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -171,6 +175,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -214,8 +219,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -225,29 +231,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282940468
+                                  transient_lastDdlTime 1284588766
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket22.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket23.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -261,13 +268,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940466
+              transient_lastDdlTime 1284588764
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -279,32 +286,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940466
+                transient_lastDdlTime 1284588764
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -314,20 +321,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940468
+                transient_lastDdlTime 1284588766
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -343,9 +354,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -356,12 +367,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940468
+              transient_lastDdlTime 1284588766
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -372,12 +383,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940468
+                transient_lastDdlTime 1284588766
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -386,7 +397,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-08_428_5895841844554846760/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-12-46_549_3101553181701427848/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -397,15 +408,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940468
+                  transient_lastDdlTime 1284588766
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -431,11 +443,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-18_101_2503635838902230563/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-01_096_4484863590206602158/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-18_101_2503635838902230563/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-01_096_4484863590206602158/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin_part_2)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin_part_2)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -484,11 +496,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-33_708_6713438406371908224/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-25_644_8867517971206095003/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-33_708_6713438406371908224/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-25_644_8867517971206095003/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -527,14 +539,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-40_391_5136557064866380488/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-35_901_2964068933413297965/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-40_391_5136557064866380488/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-35_901_2964068933413297965/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -577,10 +589,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -589,6 +602,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -632,8 +646,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -643,15 +658,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 564
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940493
+                              totalSize 11067
+                              transient_lastDdlTime 1284588805
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -663,6 +683,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -706,8 +727,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -717,31 +739,36 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
+                                  numFiles 1
+                                  numPartitions 0
+                                  numRows 564
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282940493
+                                  totalSize 11067
+                                  transient_lastDdlTime 1284588805
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt], srcbucket22.txt=[srcbucket22.txt], srcbucket23.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -755,13 +782,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940464
+              transient_lastDdlTime 1284588762
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -773,32 +800,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940464
+                transient_lastDdlTime 1284588762
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -808,20 +835,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 564
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940493
+                totalSize 11067
+                transient_lastDdlTime 1284588805
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -837,9 +872,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -850,12 +885,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 564
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940493
+              totalSize 11067
+              transient_lastDdlTime 1284588805
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -866,12 +905,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 564
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940493
+                totalSize 11067
+                transient_lastDdlTime 1284588805
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -880,7 +923,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-21-44_043_2208309954683066173/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-13-41_006_1376321010493868240/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -891,15 +934,20 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 564
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940493
+                  totalSize 11067
+                  transient_lastDdlTime 1284588805
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -937,11 +985,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-54_369_3834715752895970116/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-56_483_5413784896845148593/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-21-54_369_3834715752895970116/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-13-56_483_5413784896845148593/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1026,11 +1074,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-11_829_429037448585234121/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-22_292_3147948323988691275/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-11_829_429037448585234121/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-22_292_3147948323988691275/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1093,14 +1141,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-18_524_6184888372779522742/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-33_091_6525629200181342773/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-18_524_6184888372779522742/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-33_091_6525629200181342773/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/mapreduce1.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce1.q.out	(working copy)
@@ -25,6 +25,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -103,7 +104,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -129,11 +133,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-13_640_8293614477865253052/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-02-58_524_122150043669563126/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-13_640_8293614477865253052/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-02-58_524_122150043669563126/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucket2.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucket2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucket2.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -45,9 +47,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -58,12 +60,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -74,12 +76,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -95,8 +97,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-11_789_5710176838021451402/10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-13_088_4215892022529804638/-ext-10000
               NumFilesPerFileSink: 2
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-13_088_4215892022529804638/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -107,22 +110,23 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket2_1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket2_1
                     name bucket2_1
                     serialization.ddl struct bucket2_1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279735751
+                    transient_lastDdlTime 1284504613
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket2_1
               TotalFiles: 2
+              GatherStats: true
               MultiFileSpray: true
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-11_789_5710176838021451402/10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-13_088_4215892022529804638/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -133,17 +137,21 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket2_1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket2_1
                 name bucket2_1
                 serialization.ddl struct bucket2_1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735751
+                transient_lastDdlTime 1284504613
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket2_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-11_789_5710176838021451402/10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-13_088_4215892022529804638/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-13_088_4215892022529804638/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket2_1
 select * from src
 PREHOOK: type: QUERY
@@ -221,11 +229,11 @@
 PREHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket2_1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-14_833_8954758164660929050/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-20_404_4866989336023198470/-mr-10000
 POSTHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket2_1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-14_833_8954758164660929050/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-20_404_4866989336023198470/-mr-10000
 POSTHOOK: Lineage: bucket2_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket2_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/union12.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union12.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/union12.q.out_0.17	(working copy)
@@ -28,13 +28,14 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6, Stage-7
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7, Stage-8
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
   Stage-7 is a root stage
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -80,7 +81,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-39-13_146_6578228270380339492/10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-36-11_264_7419158006288845005/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -104,7 +105,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-39-13_146_6578228270380339492/10004 
+        file:/tmp/nzhang/hive_2010-09-15_17-36-11_264_7419158006288845005/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -128,7 +129,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-39-13_146_6578228270380339492/10005 
+        file:/tmp/nzhang/hive_2010-09-15_17-36-11_264_7419158006288845005/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -153,14 +154,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-39-13_146_6578228270380339492/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-36-11_264_7419158006288845005/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -173,9 +174,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-39-13_146_6578228270380339492/10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-36-11_264_7419158006288845005/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -198,7 +202,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery2:unionsrc-subquery1-subquery2:s2 
@@ -238,7 +242,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s3 
@@ -306,11 +310,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-39-25_864_5858813916026518675/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-36-35_865_5938048403656710237/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-39-25_864_5858813916026518675/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-36-35_865_5938048403656710237/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.null, (srcbucket)s3.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/input20.q.out
===================================================================
--- ql/src/test/results/clientpositive/input20.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input20.q.out	(working copy)
@@ -35,6 +35,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -111,7 +112,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   MAP src.key, src.key
@@ -145,11 +149,11 @@
 PREHOOK: query: SELECT * FROM dest1 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-05_886_2456146967010300561/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-28-07_786_8910183540779340449/-mr-10000
 POSTHOOK: query: SELECT * FROM dest1 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-12-05_886_2456146967010300561/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-28-07_786_8910183540779340449/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 1	105_105
Index: ql/src/test/results/clientpositive/input14_limit.q.out
===================================================================
--- ql/src/test/results/clientpositive/input14_limit.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input14_limit.q.out	(working copy)
@@ -28,6 +28,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -75,7 +76,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-32_045_8209944699566698398/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-27-07_332_2694319864765120880/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -130,7 +131,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value)
@@ -156,11 +160,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-42_104_2524142463766517649/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-18_010_425020749270297262/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-42_104_2524142463766517649/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-18_010_425020749270297262/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/load_dyn_part1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part1.q.out_0.17	(working copy)
@@ -34,15 +34,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Thu Sep 16 12:39:43 PDT 2010	 
+CreateTime:         	Tue Sep 21 08:17:46 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive.unsecure/build/ql/test/data/warehouse/nzhang_part1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284665983          
+	transient_lastDdlTime	1285082266          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -71,7 +71,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -138,6 +140,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -151,7 +156,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from srcpart
 insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
 insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
@@ -212,12 +220,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
 PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-39-47_201_4918197188329803292/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-17-59_635_2097535868248761512/-mr-10000
 POSTHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-39-47_201_4918197188329803292/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-17-59_635_2097535868248761512/-mr-10000
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1230,12 +1238,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
 PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-39-47_479_2779574576855657335/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-18-00_976_813450084433795554/-mr-10000
 POSTHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
 POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-39-47_479_2779574576855657335/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-18-00_976_813450084433795554/-mr-10000
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/load_dyn_part9.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part9.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:15:19 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:22:45 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part9	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part9	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473719          
+	transient_lastDdlTime	1285053765          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -64,6 +64,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -113,7 +114,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part9
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from srcpart
 insert overwrite table nzhang_part9 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
 PREHOOK: type: QUERY
@@ -144,12 +148,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part9@ds=2008-04-08/hr=11
 PREHOOK: Input: default@nzhang_part9@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-15-22_688_3998083922561230101/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-54_672_6614309113250566122/-mr-10000
 POSTHOOK: query: select * from nzhang_part9 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part9@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part9@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-15-22_688_3998083922561230101/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-54_672_6614309113250566122/-mr-10000
 POSTHOOK: Lineage: nzhang_part9 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part9 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part9 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/louter_join_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/louter_join_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/louter_join_ppr.q.out	(working copy)
@@ -30,6 +30,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -52,6 +53,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -78,11 +80,11 @@
                         type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -93,12 +95,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -109,16 +111,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -132,13 +134,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -149,17 +151,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -173,13 +175,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -190,13 +192,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -228,8 +230,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-13-53_609_8727040543187359730/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-09_556_7210675530968659848/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-09_556_7210675530968659848/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -238,6 +241,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -256,7 +260,7 @@
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-13-53_763_8356433223655473381/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-10_224_1696984837763912556/-mr-10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN 
@@ -268,7 +272,7 @@
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-13-53_763_8356433223655473381/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-10_224_1696984837763912556/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -313,6 +317,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -337,6 +342,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -353,13 +359,13 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -370,12 +376,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -386,16 +392,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -409,13 +415,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -426,17 +432,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -450,13 +456,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -467,17 +473,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -491,13 +497,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284964110
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -508,17 +514,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284964110
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -532,13 +538,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284964110
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -549,13 +555,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284964110
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -590,8 +596,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-13-58_421_1926636805796976144/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-16_116_9127612997676067692/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-16_116_9127612997676067692/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -600,6 +607,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -620,7 +628,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-13-58_580_4139293399371641463/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-16_465_2473618346062914194/-mr-10000
 POSTHOOK: query: FROM 
   srcpart a
  LEFT OUTER JOIN 
@@ -634,7 +642,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-13-58_580_4139293399371641463/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-16_465_2473618346062914194/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -679,6 +687,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -701,6 +710,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -719,13 +729,13 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -736,12 +746,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -752,16 +762,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -775,13 +785,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -792,17 +802,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -816,13 +826,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -833,17 +843,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -857,13 +867,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -874,17 +884,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -898,13 +908,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -915,13 +925,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -953,8 +963,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-14-03_203_9134886317608012397/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-22_662_6681874118754308011/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-22_662_6681874118754308011/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -963,6 +974,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -983,7 +995,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-14-03_392_1161117122027170023/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-22_982_2011316398183669975/-mr-10000
 POSTHOOK: query: FROM 
   src a
  LEFT OUTER JOIN 
@@ -997,7 +1009,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-14-03_392_1161117122027170023/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-22_982_2011316398183669975/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -1042,6 +1054,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1066,6 +1079,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -1082,11 +1096,11 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1097,12 +1111,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1113,16 +1127,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1136,13 +1150,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1153,17 +1167,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1177,13 +1191,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1194,13 +1208,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -1232,8 +1246,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-14-08_638_7208426036779412420/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-29_540_5718313979734119216/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-29_540_5718313979734119216/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1242,6 +1257,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -1260,7 +1276,7 @@
 PREHOOK: Input: default@src
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-14-08_790_7032133874332300547/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-29_827_4197605096609818365/-mr-10000
 POSTHOOK: query: FROM 
   srcpart a
  LEFT OUTER JOIN 
@@ -1272,7 +1288,7 @@
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-14-08_790_7032133874332300547/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-29_827_4197605096609818365/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
Index: ql/src/test/results/clientpositive/groupby8_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby8_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby8_map.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -83,7 +85,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-52_785_8638071406503879656/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-58_949_4004968194344583164/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -140,9 +142,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-52_785_8638071406503879656/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-58_949_4004968194344583164/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -198,7 +203,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -220,11 +228,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-06_590_2275036673677603002/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-16_014_8974042680779765629/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-06_590_2275036673677603002/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-16_014_8974042680779765629/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -541,11 +549,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-06_669_724511372926306276/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-16_457_9177520285019033125/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-06_669_724511372926306276/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-16_457_9177520285019033125/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join27.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join27.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join27.q.out_0.17	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-56-31_251_4944393603870636432/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-24_563_7816581781593593184/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-56-31_251_4944393603870636432/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-24_563_7816581781593593184/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -203,11 +207,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key, x.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-56-36_064_6653162392931880816/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-32_540_8901230249424541388/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key, x.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-56-36_064_6653162392931880816/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-32_540_8901230249424541388/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/merge1.q.out
===================================================================
--- ql/src/test/results/clientpositive/merge1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge1.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,14 +88,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-13_940_7552083173905722139/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-02_184_5109318380714779295/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -107,9 +108,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-13_940_7552083173905722139/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-02_184_5109318380714779295/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -135,11 +139,11 @@
 PREHOOK: query: select * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-19_317_5060865537183134906/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-09_595_3681493371451427553/-mr-10000
 POSTHOOK: query: select * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-19_317_5060865537183134906/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-09_595_3681493371451427553/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.val EXPRESSION [(src)src.null, ]
 0	3
@@ -518,10 +522,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -544,14 +549,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-29_915_2570997123189854369/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-22_681_2184529355361135428/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -564,9 +569,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-29_915_2570997123189854369/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-22_681_2184529355361135428/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -612,10 +620,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -638,14 +647,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-38_288_4799167015782282338/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-33_687_3730778879679285743/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -658,9 +667,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-38_288_4799167015782282338/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-33_687_3730778879679285743/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
Index: ql/src/test/results/clientpositive/join3.q.out
===================================================================
--- ql/src/test/results/clientpositive/join3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join3.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -108,7 +109,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key) JOIN src src3 ON (src1.key = src3.key)
 INSERT OVERWRITE TABLE dest1 SELECT src1.key, src3.value
 PREHOOK: type: QUERY
@@ -124,11 +128,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-26-58_376_2455993392951316406/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-57-14_346_6262707438334064376/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-26-58_376_2455993392951316406/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-57-14_346_6262707438334064376/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src3.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/lineage1.q.out
===================================================================
--- ql/src/test/results/clientpositive/lineage1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/lineage1.q.out	(working copy)
@@ -34,12 +34,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -101,7 +102,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-08-08_217_4989832071586172776/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-52-08_102_663019916071850448/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -125,7 +126,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_l1
-        file:/tmp/jsichi/hive_2010-08-26_16-08-08_217_4989832071586172776/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-52-08_102_663019916071850448/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -150,14 +151,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest_l1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-08-08_217_4989832071586172776/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-52-08_102_663019916071850448/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -170,9 +171,12 @@
               name: dest_l1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-08-08_217_4989832071586172776/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-52-08_102_663019916071850448/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -182,7 +186,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_l1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:j-subquery2:p2 
Index: ql/src/test/results/clientpositive/merge1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/merge1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge1.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,14 +88,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-01-42_819_2062174773461858182/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-21-49_648_2425320650010532841/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -107,9 +108,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-01-42_819_2062174773461858182/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-21-49_648_2425320650010532841/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -148,11 +152,11 @@
 PREHOOK: query: select * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-01-48_532_6136023813660823571/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-21-57_106_5240364276199708539/-mr-10000
 POSTHOOK: query: select * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-01-48_532_6136023813660823571/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-21-57_106_5240364276199708539/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.val EXPRESSION [(src)src.null, ]
 0	3
@@ -531,10 +535,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -557,14 +562,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-01-58_147_6168286585474201710/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-11_240_3244962430173384393/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -577,9 +582,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-01-58_147_6168286585474201710/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-11_240_3244962430173384393/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -636,10 +644,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -662,14 +671,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-07_167_6780183424496816185/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-23_350_6873600755109031784/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -682,9 +691,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-07_167_6780183424496816185/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-23_350_6873600755109031784/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
Index: ql/src/test/results/clientpositive/input8.q.out
===================================================================
--- ql/src/test/results/clientpositive/input8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input8.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -55,14 +56,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-57_389_146464688611491858/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-37_199_2880545020452749957/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -75,9 +76,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-57_389_146464688611491858/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-37_199_2880545020452749957/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -104,11 +108,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-01_150_4685454436996346428/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-43_734_3055902048337996946/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-01_150_4685454436996346428/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-43_734_3055902048337996946/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/filter_join_breaktask.q.out
===================================================================
--- ql/src/test/results/clientpositive/filter_join_breaktask.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/filter_join_breaktask.q.out	(working copy)
@@ -42,6 +42,7 @@
         f 
           TableScan
             alias: f
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -72,6 +73,7 @@
         m 
           TableScan
             alias: m
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -98,9 +100,9 @@
                         type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 [f, m]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 [f, m]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -113,13 +115,17 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask
               name filter_join_breaktask
+              numFiles 1
+              numPartitions 1
+              numRows 25
               partition_columns ds
               serialization.ddl struct filter_join_breaktask { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280427201
+              totalSize 236
+              transient_lastDdlTime 1284505900
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -130,13 +136,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask
                 name filter_join_breaktask
+                numFiles 1
+                numPartitions 1
+                numRows 25
                 partition_columns ds
                 serialization.ddl struct filter_join_breaktask { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280427201
+                totalSize 236
+                transient_lastDdlTime 1284505900
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: filter_join_breaktask
             name: filter_join_breaktask
@@ -167,7 +177,7 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-27_145_4349278496196246379/-mr-10002
+                  directory: file:/tmp/nzhang/hive_2010-09-14_16-11-40_459_7790372781916354077/-mr-10002
                   NumFilesPerFileSink: 1
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -177,6 +187,7 @@
                         columns.types int,string
                         escape.delim \
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
 
   Stage: Stage-2
@@ -198,6 +209,7 @@
         g 
           TableScan
             alias: g
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -222,10 +234,10 @@
                         type: string
       Needs Tagging: true
       Path -> Alias:
-        file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-27_145_4349278496196246379/-mr-10002 [$INTNAME]
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 [g]
+        file:/tmp/nzhang/hive_2010-09-14_16-11-40_459_7790372781916354077/-mr-10002 [$INTNAME]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 [g]
       Path -> Partition:
-        file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-27_145_4349278496196246379/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-11-40_459_7790372781916354077/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -241,7 +253,7 @@
                 columns _col0,_col6
                 columns.types int,string
                 escape.delim \
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -254,13 +266,17 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask
               name filter_join_breaktask
+              numFiles 1
+              numPartitions 1
+              numRows 25
               partition_columns ds
               serialization.ddl struct filter_join_breaktask { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280427201
+              totalSize 236
+              transient_lastDdlTime 1284505900
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -271,13 +287,17 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/filter_join_breaktask
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/filter_join_breaktask
                 name filter_join_breaktask
+                numFiles 1
+                numPartitions 1
+                numRows 25
                 partition_columns ds
                 serialization.ddl struct filter_join_breaktask { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280427201
+                totalSize 236
+                transient_lastDdlTime 1284505900
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: filter_join_breaktask
             name: filter_join_breaktask
@@ -300,8 +320,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-27_145_4349278496196246379/-ext-10001
+              directory: file:/tmp/nzhang/hive_2010-09-14_16-11-40_459_7790372781916354077/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-11-40_459_7790372781916354077/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -310,6 +331,7 @@
                     columns.types int:string
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -322,13 +344,13 @@
 JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
 PREHOOK: type: QUERY
 PREHOOK: Input: default@filter_join_breaktask@ds=2008-04-08
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-30_238_1373557843480629621/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-11-40_752_1857597233384714113/-mr-10000
 POSTHOOK: query: SELECT f.key, g.value 
 FROM filter_join_breaktask f JOIN filter_join_breaktask m ON( f.key = m.key AND f.ds='2008-04-08' AND m.ds='2008-04-08' AND f.key is not null) 
 JOIN filter_join_breaktask g ON(g.value = m.value AND g.ds='2008-04-08' AND m.ds='2008-04-08' AND m.value is not null AND m.value !='')
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@filter_join_breaktask@ds=2008-04-08
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-13-30_238_1373557843480629621/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-11-40_752_1857597233384714113/-mr-10000
 POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: filter_join_breaktask PARTITION(ds=2008-04-08).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 146	val_146
Index: ql/src/test/results/clientpositive/join17.q.out
===================================================================
--- ql/src/test/results/clientpositive/join17.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join17.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src1 
           TableScan
             alias: src1
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -42,6 +44,7 @@
         src2 
           TableScan
             alias: src2
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -58,9 +61,9 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src [src2, src1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src2, src1]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -71,12 +74,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430369
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +90,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430369
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -130,8 +133,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-54-40_341_4053806276596464531/-ext-10000
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-18_648_2059499692178002378/-ext-10000
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-18_648_2059499692178002378/-ext-10000/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -141,22 +145,23 @@
                       columns.types int:string:int:string
                       file.inputformat org.apache.hadoop.mapred.TextInputFormat
                       file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                      location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                       name dest1
                       serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
                       serialization.format 1
                       serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                      transient_lastDdlTime 1280433280
+                      transient_lastDdlTime 1284507438
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
                 TotalFiles: 1
+                GatherStats: true
                 MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-54-40_341_4053806276596464531/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-18_648_2059499692178002378/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -166,17 +171,21 @@
                 columns.types int:string:int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key1, string value1, i32 key2, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280433280
+                transient_lastDdlTime 1284507438
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-54-40_341_4053806276596464531/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-18_648_2059499692178002378/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-18_648_2059499692178002378/-ext-10000/
 
+
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key)
 INSERT OVERWRITE TABLE dest1 SELECT src1.*, src2.*
 PREHOOK: type: QUERY
@@ -194,11 +203,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-54-45_501_1543320247647091636/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-37-25_606_7815293390556055337/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-54-45_501_1543320247647091636/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-37-25_606_7815293390556055337/-mr-10000
 POSTHOOK: Lineage: dest1.key1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key2 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value1 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby6.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby6.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -58,7 +59,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-05_832_3928695705751091668/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-16-43_453_3773010244841701560/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -100,7 +101,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT DISTINCT substr(src.value,5,1)
 PREHOOK: type: QUERY
@@ -115,11 +119,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-14_987_96157461956550490/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-52_753_2205865681155406670/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-14_987_96157461956550490/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-52_753_2205865681155406670/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/join36.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join36.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join36.q.out_0.17	(working copy)
@@ -58,10 +58,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -157,14 +158,14 @@
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-53-04_744_2069012305000904704/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-59-13_952_8416113619056139073/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -177,9 +178,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-53-04_744_2069012305000904704/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-59-13_952_8416113619056139073/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -229,11 +233,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-53-08_462_2303969710395749873/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-59-21_226_672562533521235198/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-53-08_462_2303969710395749873/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-59-21_226_672562533521235198/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(tmp1)x.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(tmp2)y.FieldSchema(name:cnt, type:int, comment:null), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(tmp1)x.FieldSchema(name:cnt, type:int, comment:null), ]
Index: ql/src/test/results/clientpositive/input_part9.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part9.q.out	(working copy)
@@ -18,6 +18,7 @@
         x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -58,10 +59,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [x]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [x]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [x]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [x]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -75,13 +76,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450860
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -92,17 +93,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450860
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -116,13 +117,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266450860
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -133,13 +134,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266450860
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -148,8 +149,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-33_447_3691730051336453837/10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_16-34-57_615_8477963081036251433/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-34-57_615_8477963081036251433/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -158,6 +160,7 @@
                   columns.types string:string:string:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -169,12 +172,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-33_848_8118876166603140113/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-57_779_2962404660673028425/-mr-10000
 POSTHOOK: query: SELECT x.* FROM SRCPART x WHERE key IS NOT NULL AND ds = '2008-04-08' order by x.key, x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_15-54-33_848_8118876166603140113/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-57_779_2962404660673028425/-mr-10000
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
 0	val_0	2008-04-08	11
Index: ql/src/test/results/clientpositive/merge4.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/merge4.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge4.q.out_0.17	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -62,7 +63,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part partition (ds='2010-08-15', hr) select key, value, hr from srcpart where ds='2008-04-08'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
@@ -81,12 +85,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-30_838_7629815615150053920/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-01_677_3883757291544821254/-mr-10000
 POSTHOOK: query: select * from nzhang_part
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-30_838_7629815615150053920/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-01_677_3883757291544821254/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1107,6 +1111,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -1152,7 +1157,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part partition (ds='2010-08-15', hr=11) select key, value from srcpart where ds='2008-04-08'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
@@ -1173,12 +1181,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-39_689_174314225109504234/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-11_901_4644662318838172421/-mr-10000
 POSTHOOK: query: select * from nzhang_part
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=11
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=12
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-39_689_174314225109504234/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-11_901_4644662318838172421/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -2710,9 +2718,10 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-4
   Stage-0 depends on stages: Stage-2
-  Stage-3 is a root stage
+  Stage-3 depends on stages: Stage-0
+  Stage-4 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2748,7 +2757,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-15_16-54-41_064_902801052919283411/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_08-32-13_805_1434227095327278240/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -2767,7 +2776,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part
-        file:/tmp/nzhang/hive_2010-09-15_16-54-41_064_902801052919283411/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-21_08-32-13_805_1434227095327278240/-mr-10003 
           Union
             Select Operator
               expressions:
@@ -2801,6 +2810,9 @@
               name: nzhang_part
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:s-subquery2:src 
@@ -2860,14 +2872,14 @@
 POSTHOOK: Output: default@nzhang_part@ds=2010-08-15/hr=file,
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 PREHOOK: query: show partitions nzhang_part
@@ -2876,14 +2888,14 @@
 POSTHOOK: type: SHOWPARTITIONS
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 ds=2010-08-15/hr=11
@@ -2892,21 +2904,21 @@
 PREHOOK: query: select * from nzhang_part where hr = 'file,'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=file,
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-54_825_7294798270721816998/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-32_131_4306763854704134241/-mr-10000
 POSTHOOK: query: select * from nzhang_part where hr = 'file,'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part@ds=2010-08-15/hr=file,
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-54-54_825_7294798270721816998/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-32-32_131_4306763854704134241/-mr-10000
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=11).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
-POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=12).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part PARTITION(ds=2010-08-15,hr=file,).value EXPRESSION [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 1	1	2010-08-15	file,
Index: ql/src/test/results/clientpositive/load_dyn_part4.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part4.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:11:21 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:16:11 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part4	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part4	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473481          
+	transient_lastDdlTime	1285053371          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -74,6 +74,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -123,7 +124,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part4
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part4 partition (ds, hr) select key, value, ds, hr from srcpart where ds is not null and hr is not null
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
@@ -174,13 +178,13 @@
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=11
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=12
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=existing_value
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-11-27_490_2022214220778594011/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-31_503_3440445638314967808/-mr-10000
 POSTHOOK: query: select * from nzhang_part4 where ds='2008-04-08' and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=existing_value
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-11-27_490_2022214220778594011/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-31_503_3440445638314967808/-mr-10000
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1698,7 +1702,7 @@
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=existing_value
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-09/hr=11
 PREHOOK: Input: default@nzhang_part4@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-11-27_862_3063759499371481171/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-32_674_3218170732469048135/-mr-10000
 POSTHOOK: query: select * from nzhang_part4 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=11
@@ -1706,7 +1710,7 @@
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-08/hr=existing_value
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@nzhang_part4@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-11-27_862_3063759499371481171/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-16-32_674_3218170732469048135/-mr-10000
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part4 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/stats11.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/stats11.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/stats11.q.out_0.17	(revision 0)
@@ -0,0 +1,1170 @@
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin_part
+PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2
+PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
+PREHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+PREHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+PREHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+PREHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin_part b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST b))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL b) ds) "2008-04-08"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            GatherStats: false
+            Common Join Operator
+              condition map:
+                   Inner Join 0 to 1
+              condition expressions:
+                0 {key} {value}
+                1 {value} {ds}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              outputColumnNames: _col0, _col1, _col5, _col6
+              Position of Big Table: 0
+              Select Operator
+                expressions:
+                      expr: _col0
+                      type: int
+                      expr: _col1
+                      type: string
+                      expr: _col5
+                      type: string
+                      expr: _col6
+                      type: string
+                outputColumnNames: _col0, _col1, _col5, _col6
+                Filter Operator
+                  isSamplingPred: false
+                  predicate:
+                      expr: (_col6 = '2008-04-08')
+                      type: boolean
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: int
+                          expr: _col1
+                          type: string
+                          expr: _col5
+                          type: string
+                    outputColumnNames: _col0, _col1, _col2
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 1
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002
+                      NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000/
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          properties:
+                            bucket_count -1
+                            columns key,value1,value2
+                            columns.types string:string:string
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            name bucketmapjoin_tmp_result
+                            serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                            serialization.format 1
+                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            transient_lastDdlTime 1284595522
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          name: bucketmapjoin_tmp_result
+                      TotalFiles: 1
+                      GatherStats: true
+                      MultiFileSpray: false
+      Local Work:
+        Map Reduce Local Work
+          Alias -> Map Local Tables:
+            b 
+              Fetch Operator
+                limit: -1
+          Alias -> Map Local Operator Tree:
+            b 
+              TableScan
+                alias: b
+                GatherStats: false
+                Filter Operator
+                  isSamplingPred: false
+                  predicate:
+                      expr: (ds = '2008-04-08')
+                      type: boolean
+                  Common Join Operator
+                    condition map:
+                         Inner Join 0 to 1
+                    condition expressions:
+                      0 {key} {value}
+                      1 {value} {ds}
+                    handleSkewJoin: false
+                    keys:
+                      0 [Column[key]]
+                      1 [Column[key]]
+                    outputColumnNames: _col0, _col1, _col5, _col6
+                    Position of Big Table: 0
+                    Select Operator
+                      expressions:
+                            expr: _col0
+                            type: int
+                            expr: _col1
+                            type: string
+                            expr: _col5
+                            type: string
+                            expr: _col6
+                            type: string
+                      outputColumnNames: _col0, _col1, _col5, _col6
+                      Filter Operator
+                        isSamplingPred: false
+                        predicate:
+                            expr: (_col6 = '2008-04-08')
+                            type: boolean
+                        Select Operator
+                          expressions:
+                                expr: _col0
+                                type: int
+                                expr: _col1
+                                type: string
+                                expr: _col5
+                                type: string
+                          outputColumnNames: _col0, _col1, _col2
+                          File Output Operator
+                            compressed: false
+                            GlobalTableId: 1
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002
+                            NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000/
+                            table:
+                                input format: org.apache.hadoop.mapred.TextInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                properties:
+                                  bucket_count -1
+                                  columns key,value1,value2
+                                  columns.types string:string:string
+                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  name bucketmapjoin_tmp_result
+                                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                                  serialization.format 1
+                                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                  transient_lastDdlTime 1284595522
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                name: bucketmapjoin_tmp_result
+                            TotalFiles: 1
+                            GatherStats: true
+                            MultiFileSpray: false
+          Bucket Mapjoin Context:
+              Alias Bucket Base File Name Mapping:
+                b {srcbucket20.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket21.txt=[srcbucket21.txt, srcbucket23.txt]}
+              Alias Bucket File Name Mapping:
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
+          Partition
+            base file name: srcbucket_mapjoin
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count 2
+              bucket_field_name key
+              columns key,value
+              columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+              name srcbucket_mapjoin
+              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284595515
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count 2
+                bucket_field_name key
+                columns key,value
+                columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+                name srcbucket_mapjoin
+                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284595515
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcbucket_mapjoin
+            name: srcbucket_mapjoin
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284595522
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002 
+            Reduce Output Operator
+              sort order: 
+              Map-reduce partition columns:
+                    expr: rand()
+                    type: double
+              tag: -1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value1
+                    type: string
+                    expr: value2
+                    type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value1,value2
+              columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              name bucketmapjoin_tmp_result
+              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284595522
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284595522
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+            name: bucketmapjoin_tmp_result
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-05-22_445_5564336807553422597/-ext-10000
+            NumFilesPerFileSink: 1
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                properties:
+                  bucket_count -1
+                  columns key,value1,value2
+                  columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  name bucketmapjoin_tmp_result
+                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                  serialization.format 1
+                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  transient_lastDdlTime 1284595522
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: bucketmapjoin_tmp_result
+            TotalFiles: 1
+            GatherStats: false
+            MultiFileSpray: false
+
+
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-05-37_572_4848031747910632500/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-05-37_572_4848031747910632500/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-04_156_3350511673551507178/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-04_156_3350511673551507178/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_hash_result_1
+PREHOOK: Input: default@bucketmapjoin_hash_result_2
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-14_962_7137702241165804499/-mr-10000
+POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_hash_result_1
+POSTHOOK: Input: default@bucketmapjoin_hash_result_2
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-14_962_7137702241165804499/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+0	0	0
+PREHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin_part b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL b) ds) "2008-04-08"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: (ds = '2008-04-08')
+                  type: boolean
+              Common Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                condition expressions:
+                  0 {key} {value}
+                  1 {value} {ds}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                outputColumnNames: _col0, _col1, _col5, _col6
+                Position of Big Table: 1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: int
+                        expr: _col1
+                        type: string
+                        expr: _col5
+                        type: string
+                        expr: _col6
+                        type: string
+                  outputColumnNames: _col0, _col1, _col5, _col6
+                  Filter Operator
+                    isSamplingPred: false
+                    predicate:
+                        expr: (_col6 = '2008-04-08')
+                        type: boolean
+                    Select Operator
+                      expressions:
+                            expr: _col0
+                            type: int
+                            expr: _col1
+                            type: string
+                            expr: _col5
+                            type: string
+                      outputColumnNames: _col0, _col1, _col2
+                      File Output Operator
+                        compressed: false
+                        GlobalTableId: 1
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002
+                        NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000/
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            properties:
+                              bucket_count -1
+                              columns key,value1,value2
+                              columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
+                              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                              serialization.format 1
+                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                              totalSize 8983
+                              transient_lastDdlTime 1284595564
+                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            name: bucketmapjoin_tmp_result
+                        TotalFiles: 1
+                        GatherStats: true
+                        MultiFileSpray: false
+      Local Work:
+        Map Reduce Local Work
+          Alias -> Map Local Tables:
+            a 
+              Fetch Operator
+                limit: -1
+          Alias -> Map Local Operator Tree:
+            a 
+              TableScan
+                alias: a
+                GatherStats: false
+                Common Join Operator
+                  condition map:
+                       Inner Join 0 to 1
+                  condition expressions:
+                    0 {key} {value}
+                    1 {value} {ds}
+                  handleSkewJoin: false
+                  keys:
+                    0 [Column[key]]
+                    1 [Column[key]]
+                  outputColumnNames: _col0, _col1, _col5, _col6
+                  Position of Big Table: 1
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: int
+                          expr: _col1
+                          type: string
+                          expr: _col5
+                          type: string
+                          expr: _col6
+                          type: string
+                    outputColumnNames: _col0, _col1, _col5, _col6
+                    Filter Operator
+                      isSamplingPred: false
+                      predicate:
+                          expr: (_col6 = '2008-04-08')
+                          type: boolean
+                      Select Operator
+                        expressions:
+                              expr: _col0
+                              type: int
+                              expr: _col1
+                              type: string
+                              expr: _col5
+                              type: string
+                        outputColumnNames: _col0, _col1, _col2
+                        File Output Operator
+                          compressed: false
+                          GlobalTableId: 1
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002
+                          NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000/
+                          table:
+                              input format: org.apache.hadoop.mapred.TextInputFormat
+                              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              properties:
+                                bucket_count -1
+                                columns key,value1,value2
+                                columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                name bucketmapjoin_tmp_result
+                                numFiles 1
+                                numPartitions 0
+                                numRows 464
+                                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                                serialization.format 1
+                                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                totalSize 8983
+                                transient_lastDdlTime 1284595564
+                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                              name: bucketmapjoin_tmp_result
+                          TotalFiles: 1
+                          GatherStats: true
+                          MultiFileSpray: false
+          Bucket Mapjoin Context:
+              Alias Bucket Base File Name Mapping:
+                a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
+              Alias Bucket File Name Mapping:
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+          Partition
+            base file name: ds=2008-04-08
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+            properties:
+              bucket_count 4
+              bucket_field_name key
+              columns key,value
+              columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              name srcbucket_mapjoin_part
+              partition_columns ds
+              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284595515
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count 4
+                bucket_field_name key
+                columns key,value
+                columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                name srcbucket_mapjoin_part
+                partition_columns ds
+                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284595515
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcbucket_mapjoin_part
+            name: srcbucket_mapjoin_part
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 8983
+                transient_lastDdlTime 1284595564
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002 
+            Reduce Output Operator
+              sort order: 
+              Map-reduce partition columns:
+                    expr: rand()
+                    type: double
+              tag: -1
+              value expressions:
+                    expr: key
+                    type: string
+                    expr: value1
+                    type: string
+                    expr: value2
+                    type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value1,value2
+              columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
+              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 8983
+              transient_lastDdlTime 1284595564
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 8983
+                transient_lastDdlTime 1284595564
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+            name: bucketmapjoin_tmp_result
+      Reduce Operator Tree:
+        Extract
+          File Output Operator
+            compressed: false
+            GlobalTableId: 0
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-06-21_081_2446004609830031021/-ext-10000
+            NumFilesPerFileSink: 1
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                properties:
+                  bucket_count -1
+                  columns key,value1,value2
+                  columns.types string:string:string
+                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 464
+                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                  serialization.format 1
+                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  totalSize 8983
+                  transient_lastDdlTime 1284595564
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                name: bucketmapjoin_tmp_result
+            TotalFiles: 1
+            GatherStats: false
+            MultiFileSpray: false
+
+
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-38_720_7865716198362733195/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-06-38_720_7865716198362733195/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-07-05_592_1079289315489737019/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-07-05_592_1079289315489737019/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_hash_result_1
+PREHOOK: Input: default@bucketmapjoin_hash_result_2
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-07-16_357_8263819315859348196/-mr-10000
+POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_hash_result_1
+POSTHOOK: Input: default@bucketmapjoin_hash_result_2
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-07-16_357_8263819315859348196/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+0	0	0
Index: ql/src/test/results/clientpositive/sample5.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample5.q.out	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -30,6 +31,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -50,8 +52,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -61,21 +64,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282111179
+                          transient_lastDdlTime 1284510269
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +91,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110630
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -104,31 +108,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110630
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -138,24 +142,28 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111179
+                transient_lastDdlTime 1284510269
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -166,21 +174,22 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111179
+                    transient_lastDdlTime 1284510269
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-39_912_2348974019619594198/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-29_986_2811943230690720353/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -191,12 +200,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111179
+              transient_lastDdlTime 1284510269
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -207,12 +216,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111179
+                transient_lastDdlTime 1284510269
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -233,11 +242,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-47_348_7372385437159295360/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-40_832_4548020518900973837/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-47_348_7372385437159295360/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-40_832_4548020518900973837/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
Index: ql/src/test/results/clientpositive/union18.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union18.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/union18.q.out_0.17	(working copy)
@@ -31,16 +31,18 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-3 depends on stages: Stage-2, Stage-10
-  Stage-6 depends on stages: Stage-3 , consists of Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-2, Stage-12
+  Stage-7 depends on stages: Stage-3 , consists of Stage-6, Stage-5
+  Stage-6
+  Stage-0 depends on stages: Stage-6, Stage-5
+  Stage-4 depends on stages: Stage-0
   Stage-5
-  Stage-0 depends on stages: Stage-5, Stage-4
-  Stage-4
-  Stage-9 depends on stages: Stage-3 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
-  Stage-10 is a root stage
+  Stage-11 depends on stages: Stage-3 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
+  Stage-12 is a root stage
 
 STAGE PLANS:
   Stage: Stage-2
@@ -86,7 +88,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-40-07_550_3826183924486924788/10004 
+        file:/tmp/nzhang/hive_2010-09-15_17-37-44_413_719534855658961220/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -120,7 +122,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
-        file:/tmp/jssarma/hive_2010-07-21_13-40-07_550_3826183924486924788/10007 
+        file:/tmp/nzhang/hive_2010-09-15_17-37-44_413_719534855658961220/-mr-10007 
           Union
             Select Operator
               expressions:
@@ -155,14 +157,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
 
-  Stage: Stage-6
+  Stage: Stage-7
     Conditional Operator
 
-  Stage: Stage-5
+  Stage: Stage-6
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-40-07_550_3826183924486924788/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-37-44_413_719534855658961220/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -175,9 +177,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-40-07_550_3826183924486924788/10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-37-44_413_719534855658961220/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -200,14 +205,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-40-07_550_3826183924486924788/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-37-44_413_719534855658961220/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -219,10 +224,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-40-07_550_3826183924486924788/10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-37-44_413_719534855658961220/-ext-10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -247,7 +255,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
 
-  Stage: Stage-10
+  Stage: Stage-12
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -294,11 +302,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-20_062_6577181830322101134/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-38-08_981_6697459755904506833/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-20_062_6577181830322101134/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-38-08_981_6697459755904506833/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
@@ -808,11 +816,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-22_623_1808569051501536701/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-38-12_742_673551685957770579/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-22_623_1808569051501536701/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-38-12_742_673551685957770579/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join26.q.out
===================================================================
--- ql/src/test/results/clientpositive/join26.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join26.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -83,8 +85,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -94,15 +97,16 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282863512
+                                transient_lastDdlTime 1284507528
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -117,6 +121,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -153,8 +158,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -164,19 +170,21 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282863512
+                              transient_lastDdlTime 1284507528
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -213,8 +221,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -224,21 +233,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282863512
+                              transient_lastDdlTime 1284507528
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -252,13 +262,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -269,32 +279,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -304,24 +314,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863512
+                transient_lastDdlTime 1284507528
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -332,21 +346,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282863512
+                    transient_lastDdlTime 1284507528
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-32_296_8733880232228770886/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-48_342_7099969216988377302/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -357,12 +372,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282863512
+              transient_lastDdlTime 1284507528
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -373,12 +388,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863512
+                transient_lastDdlTime 1284507528
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -408,11 +423,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-58-37_050_6374384295174848949/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-38-55_538_7925205774034730305/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-58-37_050_6374384295174848949/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-38-55_538_7925205774034730305/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby5_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby5_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby5_map.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -76,7 +77,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT sum(src.key)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -89,10 +93,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-05_459_8853604482994995485/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-25_205_2877964195342389464/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-05_459_8853604482994995485/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-25_205_2877964195342389464/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 130091
Index: ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin_negative.q.out	(working copy)
@@ -55,10 +55,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -67,6 +68,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -107,8 +109,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -118,15 +121,16 @@
                             columns.types string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                             name bucketmapjoin_tmp_result
                             serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282110742
+                            transient_lastDdlTime 1284505301
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: bucketmapjoin_tmp_result
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -138,6 +142,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -183,8 +188,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -194,21 +200,22 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282110742
+                                  transient_lastDdlTime 1284505301
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -220,12 +227,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110739
+              transient_lastDdlTime 1284505298
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -237,31 +244,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110739
+                transient_lastDdlTime 1284505298
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -271,24 +278,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110742
+                transient_lastDdlTime 1284505301
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -299,21 +310,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110742
+                    transient_lastDdlTime 1284505301
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-22_122_8735013364922658238/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-41_683_3418559117121417207/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -324,12 +336,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110742
+              transient_lastDdlTime 1284505301
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -340,13 +352,14 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110742
+                transient_lastDdlTime 1284505301
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
 
+
Index: ql/src/test/results/clientpositive/load_dyn_part10.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part10.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part10.q.out	(working copy)
@@ -29,15 +29,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:05:28 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:13:58 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part10	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part10	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473128          
+	transient_lastDdlTime	1285053238          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -64,6 +64,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -111,7 +112,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part10
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from srcpart
 insert overwrite table nzhang_part10 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
 PREHOOK: type: QUERY
@@ -142,12 +146,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part10@ds=2008-12-31/hr=11
 PREHOOK: Input: default@nzhang_part10@ds=2008-12-31/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-05-31_829_4793616262436642129/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-14-06_981_2043462217259672901/-mr-10000
 POSTHOOK: query: select * from nzhang_part10 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part10@ds=2008-12-31/hr=11
 POSTHOOK: Input: default@nzhang_part10@ds=2008-12-31/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-05-31_829_4793616262436642129/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-14-06_981_2043462217259672901/-mr-10000
 POSTHOOK: Lineage: nzhang_part10 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part10 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part10 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/rcfile_default_format.q.out
===================================================================
--- ql/src/test/results/clientpositive/rcfile_default_format.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/rcfile_default_format.q.out	(working copy)
@@ -13,15 +13,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 08:20:03 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:42:27 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/rcfile_default_format	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/rcfile_default_format	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284477603          
+	transient_lastDdlTime	1285054947          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe	 
@@ -52,15 +52,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 08:20:05 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:42:31 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/rcfile_default_format_ctas	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/rcfile_default_format_ctas	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284477605          
+	transient_lastDdlTime	1285054951          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe	 
@@ -98,15 +98,19 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 08:20:06 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:42:31 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/rcfile_default_format_txtfile	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/rcfile_default_format_txtfile	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284477608          
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285054957          
+	numRows             	500                 
+	totalSize           	1906                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -139,15 +143,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 08:20:10 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:42:41 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/textfile_default_format_ctas	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/textfile_default_format_ctas	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284477610          
+	transient_lastDdlTime	1285054961          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
Index: ql/src/test/results/clientpositive/stats5.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats5.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats5.q.out	(revision 0)
@@ -0,0 +1,74 @@
+PREHOOK: query: create table analyze_src as select * from src
+PREHOOK: type: CREATETABLE
+PREHOOK: Input: default@src
+POSTHOOK: query: create table analyze_src as select * from src
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@analyze_src
+PREHOOK: query: explain analyze table analyze_src compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_src compute statistics
+POSTHOOK: type: null
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_src))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_src 
+          TableScan
+            alias: analyze_src
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_src compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_src
+PREHOOK: Output: default@analyze_src
+POSTHOOK: query: analyze table analyze_src compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_src
+POSTHOOK: Output: default@analyze_src
+PREHOOK: query: describe extended analyze_src
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_src
+POSTHOOK: type: DESCTABLE
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:11:29 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_src	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056694          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/smb_mapjoin_7.q.out
===================================================================
--- ql/src/test/results/clientpositive/smb_mapjoin_7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/smb_mapjoin_7.q.out	(working copy)
@@ -88,11 +88,11 @@
 PREHOOK: query: select * from smb_join_results_empty_bigtable order by k1, v1, k2, v2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results_empty_bigtable
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-05_497_2942078521176735166/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-43_597_2812884057477740432/-mr-10000
 POSTHOOK: query: select * from smb_join_results_empty_bigtable order by k1, v1, k2, v2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results_empty_bigtable
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-05_497_2942078521176735166/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-43_597_2812884057477740432/-mr-10000
 POSTHOOK: Lineage: smb_bucket4_2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_bucket4_2.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_join_results_empty_bigtable.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:null), ]
@@ -627,6 +627,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -688,7 +689,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: smb_join_results
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table smb_join_results
 select /*+mapjoin(a)*/ * from smb_bucket4_1 a full outer join smb_bucket4_2 b on a.key = b.key
 PREHOOK: type: QUERY
@@ -718,11 +722,11 @@
 PREHOOK: query: select * from smb_join_results order by k1, v1, k2, v2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-12_973_1372102537783813819/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-56_402_5775234737243407547/-mr-10000
 POSTHOOK: query: select * from smb_join_results order by k1, v1, k2, v2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-12_973_1372102537783813819/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-44-56_402_5775234737243407547/-mr-10000
 POSTHOOK: Lineage: smb_bucket4_2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_bucket4_2.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: smb_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:null), ]
@@ -1268,11 +1272,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@normal_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-21_393_9150168126997644301/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-10_652_8587502859369515866/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from normal_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@normal_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-21_393_9150168126997644301/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-10_652_8587502859369515866/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:null), ]
@@ -1295,11 +1299,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-24_503_4889415074353736512/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-14_322_2578694884050747972/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-24_503_4889415074353736512/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-14_322_2578694884050747972/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:null), ]
@@ -1322,11 +1326,11 @@
 PREHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results_empty_bigtable
 PREHOOK: type: QUERY
 PREHOOK: Input: default@smb_join_results_empty_bigtable
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-27_617_7238754568395999026/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-18_930_6487065842202942629/-mr-10000
 POSTHOOK: query: select sum(hash(k1)) as k1, sum(hash(k2)) as k2, sum(hash(v1)) as v1, sum(hash(v2)) as v2 from smb_join_results_empty_bigtable
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@smb_join_results_empty_bigtable
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-45-27_617_7238754568395999026/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-45-18_930_6487065842202942629/-mr-10000
 POSTHOOK: Lineage: normal_join_results.k1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.k2 SIMPLE [(smb_bucket4_2)b.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: normal_join_results.v1 SIMPLE [(smb_bucket4_1)a.FieldSchema(name:value, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/skewjoin.q.out
===================================================================
--- ql/src/test/results/clientpositive/skewjoin.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/skewjoin.q.out	(working copy)
@@ -56,9 +56,10 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3
-  Stage-3
-  Stage-0 depends on stages: Stage-1, Stage-3
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4
+  Stage-4
+  Stage-0 depends on stages: Stage-1, Stage-4
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -126,10 +127,10 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
         0 
@@ -220,7 +221,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src src1 JOIN src src2 ON (src1.key = src2.key)
 INSERT OVERWRITE TABLE dest_j1 SELECT src1.key, src2.value
 PREHOOK: type: QUERY
@@ -236,11 +240,11 @@
 PREHOOK: query: SELECT sum(hash(key)), sum(hash(value)) FROM dest_j1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-13_960_7342986927129350816/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-32-20_088_265990891413321286/-mr-10000
 POSTHOOK: query: SELECT sum(hash(key)), sum(hash(value)) FROM dest_j1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-13_960_7342986927129350816/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-32-20_088_265990891413321286/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 278697	101852390308
@@ -390,7 +394,7 @@
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t4
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-52_022_1767201564777971953/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-32-59_862_2469201922490952543/-mr-10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -400,7 +404,7 @@
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t4
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-52_022_1767201564777971953/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-32-59_862_2469201922490952543/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 2	12	2	22	2	12	2	12
@@ -550,7 +554,7 @@
 PREHOOK: Input: default@t2
 PREHOOK: Input: default@t3
 PREHOOK: Input: default@t4
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-57_280_3350316757246908252/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-05_555_320549944562504832/-mr-10000
 POSTHOOK: query: SELECT /*+ STREAMTABLE(a,c) */ *
 FROM T1 a JOIN T2 b ON a.key = b.key
           JOIN T3 c ON b.key = c.key
@@ -560,7 +564,7 @@
 POSTHOOK: Input: default@t2
 POSTHOOK: Input: default@t3
 POSTHOOK: Input: default@t4
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-35-57_280_3350316757246908252/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-05_555_320549944562504832/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 2	12	2	22	2	12	2	12
@@ -650,7 +654,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-36-02_136_6328495578232032954/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-33-11_763_3320930002757015267/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -695,12 +699,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-36-02_245_4669838590903193760/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-11_947_4948549999809455027/-mr-10000
 POSTHOOK: query: FROM T1 a JOIN src c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-36-02_245_4669838590903193760/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-11_947_4948549999809455027/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 198	6274	194
@@ -888,7 +892,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-36-08_862_197415476425996951/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-33-21_233_135416400611149220/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -932,7 +936,7 @@
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-36-09_103_4871359110375863219/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-21_509_6518293255572217703/-mr-10000
 POSTHOOK: query: FROM 
 (SELECT src.* FROM src) x
 JOIN 
@@ -941,7 +945,7 @@
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-36-09_103_4871359110375863219/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-33-21_509_6518293255572217703/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 44481300	101852390308
@@ -1139,7 +1143,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-37-33_559_1683759911944574309/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-35-01_721_1099039694801681089/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -1183,7 +1187,7 @@
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-37-33_809_6355273995807527985/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-35-02_103_1296780027454091580/-mr-10000
 POSTHOOK: query: FROM 
 (SELECT src.* FROM src) x
 JOIN 
@@ -1192,7 +1196,7 @@
 SELECT sum(hash(Y.key)), sum(hash(Y.value))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-37-33_809_6355273995807527985/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-35-02_103_1296780027454091580/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 NULL	NULL
@@ -1470,7 +1474,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-38-18_954_1325306763981144720/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-36-00_558_8264505707294012856/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -1639,7 +1643,7 @@
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-38-19_434_8371276815803951732/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-36-01_143_2592368341555694197/-mr-10000
 POSTHOOK: query: SELECT sum(hash(src1.c1)), sum(hash(src2.c4))
 FROM
 (SELECT src.key as c1, src.value as c2 from src) src1
@@ -1651,7 +1655,7 @@
 ON src1.c1 = src3.c5 AND src3.c5 < 80
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-38-19_434_8371276815803951732/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-36-01_143_2592368341555694197/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 293143	-136853010385
@@ -1728,7 +1732,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_16-39-13_370_294180111324718792/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_17-37-07_971_7104147537843225861/-mr-10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -1788,55 +1792,55 @@
 PREHOOK: query: SELECT /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) FROM T1 k LEFT OUTER JOIN T1 v ON k.key+1=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-13_481_7679227732704511200/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-08_099_6986157948200697425/-mr-10000
 POSTHOOK: query: SELECT /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) FROM T1 k LEFT OUTER JOIN T1 v ON k.key+1=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-13_481_7679227732704511200/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-08_099_6986157948200697425/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 372	6320
 PREHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.val
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-19_425_6467489422191230676/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-15_103_7565149712452268536/-mr-10000
 POSTHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.val
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-19_425_6467489422191230676/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-15_103_7565149712452268536/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 NULL	NULL
 PREHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-25_221_617492689938074682/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-21_720_2771757907682080403/-mr-10000
 POSTHOOK: query: select /*+ mapjoin(k)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-25_221_617492689938074682/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-21_720_2771757907682080403/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 429	12643
 PREHOOK: query: select sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-31_018_1528279542212500500/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-28_452_6093434418535192386/-mr-10000
 POSTHOOK: query: select sum(hash(k.key)), sum(hash(v.val)) from T1 k join T1 v on k.key=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-31_018_1528279542212500500/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-28_452_6093434418535192386/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 429	12643
 PREHOOK: query: select count(1) from  T1 a join T1 b on a.key = b.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-40_020_8878047536635722237/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-38_889_1047609014892238447/-mr-10000
 POSTHOOK: query: select count(1) from  T1 a join T1 b on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-40_020_8878047536635722237/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-38_889_1047609014892238447/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 8
@@ -1844,12 +1848,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-49_090_1421212582715517992/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-49_221_8506210790545243082/-mr-10000
 POSTHOOK: query: FROM T1 a LEFT OUTER JOIN T2 c ON c.key+1=a.key SELECT sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-49_090_1421212582715517992/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-49_221_8506210790545243082/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 317	9462	50
@@ -1857,12 +1861,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-55_254_6680876796938489109/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-56_340_6168859629052833187/-mr-10000
 POSTHOOK: query: FROM T1 a RIGHT OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-39-55_254_6680876796938489109/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-37-56_340_6168859629052833187/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 51	1570	318
@@ -1870,12 +1874,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-01_410_6993928537152626835/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-03_577_4249269048370838540/-mr-10000
 POSTHOOK: query: FROM T1 a FULL OUTER JOIN T2 c ON c.key+1=a.key SELECT /*+ STREAMTABLE(a) */ sum(hash(a.key)), sum(hash(a.val)), sum(hash(c.key))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-01_410_6993928537152626835/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-03_577_4249269048370838540/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 317	9462	318
@@ -1883,12 +1887,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-07_611_5143289292874656865/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-10_756_6811760235799500968/-mr-10000
 POSTHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 LEFT OUTER JOIN T2 src2 ON src1.key+1 = src2.key RIGHT OUTER JOIN T2 src3 ON src2.key = src3.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-07_611_5143289292874656865/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-10_756_6811760235799500968/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 370	11003	377
@@ -1896,23 +1900,23 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-14_005_1103261153715368406/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-18_994_7191347978897240811/-mr-10000
 POSTHOOK: query: SELECT sum(hash(src1.key)), sum(hash(src1.val)), sum(hash(src2.key)) FROM T1 src1 JOIN T2 src2 ON src1.key+1 = src2.key JOIN T2 src3 ON src2.key = src3.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-14_005_1103261153715368406/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-18_994_7191347978897240811/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 370	11003	377
 PREHOOK: query: select /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k left outer join T1 v on k.key+1=v.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-27_339_4249543099897472280/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-35_614_8013112114265683326/-mr-10000
 POSTHOOK: query: select /*+ mapjoin(v)*/ sum(hash(k.key)), sum(hash(v.val)) from T1 k left outer join T1 v on k.key+1=v.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-40-27_339_4249543099897472280/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-38-35_614_8013112114265683326/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 372	6320
Index: ql/src/test/results/clientpositive/udf1.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf1.q.out	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -106,14 +107,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-28_497_1183287301749922170/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-55-39_714_1712462366624932992/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -126,9 +127,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-28_497_1183287301749922170/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-55-39_714_1712462366624932992/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -182,11 +186,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-32_491_8368057233416644370/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-55-46_255_8352436092286552251/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-32_491_8368057233416644370/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-55-46_255_8352436092286552251/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c10 EXPRESSION []
 POSTHOOK: Lineage: dest1.c11 EXPRESSION []
Index: ql/src/test/results/clientpositive/join35.q.out
===================================================================
--- ql/src/test/results/clientpositive/join35.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join35.q.out	(working copy)
@@ -28,12 +28,13 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
+  Stage-7 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -42,6 +43,7 @@
         null-subquery1:subq1-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -80,9 +82,9 @@
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -93,12 +95,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110633
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -109,12 +111,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110633
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -138,7 +140,7 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10002
+              directory: file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10002
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -148,12 +150,13 @@
                     columns.types string,bigint
                     escape.delim \
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10002 
           Union
             Common Join Operator
               condition map:
@@ -197,8 +200,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -208,17 +212,18 @@
                             columns.types string:string:int
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                             name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282110894
+                            transient_lastDdlTime 1284507666
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10004 
           Union
             Common Join Operator
               condition map:
@@ -262,8 +267,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -273,15 +279,16 @@
                             columns.types string:string:int
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                             name dest_j1
                             serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282110894
+                            transient_lastDdlTime 1284507666
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest_j1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -293,6 +300,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -335,8 +343,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -346,22 +355,23 @@
                                 columns.types string:string:int
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282110894
+                                transient_lastDdlTime 1284507666
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10002 [file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10002]
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10004 [file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10004]
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10002 [file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10004 [file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10004]
       Path -> Partition:
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -377,7 +387,7 @@
                 columns _col0,_col1
                 columns.types string,bigint
                 escape.delim \
-        file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10004 
           Partition
             base file name: -mr-10004
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -394,21 +404,21 @@
                 columns.types string,bigint
                 escape.delim \
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -418,24 +428,28 @@
                 columns.types string:string:int
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110894
+                transient_lastDdlTime 1284507666
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10001
 
   Stage: Stage-3
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000/
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -446,21 +460,22 @@
                     columns.types string:string:int
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110894
+                    transient_lastDdlTime 1284507666
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-54-54_406_7263441585620958575/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-06_235_1465217120659994288/-ext-10003 
           Partition
             base file name: -ext-10003
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -471,12 +486,12 @@
               columns.types string:string:int
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, i32 val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110894
+              transient_lastDdlTime 1284507666
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -487,22 +502,23 @@
                 columns.types string:string:int
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, i32 val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110894
+                transient_lastDdlTime 1284507666
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:subq1-subquery2:x1 
           TableScan
             alias: x1
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -541,9 +557,9 @@
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -554,12 +570,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110633
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -570,12 +586,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110633
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -599,7 +615,7 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/nzhang/hive_2010-08-17_22-54-54_406_7263441585620958575/-mr-10004
+              directory: file:/tmp/nzhang/hive_2010-09-14_16-41-06_235_1465217120659994288/-mr-10004
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -609,6 +625,7 @@
                     columns.types string,bigint
                     escape.delim \
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
 
@@ -642,11 +659,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-55-11_006_4340375283672634760/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-23_904_6990538085820162143/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-55-11_006_4340375283672634760/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-23_904_6990538085820162143/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)x.null, (src)x1.null, ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input17.q.out
===================================================================
--- ql/src/test/results/clientpositive/input17.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input17.q.out	(working copy)
@@ -27,6 +27,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -96,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src_thrift
   SELECT TRANSFORM(src_thrift.aint + src_thrift.lint[0], src_thrift.lintstring[0])
@@ -122,11 +126,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-54_378_249191084022328137/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-31_868_739596655296346837/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-11-54_378_249191084022328137/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-31_868_739596655296346837/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src_thrift)src_thrift.FieldSchema(name:aint, type:int, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src_thrift)src_thrift.FieldSchema(name:aint, type:int, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 NULL	null
Index: ql/src/test/results/clientpositive/groupby1.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1.q.out	(working copy)
@@ -16,6 +16,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -63,7 +64,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        invalidscheme:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-05_667_8338333435711978851/10002 
+        file:/tmp/nzhang/hive_2010-09-16_13-04-05_232_8394152903633989016/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -119,7 +120,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_g1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest_g1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -133,11 +137,11 @@
 PREHOOK: query: SELECT dest_g1.* FROM dest_g1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_g1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-14_229_1556124769125603446/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_13-04-15_579_9082371312952892786/-mr-10000
 POSTHOOK: query: SELECT dest_g1.* FROM dest_g1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_g1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-14_229_1556124769125603446/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_13-04-15_579_9082371312952892786/-mr-10000
 POSTHOOK: Lineage: dest_g1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/bucketmapjoin2.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin2.q.out	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -130,8 +132,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -141,15 +144,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282861740
+                          transient_lastDdlTime 1284504846
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -161,6 +165,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -204,8 +209,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -215,29 +221,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282861740
+                                  transient_lastDdlTime 1284504846
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -249,12 +256,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861736
+              transient_lastDdlTime 1284504838
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -266,31 +273,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861736
+                transient_lastDdlTime 1284504838
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -300,24 +307,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861740
+                transient_lastDdlTime 1284504846
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -328,21 +339,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861740
+                    transient_lastDdlTime 1284504846
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-00_664_6737222251329303138/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-06_179_6521652216467482451/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -353,12 +365,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861740
+              transient_lastDdlTime 1284504846
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -369,12 +381,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861740
+                transient_lastDdlTime 1284504846
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -402,11 +414,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-07_690_2072687980435480607/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-17_966_8697223797090431206/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-07_690_2072687980435480607/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-17_966_8697223797090431206/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part_2)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -455,11 +467,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-21_542_4741350660030347450/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-39_374_5776763971385970443/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-21_542_4741350660030347450/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-39_374_5776763971385970443/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -498,14 +510,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-27_906_6588668366226639259/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-49_838_4256098155623662521/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-27_906_6588668366226639259/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-54-49_838_4256098155623662521/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -548,10 +560,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -560,6 +573,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -603,8 +617,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -614,15 +629,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 0
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861761
+                              totalSize 0
+                              transient_lastDdlTime 1284504879
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -634,6 +654,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -667,8 +688,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -678,29 +700,34 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 0
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861761
+                              totalSize 0
+                              transient_lastDdlTime 1284504879
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -714,13 +741,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861739
+              transient_lastDdlTime 1284504843
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -732,32 +759,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861739
+                transient_lastDdlTime 1284504843
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -767,24 +794,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 0
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861761
+                totalSize 0
+                transient_lastDdlTime 1284504879
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -795,21 +830,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 0
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861761
+                    totalSize 0
+                    transient_lastDdlTime 1284504879
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-29-31_208_6758488839295751961/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-54-55_054_5147409437043781660/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -820,12 +860,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 0
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861761
+              totalSize 0
+              transient_lastDdlTime 1284504879
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -836,12 +880,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 0
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861761
+                totalSize 0
+                transient_lastDdlTime 1284504879
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -881,11 +929,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-38_202_3729411326545213662/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-07_203_4137128469733058276/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-38_202_3729411326545213662/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-07_203_4137128469733058276/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -970,11 +1018,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-52_089_4107376078253101346/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-27_916_6426220424044343424/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-52_089_4107376078253101346/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-27_916_6426220424044343424/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1037,14 +1085,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-58_456_5874614412150965390/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-37_835_5727221086898908041/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-29-58_456_5874614412150965390/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-55-37_835_5727221086898908041/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/input36.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input36.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input36.q.out_0.17	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-39_984_3940250455777537034/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-47-03_190_3411933588563703729/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-39_984_3940250455777537034/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-47-03_190_3411933588563703729/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -144,11 +148,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-44_738_2361145944394412724/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-09_366_8726442488003618291/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-11-44_738_2361145944394412724/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-47-09_366_8726442488003618291/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 NULL	NULL
Index: ql/src/test/results/clientpositive/multi_insert.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/multi_insert.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/multi_insert.q.out_0.17	(working copy)
@@ -24,7 +24,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -82,6 +84,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -92,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -114,11 +122,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-21_712_5062335963199774462/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-38_542_2270092604120536477/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-21_712_5062335963199774462/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-38_542_2270092604120536477/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi2.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -136,11 +144,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-24_226_5046921944761310383/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-42_090_7054068177318735521/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-24_226_5046921944761310383/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-42_090_7054068177318735521/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi2.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -173,14 +181,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -228,14 +238,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-26_695_7647953576858754386/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-24-45_689_5934667500135467981/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -248,9 +258,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-26_695_7647953576858754386/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-24-45_689_5934667500135467981/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -273,14 +286,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-26_695_7647953576858754386/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-24-45_689_5934667500135467981/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -292,10 +305,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-26_695_7647953576858754386/10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-24-45_689_5934667500135467981/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -344,11 +360,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-29_398_374250277965899089/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-54_252_3010317928750192925/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-29_398_374250277965899089/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-54_252_3010317928750192925/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
@@ -370,11 +386,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-31_972_5943245082125077624/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-57_760_7234752938726173637/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-31_972_5943245082125077624/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-24-57_760_7234752938726173637/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
@@ -416,7 +432,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -474,6 +492,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -484,7 +505,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -514,11 +538,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-37_232_5055054932535323703/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-08_762_7347509406076828396/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-37_232_5055054932535323703/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-08_762_7347509406076828396/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -544,11 +568,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-39_724_5919666556486138657/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-12_269_8104722533424705046/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-39_724_5919666556486138657/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-12_269_8104722533424705046/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -597,14 +621,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -652,14 +678,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-42_204_3144075225672991179/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-15_865_7994139129446392129/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -672,9 +698,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-42_204_3144075225672991179/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-15_865_7994139129446392129/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -697,14 +726,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-42_204_3144075225672991179/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-15_865_7994139129446392129/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -716,10 +745,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-41-42_204_3144075225672991179/10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-15_865_7994139129446392129/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -776,11 +808,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-44_892_3027065579813818242/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-23_966_5331285986700185679/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-44_892_3027065579813818242/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-23_966_5331285986700185679/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -810,11 +842,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-47_356_9057856219474591094/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-27_486_7040610682521460075/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-47_356_9057856219474591094/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-27_486_7040610682521460075/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -872,8 +904,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -978,9 +1012,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-41-49_873_5452620989462977001/10004 
+        file:/tmp/nzhang/hive_2010-09-15_16-25-31_006_4309783015953454863/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1030,7 +1067,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10 group by key, value
 insert overwrite table src_multi2 select * where key > 10 and key < 20 group by key, value
@@ -1068,11 +1108,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-55_158_3039517705245630432/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-43_808_448081382055910931/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-55_158_3039517705245630432/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-43_808_448081382055910931/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1102,11 +1142,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-57_720_498471983118793979/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-47_374_6837532585743306461/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-41-57_720_498471983118793979/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-25-47_374_6837532585743306461/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1168,15 +1208,17 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 depends on stages: Stage-2
-  Stage-9 depends on stages: Stage-6 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
+  Stage-7 depends on stages: Stage-2
+  Stage-11 depends on stages: Stage-7 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1270,14 +1312,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-00_181_6805544255394938954/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-50_908_1628047525349335922/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -1290,9 +1332,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-00_181_6805544255394938954/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-50_908_1628047525349335922/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1315,10 +1360,10 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-42-00_181_6805544255394938954/10005 
+        file:/tmp/nzhang/hive_2010-09-15_16-25-50_908_1628047525349335922/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1358,14 +1403,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi2
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-00_181_6805544255394938954/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-50_908_1628047525349335922/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -1377,10 +1422,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-00_181_6805544255394938954/10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-25-50_908_1628047525349335922/-ext-10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -1445,11 +1493,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-05_457_2938335370779332907/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-04_904_1173113980695958694/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-05_457_2938335370779332907/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-04_904_1173113980695958694/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1483,11 +1531,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-07_979_1197234407834858516/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-08_456_3107961049609939498/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-07_979_1197234407834858516/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-08_456_3107961049609939498/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1558,8 +1606,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1664,9 +1714,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-42-10_540_8287802089011554187/10004 
+        file:/tmp/nzhang/hive_2010-09-15_16-26-11_931_8386741128813885776/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1716,7 +1769,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10 group by key, value
 insert overwrite table src_multi2 select * where key > 10 and key < 20 group by key, value
@@ -1762,11 +1818,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-15_956_8233613409144913424/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-25_905_3736411148762441404/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-15_956_8233613409144913424/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-25_905_3736411148762441404/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1804,11 +1860,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-18_525_6028070244185370122/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-29_441_8945333953910935265/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-18_525_6028070244185370122/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-29_441_8945333953910935265/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1886,15 +1942,17 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 depends on stages: Stage-2
-  Stage-9 depends on stages: Stage-6 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
+  Stage-7 depends on stages: Stage-2
+  Stage-11 depends on stages: Stage-7 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1988,14 +2046,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-21_003_5167136917621088373/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-26-32_967_7948671017665598801/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -2008,9 +2066,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-21_003_5167136917621088373/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-26-32_967_7948671017665598801/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2033,10 +2094,10 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-42-21_003_5167136917621088373/10005 
+        file:/tmp/nzhang/hive_2010-09-15_16-26-32_967_7948671017665598801/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -2076,14 +2137,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi2
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-21_003_5167136917621088373/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-26-32_967_7948671017665598801/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -2095,10 +2156,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-21_003_5167136917621088373/10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-26-32_967_7948671017665598801/-ext-10006 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2171,11 +2235,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-26_240_3559046036845532/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-47_121_4542038743457481911/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-26_240_3559046036845532/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-47_121_4542038743457481911/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2217,11 +2281,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-28_796_451544540094033007/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-50_620_720829618671960675/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-28_796_451544540094033007/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-26-50_620_720829618671960675/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2308,7 +2372,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -2423,6 +2489,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -2433,7 +2502,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from (select * from src  union all select * from src) s
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -2487,11 +2559,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-34_097_7757454628091368486/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-01_872_8371026071058200450/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-34_097_7757454628091368486/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-01_872_8371026071058200450/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2551,11 +2623,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-36_786_8996732990789151375/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-05_470_3500927499951606556/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-36_786_8996732990789151375/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-05_470_3500927499951606556/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2661,14 +2733,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -2773,14 +2847,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-39_255_2282025271684185143/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-09_024_6232895060968189495/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -2793,9 +2867,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-39_255_2282025271684185143/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-09_024_6232895060968189495/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2818,14 +2895,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-39_255_2282025271684185143/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-09_024_6232895060968189495/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -2837,10 +2914,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-39_255_2282025271684185143/10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-09_024_6232895060968189495/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -2921,11 +3001,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-42_021_1773614549788907879/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-17_870_620054452609631193/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-42_021_1773614549788907879/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-17_870_620054452609631193/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2989,11 +3069,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-44_498_2123904018906456758/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-21_374_1948399240022869772/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-44_498_2123904018906456758/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-21_374_1948399240022869772/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3108,7 +3188,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -3223,6 +3305,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -3233,7 +3318,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from (select * from src  union all select * from src) s
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -3295,11 +3383,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-49_805_7878050643299431709/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-33_653_1048219271260928033/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-49_805_7878050643299431709/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-33_653_1048219271260928033/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3367,11 +3455,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-52_268_1999896450202641016/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-37_202_5623447585466896557/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-52_268_1999896450202641016/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-37_202_5623447585466896557/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3493,14 +3581,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -3605,14 +3695,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-54_799_7180997344452135463/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-40_685_1109210091347718278/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -3625,9 +3715,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-54_799_7180997344452135463/10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-40_685_1109210091347718278/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -3650,14 +3743,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-54_799_7180997344452135463/10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-40_685_1109210091347718278/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -3669,10 +3762,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-42-54_799_7180997344452135463/10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-27-40_685_1109210091347718278/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -3761,11 +3857,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-57_592_4817069631526155036/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-48_917_1774957050669222036/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-42-57_592_4817069631526155036/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-48_917_1774957050669222036/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3837,11 +3933,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-43-00_113_6879485217176937186/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-52_412_7103277610963964494/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-43-00_113_6879485217176937186/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-27-52_412_7103277610963964494/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucket_groupby.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucket_groupby.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucket_groupby.q.out	(working copy)
@@ -19,15 +19,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:01:29 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:12:00 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/clustergroupby	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/clustergroupby	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284472889          
+	transient_lastDdlTime	1285049520          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -139,11 +139,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby where ds='100' group by key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=100
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-32_671_184754291794205519/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-08_471_264777909273341136/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby where ds='100' group by key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=100
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-32_671_184754291794205519/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-08_471_264777909273341136/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	3
@@ -184,17 +184,21 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:01:29 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:12:00 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/clustergroupby	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/clustergroupby	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472895          
-	transient_lastDdlTime	1284472895          
+	numPartitions       	1                   
+	numFiles            	1                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049532          
+	transient_lastDdlTime	1285049532          
+	numRows             	500                 
+	totalSize           	5812                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -312,11 +316,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='101' group by key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-37_660_5184895418229732010/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-20_193_4381502362232094489/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='101' group by key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-37_660_5184895418229732010/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-20_193_4381502362232094489/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -424,11 +428,11 @@
 PREHOOK: query: select length(key), count(1) from clustergroupby  where ds='101' group by length(key) limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-40_136_5333503944919429418/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-24_121_8011305195289924924/-mr-10000
 POSTHOOK: query: select length(key), count(1) from clustergroupby  where ds='101' group by length(key) limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-40_136_5333503944919429418/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-24_121_8011305195289924924/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -527,11 +531,11 @@
 PREHOOK: query: select abs(length(key)), count(1) from clustergroupby  where ds='101' group by abs(length(key)) limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-42_537_6448635417298664043/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-28_041_4377337206683711142/-mr-10000
 POSTHOOK: query: select abs(length(key)), count(1) from clustergroupby  where ds='101' group by abs(length(key)) limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-42_537_6448635417298664043/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-28_041_4377337206683711142/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -640,11 +644,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='101' group by key,3 limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-45_085_2973729075661678981/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-31_955_2035389635675970206/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='101' group by key,3 limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-45_085_2973729075661678981/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-31_955_2035389635675970206/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -757,11 +761,11 @@
 PREHOOK: query: select key, count(1) from (select value as key, key as value from clustergroupby where ds='101')subq group by key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-47_519_4150023209351271110/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-35_858_682244352816074312/-mr-10000
 POSTHOOK: query: select key, count(1) from (select value as key, key as value from clustergroupby where ds='101')subq group by key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-47_519_4150023209351271110/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-35_858_682244352816074312/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -859,12 +863,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=100
 PREHOOK: Input: default@clustergroupby@ds=101
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-49_963_847364919817016340/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-39_667_6993113161354815698/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  group by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=100
 POSTHOOK: Input: default@clustergroupby@ds=101
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-49_963_847364919817016340/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-39_667_6993113161354815698/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1299,17 +1303,21 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:01:29 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:12:00 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/clustergroupby	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/clustergroupby	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472912          
-	transient_lastDdlTime	1284472912          
+	numPartitions       	2                   
+	numFiles            	2                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049564          
+	transient_lastDdlTime	1285049564          
+	numRows             	1000                
+	totalSize           	11624               
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -1429,11 +1437,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='102' group by key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=102
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-55_167_3909629834677935174/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-52_423_5195000162572997399/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='102' group by key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=102
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-55_167_3909629834677935174/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-52_423_5195000162572997399/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1543,11 +1551,11 @@
 PREHOOK: query: select value, count(1) from clustergroupby  where ds='102'  group by value limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=102
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-57_637_509238495868255690/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-56_614_4460480942841985035/-mr-10000
 POSTHOOK: query: select value, count(1) from clustergroupby  where ds='102'  group by value limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=102
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-01-57_637_509238495868255690/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-12-56_614_4460480942841985035/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1667,11 +1675,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='102'  group by key, value limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=102
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-00_148_921063500290226800/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-00_558_2886682989236055618/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='102'  group by key, value limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=102
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-00_148_921063500290226800/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-00_558_2886682989236055618/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1724,17 +1732,21 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:01:29 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:12:00 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/clustergroupby	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/clustergroupby	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472922          
-	transient_lastDdlTime	1284472922          
+	numPartitions       	3                   
+	numFiles            	3                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049584          
+	transient_lastDdlTime	1285049584          
+	numRows             	1500                
+	totalSize           	17436               
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -1858,11 +1870,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='103' group by key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=103
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-05_044_5429885382737940304/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-11_680_1170880569605249416/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='103' group by key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=103
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-05_044_5429885382737940304/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-11_680_1170880569605249416/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1986,11 +1998,11 @@
 PREHOOK: query: select key, count(1) from clustergroupby  where ds='103' group by  value, key limit 10
 PREHOOK: type: QUERY
 PREHOOK: Input: default@clustergroupby@ds=103
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-07_481_6550793560447230881/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-15_849_1305890724778001430/-mr-10000
 POSTHOOK: query: select key, count(1) from clustergroupby  where ds='103' group by  value, key limit 10
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@clustergroupby@ds=103
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-02-07_481_6550793560447230881/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-13-15_849_1305890724778001430/-mr-10000
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=100).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: clustergroupby PARTITION(ds=101).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udf_length.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/udf_length.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_length.q.out_0.17	(working copy)
@@ -25,10 +25,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-03-05_243_1924060197923302676/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-23-28_781_1116385644916769778/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-03-05_243_1924060197923302676/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-23-28_781_1116385644916769778/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -107,11 +111,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-09_783_5734453621251438276/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-23-35_105_4554968271416069503/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-09_783_5734453621251438276/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-23-35_105_4554968271416069503/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 7
 0
@@ -200,10 +204,10 @@
 PREHOOK: query: SELECT length(dest1.name) FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-11_141_7103995301140553325/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-23-37_127_3342114754622751938/-mr-10000
 POSTHOOK: query: SELECT length(dest1.name) FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-11_141_7103995301140553325/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-23-37_127_3342114754622751938/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 2
Index: ql/src/test/results/clientpositive/groupby11.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby11.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby11.q.out	(working copy)
@@ -29,8 +29,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -91,7 +93,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-22-39_568_3957054152816650703/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-13-06_619_2524206957556241682/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -157,9 +159,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-22-39_568_3957054152816650703/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-13-06_619_2524206957556241682/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -224,7 +229,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 partition(ds='111')
   SELECT src.value, count(src.key), count(distinct src.key) GROUP BY src.value
@@ -252,11 +260,11 @@
 PREHOOK: query: SELECT * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1@ds=111
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-47_442_688004092056696440/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-23_878_7631144378551966147/-mr-10000
 POSTHOOK: query: SELECT * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1@ds=111
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-47_442_688004092056696440/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-23_878_7631144378551966147/-mr-10000
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).key SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).val1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).val2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -575,11 +583,11 @@
 PREHOOK: query: SELECT * from dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2@ds=111
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-47_517_4221724803022357819/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-24_357_749669543090460434/-mr-10000
 POSTHOOK: query: SELECT * from dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2@ds=111
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-22-47_517_4221724803022357819/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-24_357_749669543090460434/-mr-10000
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).key SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).val1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(ds=111).val2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/mapreduce7.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce7.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -108,7 +109,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.*, src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -134,11 +138,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-28_602_6476291733202587590/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-52_601_3536108148585696889/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-28_602_6476291733202587590/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-52_601_3536108148585696889/-mr-10000
 POSTHOOK: Lineage: dest1.k SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input8.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input8.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input8.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -55,14 +56,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-36_588_2565331403714655213/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-44_057_8831668061686642037/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -75,9 +76,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-36_588_2565331403714655213/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-44_057_8831668061686642037/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -119,11 +123,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-41_080_1245549605067769651/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-50_233_1032529439211250774/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-41_080_1245549605067769651/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-50_233_1032529439211250774/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/udf_explode.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf_explode.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_explode.q.out	(working copy)
@@ -26,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: array(1,2,3)
@@ -37,8 +38,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/tmp/jssarma/hive_2010-07-25_12-45-28_746_6403683001829896191/-ext-10001
+                    directory: file:/tmp/nzhang/hive_2010-09-15_17-19-40_025_3910076199083461129/-ext-10001
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-19-40_025_3910076199083461129/-ext-10001/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -47,12 +49,13 @@
                           columns.types int
                           serialization.format 1
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -63,12 +66,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280086854
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -79,12 +82,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280086854
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -113,6 +116,7 @@
         a:src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: array(1,2,3)
@@ -129,9 +133,9 @@
                           type: int
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [a:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a:src]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -142,12 +146,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280086854
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -158,12 +162,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280086854
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -187,7 +191,7 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-mr-10002
+                  directory: file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-mr-10002
                   NumFilesPerFileSink: 1
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -197,12 +201,13 @@
                         columns.types int,bigint
                         escape.delim \
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -217,9 +222,9 @@
                     type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-mr-10002 [file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-mr-10002 [file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-mr-10002]
       Path -> Partition:
-        file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -255,8 +260,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/jssarma/hive_2010-07-25_12-45-28_813_2941624137821891314/-ext-10001
+              directory: file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-19-40_065_141080764987446855/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -265,6 +271,7 @@
                     columns.types int:bigint
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -275,33 +282,33 @@
 PREHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-28_892_2431440475493662931/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-19-40_117_2393476748831762851/-mr-10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-28_892_2431440475493662931/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-19-40_117_2393476748831762851/-mr-10000
 1
 2
 3
 PREHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-31_372_2926720035905767102/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-20-00_614_4063766451500768976/-mr-10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-31_372_2926720035905767102/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-20-00_614_4063766451500768976/-mr-10000
 1
 2
 3
 PREHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-33_795_6481265984988751332/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-20-08_183_2692769490322479197/-mr-10000
 POSTHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-45-33_795_6481265984988751332/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-20-08_183_2692769490322479197/-mr-10000
 1	1
 2	1
 3	1
Index: ql/src/test/results/clientpositive/groupby2_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby2_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby2_map.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -108,7 +109,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -125,11 +129,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-28_182_416296318500795385/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-26_222_9011795612818915282/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-28_182_416296318500795385/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-26_222_9011795612818915282/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample1.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: true
               predicate:
@@ -72,8 +74,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -83,21 +86,22 @@
                               columns.types int:string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                               name dest1
                               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282158174
+                              transient_lastDdlTime 1284594086
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,13 +115,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -128,32 +132,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -163,20 +167,24 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282158174
+                transient_lastDdlTime 1284594086
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -194,9 +202,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -207,12 +215,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282158174
+              transient_lastDdlTime 1284594086
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -223,12 +231,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282158174
+                transient_lastDdlTime 1284594086
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -237,7 +245,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-54_832_7020828807568587186/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-26_167_2226170390039286542/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -248,15 +256,16 @@
                   columns.types int:string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282158174
+                  transient_lastDdlTime 1284594086
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -279,11 +288,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-59_512_4600533098023234676/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-32_495_1079805714835705203/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-59_512_4600533098023234676/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-32_495_1079805714835705203/-mr-10000
 POSTHOOK: Lineage: dest1.dt SIMPLE [(srcpart)s.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)s.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)s.FieldSchema(name:key, type:string, comment:default), ]
@@ -791,11 +800,11 @@
 PREHOOK: query: select count(1) from srcbucket
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-59_950_5869755348025190685/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-33_179_4014900064903470061/-mr-10000
 POSTHOOK: query: select count(1) from srcbucket
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-59_950_5869755348025190685/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-33_179_4014900064903470061/-mr-10000
 POSTHOOK: Lineage: dest1.dt SIMPLE [(srcpart)s.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)s.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)s.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join_map_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/join_map_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join_map_ppr.q.out	(working copy)
@@ -22,10 +22,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -34,6 +35,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -84,8 +86,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -95,15 +98,16 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282863743
+                              transient_lastDdlTime 1284507870
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -118,6 +122,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -163,8 +168,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -174,19 +180,21 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282863743
+                                transient_lastDdlTime 1284507870
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -232,8 +240,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -243,21 +252,22 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282863743
+                                transient_lastDdlTime 1284507870
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -271,13 +281,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -288,32 +298,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -323,24 +333,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863743
+                transient_lastDdlTime 1284507870
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -351,21 +365,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282863743
+                    transient_lastDdlTime 1284507870
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-23_861_1154531129947007530/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-30_437_7008487967784489062/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -376,12 +391,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282863743
+              transient_lastDdlTime 1284507870
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -392,17 +407,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863743
+                transient_lastDdlTime 1284507870
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
 
-
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1
 SELECT /*+ MAPJOIN(x,y) */ x.key, z.value, y.value
 FROM src1 x JOIN src y ON (x.key = y.key) 
@@ -429,11 +443,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-02-28_814_1337540899332242986/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-38_226_829082970114385403/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-02-28_814_1337540899332242986/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-38_226_829082970114385403/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
@@ -614,10 +628,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -626,6 +641,7 @@
         z 
           TableScan
             alias: z
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -676,8 +692,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -687,15 +704,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
+                              numFiles 1
+                              numPartitions 0
+                              numRows 107
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282863748
+                              totalSize 2125
+                              transient_lastDdlTime 1284507878
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -710,6 +732,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -755,8 +778,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -766,19 +790,25 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
+                                numFiles 1
+                                numPartitions 0
+                                numRows 107
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282863748
+                                totalSize 2125
+                                transient_lastDdlTime 1284507878
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
             y 
               TableScan
                 alias: y
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -824,8 +854,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -835,21 +866,26 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                 name dest_j1
+                                numFiles 1
+                                numPartitions 0
+                                numRows 107
                                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282863748
+                                totalSize 2125
+                                transient_lastDdlTime 1284507878
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [z]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -863,13 +899,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -880,32 +916,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -915,24 +951,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
+                numFiles 1
+                numPartitions 0
+                numRows 107
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863748
+                totalSize 2125
+                transient_lastDdlTime 1284507878
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -943,21 +987,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
+                    numFiles 1
+                    numPartitions 0
+                    numRows 107
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282863748
+                    totalSize 2125
+                    transient_lastDdlTime 1284507878
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-02-38_736_8579991155336776655/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-54_999_5430658658503744271/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -968,12 +1017,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
+              numFiles 1
+              numPartitions 0
+              numRows 107
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282863748
+              totalSize 2125
+              transient_lastDdlTime 1284507878
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -984,12 +1037,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
+                numFiles 1
+                numPartitions 0
+                numRows 107
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863748
+                totalSize 2125
+                transient_lastDdlTime 1284507878
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -1028,11 +1085,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-02-43_530_7872552317980540717/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-45-02_649_8915711725845197169/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-02-43_530_7872552317980540717/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-45-02_649_8915711725845197169/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1_copy)x.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/stats0.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats0.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats0.q.out	(revision 0)
@@ -0,0 +1,2938 @@
+PREHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_non_partitioned
+PREHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_non_partitioned)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-06_292_8918619100303505951/-ext-10000
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-06_292_8918619100303505951/-ext-10000/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      bucket_count -1
+                      columns key,value
+                      columns.types string:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                      name stats_non_partitioned
+                      serialization.ddl struct stats_non_partitioned { string key, string value}
+                      serialization.format 1
+                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      transient_lastDdlTime 1285056426
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_non_partitioned
+                TotalFiles: 1
+                GatherStats: true
+                MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
+          Partition
+            base file name: src
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285049308
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285049308
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: src
+            name: src
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-06_292_8918619100303505951/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285056426
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-06_292_8918619100303505951/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-06_292_8918619100303505951/-ext-10000/
+
+
+PREHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended stats_non_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended stats_non_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:06 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056431          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: select * from stats_non_partitioned
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-12_144_2758740293957557207/-mr-10000
+POSTHOOK: query: select * from stats_non_partitioned
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-12_144_2758740293957557207/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238
+86	val_86
+311	val_311
+27	val_27
+165	val_165
+409	val_409
+255	val_255
+278	val_278
+98	val_98
+484	val_484
+265	val_265
+193	val_193
+401	val_401
+150	val_150
+273	val_273
+224	val_224
+369	val_369
+66	val_66
+128	val_128
+213	val_213
+146	val_146
+406	val_406
+429	val_429
+374	val_374
+152	val_152
+469	val_469
+145	val_145
+495	val_495
+37	val_37
+327	val_327
+281	val_281
+277	val_277
+209	val_209
+15	val_15
+82	val_82
+403	val_403
+166	val_166
+417	val_417
+430	val_430
+252	val_252
+292	val_292
+219	val_219
+287	val_287
+153	val_153
+193	val_193
+338	val_338
+446	val_446
+459	val_459
+394	val_394
+237	val_237
+482	val_482
+174	val_174
+413	val_413
+494	val_494
+207	val_207
+199	val_199
+466	val_466
+208	val_208
+174	val_174
+399	val_399
+396	val_396
+247	val_247
+417	val_417
+489	val_489
+162	val_162
+377	val_377
+397	val_397
+309	val_309
+365	val_365
+266	val_266
+439	val_439
+342	val_342
+367	val_367
+325	val_325
+167	val_167
+195	val_195
+475	val_475
+17	val_17
+113	val_113
+155	val_155
+203	val_203
+339	val_339
+0	val_0
+455	val_455
+128	val_128
+311	val_311
+316	val_316
+57	val_57
+302	val_302
+205	val_205
+149	val_149
+438	val_438
+345	val_345
+129	val_129
+170	val_170
+20	val_20
+489	val_489
+157	val_157
+378	val_378
+221	val_221
+92	val_92
+111	val_111
+47	val_47
+72	val_72
+4	val_4
+280	val_280
+35	val_35
+427	val_427
+277	val_277
+208	val_208
+356	val_356
+399	val_399
+169	val_169
+382	val_382
+498	val_498
+125	val_125
+386	val_386
+437	val_437
+469	val_469
+192	val_192
+286	val_286
+187	val_187
+176	val_176
+54	val_54
+459	val_459
+51	val_51
+138	val_138
+103	val_103
+239	val_239
+213	val_213
+216	val_216
+430	val_430
+278	val_278
+176	val_176
+289	val_289
+221	val_221
+65	val_65
+318	val_318
+332	val_332
+311	val_311
+275	val_275
+137	val_137
+241	val_241
+83	val_83
+333	val_333
+180	val_180
+284	val_284
+12	val_12
+230	val_230
+181	val_181
+67	val_67
+260	val_260
+404	val_404
+384	val_384
+489	val_489
+353	val_353
+373	val_373
+272	val_272
+138	val_138
+217	val_217
+84	val_84
+348	val_348
+466	val_466
+58	val_58
+8	val_8
+411	val_411
+230	val_230
+208	val_208
+348	val_348
+24	val_24
+463	val_463
+431	val_431
+179	val_179
+172	val_172
+42	val_42
+129	val_129
+158	val_158
+119	val_119
+496	val_496
+0	val_0
+322	val_322
+197	val_197
+468	val_468
+393	val_393
+454	val_454
+100	val_100
+298	val_298
+199	val_199
+191	val_191
+418	val_418
+96	val_96
+26	val_26
+165	val_165
+327	val_327
+230	val_230
+205	val_205
+120	val_120
+131	val_131
+51	val_51
+404	val_404
+43	val_43
+436	val_436
+156	val_156
+469	val_469
+468	val_468
+308	val_308
+95	val_95
+196	val_196
+288	val_288
+481	val_481
+457	val_457
+98	val_98
+282	val_282
+197	val_197
+187	val_187
+318	val_318
+318	val_318
+409	val_409
+470	val_470
+137	val_137
+369	val_369
+316	val_316
+169	val_169
+413	val_413
+85	val_85
+77	val_77
+0	val_0
+490	val_490
+87	val_87
+364	val_364
+179	val_179
+118	val_118
+134	val_134
+395	val_395
+282	val_282
+138	val_138
+238	val_238
+419	val_419
+15	val_15
+118	val_118
+72	val_72
+90	val_90
+307	val_307
+19	val_19
+435	val_435
+10	val_10
+277	val_277
+273	val_273
+306	val_306
+224	val_224
+309	val_309
+389	val_389
+327	val_327
+242	val_242
+369	val_369
+392	val_392
+272	val_272
+331	val_331
+401	val_401
+242	val_242
+452	val_452
+177	val_177
+226	val_226
+5	val_5
+497	val_497
+402	val_402
+396	val_396
+317	val_317
+395	val_395
+58	val_58
+35	val_35
+336	val_336
+95	val_95
+11	val_11
+168	val_168
+34	val_34
+229	val_229
+233	val_233
+143	val_143
+472	val_472
+322	val_322
+498	val_498
+160	val_160
+195	val_195
+42	val_42
+321	val_321
+430	val_430
+119	val_119
+489	val_489
+458	val_458
+78	val_78
+76	val_76
+41	val_41
+223	val_223
+492	val_492
+149	val_149
+449	val_449
+218	val_218
+228	val_228
+138	val_138
+453	val_453
+30	val_30
+209	val_209
+64	val_64
+468	val_468
+76	val_76
+74	val_74
+342	val_342
+69	val_69
+230	val_230
+33	val_33
+368	val_368
+103	val_103
+296	val_296
+113	val_113
+216	val_216
+367	val_367
+344	val_344
+167	val_167
+274	val_274
+219	val_219
+239	val_239
+485	val_485
+116	val_116
+223	val_223
+256	val_256
+263	val_263
+70	val_70
+487	val_487
+480	val_480
+401	val_401
+288	val_288
+191	val_191
+5	val_5
+244	val_244
+438	val_438
+128	val_128
+467	val_467
+432	val_432
+202	val_202
+316	val_316
+229	val_229
+469	val_469
+463	val_463
+280	val_280
+2	val_2
+35	val_35
+283	val_283
+331	val_331
+235	val_235
+80	val_80
+44	val_44
+193	val_193
+321	val_321
+335	val_335
+104	val_104
+466	val_466
+366	val_366
+175	val_175
+403	val_403
+483	val_483
+53	val_53
+105	val_105
+257	val_257
+406	val_406
+409	val_409
+190	val_190
+406	val_406
+401	val_401
+114	val_114
+258	val_258
+90	val_90
+203	val_203
+262	val_262
+348	val_348
+424	val_424
+12	val_12
+396	val_396
+201	val_201
+217	val_217
+164	val_164
+431	val_431
+454	val_454
+478	val_478
+298	val_298
+125	val_125
+431	val_431
+164	val_164
+424	val_424
+187	val_187
+382	val_382
+5	val_5
+70	val_70
+397	val_397
+480	val_480
+291	val_291
+24	val_24
+351	val_351
+255	val_255
+104	val_104
+70	val_70
+163	val_163
+438	val_438
+119	val_119
+414	val_414
+200	val_200
+491	val_491
+237	val_237
+439	val_439
+360	val_360
+248	val_248
+479	val_479
+305	val_305
+417	val_417
+199	val_199
+444	val_444
+120	val_120
+429	val_429
+169	val_169
+443	val_443
+323	val_323
+325	val_325
+277	val_277
+230	val_230
+478	val_478
+178	val_178
+468	val_468
+310	val_310
+317	val_317
+333	val_333
+493	val_493
+460	val_460
+207	val_207
+249	val_249
+265	val_265
+480	val_480
+83	val_83
+136	val_136
+353	val_353
+172	val_172
+214	val_214
+462	val_462
+233	val_233
+406	val_406
+133	val_133
+175	val_175
+189	val_189
+454	val_454
+375	val_375
+401	val_401
+421	val_421
+407	val_407
+384	val_384
+256	val_256
+26	val_26
+134	val_134
+67	val_67
+384	val_384
+379	val_379
+18	val_18
+462	val_462
+492	val_492
+100	val_100
+298	val_298
+9	val_9
+341	val_341
+498	val_498
+146	val_146
+458	val_458
+362	val_362
+186	val_186
+285	val_285
+348	val_348
+167	val_167
+18	val_18
+273	val_273
+183	val_183
+281	val_281
+344	val_344
+97	val_97
+469	val_469
+315	val_315
+84	val_84
+28	val_28
+37	val_37
+448	val_448
+152	val_152
+348	val_348
+307	val_307
+194	val_194
+414	val_414
+477	val_477
+222	val_222
+126	val_126
+90	val_90
+169	val_169
+403	val_403
+400	val_400
+200	val_200
+97	val_97
+PREHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_partitioned (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_partitioned
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_partitioned
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+
+PREHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions stats_partitioned
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions stats_partitioned
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ds=1
+PREHOOK: query: select * from stats_partitioned where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_partitioned@ds=1
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-19_645_2560442626137801088/-mr-10000
+POSTHOOK: query: select * from stats_partitioned where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_partitioned@ds=1
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-19_645_2560442626137801088/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	1
+86	val_86	1
+311	val_311	1
+27	val_27	1
+165	val_165	1
+409	val_409	1
+255	val_255	1
+278	val_278	1
+98	val_98	1
+484	val_484	1
+265	val_265	1
+193	val_193	1
+401	val_401	1
+150	val_150	1
+273	val_273	1
+224	val_224	1
+369	val_369	1
+66	val_66	1
+128	val_128	1
+213	val_213	1
+146	val_146	1
+406	val_406	1
+429	val_429	1
+374	val_374	1
+152	val_152	1
+469	val_469	1
+145	val_145	1
+495	val_495	1
+37	val_37	1
+327	val_327	1
+281	val_281	1
+277	val_277	1
+209	val_209	1
+15	val_15	1
+82	val_82	1
+403	val_403	1
+166	val_166	1
+417	val_417	1
+430	val_430	1
+252	val_252	1
+292	val_292	1
+219	val_219	1
+287	val_287	1
+153	val_153	1
+193	val_193	1
+338	val_338	1
+446	val_446	1
+459	val_459	1
+394	val_394	1
+237	val_237	1
+482	val_482	1
+174	val_174	1
+413	val_413	1
+494	val_494	1
+207	val_207	1
+199	val_199	1
+466	val_466	1
+208	val_208	1
+174	val_174	1
+399	val_399	1
+396	val_396	1
+247	val_247	1
+417	val_417	1
+489	val_489	1
+162	val_162	1
+377	val_377	1
+397	val_397	1
+309	val_309	1
+365	val_365	1
+266	val_266	1
+439	val_439	1
+342	val_342	1
+367	val_367	1
+325	val_325	1
+167	val_167	1
+195	val_195	1
+475	val_475	1
+17	val_17	1
+113	val_113	1
+155	val_155	1
+203	val_203	1
+339	val_339	1
+0	val_0	1
+455	val_455	1
+128	val_128	1
+311	val_311	1
+316	val_316	1
+57	val_57	1
+302	val_302	1
+205	val_205	1
+149	val_149	1
+438	val_438	1
+345	val_345	1
+129	val_129	1
+170	val_170	1
+20	val_20	1
+489	val_489	1
+157	val_157	1
+378	val_378	1
+221	val_221	1
+92	val_92	1
+111	val_111	1
+47	val_47	1
+72	val_72	1
+4	val_4	1
+280	val_280	1
+35	val_35	1
+427	val_427	1
+277	val_277	1
+208	val_208	1
+356	val_356	1
+399	val_399	1
+169	val_169	1
+382	val_382	1
+498	val_498	1
+125	val_125	1
+386	val_386	1
+437	val_437	1
+469	val_469	1
+192	val_192	1
+286	val_286	1
+187	val_187	1
+176	val_176	1
+54	val_54	1
+459	val_459	1
+51	val_51	1
+138	val_138	1
+103	val_103	1
+239	val_239	1
+213	val_213	1
+216	val_216	1
+430	val_430	1
+278	val_278	1
+176	val_176	1
+289	val_289	1
+221	val_221	1
+65	val_65	1
+318	val_318	1
+332	val_332	1
+311	val_311	1
+275	val_275	1
+137	val_137	1
+241	val_241	1
+83	val_83	1
+333	val_333	1
+180	val_180	1
+284	val_284	1
+12	val_12	1
+230	val_230	1
+181	val_181	1
+67	val_67	1
+260	val_260	1
+404	val_404	1
+384	val_384	1
+489	val_489	1
+353	val_353	1
+373	val_373	1
+272	val_272	1
+138	val_138	1
+217	val_217	1
+84	val_84	1
+348	val_348	1
+466	val_466	1
+58	val_58	1
+8	val_8	1
+411	val_411	1
+230	val_230	1
+208	val_208	1
+348	val_348	1
+24	val_24	1
+463	val_463	1
+431	val_431	1
+179	val_179	1
+172	val_172	1
+42	val_42	1
+129	val_129	1
+158	val_158	1
+119	val_119	1
+496	val_496	1
+0	val_0	1
+322	val_322	1
+197	val_197	1
+468	val_468	1
+393	val_393	1
+454	val_454	1
+100	val_100	1
+298	val_298	1
+199	val_199	1
+191	val_191	1
+418	val_418	1
+96	val_96	1
+26	val_26	1
+165	val_165	1
+327	val_327	1
+230	val_230	1
+205	val_205	1
+120	val_120	1
+131	val_131	1
+51	val_51	1
+404	val_404	1
+43	val_43	1
+436	val_436	1
+156	val_156	1
+469	val_469	1
+468	val_468	1
+308	val_308	1
+95	val_95	1
+196	val_196	1
+288	val_288	1
+481	val_481	1
+457	val_457	1
+98	val_98	1
+282	val_282	1
+197	val_197	1
+187	val_187	1
+318	val_318	1
+318	val_318	1
+409	val_409	1
+470	val_470	1
+137	val_137	1
+369	val_369	1
+316	val_316	1
+169	val_169	1
+413	val_413	1
+85	val_85	1
+77	val_77	1
+0	val_0	1
+490	val_490	1
+87	val_87	1
+364	val_364	1
+179	val_179	1
+118	val_118	1
+134	val_134	1
+395	val_395	1
+282	val_282	1
+138	val_138	1
+238	val_238	1
+419	val_419	1
+15	val_15	1
+118	val_118	1
+72	val_72	1
+90	val_90	1
+307	val_307	1
+19	val_19	1
+435	val_435	1
+10	val_10	1
+277	val_277	1
+273	val_273	1
+306	val_306	1
+224	val_224	1
+309	val_309	1
+389	val_389	1
+327	val_327	1
+242	val_242	1
+369	val_369	1
+392	val_392	1
+272	val_272	1
+331	val_331	1
+401	val_401	1
+242	val_242	1
+452	val_452	1
+177	val_177	1
+226	val_226	1
+5	val_5	1
+497	val_497	1
+402	val_402	1
+396	val_396	1
+317	val_317	1
+395	val_395	1
+58	val_58	1
+35	val_35	1
+336	val_336	1
+95	val_95	1
+11	val_11	1
+168	val_168	1
+34	val_34	1
+229	val_229	1
+233	val_233	1
+143	val_143	1
+472	val_472	1
+322	val_322	1
+498	val_498	1
+160	val_160	1
+195	val_195	1
+42	val_42	1
+321	val_321	1
+430	val_430	1
+119	val_119	1
+489	val_489	1
+458	val_458	1
+78	val_78	1
+76	val_76	1
+41	val_41	1
+223	val_223	1
+492	val_492	1
+149	val_149	1
+449	val_449	1
+218	val_218	1
+228	val_228	1
+138	val_138	1
+453	val_453	1
+30	val_30	1
+209	val_209	1
+64	val_64	1
+468	val_468	1
+76	val_76	1
+74	val_74	1
+342	val_342	1
+69	val_69	1
+230	val_230	1
+33	val_33	1
+368	val_368	1
+103	val_103	1
+296	val_296	1
+113	val_113	1
+216	val_216	1
+367	val_367	1
+344	val_344	1
+167	val_167	1
+274	val_274	1
+219	val_219	1
+239	val_239	1
+485	val_485	1
+116	val_116	1
+223	val_223	1
+256	val_256	1
+263	val_263	1
+70	val_70	1
+487	val_487	1
+480	val_480	1
+401	val_401	1
+288	val_288	1
+191	val_191	1
+5	val_5	1
+244	val_244	1
+438	val_438	1
+128	val_128	1
+467	val_467	1
+432	val_432	1
+202	val_202	1
+316	val_316	1
+229	val_229	1
+469	val_469	1
+463	val_463	1
+280	val_280	1
+2	val_2	1
+35	val_35	1
+283	val_283	1
+331	val_331	1
+235	val_235	1
+80	val_80	1
+44	val_44	1
+193	val_193	1
+321	val_321	1
+335	val_335	1
+104	val_104	1
+466	val_466	1
+366	val_366	1
+175	val_175	1
+403	val_403	1
+483	val_483	1
+53	val_53	1
+105	val_105	1
+257	val_257	1
+406	val_406	1
+409	val_409	1
+190	val_190	1
+406	val_406	1
+401	val_401	1
+114	val_114	1
+258	val_258	1
+90	val_90	1
+203	val_203	1
+262	val_262	1
+348	val_348	1
+424	val_424	1
+12	val_12	1
+396	val_396	1
+201	val_201	1
+217	val_217	1
+164	val_164	1
+431	val_431	1
+454	val_454	1
+478	val_478	1
+298	val_298	1
+125	val_125	1
+431	val_431	1
+164	val_164	1
+424	val_424	1
+187	val_187	1
+382	val_382	1
+5	val_5	1
+70	val_70	1
+397	val_397	1
+480	val_480	1
+291	val_291	1
+24	val_24	1
+351	val_351	1
+255	val_255	1
+104	val_104	1
+70	val_70	1
+163	val_163	1
+438	val_438	1
+119	val_119	1
+414	val_414	1
+200	val_200	1
+491	val_491	1
+237	val_237	1
+439	val_439	1
+360	val_360	1
+248	val_248	1
+479	val_479	1
+305	val_305	1
+417	val_417	1
+199	val_199	1
+444	val_444	1
+120	val_120	1
+429	val_429	1
+169	val_169	1
+443	val_443	1
+323	val_323	1
+325	val_325	1
+277	val_277	1
+230	val_230	1
+478	val_478	1
+178	val_178	1
+468	val_468	1
+310	val_310	1
+317	val_317	1
+333	val_333	1
+493	val_493	1
+460	val_460	1
+207	val_207	1
+249	val_249	1
+265	val_265	1
+480	val_480	1
+83	val_83	1
+136	val_136	1
+353	val_353	1
+172	val_172	1
+214	val_214	1
+462	val_462	1
+233	val_233	1
+406	val_406	1
+133	val_133	1
+175	val_175	1
+189	val_189	1
+454	val_454	1
+375	val_375	1
+401	val_401	1
+421	val_421	1
+407	val_407	1
+384	val_384	1
+256	val_256	1
+26	val_26	1
+134	val_134	1
+67	val_67	1
+384	val_384	1
+379	val_379	1
+18	val_18	1
+462	val_462	1
+492	val_492	1
+100	val_100	1
+298	val_298	1
+9	val_9	1
+341	val_341	1
+498	val_498	1
+146	val_146	1
+458	val_458	1
+362	val_362	1
+186	val_186	1
+285	val_285	1
+348	val_348	1
+167	val_167	1
+18	val_18	1
+273	val_273	1
+183	val_183	1
+281	val_281	1
+344	val_344	1
+97	val_97	1
+469	val_469	1
+315	val_315	1
+84	val_84	1
+28	val_28	1
+37	val_37	1
+448	val_448	1
+152	val_152	1
+348	val_348	1
+307	val_307	1
+194	val_194	1
+414	val_414	1
+477	val_477	1
+222	val_222	1
+126	val_126	1
+90	val_90	1
+169	val_169	1
+403	val_403	1
+400	val_400	1
+200	val_200	1
+97	val_97	1
+PREHOOK: query: describe extended stats_partitioned partition (ds='1')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned partition (ds='1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[1]                 	 
+Database:           	default             	 
+Table:              	stats_partitioned   	 
+CreateTime:         	Tue Sep 21 01:07:19 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned/ds=1	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056439          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended stats_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:12 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056439          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: drop table stats_non_partitioned
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: drop table stats_non_partitioned
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: drop table stats_partitioned
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@stats_partitioned
+PREHOOK: Output: default@stats_partitioned
+POSTHOOK: query: drop table stats_partitioned
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@stats_partitioned
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_non_partitioned (key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_non_partitioned)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10000/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      bucket_count -1
+                      columns key,value
+                      columns.types string:string
+                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                      name stats_non_partitioned
+                      serialization.ddl struct stats_non_partitioned { string key, string value}
+                      serialization.format 1
+                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      transient_lastDdlTime 1285056440
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_non_partitioned
+                TotalFiles: 1
+                GatherStats: true
+                MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
+          Partition
+            base file name: src
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+              name src
+              serialization.ddl struct src { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285049308
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
+                name src
+                serialization.ddl struct src { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285049308
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: src
+            name: src
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285056440
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10000
+              NumFilesPerFileSink: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    bucket_count -1
+                    columns key,value
+                    columns.types string:string
+                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                    name stats_non_partitioned
+                    serialization.ddl struct stats_non_partitioned { string key, string value}
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    transient_lastDdlTime 1285056440
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: stats_non_partitioned
+              TotalFiles: 1
+              GatherStats: false
+              MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-20_991_2107869948985136652/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+              name stats_non_partitioned
+              serialization.ddl struct stats_non_partitioned { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1285056440
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned
+                name stats_non_partitioned
+                serialization.ddl struct stats_non_partitioned { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1285056440
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_non_partitioned
+            name: stats_non_partitioned
+
+
+PREHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_non_partitioned
+POSTHOOK: query: insert overwrite table stats_non_partitioned
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_non_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended stats_non_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended stats_non_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:20 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_non_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056446          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: select * from stats_non_partitioned
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_non_partitioned
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-27_190_8480785613167358093/-mr-10000
+POSTHOOK: query: select * from stats_non_partitioned
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_non_partitioned
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-27_190_8480785613167358093/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238
+86	val_86
+311	val_311
+27	val_27
+165	val_165
+409	val_409
+255	val_255
+278	val_278
+98	val_98
+484	val_484
+265	val_265
+193	val_193
+401	val_401
+150	val_150
+273	val_273
+224	val_224
+369	val_369
+66	val_66
+128	val_128
+213	val_213
+146	val_146
+406	val_406
+429	val_429
+374	val_374
+152	val_152
+469	val_469
+145	val_145
+495	val_495
+37	val_37
+327	val_327
+281	val_281
+277	val_277
+209	val_209
+15	val_15
+82	val_82
+403	val_403
+166	val_166
+417	val_417
+430	val_430
+252	val_252
+292	val_292
+219	val_219
+287	val_287
+153	val_153
+193	val_193
+338	val_338
+446	val_446
+459	val_459
+394	val_394
+237	val_237
+482	val_482
+174	val_174
+413	val_413
+494	val_494
+207	val_207
+199	val_199
+466	val_466
+208	val_208
+174	val_174
+399	val_399
+396	val_396
+247	val_247
+417	val_417
+489	val_489
+162	val_162
+377	val_377
+397	val_397
+309	val_309
+365	val_365
+266	val_266
+439	val_439
+342	val_342
+367	val_367
+325	val_325
+167	val_167
+195	val_195
+475	val_475
+17	val_17
+113	val_113
+155	val_155
+203	val_203
+339	val_339
+0	val_0
+455	val_455
+128	val_128
+311	val_311
+316	val_316
+57	val_57
+302	val_302
+205	val_205
+149	val_149
+438	val_438
+345	val_345
+129	val_129
+170	val_170
+20	val_20
+489	val_489
+157	val_157
+378	val_378
+221	val_221
+92	val_92
+111	val_111
+47	val_47
+72	val_72
+4	val_4
+280	val_280
+35	val_35
+427	val_427
+277	val_277
+208	val_208
+356	val_356
+399	val_399
+169	val_169
+382	val_382
+498	val_498
+125	val_125
+386	val_386
+437	val_437
+469	val_469
+192	val_192
+286	val_286
+187	val_187
+176	val_176
+54	val_54
+459	val_459
+51	val_51
+138	val_138
+103	val_103
+239	val_239
+213	val_213
+216	val_216
+430	val_430
+278	val_278
+176	val_176
+289	val_289
+221	val_221
+65	val_65
+318	val_318
+332	val_332
+311	val_311
+275	val_275
+137	val_137
+241	val_241
+83	val_83
+333	val_333
+180	val_180
+284	val_284
+12	val_12
+230	val_230
+181	val_181
+67	val_67
+260	val_260
+404	val_404
+384	val_384
+489	val_489
+353	val_353
+373	val_373
+272	val_272
+138	val_138
+217	val_217
+84	val_84
+348	val_348
+466	val_466
+58	val_58
+8	val_8
+411	val_411
+230	val_230
+208	val_208
+348	val_348
+24	val_24
+463	val_463
+431	val_431
+179	val_179
+172	val_172
+42	val_42
+129	val_129
+158	val_158
+119	val_119
+496	val_496
+0	val_0
+322	val_322
+197	val_197
+468	val_468
+393	val_393
+454	val_454
+100	val_100
+298	val_298
+199	val_199
+191	val_191
+418	val_418
+96	val_96
+26	val_26
+165	val_165
+327	val_327
+230	val_230
+205	val_205
+120	val_120
+131	val_131
+51	val_51
+404	val_404
+43	val_43
+436	val_436
+156	val_156
+469	val_469
+468	val_468
+308	val_308
+95	val_95
+196	val_196
+288	val_288
+481	val_481
+457	val_457
+98	val_98
+282	val_282
+197	val_197
+187	val_187
+318	val_318
+318	val_318
+409	val_409
+470	val_470
+137	val_137
+369	val_369
+316	val_316
+169	val_169
+413	val_413
+85	val_85
+77	val_77
+0	val_0
+490	val_490
+87	val_87
+364	val_364
+179	val_179
+118	val_118
+134	val_134
+395	val_395
+282	val_282
+138	val_138
+238	val_238
+419	val_419
+15	val_15
+118	val_118
+72	val_72
+90	val_90
+307	val_307
+19	val_19
+435	val_435
+10	val_10
+277	val_277
+273	val_273
+306	val_306
+224	val_224
+309	val_309
+389	val_389
+327	val_327
+242	val_242
+369	val_369
+392	val_392
+272	val_272
+331	val_331
+401	val_401
+242	val_242
+452	val_452
+177	val_177
+226	val_226
+5	val_5
+497	val_497
+402	val_402
+396	val_396
+317	val_317
+395	val_395
+58	val_58
+35	val_35
+336	val_336
+95	val_95
+11	val_11
+168	val_168
+34	val_34
+229	val_229
+233	val_233
+143	val_143
+472	val_472
+322	val_322
+498	val_498
+160	val_160
+195	val_195
+42	val_42
+321	val_321
+430	val_430
+119	val_119
+489	val_489
+458	val_458
+78	val_78
+76	val_76
+41	val_41
+223	val_223
+492	val_492
+149	val_149
+449	val_449
+218	val_218
+228	val_228
+138	val_138
+453	val_453
+30	val_30
+209	val_209
+64	val_64
+468	val_468
+76	val_76
+74	val_74
+342	val_342
+69	val_69
+230	val_230
+33	val_33
+368	val_368
+103	val_103
+296	val_296
+113	val_113
+216	val_216
+367	val_367
+344	val_344
+167	val_167
+274	val_274
+219	val_219
+239	val_239
+485	val_485
+116	val_116
+223	val_223
+256	val_256
+263	val_263
+70	val_70
+487	val_487
+480	val_480
+401	val_401
+288	val_288
+191	val_191
+5	val_5
+244	val_244
+438	val_438
+128	val_128
+467	val_467
+432	val_432
+202	val_202
+316	val_316
+229	val_229
+469	val_469
+463	val_463
+280	val_280
+2	val_2
+35	val_35
+283	val_283
+331	val_331
+235	val_235
+80	val_80
+44	val_44
+193	val_193
+321	val_321
+335	val_335
+104	val_104
+466	val_466
+366	val_366
+175	val_175
+403	val_403
+483	val_483
+53	val_53
+105	val_105
+257	val_257
+406	val_406
+409	val_409
+190	val_190
+406	val_406
+401	val_401
+114	val_114
+258	val_258
+90	val_90
+203	val_203
+262	val_262
+348	val_348
+424	val_424
+12	val_12
+396	val_396
+201	val_201
+217	val_217
+164	val_164
+431	val_431
+454	val_454
+478	val_478
+298	val_298
+125	val_125
+431	val_431
+164	val_164
+424	val_424
+187	val_187
+382	val_382
+5	val_5
+70	val_70
+397	val_397
+480	val_480
+291	val_291
+24	val_24
+351	val_351
+255	val_255
+104	val_104
+70	val_70
+163	val_163
+438	val_438
+119	val_119
+414	val_414
+200	val_200
+491	val_491
+237	val_237
+439	val_439
+360	val_360
+248	val_248
+479	val_479
+305	val_305
+417	val_417
+199	val_199
+444	val_444
+120	val_120
+429	val_429
+169	val_169
+443	val_443
+323	val_323
+325	val_325
+277	val_277
+230	val_230
+478	val_478
+178	val_178
+468	val_468
+310	val_310
+317	val_317
+333	val_333
+493	val_493
+460	val_460
+207	val_207
+249	val_249
+265	val_265
+480	val_480
+83	val_83
+136	val_136
+353	val_353
+172	val_172
+214	val_214
+462	val_462
+233	val_233
+406	val_406
+133	val_133
+175	val_175
+189	val_189
+454	val_454
+375	val_375
+401	val_401
+421	val_421
+407	val_407
+384	val_384
+256	val_256
+26	val_26
+134	val_134
+67	val_67
+384	val_384
+379	val_379
+18	val_18
+462	val_462
+492	val_492
+100	val_100
+298	val_298
+9	val_9
+341	val_341
+498	val_498
+146	val_146
+458	val_458
+362	val_362
+186	val_186
+285	val_285
+348	val_348
+167	val_167
+18	val_18
+273	val_273
+183	val_183
+281	val_281
+344	val_344
+97	val_97
+469	val_469
+315	val_315
+84	val_84
+28	val_28
+37	val_37
+448	val_448
+152	val_152
+348	val_348
+307	val_307
+194	val_194
+414	val_414
+477	val_477
+222	val_222
+126	val_126
+90	val_90
+169	val_169
+403	val_403
+400	val_400
+200	val_200
+97	val_97
+PREHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@stats_partitioned
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB stats_partitioned (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: stats_partitioned
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-27_727_1739481489899004569/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: stats_partitioned
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_01-07-27_727_1739481489899004569/-ext-10002 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: stats_partitioned
+
+
+PREHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: query: insert overwrite table stats_partitioned partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@stats_partitioned@ds=1
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions stats_partitioned
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions stats_partitioned
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ds=1
+PREHOOK: query: select * from stats_partitioned where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@stats_partitioned@ds=1
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-35_118_761805172422134932/-mr-10000
+POSTHOOK: query: select * from stats_partitioned where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@stats_partitioned@ds=1
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-35_118_761805172422134932/-mr-10000
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	1
+86	val_86	1
+311	val_311	1
+27	val_27	1
+165	val_165	1
+409	val_409	1
+255	val_255	1
+278	val_278	1
+98	val_98	1
+484	val_484	1
+265	val_265	1
+193	val_193	1
+401	val_401	1
+150	val_150	1
+273	val_273	1
+224	val_224	1
+369	val_369	1
+66	val_66	1
+128	val_128	1
+213	val_213	1
+146	val_146	1
+406	val_406	1
+429	val_429	1
+374	val_374	1
+152	val_152	1
+469	val_469	1
+145	val_145	1
+495	val_495	1
+37	val_37	1
+327	val_327	1
+281	val_281	1
+277	val_277	1
+209	val_209	1
+15	val_15	1
+82	val_82	1
+403	val_403	1
+166	val_166	1
+417	val_417	1
+430	val_430	1
+252	val_252	1
+292	val_292	1
+219	val_219	1
+287	val_287	1
+153	val_153	1
+193	val_193	1
+338	val_338	1
+446	val_446	1
+459	val_459	1
+394	val_394	1
+237	val_237	1
+482	val_482	1
+174	val_174	1
+413	val_413	1
+494	val_494	1
+207	val_207	1
+199	val_199	1
+466	val_466	1
+208	val_208	1
+174	val_174	1
+399	val_399	1
+396	val_396	1
+247	val_247	1
+417	val_417	1
+489	val_489	1
+162	val_162	1
+377	val_377	1
+397	val_397	1
+309	val_309	1
+365	val_365	1
+266	val_266	1
+439	val_439	1
+342	val_342	1
+367	val_367	1
+325	val_325	1
+167	val_167	1
+195	val_195	1
+475	val_475	1
+17	val_17	1
+113	val_113	1
+155	val_155	1
+203	val_203	1
+339	val_339	1
+0	val_0	1
+455	val_455	1
+128	val_128	1
+311	val_311	1
+316	val_316	1
+57	val_57	1
+302	val_302	1
+205	val_205	1
+149	val_149	1
+438	val_438	1
+345	val_345	1
+129	val_129	1
+170	val_170	1
+20	val_20	1
+489	val_489	1
+157	val_157	1
+378	val_378	1
+221	val_221	1
+92	val_92	1
+111	val_111	1
+47	val_47	1
+72	val_72	1
+4	val_4	1
+280	val_280	1
+35	val_35	1
+427	val_427	1
+277	val_277	1
+208	val_208	1
+356	val_356	1
+399	val_399	1
+169	val_169	1
+382	val_382	1
+498	val_498	1
+125	val_125	1
+386	val_386	1
+437	val_437	1
+469	val_469	1
+192	val_192	1
+286	val_286	1
+187	val_187	1
+176	val_176	1
+54	val_54	1
+459	val_459	1
+51	val_51	1
+138	val_138	1
+103	val_103	1
+239	val_239	1
+213	val_213	1
+216	val_216	1
+430	val_430	1
+278	val_278	1
+176	val_176	1
+289	val_289	1
+221	val_221	1
+65	val_65	1
+318	val_318	1
+332	val_332	1
+311	val_311	1
+275	val_275	1
+137	val_137	1
+241	val_241	1
+83	val_83	1
+333	val_333	1
+180	val_180	1
+284	val_284	1
+12	val_12	1
+230	val_230	1
+181	val_181	1
+67	val_67	1
+260	val_260	1
+404	val_404	1
+384	val_384	1
+489	val_489	1
+353	val_353	1
+373	val_373	1
+272	val_272	1
+138	val_138	1
+217	val_217	1
+84	val_84	1
+348	val_348	1
+466	val_466	1
+58	val_58	1
+8	val_8	1
+411	val_411	1
+230	val_230	1
+208	val_208	1
+348	val_348	1
+24	val_24	1
+463	val_463	1
+431	val_431	1
+179	val_179	1
+172	val_172	1
+42	val_42	1
+129	val_129	1
+158	val_158	1
+119	val_119	1
+496	val_496	1
+0	val_0	1
+322	val_322	1
+197	val_197	1
+468	val_468	1
+393	val_393	1
+454	val_454	1
+100	val_100	1
+298	val_298	1
+199	val_199	1
+191	val_191	1
+418	val_418	1
+96	val_96	1
+26	val_26	1
+165	val_165	1
+327	val_327	1
+230	val_230	1
+205	val_205	1
+120	val_120	1
+131	val_131	1
+51	val_51	1
+404	val_404	1
+43	val_43	1
+436	val_436	1
+156	val_156	1
+469	val_469	1
+468	val_468	1
+308	val_308	1
+95	val_95	1
+196	val_196	1
+288	val_288	1
+481	val_481	1
+457	val_457	1
+98	val_98	1
+282	val_282	1
+197	val_197	1
+187	val_187	1
+318	val_318	1
+318	val_318	1
+409	val_409	1
+470	val_470	1
+137	val_137	1
+369	val_369	1
+316	val_316	1
+169	val_169	1
+413	val_413	1
+85	val_85	1
+77	val_77	1
+0	val_0	1
+490	val_490	1
+87	val_87	1
+364	val_364	1
+179	val_179	1
+118	val_118	1
+134	val_134	1
+395	val_395	1
+282	val_282	1
+138	val_138	1
+238	val_238	1
+419	val_419	1
+15	val_15	1
+118	val_118	1
+72	val_72	1
+90	val_90	1
+307	val_307	1
+19	val_19	1
+435	val_435	1
+10	val_10	1
+277	val_277	1
+273	val_273	1
+306	val_306	1
+224	val_224	1
+309	val_309	1
+389	val_389	1
+327	val_327	1
+242	val_242	1
+369	val_369	1
+392	val_392	1
+272	val_272	1
+331	val_331	1
+401	val_401	1
+242	val_242	1
+452	val_452	1
+177	val_177	1
+226	val_226	1
+5	val_5	1
+497	val_497	1
+402	val_402	1
+396	val_396	1
+317	val_317	1
+395	val_395	1
+58	val_58	1
+35	val_35	1
+336	val_336	1
+95	val_95	1
+11	val_11	1
+168	val_168	1
+34	val_34	1
+229	val_229	1
+233	val_233	1
+143	val_143	1
+472	val_472	1
+322	val_322	1
+498	val_498	1
+160	val_160	1
+195	val_195	1
+42	val_42	1
+321	val_321	1
+430	val_430	1
+119	val_119	1
+489	val_489	1
+458	val_458	1
+78	val_78	1
+76	val_76	1
+41	val_41	1
+223	val_223	1
+492	val_492	1
+149	val_149	1
+449	val_449	1
+218	val_218	1
+228	val_228	1
+138	val_138	1
+453	val_453	1
+30	val_30	1
+209	val_209	1
+64	val_64	1
+468	val_468	1
+76	val_76	1
+74	val_74	1
+342	val_342	1
+69	val_69	1
+230	val_230	1
+33	val_33	1
+368	val_368	1
+103	val_103	1
+296	val_296	1
+113	val_113	1
+216	val_216	1
+367	val_367	1
+344	val_344	1
+167	val_167	1
+274	val_274	1
+219	val_219	1
+239	val_239	1
+485	val_485	1
+116	val_116	1
+223	val_223	1
+256	val_256	1
+263	val_263	1
+70	val_70	1
+487	val_487	1
+480	val_480	1
+401	val_401	1
+288	val_288	1
+191	val_191	1
+5	val_5	1
+244	val_244	1
+438	val_438	1
+128	val_128	1
+467	val_467	1
+432	val_432	1
+202	val_202	1
+316	val_316	1
+229	val_229	1
+469	val_469	1
+463	val_463	1
+280	val_280	1
+2	val_2	1
+35	val_35	1
+283	val_283	1
+331	val_331	1
+235	val_235	1
+80	val_80	1
+44	val_44	1
+193	val_193	1
+321	val_321	1
+335	val_335	1
+104	val_104	1
+466	val_466	1
+366	val_366	1
+175	val_175	1
+403	val_403	1
+483	val_483	1
+53	val_53	1
+105	val_105	1
+257	val_257	1
+406	val_406	1
+409	val_409	1
+190	val_190	1
+406	val_406	1
+401	val_401	1
+114	val_114	1
+258	val_258	1
+90	val_90	1
+203	val_203	1
+262	val_262	1
+348	val_348	1
+424	val_424	1
+12	val_12	1
+396	val_396	1
+201	val_201	1
+217	val_217	1
+164	val_164	1
+431	val_431	1
+454	val_454	1
+478	val_478	1
+298	val_298	1
+125	val_125	1
+431	val_431	1
+164	val_164	1
+424	val_424	1
+187	val_187	1
+382	val_382	1
+5	val_5	1
+70	val_70	1
+397	val_397	1
+480	val_480	1
+291	val_291	1
+24	val_24	1
+351	val_351	1
+255	val_255	1
+104	val_104	1
+70	val_70	1
+163	val_163	1
+438	val_438	1
+119	val_119	1
+414	val_414	1
+200	val_200	1
+491	val_491	1
+237	val_237	1
+439	val_439	1
+360	val_360	1
+248	val_248	1
+479	val_479	1
+305	val_305	1
+417	val_417	1
+199	val_199	1
+444	val_444	1
+120	val_120	1
+429	val_429	1
+169	val_169	1
+443	val_443	1
+323	val_323	1
+325	val_325	1
+277	val_277	1
+230	val_230	1
+478	val_478	1
+178	val_178	1
+468	val_468	1
+310	val_310	1
+317	val_317	1
+333	val_333	1
+493	val_493	1
+460	val_460	1
+207	val_207	1
+249	val_249	1
+265	val_265	1
+480	val_480	1
+83	val_83	1
+136	val_136	1
+353	val_353	1
+172	val_172	1
+214	val_214	1
+462	val_462	1
+233	val_233	1
+406	val_406	1
+133	val_133	1
+175	val_175	1
+189	val_189	1
+454	val_454	1
+375	val_375	1
+401	val_401	1
+421	val_421	1
+407	val_407	1
+384	val_384	1
+256	val_256	1
+26	val_26	1
+134	val_134	1
+67	val_67	1
+384	val_384	1
+379	val_379	1
+18	val_18	1
+462	val_462	1
+492	val_492	1
+100	val_100	1
+298	val_298	1
+9	val_9	1
+341	val_341	1
+498	val_498	1
+146	val_146	1
+458	val_458	1
+362	val_362	1
+186	val_186	1
+285	val_285	1
+348	val_348	1
+167	val_167	1
+18	val_18	1
+273	val_273	1
+183	val_183	1
+281	val_281	1
+344	val_344	1
+97	val_97	1
+469	val_469	1
+315	val_315	1
+84	val_84	1
+28	val_28	1
+37	val_37	1
+448	val_448	1
+152	val_152	1
+348	val_348	1
+307	val_307	1
+194	val_194	1
+414	val_414	1
+477	val_477	1
+222	val_222	1
+126	val_126	1
+90	val_90	1
+169	val_169	1
+403	val_403	1
+400	val_400	1
+200	val_200	1
+97	val_97	1
+PREHOOK: query: describe extended stats_partitioned partition (ds='1')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned partition (ds='1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[1]                 	 
+Database:           	default             	 
+Table:              	stats_partitioned   	 
+CreateTime:         	Tue Sep 21 01:07:34 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned/ds=1	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056454          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended stats_partitioned
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended stats_partitioned
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_non_partitioned.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: stats_partitioned PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:27 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/stats_partitioned	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	1                   
+	numFiles            	1                   
+	transient_lastDdlTime	1285056454          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/ppd_multi_insert.q.out
===================================================================
--- ql/src/test/results/clientpositive/ppd_multi_insert.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/ppd_multi_insert.q.out	(working copy)
@@ -33,8 +33,11 @@
 STAGE DEPENDENCIES:
   Stage-4 is a root stage
   Stage-0 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-4
+  Stage-6 depends on stages: Stage-1
   Stage-2 depends on stages: Stage-4
+  Stage-7 depends on stages: Stage-2
   Stage-3 depends on stages: Stage-4
 
 STAGE PLANS:
@@ -179,6 +182,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: mi1
 
+  Stage: Stage-5
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -189,6 +195,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: mi2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
+
   Stage: Stage-2
     Move Operator
       tables:
@@ -202,6 +211,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: mi3
 
+  Stage: Stage-7
+    Stats-Aggr Operator
+
   Stage: Stage-3
     Move Operator
       files:
@@ -239,11 +251,11 @@
 PREHOOK: query: SELECT mi1.* FROM mi1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-32_780_6038103351737463067/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_120_3503771906127933196/-mr-10000
 POSTHOOK: query: SELECT mi1.* FROM mi1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-32_780_6038103351737463067/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_120_3503771906127933196/-mr-10000
 POSTHOOK: Lineage: mi1.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: mi1.value SIMPLE [(src)a.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: mi2.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
@@ -400,11 +412,11 @@
 PREHOOK: query: SELECT mi2.* FROM mi2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-33_072_1447950994639415029/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_510_8315931585077418228/-mr-10000
 POSTHOOK: query: SELECT mi2.* FROM mi2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-33_072_1447950994639415029/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_510_8315931585077418228/-mr-10000
 POSTHOOK: Lineage: mi1.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: mi1.value SIMPLE [(src)a.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: mi2.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
@@ -624,11 +636,11 @@
 PREHOOK: query: SELECT mi3.* FROM mi3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@mi3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-33_365_8344416518806586394/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_947_8456541918849361288/-mr-10000
 POSTHOOK: query: SELECT mi3.* FROM mi3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@mi3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-24-33_365_8344416518806586394/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-46_947_8456541918849361288/-mr-10000
 POSTHOOK: Lineage: mi1.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: mi1.value SIMPLE [(src)a.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: mi2.key EXPRESSION [(src)a.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join9.q.out
===================================================================
--- ql/src/test/results/clientpositive/join9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join9.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src1 
           TableScan
             alias: src1
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -49,6 +51,7 @@
         src2 
           TableScan
             alias: src2
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -63,10 +66,10 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/src [src2]
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [src1]
       Path -> Partition:
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -77,12 +80,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474272
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -93,16 +96,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474272
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -116,13 +119,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1281474268
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -133,13 +136,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281474268
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -174,8 +177,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-34-33_664_3396325947944579239/-ext-10000
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-08_351_9180816831491941373/-ext-10000
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-08_351_9180816831491941373/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -185,22 +189,23 @@
                         columns.types int:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                         name dest1
                         serialization.ddl struct dest1 { i32 key, string value}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1281476073
+                        transient_lastDdlTime 1284507848
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-34-33_664_3396325947944579239/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-08_351_9180816831491941373/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -210,17 +215,21 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1281476073
+                transient_lastDdlTime 1284507848
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/heyongqiang/hive-trunk-clean/build/ql/scratchdir/hive_2010-08-10_14-34-33_664_3396325947944579239/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-08_351_9180816831491941373/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-44-08_351_9180816831491941373/-ext-10000/
 
+
 PREHOOK: query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
 INSERT OVERWRITE TABLE dest1 SELECT src1.key, src2.value where src1.ds = '2008-04-08' and src1.hr = '12'
 PREHOOK: type: QUERY
@@ -238,11 +247,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-34-36_730_7457350899918463300/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-16_618_7096928518483550560/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/heyongqiang/hive_2010-08-10_14-34-36_730_7457350899918463300/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-44-16_618_7096928518483550560/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src2.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/rand_partitionpruner2.q.out
===================================================================
--- ql/src/test/results/clientpositive/rand_partitionpruner2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/rand_partitionpruner2.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -51,8 +53,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -62,22 +65,23 @@
                         columns.types string:string:string:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                         name tmptable
                         serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1282111150
+                        transient_lastDdlTime 1284509996
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -91,13 +95,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -108,17 +112,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -132,13 +136,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -149,32 +153,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -184,24 +188,28 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                 name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111150
+                transient_lastDdlTime 1284509996
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -212,21 +220,22 @@
                     columns.types string:string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                     name tmptable
                     serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111150
+                    transient_lastDdlTime 1284509996
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: tmptable
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-10_367_1741057959555394215/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-19-56_871_4716747609629754062/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -237,12 +246,12 @@
               columns.types string:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
               name tmptable
               serialization.ddl struct tmptable { string key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111150
+              transient_lastDdlTime 1284509996
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -253,12 +262,12 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/tmptable
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable
                 name tmptable
                 serialization.ddl struct tmptable { string key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111150
+                transient_lastDdlTime 1284509996
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tmptable
             name: tmptable
@@ -283,11 +292,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-17_801_1929266080291306291/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-07_870_813402908601406007/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-17_801_1929266080291306291/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-07_870_813402908601406007/-mr-10000
 POSTHOOK: Lineage: tmptable.ds SIMPLE [(srcpart)a.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.hr SIMPLE [(srcpart)a.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.key SIMPLE [(srcpart)a.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_dynamicserde.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_dynamicserde.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_dynamicserde.q.out_0.17	(working copy)
@@ -28,10 +28,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -62,14 +63,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-43_270_8554014130671388965/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-50-14_952_1754823732907020279/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -82,9 +83,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-43_270_8554014130671388965/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-50-14_952_1754823732907020279/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -132,11 +136,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-48_027_2340638773474099785/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-50-21_092_6705007865583240929/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-48_027_2340638773474099785/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-50-21_092_6705007865583240929/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -156,11 +160,11 @@
 PREHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-48_088_2019866462571089916/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-50-21_719_4294892528769727163/-mr-10000
 POSTHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-48_088_2019866462571089916/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-50-21_719_4294892528769727163/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/groupby4_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby4_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby4_noskew.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -71,7 +72,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT substr(src.key,1,1) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -86,11 +90,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-56_089_1219089937794895800/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-04_350_4543908149102458043/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-56_089_1219089937794895800/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-04_350_4543908149102458043/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/join30.q.out
===================================================================
--- ql/src/test/results/clientpositive/join30.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join30.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -76,7 +77,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-33-14_350_1200822154670358029/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-39-49_545_7124720180109288751/-mr-10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -151,7 +152,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest_j1 
 SELECT /*+ MAPJOIN(x) */ x.key, count(1) FROM src1 x JOIN src y ON (x.key = y.key) group by x.key
 PREHOOK: type: QUERY
@@ -169,11 +173,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-19_511_4245286174894412683/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-59_225_1677785212354840326/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-19_511_4245286174894412683/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-59_225_1677785212354840326/-mr-10000
 POSTHOOK: Lineage: dest_j1.cnt EXPRESSION [(src1)x.null, (src)y.null, ]
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 66	1
Index: ql/src/test/results/clientpositive/input12.q.out
===================================================================
--- ql/src/test/results/clientpositive/input12.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input12.q.out	(working copy)
@@ -30,18 +30,21 @@
 
 STAGE DEPENDENCIES:
   Stage-3 is a root stage
-  Stage-6 depends on stages: Stage-3 , consists of Stage-5, Stage-4
+  Stage-7 depends on stages: Stage-3 , consists of Stage-6, Stage-5
+  Stage-6
+  Stage-0 depends on stages: Stage-6, Stage-5
+  Stage-4 depends on stages: Stage-0
   Stage-5
-  Stage-0 depends on stages: Stage-5, Stage-4
-  Stage-4
-  Stage-9 depends on stages: Stage-3 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
-  Stage-12 depends on stages: Stage-3 , consists of Stage-11, Stage-10
-  Stage-11
-  Stage-2 depends on stages: Stage-11, Stage-10
+  Stage-11 depends on stages: Stage-3 , consists of Stage-10, Stage-9
   Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
+  Stage-15 depends on stages: Stage-3 , consists of Stage-14, Stage-13
+  Stage-14
+  Stage-2 depends on stages: Stage-14, Stage-13
+  Stage-12 depends on stages: Stage-2
+  Stage-13
 
 STAGE PLANS:
   Stage: Stage-3
@@ -125,14 +128,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest3
 
-  Stage: Stage-6
+  Stage: Stage-7
     Conditional Operator
 
-  Stage: Stage-5
+  Stage: Stage-6
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -145,9 +148,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10006 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -157,14 +163,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -176,10 +182,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10007 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10007 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -189,14 +198,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest2
 
-  Stage: Stage-12
+  Stage: Stage-15
     Conditional Operator
 
-  Stage: Stage-11
+  Stage: Stage-14
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10004
 
   Stage: Stage-2
     Move Operator
@@ -211,10 +220,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest3
 
-  Stage: Stage-10
+  Stage: Stage-12
+    Stats-Aggr Operator
+
+  Stage: Stage-13
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-43_632_8683422802049631950/-ext-10008 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-35_986_1783793979784635729/-ext-10008 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -251,11 +263,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-48_633_3098045335799323092/-mr-10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-45_582_5567777802564652649/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-48_633_3098045335799323092/-mr-10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-45_582_5567777802564652649/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -348,11 +360,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-48_864_4321790749435091736/-mr-10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-45_917_708064163493602688/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-48_864_4321790749435091736/-mr-10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-45_917_708064163493602688/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -466,11 +478,11 @@
 PREHOOK: query: SELECT dest3.* FROM dest3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-49_077_6670527630558017989/-mr-10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-46_261_4933108995689043596/-mr-10000
 POSTHOOK: query: SELECT dest3.* FROM dest3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-49_077_6670527630558017989/-mr-10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-46_261_4933108995689043596/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input35.q.out
===================================================================
--- ql/src/test/results/clientpositive/input35.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input35.q.out	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-39_059_3888640194483129382/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-29-54_475_987682472980858307/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-39_059_3888640194483129382/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-29-54_475_987682472980858307/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -131,11 +135,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-43_302_4797193311977202177/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-01_261_3930011600895950760/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-43_302_4797193311977202177/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-01_261_3930011600895950760/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/sample4.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample4.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample4.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -52,8 +54,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -63,21 +66,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1280085939
+                          transient_lastDdlTime 1284594113
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -89,12 +93,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -106,31 +110,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -140,20 +144,24 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085939
+                transient_lastDdlTime 1284594113
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -167,9 +175,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -180,12 +188,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280085939
+              transient_lastDdlTime 1284594113
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -196,12 +204,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085939
+                transient_lastDdlTime 1284594113
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -210,7 +218,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-39_858_5837414475201837656/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-53_814_6781487881659692809/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -221,15 +229,16 @@
                   columns.types int:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280085939
+                  transient_lastDdlTime 1284594113
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -248,11 +257,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-43_186_3357770163777004935/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-00_422_5033167721450222886/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-43_186_3357770163777004935/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-00_422_5033167721450222886/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 474	val_475
Index: ql/src/test/results/clientpositive/input3_limit.q.out
===================================================================
--- ql/src/test/results/clientpositive/input3_limit.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input3_limit.q.out	(working copy)
@@ -31,6 +31,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -82,7 +83,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-28-28_770_5844411471048586267/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-30-52_861_1975779672781338215/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -113,7 +114,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: t2
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE T2 SELECT * FROM (SELECT * FROM T1 DISTRIBUTE BY key SORT BY key, value) T LIMIT 20
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t1
@@ -127,11 +131,11 @@
 PREHOOK: query: SELECT * FROM T2 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-28-33_846_8194327293225084148/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-03_039_904488643585504415/-mr-10000
 POSTHOOK: query: SELECT * FROM T2 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-28-33_846_8194327293225084148/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-31-03_039_904488643585504415/-mr-10000
 POSTHOOK: Lineage: t2.key SIMPLE [(t1)t1.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: t2.value SIMPLE [(t1)t1.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
Index: ql/src/test/results/clientpositive/mapreduce2.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce2.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -96,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -120,11 +124,11 @@
 PREHOOK: query: SELECT * FROM (SELECT dest1.* FROM dest1 DISTRIBUTE BY key SORT BY key, ten, one, value) T
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-22-45_087_4277793759176252111/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-06_482_1517464312238949080/-mr-10000
 POSTHOOK: query: SELECT * FROM (SELECT dest1.* FROM dest1 DISTRIBUTE BY key SORT BY key, ten, one, value) T
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-22-45_087_4277793759176252111/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-06_482_1517464312238949080/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucket3.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucket3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucket3.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -45,9 +47,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -58,12 +60,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -74,12 +76,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -95,8 +97,10 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-18_069_2499676602955827966/10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-25_474_5885854630941081859/-ext-10000
               NumFilesPerFileSink: 2
+              Static Partition Specification: ds=1/
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-25_474_5885854630941081859/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -107,16 +111,17 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket3_1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket3_1
                     name bucket3_1
                     partition_columns ds
                     serialization.ddl struct bucket3_1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279735757
+                    transient_lastDdlTime 1284504625
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket3_1
               TotalFiles: 2
+              GatherStats: true
               MultiFileSpray: true
 
   Stage: Stage-0
@@ -125,7 +130,7 @@
           partition:
             ds 1
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-18_069_2499676602955827966/10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-25_474_5885854630941081859/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -136,18 +141,22 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket3_1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket3_1
                 name bucket3_1
                 partition_columns ds
                 serialization.ddl struct bucket3_1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735757
+                transient_lastDdlTime 1284504625
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket3_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-18_069_2499676602955827966/10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-25_474_5885854630941081859/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-50-25_474_5885854630941081859/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket3_1 partition (ds='1')
 select * from src
 PREHOOK: type: QUERY
@@ -249,11 +258,11 @@
 PREHOOK: query: select * from bucket3_1 tablesample (bucket 1 out of 2) s where ds = '1' order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket3_1@ds=1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-23_782_5794755668640533078/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-40_619_7952584250556107198/-mr-10000
 POSTHOOK: query: select * from bucket3_1 tablesample (bucket 1 out of 2) s where ds = '1' order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket3_1@ds=1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-23_782_5794755668640533078/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-50-40_619_7952584250556107198/-mr-10000
 POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample7.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample7.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample7.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -57,8 +59,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -68,21 +71,22 @@
                             columns.types int:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                             name dest1
                             serialization.ddl struct dest1 { i32 key, string value}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1280085975
+                            transient_lastDdlTime 1284594180
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -94,12 +98,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,31 +115,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -145,20 +149,24 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085975
+                transient_lastDdlTime 1284594180
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -172,9 +180,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -185,12 +193,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280085975
+              transient_lastDdlTime 1284594180
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -201,12 +209,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085975
+                transient_lastDdlTime 1284594180
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -215,7 +223,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-26-15_464_8761284331746638175/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-43-00_537_3165447624721701712/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -226,15 +234,16 @@
                   columns.types int:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280085975
+                  transient_lastDdlTime 1284594180
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -255,11 +264,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-18_926_6225738491472310076/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-43-09_540_8309503687517388631/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-26-18_926_6225738491472310076/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-43-09_540_8309503687517388631/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 468	val_469
Index: ql/src/test/results/clientpositive/input_lazyserde.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_lazyserde.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_lazyserde.q.out	(working copy)
@@ -29,6 +29,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -88,7 +89,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src_thrift
 INSERT OVERWRITE TABLE dest1 SELECT src_thrift.lint, src_thrift.lstring, src_thrift.mstringstring, src_thrift.aint, src_thrift.astring DISTRIBUTE BY 1
 PREHOOK: type: QUERY
@@ -107,11 +111,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1 DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-36_002_6394574811571020120/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-25_073_8539790003663419019/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-36_002_6394574811571020120/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-25_073_8539790003663419019/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -131,11 +135,11 @@
 PREHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1 DISTRIBUTE BY 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-39_505_1202718209239610725/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-28_671_2104052666178146727/-mr-10000
 POSTHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1 DISTRIBUTE BY 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-39_505_1202718209239610725/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-28_671_2104052666178146727/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -192,11 +196,11 @@
 PREHOOK: query: SELECT * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-47_026_3993263922773820549/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-39_265_3585210195406224800/-mr-10000
 POSTHOOK: query: SELECT * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-47_026_3993263922773820549/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-39_265_3585210195406224800/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
@@ -257,11 +261,11 @@
 PREHOOK: query: SELECT * from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-51_790_8751887109831886457/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-46_712_2519354046309726594/-mr-10000
 POSTHOOK: query: SELECT * from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/njain/hive_2010-08-17_00-00-51_790_8751887109831886457/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-46_712_2519354046309726594/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/merge2.q.out
===================================================================
--- ql/src/test/results/clientpositive/merge2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge2.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,14 +88,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-55-56_362_1817457196403184484/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-41_587_1479117521763139913/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -107,9 +108,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-55-56_362_1817457196403184484/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-04-41_587_1479117521763139913/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -135,11 +139,11 @@
 PREHOOK: query: select * from test1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@test1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-56-01_340_9175387669424641848/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-48_974_2460598230030561192/-mr-10000
 POSTHOOK: query: select * from test1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@test1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-56-01_340_9175387669424641848/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-48_974_2460598230030561192/-mr-10000
 POSTHOOK: Lineage: test1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: test1.val EXPRESSION [(src)src.null, ]
 0	3
@@ -518,10 +522,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -544,14 +549,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-56-09_531_6975056240827314343/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-02_998_781535564297659708/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -564,9 +569,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-56-09_531_6975056240827314343/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-02_998_781535564297659708/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -612,10 +620,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -638,14 +647,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-56-17_602_4349159757722990372/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-13_368_8155747604457943596/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -658,9 +667,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-56-17_602_4349159757722990372/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-13_368_8155747604457943596/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
Index: ql/src/test/results/clientpositive/join4.q.out
===================================================================
--- ql/src/test/results/clientpositive/join4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join4.q.out	(working copy)
@@ -39,6 +39,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -169,7 +170,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -209,11 +213,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-16-59_447_2362829536722202223/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-42-40_850_7324476183424301778/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-16-59_447_2362829536722202223/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-42-40_850_7324476183424301778/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_dynamicserde.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_dynamicserde.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_dynamicserde.q.out	(working copy)
@@ -28,10 +28,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -62,14 +63,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-01_757_5819014558774174140/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-07_213_5098972181857672126/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -82,9 +83,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-01_757_5819014558774174140/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-07_213_5098972181857672126/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -113,11 +117,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-05_921_5875180124679138012/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-13_547_5402297268276891777/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-05_921_5875180124679138012/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-13_547_5402297268276891777/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
@@ -137,11 +141,11 @@
 PREHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-06_171_2453831878768834955/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-13_900_7937348779609118653/-mr-10000
 POSTHOOK: query: SELECT dest1.a[0], dest1.b[0], dest1.c['key2'], dest1.d, dest1.e FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-06_171_2453831878768834955/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-13_900_7937348779609118653/-mr-10000
 POSTHOOK: Lineage: dest1.a SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.b SIMPLE [(src_thrift)src_thrift.FieldSchema(name:lstring, type:array<string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.c SIMPLE [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/stats4.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/stats4.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/stats4.q.out_0.17	(revision 0)
@@ -0,0 +1,2549 @@
+PREHOOK: query: show partitions srcpart
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions srcpart
+POSTHOOK: type: SHOWPARTITIONS
+ds=2008-04-08/hr=11
+ds=2008-04-08/hr=12
+ds=2008-04-09/hr=11
+ds=2008-04-09/hr=12
+PREHOOK: query: drop table nzhang_part1
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table nzhang_part1
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: drop table nzhang_part2
+PREHOOK: type: DROPTABLE
+POSTHOOK: query: drop table nzhang_part2
+POSTHOOK: type: DROPTABLE
+PREHOOK: query: create table if not exists nzhang_part1 like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table if not exists nzhang_part1 like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@nzhang_part1
+PREHOOK: query: create table if not exists nzhang_part2 like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table if not exists nzhang_part2 like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@nzhang_part2
+PREHOOK: query: explain
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB nzhang_part1 (TOK_PARTSPEC (TOK_PARTVAL ds) (TOK_PARTVAL hr)))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL ds)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (<= (TOK_TABLE_OR_COL ds) '2008-04-08'))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB nzhang_part2 (TOK_PARTSPEC (TOK_PARTVAL ds '2008-12-31') (TOK_PARTVAL hr)))) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)) (TOK_SELEXPR (TOK_TABLE_OR_COL value)) (TOK_SELEXPR (TOK_TABLE_OR_COL hr))) (TOK_WHERE (> (TOK_TABLE_OR_COL ds) '2008-04-08'))))
+
+STAGE DEPENDENCIES:
+  Stage-2 is a root stage
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-2
+    Map Reduce
+      Alias -> Map Operator Tree:
+        srcpart 
+          TableScan
+            alias: srcpart
+            Filter Operator
+              predicate:
+                  expr: (ds <= '2008-04-08')
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                      expr: ds
+                      type: string
+                      expr: hr
+                      type: string
+                outputColumnNames: _col0, _col1, _col2, _col3
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 1
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: nzhang_part1
+            Filter Operator
+              predicate:
+                  expr: (ds > '2008-04-08')
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                      expr: hr
+                      type: string
+                outputColumnNames: _col0, _col1, _col2
+                File Output Operator
+                  compressed: false
+                  GlobalTableId: 2
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                      name: nzhang_part2
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 
+            hr 
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: nzhang_part1
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-1
+    Move Operator
+      tables:
+          partition:
+            ds 2008-12-31
+            hr 
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: nzhang_part2
+
+  Stage: Stage-4
+    Stats-Aggr Operator
+
+
+PREHOOK: query: from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08'
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@nzhang_part1@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@nzhang_part1@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@nzhang_part2@ds=2008-12-31/hr=11
+POSTHOOK: Output: default@nzhang_part2@ds=2008-12-31/hr=12
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: show partitions nzhang_part1
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions nzhang_part1
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ds=2008-04-08/hr=11
+ds=2008-04-08/hr=12
+PREHOOK: query: show partitions nzhang_part2
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions nzhang_part2
+POSTHOOK: type: SHOWPARTITIONS
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ds=2008-12-31/hr=11
+ds=2008-12-31/hr=12
+PREHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
+PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-15-32_388_3671595497118363058/-mr-10000
+POSTHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-15-32_388_3671595497118363058/-mr-10000
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	2008-04-08	11
+86	val_86	2008-04-08	11
+311	val_311	2008-04-08	11
+27	val_27	2008-04-08	11
+165	val_165	2008-04-08	11
+409	val_409	2008-04-08	11
+255	val_255	2008-04-08	11
+278	val_278	2008-04-08	11
+98	val_98	2008-04-08	11
+484	val_484	2008-04-08	11
+265	val_265	2008-04-08	11
+193	val_193	2008-04-08	11
+401	val_401	2008-04-08	11
+150	val_150	2008-04-08	11
+273	val_273	2008-04-08	11
+224	val_224	2008-04-08	11
+369	val_369	2008-04-08	11
+66	val_66	2008-04-08	11
+128	val_128	2008-04-08	11
+213	val_213	2008-04-08	11
+146	val_146	2008-04-08	11
+406	val_406	2008-04-08	11
+429	val_429	2008-04-08	11
+374	val_374	2008-04-08	11
+152	val_152	2008-04-08	11
+469	val_469	2008-04-08	11
+145	val_145	2008-04-08	11
+495	val_495	2008-04-08	11
+37	val_37	2008-04-08	11
+327	val_327	2008-04-08	11
+281	val_281	2008-04-08	11
+277	val_277	2008-04-08	11
+209	val_209	2008-04-08	11
+15	val_15	2008-04-08	11
+82	val_82	2008-04-08	11
+403	val_403	2008-04-08	11
+166	val_166	2008-04-08	11
+417	val_417	2008-04-08	11
+430	val_430	2008-04-08	11
+252	val_252	2008-04-08	11
+292	val_292	2008-04-08	11
+219	val_219	2008-04-08	11
+287	val_287	2008-04-08	11
+153	val_153	2008-04-08	11
+193	val_193	2008-04-08	11
+338	val_338	2008-04-08	11
+446	val_446	2008-04-08	11
+459	val_459	2008-04-08	11
+394	val_394	2008-04-08	11
+237	val_237	2008-04-08	11
+482	val_482	2008-04-08	11
+174	val_174	2008-04-08	11
+413	val_413	2008-04-08	11
+494	val_494	2008-04-08	11
+207	val_207	2008-04-08	11
+199	val_199	2008-04-08	11
+466	val_466	2008-04-08	11
+208	val_208	2008-04-08	11
+174	val_174	2008-04-08	11
+399	val_399	2008-04-08	11
+396	val_396	2008-04-08	11
+247	val_247	2008-04-08	11
+417	val_417	2008-04-08	11
+489	val_489	2008-04-08	11
+162	val_162	2008-04-08	11
+377	val_377	2008-04-08	11
+397	val_397	2008-04-08	11
+309	val_309	2008-04-08	11
+365	val_365	2008-04-08	11
+266	val_266	2008-04-08	11
+439	val_439	2008-04-08	11
+342	val_342	2008-04-08	11
+367	val_367	2008-04-08	11
+325	val_325	2008-04-08	11
+167	val_167	2008-04-08	11
+195	val_195	2008-04-08	11
+475	val_475	2008-04-08	11
+17	val_17	2008-04-08	11
+113	val_113	2008-04-08	11
+155	val_155	2008-04-08	11
+203	val_203	2008-04-08	11
+339	val_339	2008-04-08	11
+0	val_0	2008-04-08	11
+455	val_455	2008-04-08	11
+128	val_128	2008-04-08	11
+311	val_311	2008-04-08	11
+316	val_316	2008-04-08	11
+57	val_57	2008-04-08	11
+302	val_302	2008-04-08	11
+205	val_205	2008-04-08	11
+149	val_149	2008-04-08	11
+438	val_438	2008-04-08	11
+345	val_345	2008-04-08	11
+129	val_129	2008-04-08	11
+170	val_170	2008-04-08	11
+20	val_20	2008-04-08	11
+489	val_489	2008-04-08	11
+157	val_157	2008-04-08	11
+378	val_378	2008-04-08	11
+221	val_221	2008-04-08	11
+92	val_92	2008-04-08	11
+111	val_111	2008-04-08	11
+47	val_47	2008-04-08	11
+72	val_72	2008-04-08	11
+4	val_4	2008-04-08	11
+280	val_280	2008-04-08	11
+35	val_35	2008-04-08	11
+427	val_427	2008-04-08	11
+277	val_277	2008-04-08	11
+208	val_208	2008-04-08	11
+356	val_356	2008-04-08	11
+399	val_399	2008-04-08	11
+169	val_169	2008-04-08	11
+382	val_382	2008-04-08	11
+498	val_498	2008-04-08	11
+125	val_125	2008-04-08	11
+386	val_386	2008-04-08	11
+437	val_437	2008-04-08	11
+469	val_469	2008-04-08	11
+192	val_192	2008-04-08	11
+286	val_286	2008-04-08	11
+187	val_187	2008-04-08	11
+176	val_176	2008-04-08	11
+54	val_54	2008-04-08	11
+459	val_459	2008-04-08	11
+51	val_51	2008-04-08	11
+138	val_138	2008-04-08	11
+103	val_103	2008-04-08	11
+239	val_239	2008-04-08	11
+213	val_213	2008-04-08	11
+216	val_216	2008-04-08	11
+430	val_430	2008-04-08	11
+278	val_278	2008-04-08	11
+176	val_176	2008-04-08	11
+289	val_289	2008-04-08	11
+221	val_221	2008-04-08	11
+65	val_65	2008-04-08	11
+318	val_318	2008-04-08	11
+332	val_332	2008-04-08	11
+311	val_311	2008-04-08	11
+275	val_275	2008-04-08	11
+137	val_137	2008-04-08	11
+241	val_241	2008-04-08	11
+83	val_83	2008-04-08	11
+333	val_333	2008-04-08	11
+180	val_180	2008-04-08	11
+284	val_284	2008-04-08	11
+12	val_12	2008-04-08	11
+230	val_230	2008-04-08	11
+181	val_181	2008-04-08	11
+67	val_67	2008-04-08	11
+260	val_260	2008-04-08	11
+404	val_404	2008-04-08	11
+384	val_384	2008-04-08	11
+489	val_489	2008-04-08	11
+353	val_353	2008-04-08	11
+373	val_373	2008-04-08	11
+272	val_272	2008-04-08	11
+138	val_138	2008-04-08	11
+217	val_217	2008-04-08	11
+84	val_84	2008-04-08	11
+348	val_348	2008-04-08	11
+466	val_466	2008-04-08	11
+58	val_58	2008-04-08	11
+8	val_8	2008-04-08	11
+411	val_411	2008-04-08	11
+230	val_230	2008-04-08	11
+208	val_208	2008-04-08	11
+348	val_348	2008-04-08	11
+24	val_24	2008-04-08	11
+463	val_463	2008-04-08	11
+431	val_431	2008-04-08	11
+179	val_179	2008-04-08	11
+172	val_172	2008-04-08	11
+42	val_42	2008-04-08	11
+129	val_129	2008-04-08	11
+158	val_158	2008-04-08	11
+119	val_119	2008-04-08	11
+496	val_496	2008-04-08	11
+0	val_0	2008-04-08	11
+322	val_322	2008-04-08	11
+197	val_197	2008-04-08	11
+468	val_468	2008-04-08	11
+393	val_393	2008-04-08	11
+454	val_454	2008-04-08	11
+100	val_100	2008-04-08	11
+298	val_298	2008-04-08	11
+199	val_199	2008-04-08	11
+191	val_191	2008-04-08	11
+418	val_418	2008-04-08	11
+96	val_96	2008-04-08	11
+26	val_26	2008-04-08	11
+165	val_165	2008-04-08	11
+327	val_327	2008-04-08	11
+230	val_230	2008-04-08	11
+205	val_205	2008-04-08	11
+120	val_120	2008-04-08	11
+131	val_131	2008-04-08	11
+51	val_51	2008-04-08	11
+404	val_404	2008-04-08	11
+43	val_43	2008-04-08	11
+436	val_436	2008-04-08	11
+156	val_156	2008-04-08	11
+469	val_469	2008-04-08	11
+468	val_468	2008-04-08	11
+308	val_308	2008-04-08	11
+95	val_95	2008-04-08	11
+196	val_196	2008-04-08	11
+288	val_288	2008-04-08	11
+481	val_481	2008-04-08	11
+457	val_457	2008-04-08	11
+98	val_98	2008-04-08	11
+282	val_282	2008-04-08	11
+197	val_197	2008-04-08	11
+187	val_187	2008-04-08	11
+318	val_318	2008-04-08	11
+318	val_318	2008-04-08	11
+409	val_409	2008-04-08	11
+470	val_470	2008-04-08	11
+137	val_137	2008-04-08	11
+369	val_369	2008-04-08	11
+316	val_316	2008-04-08	11
+169	val_169	2008-04-08	11
+413	val_413	2008-04-08	11
+85	val_85	2008-04-08	11
+77	val_77	2008-04-08	11
+0	val_0	2008-04-08	11
+490	val_490	2008-04-08	11
+87	val_87	2008-04-08	11
+364	val_364	2008-04-08	11
+179	val_179	2008-04-08	11
+118	val_118	2008-04-08	11
+134	val_134	2008-04-08	11
+395	val_395	2008-04-08	11
+282	val_282	2008-04-08	11
+138	val_138	2008-04-08	11
+238	val_238	2008-04-08	11
+419	val_419	2008-04-08	11
+15	val_15	2008-04-08	11
+118	val_118	2008-04-08	11
+72	val_72	2008-04-08	11
+90	val_90	2008-04-08	11
+307	val_307	2008-04-08	11
+19	val_19	2008-04-08	11
+435	val_435	2008-04-08	11
+10	val_10	2008-04-08	11
+277	val_277	2008-04-08	11
+273	val_273	2008-04-08	11
+306	val_306	2008-04-08	11
+224	val_224	2008-04-08	11
+309	val_309	2008-04-08	11
+389	val_389	2008-04-08	11
+327	val_327	2008-04-08	11
+242	val_242	2008-04-08	11
+369	val_369	2008-04-08	11
+392	val_392	2008-04-08	11
+272	val_272	2008-04-08	11
+331	val_331	2008-04-08	11
+401	val_401	2008-04-08	11
+242	val_242	2008-04-08	11
+452	val_452	2008-04-08	11
+177	val_177	2008-04-08	11
+226	val_226	2008-04-08	11
+5	val_5	2008-04-08	11
+497	val_497	2008-04-08	11
+402	val_402	2008-04-08	11
+396	val_396	2008-04-08	11
+317	val_317	2008-04-08	11
+395	val_395	2008-04-08	11
+58	val_58	2008-04-08	11
+35	val_35	2008-04-08	11
+336	val_336	2008-04-08	11
+95	val_95	2008-04-08	11
+11	val_11	2008-04-08	11
+168	val_168	2008-04-08	11
+34	val_34	2008-04-08	11
+229	val_229	2008-04-08	11
+233	val_233	2008-04-08	11
+143	val_143	2008-04-08	11
+472	val_472	2008-04-08	11
+322	val_322	2008-04-08	11
+498	val_498	2008-04-08	11
+160	val_160	2008-04-08	11
+195	val_195	2008-04-08	11
+42	val_42	2008-04-08	11
+321	val_321	2008-04-08	11
+430	val_430	2008-04-08	11
+119	val_119	2008-04-08	11
+489	val_489	2008-04-08	11
+458	val_458	2008-04-08	11
+78	val_78	2008-04-08	11
+76	val_76	2008-04-08	11
+41	val_41	2008-04-08	11
+223	val_223	2008-04-08	11
+492	val_492	2008-04-08	11
+149	val_149	2008-04-08	11
+449	val_449	2008-04-08	11
+218	val_218	2008-04-08	11
+228	val_228	2008-04-08	11
+138	val_138	2008-04-08	11
+453	val_453	2008-04-08	11
+30	val_30	2008-04-08	11
+209	val_209	2008-04-08	11
+64	val_64	2008-04-08	11
+468	val_468	2008-04-08	11
+76	val_76	2008-04-08	11
+74	val_74	2008-04-08	11
+342	val_342	2008-04-08	11
+69	val_69	2008-04-08	11
+230	val_230	2008-04-08	11
+33	val_33	2008-04-08	11
+368	val_368	2008-04-08	11
+103	val_103	2008-04-08	11
+296	val_296	2008-04-08	11
+113	val_113	2008-04-08	11
+216	val_216	2008-04-08	11
+367	val_367	2008-04-08	11
+344	val_344	2008-04-08	11
+167	val_167	2008-04-08	11
+274	val_274	2008-04-08	11
+219	val_219	2008-04-08	11
+239	val_239	2008-04-08	11
+485	val_485	2008-04-08	11
+116	val_116	2008-04-08	11
+223	val_223	2008-04-08	11
+256	val_256	2008-04-08	11
+263	val_263	2008-04-08	11
+70	val_70	2008-04-08	11
+487	val_487	2008-04-08	11
+480	val_480	2008-04-08	11
+401	val_401	2008-04-08	11
+288	val_288	2008-04-08	11
+191	val_191	2008-04-08	11
+5	val_5	2008-04-08	11
+244	val_244	2008-04-08	11
+438	val_438	2008-04-08	11
+128	val_128	2008-04-08	11
+467	val_467	2008-04-08	11
+432	val_432	2008-04-08	11
+202	val_202	2008-04-08	11
+316	val_316	2008-04-08	11
+229	val_229	2008-04-08	11
+469	val_469	2008-04-08	11
+463	val_463	2008-04-08	11
+280	val_280	2008-04-08	11
+2	val_2	2008-04-08	11
+35	val_35	2008-04-08	11
+283	val_283	2008-04-08	11
+331	val_331	2008-04-08	11
+235	val_235	2008-04-08	11
+80	val_80	2008-04-08	11
+44	val_44	2008-04-08	11
+193	val_193	2008-04-08	11
+321	val_321	2008-04-08	11
+335	val_335	2008-04-08	11
+104	val_104	2008-04-08	11
+466	val_466	2008-04-08	11
+366	val_366	2008-04-08	11
+175	val_175	2008-04-08	11
+403	val_403	2008-04-08	11
+483	val_483	2008-04-08	11
+53	val_53	2008-04-08	11
+105	val_105	2008-04-08	11
+257	val_257	2008-04-08	11
+406	val_406	2008-04-08	11
+409	val_409	2008-04-08	11
+190	val_190	2008-04-08	11
+406	val_406	2008-04-08	11
+401	val_401	2008-04-08	11
+114	val_114	2008-04-08	11
+258	val_258	2008-04-08	11
+90	val_90	2008-04-08	11
+203	val_203	2008-04-08	11
+262	val_262	2008-04-08	11
+348	val_348	2008-04-08	11
+424	val_424	2008-04-08	11
+12	val_12	2008-04-08	11
+396	val_396	2008-04-08	11
+201	val_201	2008-04-08	11
+217	val_217	2008-04-08	11
+164	val_164	2008-04-08	11
+431	val_431	2008-04-08	11
+454	val_454	2008-04-08	11
+478	val_478	2008-04-08	11
+298	val_298	2008-04-08	11
+125	val_125	2008-04-08	11
+431	val_431	2008-04-08	11
+164	val_164	2008-04-08	11
+424	val_424	2008-04-08	11
+187	val_187	2008-04-08	11
+382	val_382	2008-04-08	11
+5	val_5	2008-04-08	11
+70	val_70	2008-04-08	11
+397	val_397	2008-04-08	11
+480	val_480	2008-04-08	11
+291	val_291	2008-04-08	11
+24	val_24	2008-04-08	11
+351	val_351	2008-04-08	11
+255	val_255	2008-04-08	11
+104	val_104	2008-04-08	11
+70	val_70	2008-04-08	11
+163	val_163	2008-04-08	11
+438	val_438	2008-04-08	11
+119	val_119	2008-04-08	11
+414	val_414	2008-04-08	11
+200	val_200	2008-04-08	11
+491	val_491	2008-04-08	11
+237	val_237	2008-04-08	11
+439	val_439	2008-04-08	11
+360	val_360	2008-04-08	11
+248	val_248	2008-04-08	11
+479	val_479	2008-04-08	11
+305	val_305	2008-04-08	11
+417	val_417	2008-04-08	11
+199	val_199	2008-04-08	11
+444	val_444	2008-04-08	11
+120	val_120	2008-04-08	11
+429	val_429	2008-04-08	11
+169	val_169	2008-04-08	11
+443	val_443	2008-04-08	11
+323	val_323	2008-04-08	11
+325	val_325	2008-04-08	11
+277	val_277	2008-04-08	11
+230	val_230	2008-04-08	11
+478	val_478	2008-04-08	11
+178	val_178	2008-04-08	11
+468	val_468	2008-04-08	11
+310	val_310	2008-04-08	11
+317	val_317	2008-04-08	11
+333	val_333	2008-04-08	11
+493	val_493	2008-04-08	11
+460	val_460	2008-04-08	11
+207	val_207	2008-04-08	11
+249	val_249	2008-04-08	11
+265	val_265	2008-04-08	11
+480	val_480	2008-04-08	11
+83	val_83	2008-04-08	11
+136	val_136	2008-04-08	11
+353	val_353	2008-04-08	11
+172	val_172	2008-04-08	11
+214	val_214	2008-04-08	11
+462	val_462	2008-04-08	11
+233	val_233	2008-04-08	11
+406	val_406	2008-04-08	11
+133	val_133	2008-04-08	11
+175	val_175	2008-04-08	11
+189	val_189	2008-04-08	11
+454	val_454	2008-04-08	11
+375	val_375	2008-04-08	11
+401	val_401	2008-04-08	11
+421	val_421	2008-04-08	11
+407	val_407	2008-04-08	11
+384	val_384	2008-04-08	11
+256	val_256	2008-04-08	11
+26	val_26	2008-04-08	11
+134	val_134	2008-04-08	11
+67	val_67	2008-04-08	11
+384	val_384	2008-04-08	11
+379	val_379	2008-04-08	11
+18	val_18	2008-04-08	11
+462	val_462	2008-04-08	11
+492	val_492	2008-04-08	11
+100	val_100	2008-04-08	11
+298	val_298	2008-04-08	11
+9	val_9	2008-04-08	11
+341	val_341	2008-04-08	11
+498	val_498	2008-04-08	11
+146	val_146	2008-04-08	11
+458	val_458	2008-04-08	11
+362	val_362	2008-04-08	11
+186	val_186	2008-04-08	11
+285	val_285	2008-04-08	11
+348	val_348	2008-04-08	11
+167	val_167	2008-04-08	11
+18	val_18	2008-04-08	11
+273	val_273	2008-04-08	11
+183	val_183	2008-04-08	11
+281	val_281	2008-04-08	11
+344	val_344	2008-04-08	11
+97	val_97	2008-04-08	11
+469	val_469	2008-04-08	11
+315	val_315	2008-04-08	11
+84	val_84	2008-04-08	11
+28	val_28	2008-04-08	11
+37	val_37	2008-04-08	11
+448	val_448	2008-04-08	11
+152	val_152	2008-04-08	11
+348	val_348	2008-04-08	11
+307	val_307	2008-04-08	11
+194	val_194	2008-04-08	11
+414	val_414	2008-04-08	11
+477	val_477	2008-04-08	11
+222	val_222	2008-04-08	11
+126	val_126	2008-04-08	11
+90	val_90	2008-04-08	11
+169	val_169	2008-04-08	11
+403	val_403	2008-04-08	11
+400	val_400	2008-04-08	11
+200	val_200	2008-04-08	11
+97	val_97	2008-04-08	11
+238	val_238	2008-04-08	12
+86	val_86	2008-04-08	12
+311	val_311	2008-04-08	12
+27	val_27	2008-04-08	12
+165	val_165	2008-04-08	12
+409	val_409	2008-04-08	12
+255	val_255	2008-04-08	12
+278	val_278	2008-04-08	12
+98	val_98	2008-04-08	12
+484	val_484	2008-04-08	12
+265	val_265	2008-04-08	12
+193	val_193	2008-04-08	12
+401	val_401	2008-04-08	12
+150	val_150	2008-04-08	12
+273	val_273	2008-04-08	12
+224	val_224	2008-04-08	12
+369	val_369	2008-04-08	12
+66	val_66	2008-04-08	12
+128	val_128	2008-04-08	12
+213	val_213	2008-04-08	12
+146	val_146	2008-04-08	12
+406	val_406	2008-04-08	12
+429	val_429	2008-04-08	12
+374	val_374	2008-04-08	12
+152	val_152	2008-04-08	12
+469	val_469	2008-04-08	12
+145	val_145	2008-04-08	12
+495	val_495	2008-04-08	12
+37	val_37	2008-04-08	12
+327	val_327	2008-04-08	12
+281	val_281	2008-04-08	12
+277	val_277	2008-04-08	12
+209	val_209	2008-04-08	12
+15	val_15	2008-04-08	12
+82	val_82	2008-04-08	12
+403	val_403	2008-04-08	12
+166	val_166	2008-04-08	12
+417	val_417	2008-04-08	12
+430	val_430	2008-04-08	12
+252	val_252	2008-04-08	12
+292	val_292	2008-04-08	12
+219	val_219	2008-04-08	12
+287	val_287	2008-04-08	12
+153	val_153	2008-04-08	12
+193	val_193	2008-04-08	12
+338	val_338	2008-04-08	12
+446	val_446	2008-04-08	12
+459	val_459	2008-04-08	12
+394	val_394	2008-04-08	12
+237	val_237	2008-04-08	12
+482	val_482	2008-04-08	12
+174	val_174	2008-04-08	12
+413	val_413	2008-04-08	12
+494	val_494	2008-04-08	12
+207	val_207	2008-04-08	12
+199	val_199	2008-04-08	12
+466	val_466	2008-04-08	12
+208	val_208	2008-04-08	12
+174	val_174	2008-04-08	12
+399	val_399	2008-04-08	12
+396	val_396	2008-04-08	12
+247	val_247	2008-04-08	12
+417	val_417	2008-04-08	12
+489	val_489	2008-04-08	12
+162	val_162	2008-04-08	12
+377	val_377	2008-04-08	12
+397	val_397	2008-04-08	12
+309	val_309	2008-04-08	12
+365	val_365	2008-04-08	12
+266	val_266	2008-04-08	12
+439	val_439	2008-04-08	12
+342	val_342	2008-04-08	12
+367	val_367	2008-04-08	12
+325	val_325	2008-04-08	12
+167	val_167	2008-04-08	12
+195	val_195	2008-04-08	12
+475	val_475	2008-04-08	12
+17	val_17	2008-04-08	12
+113	val_113	2008-04-08	12
+155	val_155	2008-04-08	12
+203	val_203	2008-04-08	12
+339	val_339	2008-04-08	12
+0	val_0	2008-04-08	12
+455	val_455	2008-04-08	12
+128	val_128	2008-04-08	12
+311	val_311	2008-04-08	12
+316	val_316	2008-04-08	12
+57	val_57	2008-04-08	12
+302	val_302	2008-04-08	12
+205	val_205	2008-04-08	12
+149	val_149	2008-04-08	12
+438	val_438	2008-04-08	12
+345	val_345	2008-04-08	12
+129	val_129	2008-04-08	12
+170	val_170	2008-04-08	12
+20	val_20	2008-04-08	12
+489	val_489	2008-04-08	12
+157	val_157	2008-04-08	12
+378	val_378	2008-04-08	12
+221	val_221	2008-04-08	12
+92	val_92	2008-04-08	12
+111	val_111	2008-04-08	12
+47	val_47	2008-04-08	12
+72	val_72	2008-04-08	12
+4	val_4	2008-04-08	12
+280	val_280	2008-04-08	12
+35	val_35	2008-04-08	12
+427	val_427	2008-04-08	12
+277	val_277	2008-04-08	12
+208	val_208	2008-04-08	12
+356	val_356	2008-04-08	12
+399	val_399	2008-04-08	12
+169	val_169	2008-04-08	12
+382	val_382	2008-04-08	12
+498	val_498	2008-04-08	12
+125	val_125	2008-04-08	12
+386	val_386	2008-04-08	12
+437	val_437	2008-04-08	12
+469	val_469	2008-04-08	12
+192	val_192	2008-04-08	12
+286	val_286	2008-04-08	12
+187	val_187	2008-04-08	12
+176	val_176	2008-04-08	12
+54	val_54	2008-04-08	12
+459	val_459	2008-04-08	12
+51	val_51	2008-04-08	12
+138	val_138	2008-04-08	12
+103	val_103	2008-04-08	12
+239	val_239	2008-04-08	12
+213	val_213	2008-04-08	12
+216	val_216	2008-04-08	12
+430	val_430	2008-04-08	12
+278	val_278	2008-04-08	12
+176	val_176	2008-04-08	12
+289	val_289	2008-04-08	12
+221	val_221	2008-04-08	12
+65	val_65	2008-04-08	12
+318	val_318	2008-04-08	12
+332	val_332	2008-04-08	12
+311	val_311	2008-04-08	12
+275	val_275	2008-04-08	12
+137	val_137	2008-04-08	12
+241	val_241	2008-04-08	12
+83	val_83	2008-04-08	12
+333	val_333	2008-04-08	12
+180	val_180	2008-04-08	12
+284	val_284	2008-04-08	12
+12	val_12	2008-04-08	12
+230	val_230	2008-04-08	12
+181	val_181	2008-04-08	12
+67	val_67	2008-04-08	12
+260	val_260	2008-04-08	12
+404	val_404	2008-04-08	12
+384	val_384	2008-04-08	12
+489	val_489	2008-04-08	12
+353	val_353	2008-04-08	12
+373	val_373	2008-04-08	12
+272	val_272	2008-04-08	12
+138	val_138	2008-04-08	12
+217	val_217	2008-04-08	12
+84	val_84	2008-04-08	12
+348	val_348	2008-04-08	12
+466	val_466	2008-04-08	12
+58	val_58	2008-04-08	12
+8	val_8	2008-04-08	12
+411	val_411	2008-04-08	12
+230	val_230	2008-04-08	12
+208	val_208	2008-04-08	12
+348	val_348	2008-04-08	12
+24	val_24	2008-04-08	12
+463	val_463	2008-04-08	12
+431	val_431	2008-04-08	12
+179	val_179	2008-04-08	12
+172	val_172	2008-04-08	12
+42	val_42	2008-04-08	12
+129	val_129	2008-04-08	12
+158	val_158	2008-04-08	12
+119	val_119	2008-04-08	12
+496	val_496	2008-04-08	12
+0	val_0	2008-04-08	12
+322	val_322	2008-04-08	12
+197	val_197	2008-04-08	12
+468	val_468	2008-04-08	12
+393	val_393	2008-04-08	12
+454	val_454	2008-04-08	12
+100	val_100	2008-04-08	12
+298	val_298	2008-04-08	12
+199	val_199	2008-04-08	12
+191	val_191	2008-04-08	12
+418	val_418	2008-04-08	12
+96	val_96	2008-04-08	12
+26	val_26	2008-04-08	12
+165	val_165	2008-04-08	12
+327	val_327	2008-04-08	12
+230	val_230	2008-04-08	12
+205	val_205	2008-04-08	12
+120	val_120	2008-04-08	12
+131	val_131	2008-04-08	12
+51	val_51	2008-04-08	12
+404	val_404	2008-04-08	12
+43	val_43	2008-04-08	12
+436	val_436	2008-04-08	12
+156	val_156	2008-04-08	12
+469	val_469	2008-04-08	12
+468	val_468	2008-04-08	12
+308	val_308	2008-04-08	12
+95	val_95	2008-04-08	12
+196	val_196	2008-04-08	12
+288	val_288	2008-04-08	12
+481	val_481	2008-04-08	12
+457	val_457	2008-04-08	12
+98	val_98	2008-04-08	12
+282	val_282	2008-04-08	12
+197	val_197	2008-04-08	12
+187	val_187	2008-04-08	12
+318	val_318	2008-04-08	12
+318	val_318	2008-04-08	12
+409	val_409	2008-04-08	12
+470	val_470	2008-04-08	12
+137	val_137	2008-04-08	12
+369	val_369	2008-04-08	12
+316	val_316	2008-04-08	12
+169	val_169	2008-04-08	12
+413	val_413	2008-04-08	12
+85	val_85	2008-04-08	12
+77	val_77	2008-04-08	12
+0	val_0	2008-04-08	12
+490	val_490	2008-04-08	12
+87	val_87	2008-04-08	12
+364	val_364	2008-04-08	12
+179	val_179	2008-04-08	12
+118	val_118	2008-04-08	12
+134	val_134	2008-04-08	12
+395	val_395	2008-04-08	12
+282	val_282	2008-04-08	12
+138	val_138	2008-04-08	12
+238	val_238	2008-04-08	12
+419	val_419	2008-04-08	12
+15	val_15	2008-04-08	12
+118	val_118	2008-04-08	12
+72	val_72	2008-04-08	12
+90	val_90	2008-04-08	12
+307	val_307	2008-04-08	12
+19	val_19	2008-04-08	12
+435	val_435	2008-04-08	12
+10	val_10	2008-04-08	12
+277	val_277	2008-04-08	12
+273	val_273	2008-04-08	12
+306	val_306	2008-04-08	12
+224	val_224	2008-04-08	12
+309	val_309	2008-04-08	12
+389	val_389	2008-04-08	12
+327	val_327	2008-04-08	12
+242	val_242	2008-04-08	12
+369	val_369	2008-04-08	12
+392	val_392	2008-04-08	12
+272	val_272	2008-04-08	12
+331	val_331	2008-04-08	12
+401	val_401	2008-04-08	12
+242	val_242	2008-04-08	12
+452	val_452	2008-04-08	12
+177	val_177	2008-04-08	12
+226	val_226	2008-04-08	12
+5	val_5	2008-04-08	12
+497	val_497	2008-04-08	12
+402	val_402	2008-04-08	12
+396	val_396	2008-04-08	12
+317	val_317	2008-04-08	12
+395	val_395	2008-04-08	12
+58	val_58	2008-04-08	12
+35	val_35	2008-04-08	12
+336	val_336	2008-04-08	12
+95	val_95	2008-04-08	12
+11	val_11	2008-04-08	12
+168	val_168	2008-04-08	12
+34	val_34	2008-04-08	12
+229	val_229	2008-04-08	12
+233	val_233	2008-04-08	12
+143	val_143	2008-04-08	12
+472	val_472	2008-04-08	12
+322	val_322	2008-04-08	12
+498	val_498	2008-04-08	12
+160	val_160	2008-04-08	12
+195	val_195	2008-04-08	12
+42	val_42	2008-04-08	12
+321	val_321	2008-04-08	12
+430	val_430	2008-04-08	12
+119	val_119	2008-04-08	12
+489	val_489	2008-04-08	12
+458	val_458	2008-04-08	12
+78	val_78	2008-04-08	12
+76	val_76	2008-04-08	12
+41	val_41	2008-04-08	12
+223	val_223	2008-04-08	12
+492	val_492	2008-04-08	12
+149	val_149	2008-04-08	12
+449	val_449	2008-04-08	12
+218	val_218	2008-04-08	12
+228	val_228	2008-04-08	12
+138	val_138	2008-04-08	12
+453	val_453	2008-04-08	12
+30	val_30	2008-04-08	12
+209	val_209	2008-04-08	12
+64	val_64	2008-04-08	12
+468	val_468	2008-04-08	12
+76	val_76	2008-04-08	12
+74	val_74	2008-04-08	12
+342	val_342	2008-04-08	12
+69	val_69	2008-04-08	12
+230	val_230	2008-04-08	12
+33	val_33	2008-04-08	12
+368	val_368	2008-04-08	12
+103	val_103	2008-04-08	12
+296	val_296	2008-04-08	12
+113	val_113	2008-04-08	12
+216	val_216	2008-04-08	12
+367	val_367	2008-04-08	12
+344	val_344	2008-04-08	12
+167	val_167	2008-04-08	12
+274	val_274	2008-04-08	12
+219	val_219	2008-04-08	12
+239	val_239	2008-04-08	12
+485	val_485	2008-04-08	12
+116	val_116	2008-04-08	12
+223	val_223	2008-04-08	12
+256	val_256	2008-04-08	12
+263	val_263	2008-04-08	12
+70	val_70	2008-04-08	12
+487	val_487	2008-04-08	12
+480	val_480	2008-04-08	12
+401	val_401	2008-04-08	12
+288	val_288	2008-04-08	12
+191	val_191	2008-04-08	12
+5	val_5	2008-04-08	12
+244	val_244	2008-04-08	12
+438	val_438	2008-04-08	12
+128	val_128	2008-04-08	12
+467	val_467	2008-04-08	12
+432	val_432	2008-04-08	12
+202	val_202	2008-04-08	12
+316	val_316	2008-04-08	12
+229	val_229	2008-04-08	12
+469	val_469	2008-04-08	12
+463	val_463	2008-04-08	12
+280	val_280	2008-04-08	12
+2	val_2	2008-04-08	12
+35	val_35	2008-04-08	12
+283	val_283	2008-04-08	12
+331	val_331	2008-04-08	12
+235	val_235	2008-04-08	12
+80	val_80	2008-04-08	12
+44	val_44	2008-04-08	12
+193	val_193	2008-04-08	12
+321	val_321	2008-04-08	12
+335	val_335	2008-04-08	12
+104	val_104	2008-04-08	12
+466	val_466	2008-04-08	12
+366	val_366	2008-04-08	12
+175	val_175	2008-04-08	12
+403	val_403	2008-04-08	12
+483	val_483	2008-04-08	12
+53	val_53	2008-04-08	12
+105	val_105	2008-04-08	12
+257	val_257	2008-04-08	12
+406	val_406	2008-04-08	12
+409	val_409	2008-04-08	12
+190	val_190	2008-04-08	12
+406	val_406	2008-04-08	12
+401	val_401	2008-04-08	12
+114	val_114	2008-04-08	12
+258	val_258	2008-04-08	12
+90	val_90	2008-04-08	12
+203	val_203	2008-04-08	12
+262	val_262	2008-04-08	12
+348	val_348	2008-04-08	12
+424	val_424	2008-04-08	12
+12	val_12	2008-04-08	12
+396	val_396	2008-04-08	12
+201	val_201	2008-04-08	12
+217	val_217	2008-04-08	12
+164	val_164	2008-04-08	12
+431	val_431	2008-04-08	12
+454	val_454	2008-04-08	12
+478	val_478	2008-04-08	12
+298	val_298	2008-04-08	12
+125	val_125	2008-04-08	12
+431	val_431	2008-04-08	12
+164	val_164	2008-04-08	12
+424	val_424	2008-04-08	12
+187	val_187	2008-04-08	12
+382	val_382	2008-04-08	12
+5	val_5	2008-04-08	12
+70	val_70	2008-04-08	12
+397	val_397	2008-04-08	12
+480	val_480	2008-04-08	12
+291	val_291	2008-04-08	12
+24	val_24	2008-04-08	12
+351	val_351	2008-04-08	12
+255	val_255	2008-04-08	12
+104	val_104	2008-04-08	12
+70	val_70	2008-04-08	12
+163	val_163	2008-04-08	12
+438	val_438	2008-04-08	12
+119	val_119	2008-04-08	12
+414	val_414	2008-04-08	12
+200	val_200	2008-04-08	12
+491	val_491	2008-04-08	12
+237	val_237	2008-04-08	12
+439	val_439	2008-04-08	12
+360	val_360	2008-04-08	12
+248	val_248	2008-04-08	12
+479	val_479	2008-04-08	12
+305	val_305	2008-04-08	12
+417	val_417	2008-04-08	12
+199	val_199	2008-04-08	12
+444	val_444	2008-04-08	12
+120	val_120	2008-04-08	12
+429	val_429	2008-04-08	12
+169	val_169	2008-04-08	12
+443	val_443	2008-04-08	12
+323	val_323	2008-04-08	12
+325	val_325	2008-04-08	12
+277	val_277	2008-04-08	12
+230	val_230	2008-04-08	12
+478	val_478	2008-04-08	12
+178	val_178	2008-04-08	12
+468	val_468	2008-04-08	12
+310	val_310	2008-04-08	12
+317	val_317	2008-04-08	12
+333	val_333	2008-04-08	12
+493	val_493	2008-04-08	12
+460	val_460	2008-04-08	12
+207	val_207	2008-04-08	12
+249	val_249	2008-04-08	12
+265	val_265	2008-04-08	12
+480	val_480	2008-04-08	12
+83	val_83	2008-04-08	12
+136	val_136	2008-04-08	12
+353	val_353	2008-04-08	12
+172	val_172	2008-04-08	12
+214	val_214	2008-04-08	12
+462	val_462	2008-04-08	12
+233	val_233	2008-04-08	12
+406	val_406	2008-04-08	12
+133	val_133	2008-04-08	12
+175	val_175	2008-04-08	12
+189	val_189	2008-04-08	12
+454	val_454	2008-04-08	12
+375	val_375	2008-04-08	12
+401	val_401	2008-04-08	12
+421	val_421	2008-04-08	12
+407	val_407	2008-04-08	12
+384	val_384	2008-04-08	12
+256	val_256	2008-04-08	12
+26	val_26	2008-04-08	12
+134	val_134	2008-04-08	12
+67	val_67	2008-04-08	12
+384	val_384	2008-04-08	12
+379	val_379	2008-04-08	12
+18	val_18	2008-04-08	12
+462	val_462	2008-04-08	12
+492	val_492	2008-04-08	12
+100	val_100	2008-04-08	12
+298	val_298	2008-04-08	12
+9	val_9	2008-04-08	12
+341	val_341	2008-04-08	12
+498	val_498	2008-04-08	12
+146	val_146	2008-04-08	12
+458	val_458	2008-04-08	12
+362	val_362	2008-04-08	12
+186	val_186	2008-04-08	12
+285	val_285	2008-04-08	12
+348	val_348	2008-04-08	12
+167	val_167	2008-04-08	12
+18	val_18	2008-04-08	12
+273	val_273	2008-04-08	12
+183	val_183	2008-04-08	12
+281	val_281	2008-04-08	12
+344	val_344	2008-04-08	12
+97	val_97	2008-04-08	12
+469	val_469	2008-04-08	12
+315	val_315	2008-04-08	12
+84	val_84	2008-04-08	12
+28	val_28	2008-04-08	12
+37	val_37	2008-04-08	12
+448	val_448	2008-04-08	12
+152	val_152	2008-04-08	12
+348	val_348	2008-04-08	12
+307	val_307	2008-04-08	12
+194	val_194	2008-04-08	12
+414	val_414	2008-04-08	12
+477	val_477	2008-04-08	12
+222	val_222	2008-04-08	12
+126	val_126	2008-04-08	12
+90	val_90	2008-04-08	12
+169	val_169	2008-04-08	12
+403	val_403	2008-04-08	12
+400	val_400	2008-04-08	12
+200	val_200	2008-04-08	12
+97	val_97	2008-04-08	12
+PREHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
+PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-15-33_974_7699296351752491646/-mr-10000
+POSTHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
+POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_09-15-33_974_7699296351752491646/-mr-10000
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+238	val_238	2008-12-31	11
+86	val_86	2008-12-31	11
+311	val_311	2008-12-31	11
+27	val_27	2008-12-31	11
+165	val_165	2008-12-31	11
+409	val_409	2008-12-31	11
+255	val_255	2008-12-31	11
+278	val_278	2008-12-31	11
+98	val_98	2008-12-31	11
+484	val_484	2008-12-31	11
+265	val_265	2008-12-31	11
+193	val_193	2008-12-31	11
+401	val_401	2008-12-31	11
+150	val_150	2008-12-31	11
+273	val_273	2008-12-31	11
+224	val_224	2008-12-31	11
+369	val_369	2008-12-31	11
+66	val_66	2008-12-31	11
+128	val_128	2008-12-31	11
+213	val_213	2008-12-31	11
+146	val_146	2008-12-31	11
+406	val_406	2008-12-31	11
+429	val_429	2008-12-31	11
+374	val_374	2008-12-31	11
+152	val_152	2008-12-31	11
+469	val_469	2008-12-31	11
+145	val_145	2008-12-31	11
+495	val_495	2008-12-31	11
+37	val_37	2008-12-31	11
+327	val_327	2008-12-31	11
+281	val_281	2008-12-31	11
+277	val_277	2008-12-31	11
+209	val_209	2008-12-31	11
+15	val_15	2008-12-31	11
+82	val_82	2008-12-31	11
+403	val_403	2008-12-31	11
+166	val_166	2008-12-31	11
+417	val_417	2008-12-31	11
+430	val_430	2008-12-31	11
+252	val_252	2008-12-31	11
+292	val_292	2008-12-31	11
+219	val_219	2008-12-31	11
+287	val_287	2008-12-31	11
+153	val_153	2008-12-31	11
+193	val_193	2008-12-31	11
+338	val_338	2008-12-31	11
+446	val_446	2008-12-31	11
+459	val_459	2008-12-31	11
+394	val_394	2008-12-31	11
+237	val_237	2008-12-31	11
+482	val_482	2008-12-31	11
+174	val_174	2008-12-31	11
+413	val_413	2008-12-31	11
+494	val_494	2008-12-31	11
+207	val_207	2008-12-31	11
+199	val_199	2008-12-31	11
+466	val_466	2008-12-31	11
+208	val_208	2008-12-31	11
+174	val_174	2008-12-31	11
+399	val_399	2008-12-31	11
+396	val_396	2008-12-31	11
+247	val_247	2008-12-31	11
+417	val_417	2008-12-31	11
+489	val_489	2008-12-31	11
+162	val_162	2008-12-31	11
+377	val_377	2008-12-31	11
+397	val_397	2008-12-31	11
+309	val_309	2008-12-31	11
+365	val_365	2008-12-31	11
+266	val_266	2008-12-31	11
+439	val_439	2008-12-31	11
+342	val_342	2008-12-31	11
+367	val_367	2008-12-31	11
+325	val_325	2008-12-31	11
+167	val_167	2008-12-31	11
+195	val_195	2008-12-31	11
+475	val_475	2008-12-31	11
+17	val_17	2008-12-31	11
+113	val_113	2008-12-31	11
+155	val_155	2008-12-31	11
+203	val_203	2008-12-31	11
+339	val_339	2008-12-31	11
+0	val_0	2008-12-31	11
+455	val_455	2008-12-31	11
+128	val_128	2008-12-31	11
+311	val_311	2008-12-31	11
+316	val_316	2008-12-31	11
+57	val_57	2008-12-31	11
+302	val_302	2008-12-31	11
+205	val_205	2008-12-31	11
+149	val_149	2008-12-31	11
+438	val_438	2008-12-31	11
+345	val_345	2008-12-31	11
+129	val_129	2008-12-31	11
+170	val_170	2008-12-31	11
+20	val_20	2008-12-31	11
+489	val_489	2008-12-31	11
+157	val_157	2008-12-31	11
+378	val_378	2008-12-31	11
+221	val_221	2008-12-31	11
+92	val_92	2008-12-31	11
+111	val_111	2008-12-31	11
+47	val_47	2008-12-31	11
+72	val_72	2008-12-31	11
+4	val_4	2008-12-31	11
+280	val_280	2008-12-31	11
+35	val_35	2008-12-31	11
+427	val_427	2008-12-31	11
+277	val_277	2008-12-31	11
+208	val_208	2008-12-31	11
+356	val_356	2008-12-31	11
+399	val_399	2008-12-31	11
+169	val_169	2008-12-31	11
+382	val_382	2008-12-31	11
+498	val_498	2008-12-31	11
+125	val_125	2008-12-31	11
+386	val_386	2008-12-31	11
+437	val_437	2008-12-31	11
+469	val_469	2008-12-31	11
+192	val_192	2008-12-31	11
+286	val_286	2008-12-31	11
+187	val_187	2008-12-31	11
+176	val_176	2008-12-31	11
+54	val_54	2008-12-31	11
+459	val_459	2008-12-31	11
+51	val_51	2008-12-31	11
+138	val_138	2008-12-31	11
+103	val_103	2008-12-31	11
+239	val_239	2008-12-31	11
+213	val_213	2008-12-31	11
+216	val_216	2008-12-31	11
+430	val_430	2008-12-31	11
+278	val_278	2008-12-31	11
+176	val_176	2008-12-31	11
+289	val_289	2008-12-31	11
+221	val_221	2008-12-31	11
+65	val_65	2008-12-31	11
+318	val_318	2008-12-31	11
+332	val_332	2008-12-31	11
+311	val_311	2008-12-31	11
+275	val_275	2008-12-31	11
+137	val_137	2008-12-31	11
+241	val_241	2008-12-31	11
+83	val_83	2008-12-31	11
+333	val_333	2008-12-31	11
+180	val_180	2008-12-31	11
+284	val_284	2008-12-31	11
+12	val_12	2008-12-31	11
+230	val_230	2008-12-31	11
+181	val_181	2008-12-31	11
+67	val_67	2008-12-31	11
+260	val_260	2008-12-31	11
+404	val_404	2008-12-31	11
+384	val_384	2008-12-31	11
+489	val_489	2008-12-31	11
+353	val_353	2008-12-31	11
+373	val_373	2008-12-31	11
+272	val_272	2008-12-31	11
+138	val_138	2008-12-31	11
+217	val_217	2008-12-31	11
+84	val_84	2008-12-31	11
+348	val_348	2008-12-31	11
+466	val_466	2008-12-31	11
+58	val_58	2008-12-31	11
+8	val_8	2008-12-31	11
+411	val_411	2008-12-31	11
+230	val_230	2008-12-31	11
+208	val_208	2008-12-31	11
+348	val_348	2008-12-31	11
+24	val_24	2008-12-31	11
+463	val_463	2008-12-31	11
+431	val_431	2008-12-31	11
+179	val_179	2008-12-31	11
+172	val_172	2008-12-31	11
+42	val_42	2008-12-31	11
+129	val_129	2008-12-31	11
+158	val_158	2008-12-31	11
+119	val_119	2008-12-31	11
+496	val_496	2008-12-31	11
+0	val_0	2008-12-31	11
+322	val_322	2008-12-31	11
+197	val_197	2008-12-31	11
+468	val_468	2008-12-31	11
+393	val_393	2008-12-31	11
+454	val_454	2008-12-31	11
+100	val_100	2008-12-31	11
+298	val_298	2008-12-31	11
+199	val_199	2008-12-31	11
+191	val_191	2008-12-31	11
+418	val_418	2008-12-31	11
+96	val_96	2008-12-31	11
+26	val_26	2008-12-31	11
+165	val_165	2008-12-31	11
+327	val_327	2008-12-31	11
+230	val_230	2008-12-31	11
+205	val_205	2008-12-31	11
+120	val_120	2008-12-31	11
+131	val_131	2008-12-31	11
+51	val_51	2008-12-31	11
+404	val_404	2008-12-31	11
+43	val_43	2008-12-31	11
+436	val_436	2008-12-31	11
+156	val_156	2008-12-31	11
+469	val_469	2008-12-31	11
+468	val_468	2008-12-31	11
+308	val_308	2008-12-31	11
+95	val_95	2008-12-31	11
+196	val_196	2008-12-31	11
+288	val_288	2008-12-31	11
+481	val_481	2008-12-31	11
+457	val_457	2008-12-31	11
+98	val_98	2008-12-31	11
+282	val_282	2008-12-31	11
+197	val_197	2008-12-31	11
+187	val_187	2008-12-31	11
+318	val_318	2008-12-31	11
+318	val_318	2008-12-31	11
+409	val_409	2008-12-31	11
+470	val_470	2008-12-31	11
+137	val_137	2008-12-31	11
+369	val_369	2008-12-31	11
+316	val_316	2008-12-31	11
+169	val_169	2008-12-31	11
+413	val_413	2008-12-31	11
+85	val_85	2008-12-31	11
+77	val_77	2008-12-31	11
+0	val_0	2008-12-31	11
+490	val_490	2008-12-31	11
+87	val_87	2008-12-31	11
+364	val_364	2008-12-31	11
+179	val_179	2008-12-31	11
+118	val_118	2008-12-31	11
+134	val_134	2008-12-31	11
+395	val_395	2008-12-31	11
+282	val_282	2008-12-31	11
+138	val_138	2008-12-31	11
+238	val_238	2008-12-31	11
+419	val_419	2008-12-31	11
+15	val_15	2008-12-31	11
+118	val_118	2008-12-31	11
+72	val_72	2008-12-31	11
+90	val_90	2008-12-31	11
+307	val_307	2008-12-31	11
+19	val_19	2008-12-31	11
+435	val_435	2008-12-31	11
+10	val_10	2008-12-31	11
+277	val_277	2008-12-31	11
+273	val_273	2008-12-31	11
+306	val_306	2008-12-31	11
+224	val_224	2008-12-31	11
+309	val_309	2008-12-31	11
+389	val_389	2008-12-31	11
+327	val_327	2008-12-31	11
+242	val_242	2008-12-31	11
+369	val_369	2008-12-31	11
+392	val_392	2008-12-31	11
+272	val_272	2008-12-31	11
+331	val_331	2008-12-31	11
+401	val_401	2008-12-31	11
+242	val_242	2008-12-31	11
+452	val_452	2008-12-31	11
+177	val_177	2008-12-31	11
+226	val_226	2008-12-31	11
+5	val_5	2008-12-31	11
+497	val_497	2008-12-31	11
+402	val_402	2008-12-31	11
+396	val_396	2008-12-31	11
+317	val_317	2008-12-31	11
+395	val_395	2008-12-31	11
+58	val_58	2008-12-31	11
+35	val_35	2008-12-31	11
+336	val_336	2008-12-31	11
+95	val_95	2008-12-31	11
+11	val_11	2008-12-31	11
+168	val_168	2008-12-31	11
+34	val_34	2008-12-31	11
+229	val_229	2008-12-31	11
+233	val_233	2008-12-31	11
+143	val_143	2008-12-31	11
+472	val_472	2008-12-31	11
+322	val_322	2008-12-31	11
+498	val_498	2008-12-31	11
+160	val_160	2008-12-31	11
+195	val_195	2008-12-31	11
+42	val_42	2008-12-31	11
+321	val_321	2008-12-31	11
+430	val_430	2008-12-31	11
+119	val_119	2008-12-31	11
+489	val_489	2008-12-31	11
+458	val_458	2008-12-31	11
+78	val_78	2008-12-31	11
+76	val_76	2008-12-31	11
+41	val_41	2008-12-31	11
+223	val_223	2008-12-31	11
+492	val_492	2008-12-31	11
+149	val_149	2008-12-31	11
+449	val_449	2008-12-31	11
+218	val_218	2008-12-31	11
+228	val_228	2008-12-31	11
+138	val_138	2008-12-31	11
+453	val_453	2008-12-31	11
+30	val_30	2008-12-31	11
+209	val_209	2008-12-31	11
+64	val_64	2008-12-31	11
+468	val_468	2008-12-31	11
+76	val_76	2008-12-31	11
+74	val_74	2008-12-31	11
+342	val_342	2008-12-31	11
+69	val_69	2008-12-31	11
+230	val_230	2008-12-31	11
+33	val_33	2008-12-31	11
+368	val_368	2008-12-31	11
+103	val_103	2008-12-31	11
+296	val_296	2008-12-31	11
+113	val_113	2008-12-31	11
+216	val_216	2008-12-31	11
+367	val_367	2008-12-31	11
+344	val_344	2008-12-31	11
+167	val_167	2008-12-31	11
+274	val_274	2008-12-31	11
+219	val_219	2008-12-31	11
+239	val_239	2008-12-31	11
+485	val_485	2008-12-31	11
+116	val_116	2008-12-31	11
+223	val_223	2008-12-31	11
+256	val_256	2008-12-31	11
+263	val_263	2008-12-31	11
+70	val_70	2008-12-31	11
+487	val_487	2008-12-31	11
+480	val_480	2008-12-31	11
+401	val_401	2008-12-31	11
+288	val_288	2008-12-31	11
+191	val_191	2008-12-31	11
+5	val_5	2008-12-31	11
+244	val_244	2008-12-31	11
+438	val_438	2008-12-31	11
+128	val_128	2008-12-31	11
+467	val_467	2008-12-31	11
+432	val_432	2008-12-31	11
+202	val_202	2008-12-31	11
+316	val_316	2008-12-31	11
+229	val_229	2008-12-31	11
+469	val_469	2008-12-31	11
+463	val_463	2008-12-31	11
+280	val_280	2008-12-31	11
+2	val_2	2008-12-31	11
+35	val_35	2008-12-31	11
+283	val_283	2008-12-31	11
+331	val_331	2008-12-31	11
+235	val_235	2008-12-31	11
+80	val_80	2008-12-31	11
+44	val_44	2008-12-31	11
+193	val_193	2008-12-31	11
+321	val_321	2008-12-31	11
+335	val_335	2008-12-31	11
+104	val_104	2008-12-31	11
+466	val_466	2008-12-31	11
+366	val_366	2008-12-31	11
+175	val_175	2008-12-31	11
+403	val_403	2008-12-31	11
+483	val_483	2008-12-31	11
+53	val_53	2008-12-31	11
+105	val_105	2008-12-31	11
+257	val_257	2008-12-31	11
+406	val_406	2008-12-31	11
+409	val_409	2008-12-31	11
+190	val_190	2008-12-31	11
+406	val_406	2008-12-31	11
+401	val_401	2008-12-31	11
+114	val_114	2008-12-31	11
+258	val_258	2008-12-31	11
+90	val_90	2008-12-31	11
+203	val_203	2008-12-31	11
+262	val_262	2008-12-31	11
+348	val_348	2008-12-31	11
+424	val_424	2008-12-31	11
+12	val_12	2008-12-31	11
+396	val_396	2008-12-31	11
+201	val_201	2008-12-31	11
+217	val_217	2008-12-31	11
+164	val_164	2008-12-31	11
+431	val_431	2008-12-31	11
+454	val_454	2008-12-31	11
+478	val_478	2008-12-31	11
+298	val_298	2008-12-31	11
+125	val_125	2008-12-31	11
+431	val_431	2008-12-31	11
+164	val_164	2008-12-31	11
+424	val_424	2008-12-31	11
+187	val_187	2008-12-31	11
+382	val_382	2008-12-31	11
+5	val_5	2008-12-31	11
+70	val_70	2008-12-31	11
+397	val_397	2008-12-31	11
+480	val_480	2008-12-31	11
+291	val_291	2008-12-31	11
+24	val_24	2008-12-31	11
+351	val_351	2008-12-31	11
+255	val_255	2008-12-31	11
+104	val_104	2008-12-31	11
+70	val_70	2008-12-31	11
+163	val_163	2008-12-31	11
+438	val_438	2008-12-31	11
+119	val_119	2008-12-31	11
+414	val_414	2008-12-31	11
+200	val_200	2008-12-31	11
+491	val_491	2008-12-31	11
+237	val_237	2008-12-31	11
+439	val_439	2008-12-31	11
+360	val_360	2008-12-31	11
+248	val_248	2008-12-31	11
+479	val_479	2008-12-31	11
+305	val_305	2008-12-31	11
+417	val_417	2008-12-31	11
+199	val_199	2008-12-31	11
+444	val_444	2008-12-31	11
+120	val_120	2008-12-31	11
+429	val_429	2008-12-31	11
+169	val_169	2008-12-31	11
+443	val_443	2008-12-31	11
+323	val_323	2008-12-31	11
+325	val_325	2008-12-31	11
+277	val_277	2008-12-31	11
+230	val_230	2008-12-31	11
+478	val_478	2008-12-31	11
+178	val_178	2008-12-31	11
+468	val_468	2008-12-31	11
+310	val_310	2008-12-31	11
+317	val_317	2008-12-31	11
+333	val_333	2008-12-31	11
+493	val_493	2008-12-31	11
+460	val_460	2008-12-31	11
+207	val_207	2008-12-31	11
+249	val_249	2008-12-31	11
+265	val_265	2008-12-31	11
+480	val_480	2008-12-31	11
+83	val_83	2008-12-31	11
+136	val_136	2008-12-31	11
+353	val_353	2008-12-31	11
+172	val_172	2008-12-31	11
+214	val_214	2008-12-31	11
+462	val_462	2008-12-31	11
+233	val_233	2008-12-31	11
+406	val_406	2008-12-31	11
+133	val_133	2008-12-31	11
+175	val_175	2008-12-31	11
+189	val_189	2008-12-31	11
+454	val_454	2008-12-31	11
+375	val_375	2008-12-31	11
+401	val_401	2008-12-31	11
+421	val_421	2008-12-31	11
+407	val_407	2008-12-31	11
+384	val_384	2008-12-31	11
+256	val_256	2008-12-31	11
+26	val_26	2008-12-31	11
+134	val_134	2008-12-31	11
+67	val_67	2008-12-31	11
+384	val_384	2008-12-31	11
+379	val_379	2008-12-31	11
+18	val_18	2008-12-31	11
+462	val_462	2008-12-31	11
+492	val_492	2008-12-31	11
+100	val_100	2008-12-31	11
+298	val_298	2008-12-31	11
+9	val_9	2008-12-31	11
+341	val_341	2008-12-31	11
+498	val_498	2008-12-31	11
+146	val_146	2008-12-31	11
+458	val_458	2008-12-31	11
+362	val_362	2008-12-31	11
+186	val_186	2008-12-31	11
+285	val_285	2008-12-31	11
+348	val_348	2008-12-31	11
+167	val_167	2008-12-31	11
+18	val_18	2008-12-31	11
+273	val_273	2008-12-31	11
+183	val_183	2008-12-31	11
+281	val_281	2008-12-31	11
+344	val_344	2008-12-31	11
+97	val_97	2008-12-31	11
+469	val_469	2008-12-31	11
+315	val_315	2008-12-31	11
+84	val_84	2008-12-31	11
+28	val_28	2008-12-31	11
+37	val_37	2008-12-31	11
+448	val_448	2008-12-31	11
+152	val_152	2008-12-31	11
+348	val_348	2008-12-31	11
+307	val_307	2008-12-31	11
+194	val_194	2008-12-31	11
+414	val_414	2008-12-31	11
+477	val_477	2008-12-31	11
+222	val_222	2008-12-31	11
+126	val_126	2008-12-31	11
+90	val_90	2008-12-31	11
+169	val_169	2008-12-31	11
+403	val_403	2008-12-31	11
+400	val_400	2008-12-31	11
+200	val_200	2008-12-31	11
+97	val_97	2008-12-31	11
+238	val_238	2008-12-31	12
+86	val_86	2008-12-31	12
+311	val_311	2008-12-31	12
+27	val_27	2008-12-31	12
+165	val_165	2008-12-31	12
+409	val_409	2008-12-31	12
+255	val_255	2008-12-31	12
+278	val_278	2008-12-31	12
+98	val_98	2008-12-31	12
+484	val_484	2008-12-31	12
+265	val_265	2008-12-31	12
+193	val_193	2008-12-31	12
+401	val_401	2008-12-31	12
+150	val_150	2008-12-31	12
+273	val_273	2008-12-31	12
+224	val_224	2008-12-31	12
+369	val_369	2008-12-31	12
+66	val_66	2008-12-31	12
+128	val_128	2008-12-31	12
+213	val_213	2008-12-31	12
+146	val_146	2008-12-31	12
+406	val_406	2008-12-31	12
+429	val_429	2008-12-31	12
+374	val_374	2008-12-31	12
+152	val_152	2008-12-31	12
+469	val_469	2008-12-31	12
+145	val_145	2008-12-31	12
+495	val_495	2008-12-31	12
+37	val_37	2008-12-31	12
+327	val_327	2008-12-31	12
+281	val_281	2008-12-31	12
+277	val_277	2008-12-31	12
+209	val_209	2008-12-31	12
+15	val_15	2008-12-31	12
+82	val_82	2008-12-31	12
+403	val_403	2008-12-31	12
+166	val_166	2008-12-31	12
+417	val_417	2008-12-31	12
+430	val_430	2008-12-31	12
+252	val_252	2008-12-31	12
+292	val_292	2008-12-31	12
+219	val_219	2008-12-31	12
+287	val_287	2008-12-31	12
+153	val_153	2008-12-31	12
+193	val_193	2008-12-31	12
+338	val_338	2008-12-31	12
+446	val_446	2008-12-31	12
+459	val_459	2008-12-31	12
+394	val_394	2008-12-31	12
+237	val_237	2008-12-31	12
+482	val_482	2008-12-31	12
+174	val_174	2008-12-31	12
+413	val_413	2008-12-31	12
+494	val_494	2008-12-31	12
+207	val_207	2008-12-31	12
+199	val_199	2008-12-31	12
+466	val_466	2008-12-31	12
+208	val_208	2008-12-31	12
+174	val_174	2008-12-31	12
+399	val_399	2008-12-31	12
+396	val_396	2008-12-31	12
+247	val_247	2008-12-31	12
+417	val_417	2008-12-31	12
+489	val_489	2008-12-31	12
+162	val_162	2008-12-31	12
+377	val_377	2008-12-31	12
+397	val_397	2008-12-31	12
+309	val_309	2008-12-31	12
+365	val_365	2008-12-31	12
+266	val_266	2008-12-31	12
+439	val_439	2008-12-31	12
+342	val_342	2008-12-31	12
+367	val_367	2008-12-31	12
+325	val_325	2008-12-31	12
+167	val_167	2008-12-31	12
+195	val_195	2008-12-31	12
+475	val_475	2008-12-31	12
+17	val_17	2008-12-31	12
+113	val_113	2008-12-31	12
+155	val_155	2008-12-31	12
+203	val_203	2008-12-31	12
+339	val_339	2008-12-31	12
+0	val_0	2008-12-31	12
+455	val_455	2008-12-31	12
+128	val_128	2008-12-31	12
+311	val_311	2008-12-31	12
+316	val_316	2008-12-31	12
+57	val_57	2008-12-31	12
+302	val_302	2008-12-31	12
+205	val_205	2008-12-31	12
+149	val_149	2008-12-31	12
+438	val_438	2008-12-31	12
+345	val_345	2008-12-31	12
+129	val_129	2008-12-31	12
+170	val_170	2008-12-31	12
+20	val_20	2008-12-31	12
+489	val_489	2008-12-31	12
+157	val_157	2008-12-31	12
+378	val_378	2008-12-31	12
+221	val_221	2008-12-31	12
+92	val_92	2008-12-31	12
+111	val_111	2008-12-31	12
+47	val_47	2008-12-31	12
+72	val_72	2008-12-31	12
+4	val_4	2008-12-31	12
+280	val_280	2008-12-31	12
+35	val_35	2008-12-31	12
+427	val_427	2008-12-31	12
+277	val_277	2008-12-31	12
+208	val_208	2008-12-31	12
+356	val_356	2008-12-31	12
+399	val_399	2008-12-31	12
+169	val_169	2008-12-31	12
+382	val_382	2008-12-31	12
+498	val_498	2008-12-31	12
+125	val_125	2008-12-31	12
+386	val_386	2008-12-31	12
+437	val_437	2008-12-31	12
+469	val_469	2008-12-31	12
+192	val_192	2008-12-31	12
+286	val_286	2008-12-31	12
+187	val_187	2008-12-31	12
+176	val_176	2008-12-31	12
+54	val_54	2008-12-31	12
+459	val_459	2008-12-31	12
+51	val_51	2008-12-31	12
+138	val_138	2008-12-31	12
+103	val_103	2008-12-31	12
+239	val_239	2008-12-31	12
+213	val_213	2008-12-31	12
+216	val_216	2008-12-31	12
+430	val_430	2008-12-31	12
+278	val_278	2008-12-31	12
+176	val_176	2008-12-31	12
+289	val_289	2008-12-31	12
+221	val_221	2008-12-31	12
+65	val_65	2008-12-31	12
+318	val_318	2008-12-31	12
+332	val_332	2008-12-31	12
+311	val_311	2008-12-31	12
+275	val_275	2008-12-31	12
+137	val_137	2008-12-31	12
+241	val_241	2008-12-31	12
+83	val_83	2008-12-31	12
+333	val_333	2008-12-31	12
+180	val_180	2008-12-31	12
+284	val_284	2008-12-31	12
+12	val_12	2008-12-31	12
+230	val_230	2008-12-31	12
+181	val_181	2008-12-31	12
+67	val_67	2008-12-31	12
+260	val_260	2008-12-31	12
+404	val_404	2008-12-31	12
+384	val_384	2008-12-31	12
+489	val_489	2008-12-31	12
+353	val_353	2008-12-31	12
+373	val_373	2008-12-31	12
+272	val_272	2008-12-31	12
+138	val_138	2008-12-31	12
+217	val_217	2008-12-31	12
+84	val_84	2008-12-31	12
+348	val_348	2008-12-31	12
+466	val_466	2008-12-31	12
+58	val_58	2008-12-31	12
+8	val_8	2008-12-31	12
+411	val_411	2008-12-31	12
+230	val_230	2008-12-31	12
+208	val_208	2008-12-31	12
+348	val_348	2008-12-31	12
+24	val_24	2008-12-31	12
+463	val_463	2008-12-31	12
+431	val_431	2008-12-31	12
+179	val_179	2008-12-31	12
+172	val_172	2008-12-31	12
+42	val_42	2008-12-31	12
+129	val_129	2008-12-31	12
+158	val_158	2008-12-31	12
+119	val_119	2008-12-31	12
+496	val_496	2008-12-31	12
+0	val_0	2008-12-31	12
+322	val_322	2008-12-31	12
+197	val_197	2008-12-31	12
+468	val_468	2008-12-31	12
+393	val_393	2008-12-31	12
+454	val_454	2008-12-31	12
+100	val_100	2008-12-31	12
+298	val_298	2008-12-31	12
+199	val_199	2008-12-31	12
+191	val_191	2008-12-31	12
+418	val_418	2008-12-31	12
+96	val_96	2008-12-31	12
+26	val_26	2008-12-31	12
+165	val_165	2008-12-31	12
+327	val_327	2008-12-31	12
+230	val_230	2008-12-31	12
+205	val_205	2008-12-31	12
+120	val_120	2008-12-31	12
+131	val_131	2008-12-31	12
+51	val_51	2008-12-31	12
+404	val_404	2008-12-31	12
+43	val_43	2008-12-31	12
+436	val_436	2008-12-31	12
+156	val_156	2008-12-31	12
+469	val_469	2008-12-31	12
+468	val_468	2008-12-31	12
+308	val_308	2008-12-31	12
+95	val_95	2008-12-31	12
+196	val_196	2008-12-31	12
+288	val_288	2008-12-31	12
+481	val_481	2008-12-31	12
+457	val_457	2008-12-31	12
+98	val_98	2008-12-31	12
+282	val_282	2008-12-31	12
+197	val_197	2008-12-31	12
+187	val_187	2008-12-31	12
+318	val_318	2008-12-31	12
+318	val_318	2008-12-31	12
+409	val_409	2008-12-31	12
+470	val_470	2008-12-31	12
+137	val_137	2008-12-31	12
+369	val_369	2008-12-31	12
+316	val_316	2008-12-31	12
+169	val_169	2008-12-31	12
+413	val_413	2008-12-31	12
+85	val_85	2008-12-31	12
+77	val_77	2008-12-31	12
+0	val_0	2008-12-31	12
+490	val_490	2008-12-31	12
+87	val_87	2008-12-31	12
+364	val_364	2008-12-31	12
+179	val_179	2008-12-31	12
+118	val_118	2008-12-31	12
+134	val_134	2008-12-31	12
+395	val_395	2008-12-31	12
+282	val_282	2008-12-31	12
+138	val_138	2008-12-31	12
+238	val_238	2008-12-31	12
+419	val_419	2008-12-31	12
+15	val_15	2008-12-31	12
+118	val_118	2008-12-31	12
+72	val_72	2008-12-31	12
+90	val_90	2008-12-31	12
+307	val_307	2008-12-31	12
+19	val_19	2008-12-31	12
+435	val_435	2008-12-31	12
+10	val_10	2008-12-31	12
+277	val_277	2008-12-31	12
+273	val_273	2008-12-31	12
+306	val_306	2008-12-31	12
+224	val_224	2008-12-31	12
+309	val_309	2008-12-31	12
+389	val_389	2008-12-31	12
+327	val_327	2008-12-31	12
+242	val_242	2008-12-31	12
+369	val_369	2008-12-31	12
+392	val_392	2008-12-31	12
+272	val_272	2008-12-31	12
+331	val_331	2008-12-31	12
+401	val_401	2008-12-31	12
+242	val_242	2008-12-31	12
+452	val_452	2008-12-31	12
+177	val_177	2008-12-31	12
+226	val_226	2008-12-31	12
+5	val_5	2008-12-31	12
+497	val_497	2008-12-31	12
+402	val_402	2008-12-31	12
+396	val_396	2008-12-31	12
+317	val_317	2008-12-31	12
+395	val_395	2008-12-31	12
+58	val_58	2008-12-31	12
+35	val_35	2008-12-31	12
+336	val_336	2008-12-31	12
+95	val_95	2008-12-31	12
+11	val_11	2008-12-31	12
+168	val_168	2008-12-31	12
+34	val_34	2008-12-31	12
+229	val_229	2008-12-31	12
+233	val_233	2008-12-31	12
+143	val_143	2008-12-31	12
+472	val_472	2008-12-31	12
+322	val_322	2008-12-31	12
+498	val_498	2008-12-31	12
+160	val_160	2008-12-31	12
+195	val_195	2008-12-31	12
+42	val_42	2008-12-31	12
+321	val_321	2008-12-31	12
+430	val_430	2008-12-31	12
+119	val_119	2008-12-31	12
+489	val_489	2008-12-31	12
+458	val_458	2008-12-31	12
+78	val_78	2008-12-31	12
+76	val_76	2008-12-31	12
+41	val_41	2008-12-31	12
+223	val_223	2008-12-31	12
+492	val_492	2008-12-31	12
+149	val_149	2008-12-31	12
+449	val_449	2008-12-31	12
+218	val_218	2008-12-31	12
+228	val_228	2008-12-31	12
+138	val_138	2008-12-31	12
+453	val_453	2008-12-31	12
+30	val_30	2008-12-31	12
+209	val_209	2008-12-31	12
+64	val_64	2008-12-31	12
+468	val_468	2008-12-31	12
+76	val_76	2008-12-31	12
+74	val_74	2008-12-31	12
+342	val_342	2008-12-31	12
+69	val_69	2008-12-31	12
+230	val_230	2008-12-31	12
+33	val_33	2008-12-31	12
+368	val_368	2008-12-31	12
+103	val_103	2008-12-31	12
+296	val_296	2008-12-31	12
+113	val_113	2008-12-31	12
+216	val_216	2008-12-31	12
+367	val_367	2008-12-31	12
+344	val_344	2008-12-31	12
+167	val_167	2008-12-31	12
+274	val_274	2008-12-31	12
+219	val_219	2008-12-31	12
+239	val_239	2008-12-31	12
+485	val_485	2008-12-31	12
+116	val_116	2008-12-31	12
+223	val_223	2008-12-31	12
+256	val_256	2008-12-31	12
+263	val_263	2008-12-31	12
+70	val_70	2008-12-31	12
+487	val_487	2008-12-31	12
+480	val_480	2008-12-31	12
+401	val_401	2008-12-31	12
+288	val_288	2008-12-31	12
+191	val_191	2008-12-31	12
+5	val_5	2008-12-31	12
+244	val_244	2008-12-31	12
+438	val_438	2008-12-31	12
+128	val_128	2008-12-31	12
+467	val_467	2008-12-31	12
+432	val_432	2008-12-31	12
+202	val_202	2008-12-31	12
+316	val_316	2008-12-31	12
+229	val_229	2008-12-31	12
+469	val_469	2008-12-31	12
+463	val_463	2008-12-31	12
+280	val_280	2008-12-31	12
+2	val_2	2008-12-31	12
+35	val_35	2008-12-31	12
+283	val_283	2008-12-31	12
+331	val_331	2008-12-31	12
+235	val_235	2008-12-31	12
+80	val_80	2008-12-31	12
+44	val_44	2008-12-31	12
+193	val_193	2008-12-31	12
+321	val_321	2008-12-31	12
+335	val_335	2008-12-31	12
+104	val_104	2008-12-31	12
+466	val_466	2008-12-31	12
+366	val_366	2008-12-31	12
+175	val_175	2008-12-31	12
+403	val_403	2008-12-31	12
+483	val_483	2008-12-31	12
+53	val_53	2008-12-31	12
+105	val_105	2008-12-31	12
+257	val_257	2008-12-31	12
+406	val_406	2008-12-31	12
+409	val_409	2008-12-31	12
+190	val_190	2008-12-31	12
+406	val_406	2008-12-31	12
+401	val_401	2008-12-31	12
+114	val_114	2008-12-31	12
+258	val_258	2008-12-31	12
+90	val_90	2008-12-31	12
+203	val_203	2008-12-31	12
+262	val_262	2008-12-31	12
+348	val_348	2008-12-31	12
+424	val_424	2008-12-31	12
+12	val_12	2008-12-31	12
+396	val_396	2008-12-31	12
+201	val_201	2008-12-31	12
+217	val_217	2008-12-31	12
+164	val_164	2008-12-31	12
+431	val_431	2008-12-31	12
+454	val_454	2008-12-31	12
+478	val_478	2008-12-31	12
+298	val_298	2008-12-31	12
+125	val_125	2008-12-31	12
+431	val_431	2008-12-31	12
+164	val_164	2008-12-31	12
+424	val_424	2008-12-31	12
+187	val_187	2008-12-31	12
+382	val_382	2008-12-31	12
+5	val_5	2008-12-31	12
+70	val_70	2008-12-31	12
+397	val_397	2008-12-31	12
+480	val_480	2008-12-31	12
+291	val_291	2008-12-31	12
+24	val_24	2008-12-31	12
+351	val_351	2008-12-31	12
+255	val_255	2008-12-31	12
+104	val_104	2008-12-31	12
+70	val_70	2008-12-31	12
+163	val_163	2008-12-31	12
+438	val_438	2008-12-31	12
+119	val_119	2008-12-31	12
+414	val_414	2008-12-31	12
+200	val_200	2008-12-31	12
+491	val_491	2008-12-31	12
+237	val_237	2008-12-31	12
+439	val_439	2008-12-31	12
+360	val_360	2008-12-31	12
+248	val_248	2008-12-31	12
+479	val_479	2008-12-31	12
+305	val_305	2008-12-31	12
+417	val_417	2008-12-31	12
+199	val_199	2008-12-31	12
+444	val_444	2008-12-31	12
+120	val_120	2008-12-31	12
+429	val_429	2008-12-31	12
+169	val_169	2008-12-31	12
+443	val_443	2008-12-31	12
+323	val_323	2008-12-31	12
+325	val_325	2008-12-31	12
+277	val_277	2008-12-31	12
+230	val_230	2008-12-31	12
+478	val_478	2008-12-31	12
+178	val_178	2008-12-31	12
+468	val_468	2008-12-31	12
+310	val_310	2008-12-31	12
+317	val_317	2008-12-31	12
+333	val_333	2008-12-31	12
+493	val_493	2008-12-31	12
+460	val_460	2008-12-31	12
+207	val_207	2008-12-31	12
+249	val_249	2008-12-31	12
+265	val_265	2008-12-31	12
+480	val_480	2008-12-31	12
+83	val_83	2008-12-31	12
+136	val_136	2008-12-31	12
+353	val_353	2008-12-31	12
+172	val_172	2008-12-31	12
+214	val_214	2008-12-31	12
+462	val_462	2008-12-31	12
+233	val_233	2008-12-31	12
+406	val_406	2008-12-31	12
+133	val_133	2008-12-31	12
+175	val_175	2008-12-31	12
+189	val_189	2008-12-31	12
+454	val_454	2008-12-31	12
+375	val_375	2008-12-31	12
+401	val_401	2008-12-31	12
+421	val_421	2008-12-31	12
+407	val_407	2008-12-31	12
+384	val_384	2008-12-31	12
+256	val_256	2008-12-31	12
+26	val_26	2008-12-31	12
+134	val_134	2008-12-31	12
+67	val_67	2008-12-31	12
+384	val_384	2008-12-31	12
+379	val_379	2008-12-31	12
+18	val_18	2008-12-31	12
+462	val_462	2008-12-31	12
+492	val_492	2008-12-31	12
+100	val_100	2008-12-31	12
+298	val_298	2008-12-31	12
+9	val_9	2008-12-31	12
+341	val_341	2008-12-31	12
+498	val_498	2008-12-31	12
+146	val_146	2008-12-31	12
+458	val_458	2008-12-31	12
+362	val_362	2008-12-31	12
+186	val_186	2008-12-31	12
+285	val_285	2008-12-31	12
+348	val_348	2008-12-31	12
+167	val_167	2008-12-31	12
+18	val_18	2008-12-31	12
+273	val_273	2008-12-31	12
+183	val_183	2008-12-31	12
+281	val_281	2008-12-31	12
+344	val_344	2008-12-31	12
+97	val_97	2008-12-31	12
+469	val_469	2008-12-31	12
+315	val_315	2008-12-31	12
+84	val_84	2008-12-31	12
+28	val_28	2008-12-31	12
+37	val_37	2008-12-31	12
+448	val_448	2008-12-31	12
+152	val_152	2008-12-31	12
+348	val_348	2008-12-31	12
+307	val_307	2008-12-31	12
+194	val_194	2008-12-31	12
+414	val_414	2008-12-31	12
+477	val_477	2008-12-31	12
+222	val_222	2008-12-31	12
+126	val_126	2008-12-31	12
+90	val_90	2008-12-31	12
+169	val_169	2008-12-31	12
+403	val_403	2008-12-31	12
+400	val_400	2008-12-31	12
+200	val_200	2008-12-31	12
+97	val_97	2008-12-31	12
+PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
+CreateTime:         	Tue Sep 21 09:15:29 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085731          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1 partition(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part1        	 
+CreateTime:         	Tue Sep 21 09:15:29 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085731          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 11]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+CreateTime:         	Tue Sep 21 09:15:30 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2/ds=2008-12-31/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085732          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2 partition(ds='2008-12-31',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-12-31, 12]    	 
+Database:           	default             	 
+Table:              	nzhang_part2        	 
+CreateTime:         	Tue Sep 21 09:15:31 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2/ds=2008-12-31/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285085732          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part1
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 09:15:19 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285085731          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended nzhang_part2
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended nzhang_part2
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 09:15:19 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part2	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285085732          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: drop table nzhang_part1
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@nzhang_part1
+PREHOOK: Output: default@nzhang_part1
+POSTHOOK: query: drop table nzhang_part1
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@nzhang_part1
+POSTHOOK: Output: default@nzhang_part1
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: drop table nzhang_part2
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@nzhang_part2
+PREHOOK: Output: default@nzhang_part2
+POSTHOOK: query: drop table nzhang_part2
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@nzhang_part2
+POSTHOOK: Output: default@nzhang_part2
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: nzhang_part2 PARTITION(ds=2008-12-31,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input9.q.out
===================================================================
--- ql/src/test/results/clientpositive/input9.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input9.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-09_649_5552642956985824539/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-44_899_4523655138526447161/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -79,9 +80,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-09_649_5552642956985824539/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-32-44_899_4523655138526447161/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -107,10 +111,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-13_789_2379682185511223382/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-50_790_4065446315687033253/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-13_789_2379682185511223382/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-50_790_4065446315687033253/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE []
Index: ql/src/test/results/clientpositive/case_sensitivity.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/case_sensitivity.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/case_sensitivity.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -52,14 +53,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-07-00_239_4537311833367597717/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-56_060_816802101666738393/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -72,9 +73,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-07-00_239_4537311833367597717/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-18-56_060_816802101666738393/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -113,11 +117,11 @@
 PREHOOK: query: SELECT DEST1.* FROM Dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-07-04_690_3780627545370836869/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-19-01_959_1041609340989768898/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM Dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-07-04_690_3780627545370836869/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-19-01_959_1041609340989768898/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 2	1
Index: ql/src/test/results/clientpositive/union17.q.out
===================================================================
--- ql/src/test/results/clientpositive/union17.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union17.q.out	(working copy)
@@ -31,12 +31,14 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-3 depends on stages: Stage-2, Stage-6
+  Stage-3 depends on stages: Stage-2, Stage-8
   Stage-4 depends on stages: Stage-3
   Stage-0 depends on stages: Stage-4
-  Stage-5 depends on stages: Stage-3
-  Stage-1 depends on stages: Stage-5
-  Stage-6 is a root stage
+  Stage-5 depends on stages: Stage-0
+  Stage-6 depends on stages: Stage-3
+  Stage-1 depends on stages: Stage-6
+  Stage-7 depends on stages: Stage-1
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-2
@@ -82,7 +84,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-39-54_258_7891516569971054774/10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-09_951_4321959446546233090/-mr-10004 
           Union
             Reduce Output Operator
               key expressions:
@@ -98,7 +100,7 @@
                     type: string
                     expr: _col1
                     type: string
-        file:/tmp/jssarma/hive_2010-07-21_13-39-54_258_7891516569971054774/10007 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-09_951_4321959446546233090/-mr-10007 
           Union
             Reduce Output Operator
               key expressions:
@@ -152,7 +154,7 @@
   Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-39-54_258_7891516569971054774/10005 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-09_951_4321959446546233090/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -202,9 +204,12 @@
               name: dest1
 
   Stage: Stage-5
+    Stats-Aggr Operator
+
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-39-54_258_7891516569971054774/10006 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-09_951_4321959446546233090/-mr-10006 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -261,7 +266,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -308,11 +316,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-07_128_4703708380901938283/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-35_533_8334042407221913491/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-07_128_4703708380901938283/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-35_533_8334042407221913491/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
@@ -631,11 +639,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-07_181_8284196145398809075/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-35_933_8454563848719230923/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-40-07_181_8284196145398809075/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-35_933_8454563848719230923/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input30.q.out
===================================================================
--- ql/src/test/results/clientpositive/input30.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input30.q.out	(working copy)
@@ -22,6 +22,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -83,7 +84,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tst_dest30
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table dest30
 select count(1) from src
 PREHOOK: type: QUERY
@@ -98,10 +102,10 @@
 PREHOOK: query: select * from tst_dest30
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tst_dest30
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-48_308_1489139289605344338/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-17_894_4302083977573140725/-mr-10000
 POSTHOOK: query: select * from tst_dest30
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tst_dest30
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-48_308_1489139289605344338/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-17_894_4302083977573140725/-mr-10000
 POSTHOOK: Lineage: tst_dest30.a EXPRESSION [(src)src.null, ]
 18
Index: ql/src/test/results/clientpositive/parallel.q.out
===================================================================
--- ql/src/test/results/clientpositive/parallel.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/parallel.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -129,7 +131,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-09_22-25-23_894_8240793898629070545/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_17-13-50_531_2890192072832942497/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -180,9 +182,12 @@
               name: src_a
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-09_22-25-23_894_8240793898629070545/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-14_17-13-50_531_2890192072832942497/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -232,7 +237,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_b
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from (select key, value from src group by key, value) s
 insert overwrite table src_a select s.key, s.value group by s.key, s.value
 insert overwrite table src_b select s.key, s.value group by s.key, s.value
@@ -254,11 +262,11 @@
 PREHOOK: query: select * from src_a order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_a
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-25-37_362_5325705374349052168/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-02_165_5274023346481856318/-mr-10000
 POSTHOOK: query: select * from src_a order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_a
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-25-37_362_5325705374349052168/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-02_165_5274023346481856318/-mr-10000
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_b.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -575,11 +583,11 @@
 PREHOOK: query: select * from src_b order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_b
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-25-43_561_4685920856018764066/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-06_366_5156248632763644240/-mr-10000
 POSTHOOK: query: select * from src_b order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_b
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-25-43_561_4685920856018764066/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-06_366_5156248632763644240/-mr-10000
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_b.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -918,11 +926,11 @@
 PREHOOK: query: select * from src_a order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_a
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-26-02_417_889900537103370052/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-23_195_3253242643234574753/-mr-10000
 POSTHOOK: query: select * from src_a order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_a
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-26-02_417_889900537103370052/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-23_195_3253242643234574753/-mr-10000
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
@@ -1243,11 +1251,11 @@
 PREHOOK: query: select * from src_b order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_b
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-26-08_562_2161651706050856117/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-27_387_483746667057079187/-mr-10000
 POSTHOOK: query: select * from src_b order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_b
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-09_22-26-08_562_2161651706050856117/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-14-27_387_483746667057079187/-mr-10000
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_a.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/load_dyn_part5.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part5.q.out	(working copy)
@@ -18,15 +18,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:12:09 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 00:16:35 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part5	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part5	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284473529          
+	transient_lastDdlTime	1285053395          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -51,6 +51,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,7 +88,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part5
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table nzhang_part5 partition (value) select key, value from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -1337,11 +1341,11 @@
 PREHOOK: query: select * from nzhang_part5 where value='val_0'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part5@value=val_0
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-12-50_552_998166979564751894/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-02_739_6993685440443435128/-mr-10000
 POSTHOOK: query: select * from nzhang_part5 where value='val_0'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part5@value=val_0
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-12-50_552_998166979564751894/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-02_739_6993685440443435128/-mr-10000
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_0).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_103).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1657,11 +1661,11 @@
 PREHOOK: query: select * from nzhang_part5 where value='val_2'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part5@value=val_2
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-12-50_918_3983584652479110255/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-03_529_3084528464376724751/-mr-10000
 POSTHOOK: query: select * from nzhang_part5 where value='val_2'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part5@value=val_2
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-12-50_918_3983584652479110255/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-22-03_529_3084528464376724751/-mr-10000
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_0).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_100).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part5 PARTITION(value=val_103).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby8_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby8_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby8_map_skew.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -83,7 +85,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-39_764_9221977763531522569/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-18_130_2771864261451244442/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -140,9 +142,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-39_764_9221977763531522569/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-19-18_130_2771864261451244442/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -198,7 +203,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -220,11 +228,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-52_199_4604877922873975806/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-34_779_6983072592533420151/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-52_199_4604877922873975806/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-34_779_6983072592533420151/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -541,11 +549,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-52_255_2526834698871090111/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-35_206_1431878980450207209/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-52_255_2526834698871090111/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-19-35_206_1431878980450207209/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample6.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample6.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample6.q.out	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -30,6 +31,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -50,8 +52,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -61,21 +64,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282245050
+                          transient_lastDdlTime 1284510285
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +91,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244548
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -104,31 +108,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244548
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -138,24 +142,28 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282245050
+                transient_lastDdlTime 1284510285
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -166,21 +174,22 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282245050
+                    transient_lastDdlTime 1284510285
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-10-50_343_2952851660524574553/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-46_014_8924466582548738763/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -191,12 +200,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282245050
+              transient_lastDdlTime 1284510285
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -207,12 +216,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282245050
+                transient_lastDdlTime 1284510285
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -233,11 +242,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-54_832_3329946722995838841/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-52_602_2662316424952173793/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-54_832_3329946722995838841/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-52_602_2662316424952173793/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 468	val_469
@@ -511,6 +520,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -543,9 +553,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket1.txt 
           Partition
             base file name: srcbucket1.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -557,12 +567,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244548
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -574,12 +584,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244548
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -588,8 +598,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-10-55_043_8468045342964025589/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-24-53_002_533983126018968346/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-24-53_002_533983126018968346/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -598,6 +609,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -609,12 +621,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-55_190_5538439261537473249/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-53_250_4539562322091227053/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 4 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-10-55_190_5538439261537473249/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-53_250_4539562322091227053/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 3	val_4
@@ -878,6 +890,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -910,9 +923,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -924,12 +937,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244548
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -941,12 +954,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244548
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -955,8 +968,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-00_294_8535362011881397179/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-24-57_026_2718577770255458785/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-24-57_026_2718577770255458785/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -965,6 +979,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -976,12 +991,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-00_448_7480253387781203292/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-57_277_4821900235297777819/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-00_448_7480253387781203292/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-57_277_4821900235297777819/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -1499,6 +1514,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1531,9 +1547,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1545,12 +1561,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244548
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -1562,12 +1578,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244548
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -1576,8 +1592,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-04_875_609962316830819857/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-01_051_6447605395208317671/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-01_051_6447605395208317671/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -1586,6 +1603,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -1597,12 +1615,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-04_953_8859761833516932491/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-01_161_3575686286120830874/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-04_953_8859761833516932491/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-01_161_3575686286120830874/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -1963,6 +1981,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -1995,9 +2014,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2009,12 +2028,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244548
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2026,12 +2045,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244548
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
@@ -2040,8 +2059,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-10_488_5680575794209693621/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-05_752_5484487891016862969/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-05_752_5484487891016862969/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2050,6 +2070,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2061,12 +2082,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-10_581_3319781282987541908/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-05_858_6264519128243618167/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket TABLESAMPLE (BUCKET 2 OUT OF 3 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-10_581_3319781282987541908/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-05_858_6264519128243618167/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 1	val_2
@@ -2413,6 +2434,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2445,10 +2467,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket20.txt 
           Partition
             base file name: srcbucket20.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2460,12 +2482,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244551
+              transient_lastDdlTime 1284504428
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2477,16 +2499,16 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244551
+                transient_lastDdlTime 1284504428
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket22.txt 
           Partition
             base file name: srcbucket22.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2498,12 +2520,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244551
+              transient_lastDdlTime 1284504428
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2515,12 +2537,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244551
+                transient_lastDdlTime 1284504428
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2529,8 +2551,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-15_215_8387544186865399668/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-10_451_2535168614473791178/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-10_451_2535168614473791178/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2539,6 +2562,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2550,12 +2574,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-15_610_1323328570389530866/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-11_181_8784441563940501492/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-15_610_1323328570389530866/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-11_181_8784441563940501492/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
@@ -2702,6 +2726,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2734,9 +2759,9 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2/srcbucket21.txt 
           Partition
             base file name: srcbucket21.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2748,12 +2773,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
               name srcbucket2
               serialization.ddl struct srcbucket2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244551
+              transient_lastDdlTime 1284504428
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2765,12 +2790,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket2
                 name srcbucket2
                 serialization.ddl struct srcbucket2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244551
+                transient_lastDdlTime 1284504428
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket2
             name: srcbucket2
@@ -2779,8 +2804,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-20_507_3345563483545532290/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-16_389_3169479756049941851/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-16_389_3169479756049941851/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2789,6 +2815,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2800,12 +2827,12 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-20_734_8682679695028521586/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-16_781_3157391389694103452/-mr-10000
 POSTHOOK: query: SELECT s.* FROM srcbucket2 TABLESAMPLE (BUCKET 2 OUT OF 4 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-20_734_8682679695028521586/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-16_781_3157391389694103452/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 5	val_5
@@ -2875,6 +2902,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2911,8 +2939,9 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: file:/tmp/nzhang/hive_2010-08-19_12-11-24_602_4778266469901166115/-ext-10001
+            directory: file:/tmp/nzhang/hive_2010-09-14_17-25-21_376_8476330244078104264/-ext-10001
             NumFilesPerFileSink: 1
+            Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-25-21_376_8476330244078104264/-ext-10001/
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2921,6 +2950,7 @@
                   columns.types int:string
                   serialization.format 1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
   Stage: Stage-0
@@ -2932,11 +2962,11 @@
 ORDER BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@empty_bucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-24_690_9796337575443591/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-21_480_8277252386943120890/-mr-10000
 POSTHOOK: query: SELECT s.* FROM empty_bucket TABLESAMPLE (BUCKET 1 OUT OF 2 on key) s
 ORDER BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@empty_bucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-24_690_9796337575443591/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-21_480_8277252386943120890/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/join27.q.out
===================================================================
--- ql/src/test/results/clientpositive/join27.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join27.q.out	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-24_130_5729752916619921964/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-59_915_4313549870418004995/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-24_130_5729752916619921964/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-38-59_915_4313549870418004995/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -188,11 +192,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key, x.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-28_811_7041709552591198660/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-06_541_7268389461594626671/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key, x.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-28_811_7041709552591198660/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-06_541_7268389461594626671/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udf_length.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf_length.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_length.q.out	(working copy)
@@ -25,10 +25,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-33_168_7498899558066548297/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-04-35_216_2056119119160660990/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-33_168_7498899558066548297/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-04-35_216_2056119119160660990/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -96,11 +100,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-36_843_3189643618783207706/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-04-41_523_735254050434552120/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-36_843_3189643618783207706/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-04-41_523_735254050434552120/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 7
 0
@@ -189,10 +193,10 @@
 PREHOOK: query: SELECT length(dest1.name) FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-37_797_8427369268631116879/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-04-43_257_9100387438276916655/-mr-10000
 POSTHOOK: query: SELECT length(dest1.name) FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-37_797_8427369268631116879/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-04-43_257_9100387438276916655/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 2
Index: ql/src/test/results/clientpositive/stats6.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats6.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats6.q.out	(revision 0)
@@ -0,0 +1,314 @@
+PREHOOK: query: create table analyze_srcpart like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table analyze_srcpart like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@analyze_srcpart
+PREHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:11:46 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056715          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:11:47 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056721          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:11:47 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=11	 
+Partition Parameters:	 	 
+	transient_lastDdlTime	1285056707          
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-09, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:11:48 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-09/hr=12	 
+Partition Parameters:	 	 
+	transient_lastDdlTime	1285056708          
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:11:35 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285056721          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/union12.q.out
===================================================================
--- ql/src/test/results/clientpositive/union12.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union12.q.out	(working copy)
@@ -28,13 +28,14 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6, Stage-7
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7, Stage-8
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
   Stage-7 is a root stage
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -80,7 +81,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-19_12-11-56_585_9167992291340891691/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_18-17-08_605_1439847119800045323/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -104,7 +105,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/nzhang/hive_2010-08-19_12-11-56_585_9167992291340891691/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-17-08_605_1439847119800045323/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -128,7 +129,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/nzhang/hive_2010-08-19_12-11-56_585_9167992291340891691/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-14_18-17-08_605_1439847119800045323/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -153,14 +154,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-56_585_9167992291340891691/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-17-08_605_1439847119800045323/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -173,9 +174,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-56_585_9167992291340891691/-ext-10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-17-08_605_1439847119800045323/-ext-10003 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -185,7 +189,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery2:unionsrc-subquery1-subquery2:s2 
@@ -225,7 +229,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s3 
@@ -293,11 +297,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-16_058_6174007562140968530/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-17-28_935_6340798078420535385/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-16_058_6174007562140968530/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-17-28_935_6340798078420535385/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.null, (srcbucket)s3.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/groupby1_map_nomap.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1_map_nomap.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1_map_nomap.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -94,7 +95,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -108,11 +112,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-10-56_508_46556305612715863/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-53_431_7166464393607689291/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-10-56_508_46556305612715863/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-53_431_7166464393607689291/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/input18.q.out
===================================================================
--- ql/src/test/results/clientpositive/input18.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input18.q.out	(working copy)
@@ -27,6 +27,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -104,7 +105,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value, 1+2, 3+4)
@@ -130,11 +134,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-57_230_2729086633241060768/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-40_009_4704505583726381922/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-10-57_230_2729086633241060768/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-40_009_4704505583726381922/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0+3+7
Index: ql/src/test/results/clientpositive/join36.q.out
===================================================================
--- ql/src/test/results/clientpositive/join36.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join36.q.out	(working copy)
@@ -58,10 +58,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -157,14 +158,14 @@
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-00-31_187_3818554291798258801/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-43_154_2888049314872131139/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -177,9 +178,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_16-00-31_187_3818554291798258801/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-43_154_2888049314872131139/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -214,11 +218,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-00-34_763_7222853945015683789/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-50_562_502275187594181738/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-00-34_763_7222853945015683789/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-41-50_562_502275187594181738/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(tmp1)x.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(tmp2)y.FieldSchema(name:cnt, type:int, comment:null), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(tmp1)x.FieldSchema(name:cnt, type:int, comment:null), ]
Index: ql/src/test/results/clientpositive/groupby2.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby2.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -67,7 +68,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-17_928_9113223508728392299/10002 
+        hdfs://localhost.localdomain:61365/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_02-39-32_192_1798856922728294607/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -130,7 +131,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_g2
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -147,11 +151,11 @@
 PREHOOK: query: SELECT dest_g2.* FROM dest_g2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_g2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-27_687_3540726200789882655/10000
+PREHOOK: Output: hdfs://localhost.localdomain:61365/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_02-39-44_735_8511890502067156540/-mr-10000
 POSTHOOK: query: SELECT dest_g2.* FROM dest_g2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_g2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_3/build/ql/scratchdir/hive_2010-04-05_18-09-27_687_3540726200789882655/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:61365/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_02-39-44_735_8511890502067156540/-mr-10000
 POSTHOOK: Lineage: dest_g2.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g2.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_part5.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part5.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -56,14 +57,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: tmptable
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-35_664_1396318289079329391/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-30_692_7574653588774934184/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -76,9 +77,12 @@
               name: tmptable
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-35_664_1396318289079329391/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-34-30_692_7574653588774934184/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -108,11 +112,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-44_486_6960103354911337905/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-41_336_5067322787693699900/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-44_486_6960103354911337905/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-34-41_336_5067322787693699900/-mr-10000
 POSTHOOK: Lineage: tmptable.ds SIMPLE [(srcpart)x.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.hr SIMPLE [(srcpart)x.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.key SIMPLE [(srcpart)x.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin3.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin3.q.out	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -140,8 +142,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -151,15 +154,16 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861809
+                              transient_lastDdlTime 1284504953
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -171,6 +175,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -214,8 +219,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -225,29 +231,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282861809
+                                  transient_lastDdlTime 1284504953
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket22.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket23.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -261,13 +268,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
               name srcbucket_mapjoin_part_2
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861807
+              transient_lastDdlTime 1284504951
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -279,32 +286,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2
                 name srcbucket_mapjoin_part_2
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861807
+                transient_lastDdlTime 1284504951
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part_2
             name: srcbucket_mapjoin_part_2
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -314,24 +321,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861809
+                transient_lastDdlTime 1284504953
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -342,21 +353,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861809
+                    transient_lastDdlTime 1284504953
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-09_554_7996001089560004879/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-55-53_625_5848530933180579779/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -367,12 +379,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861809
+              transient_lastDdlTime 1284504953
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -383,12 +395,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861809
+                transient_lastDdlTime 1284504953
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -416,11 +428,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-17_987_7809424755525209564/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-06_599_7079861620765207719/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-17_987_7809424755525209564/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-06_599_7079861620765207719/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin_part_2)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin_part_2)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -469,11 +481,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-31_954_5628788611181333885/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-28_712_8879884730120469839/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-31_954_5628788611181333885/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-28_712_8879884730120469839/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -512,14 +524,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-38_351_5147508732271519476/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-38_946_2041800544454288745/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-38_351_5147508732271519476/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-38_946_2041800544454288745/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -562,10 +574,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -574,6 +587,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -617,8 +631,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -628,15 +643,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 564
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861831
+                              totalSize 11067
+                              transient_lastDdlTime 1284504988
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -648,6 +668,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -691,8 +712,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -702,31 +724,36 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
+                                  numFiles 1
+                                  numPartitions 0
+                                  numRows 564
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282861831
+                                  totalSize 11067
+                                  transient_lastDdlTime 1284504988
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket22.txt], srcbucket21.txt=[srcbucket23.txt], srcbucket22.txt=[srcbucket22.txt], srcbucket23.txt=[srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part_2/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -740,13 +767,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861804
+              transient_lastDdlTime 1284504946
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -758,32 +785,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861804
+                transient_lastDdlTime 1284504946
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -793,24 +820,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 564
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861831
+                totalSize 11067
+                transient_lastDdlTime 1284504988
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -821,21 +856,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 564
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861831
+                    totalSize 11067
+                    transient_lastDdlTime 1284504988
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-30-41_651_4990138249603747064/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-56-43_857_4954976106545022146/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -846,12 +886,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 564
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861831
+              totalSize 11067
+              transient_lastDdlTime 1284504988
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -862,12 +906,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 564
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861831
+                totalSize 11067
+                transient_lastDdlTime 1284504988
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -907,11 +955,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-50_259_6194219508540281037/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-57_421_9111351844773615576/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-30-50_259_6194219508540281037/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-56-57_421_9111351844773615576/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -996,11 +1044,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-05_693_4794557309886837554/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-21_276_8220084583053039711/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-05_693_4794557309886837554/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-21_276_8220084583053039711/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1063,14 +1111,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-12_070_2692866740463855531/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-32_158_2712075681251012335/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-12_070_2692866740463855531/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-32_158_2712075681251012335/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin1.q.out_0.17	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -137,8 +139,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -148,15 +151,16 @@
                             columns.types string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                             name bucketmapjoin_tmp_result
                             serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282940312
+                            transient_lastDdlTime 1284588536
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: bucketmapjoin_tmp_result
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -168,6 +172,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -213,8 +218,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -224,29 +230,30 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                   name bucketmapjoin_tmp_result
                                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1282940312
+                                  transient_lastDdlTime 1284588536
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: bucketmapjoin_tmp_result
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket21.txt=[srcbucket21.txt, srcbucket23.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -258,12 +265,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940308
+              transient_lastDdlTime 1284588531
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -275,31 +282,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940308
+                transient_lastDdlTime 1284588531
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -309,20 +316,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940312
+                transient_lastDdlTime 1284588536
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -338,9 +349,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -351,12 +362,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940312
+              transient_lastDdlTime 1284588536
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -367,12 +378,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940312
+                transient_lastDdlTime 1284588536
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -381,7 +392,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-18-32_753_1427220055110185291/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-08-56_712_8865991313329293450/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -392,15 +403,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940312
+                  transient_lastDdlTime 1284588536
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -426,11 +438,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-18-41_448_423478493834178083/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-10_679_3158135264417308897/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-18-41_448_423478493834178083/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-10_679_3158135264417308897/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -479,11 +491,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-18-58_469_3798558653738614828/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-36_825_8616340304538636733/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-18-58_469_3798558653738614828/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-36_825_8616340304538636733/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -522,14 +534,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-05_137_9174965708481957933/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-47_273_6989662404529284911/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-05_137_9174965708481957933/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-09-47_273_6989662404529284911/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -572,10 +584,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -584,6 +597,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -629,8 +643,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -640,15 +655,20 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940338
+                              totalSize 8983
+                              transient_lastDdlTime 1284588576
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -660,6 +680,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -700,8 +721,9 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 1
-                          directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002
                           NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000/
                           table:
                               input format: org.apache.hadoop.mapred.TextInputFormat
                               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -711,31 +733,36 @@
                                 columns.types string:string:string
                                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                                 name bucketmapjoin_tmp_result
+                                numFiles 1
+                                numPartitions 0
+                                numRows 464
                                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                                 serialization.format 1
                                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                transient_lastDdlTime 1282940338
+                                totalSize 8983
+                                transient_lastDdlTime 1284588576
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: bucketmapjoin_tmp_result
                           TotalFiles: 1
+                          GatherStats: true
                           MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -749,13 +776,13 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
               name srcbucket_mapjoin_part
               partition_columns ds
               serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940308
+              transient_lastDdlTime 1284588531
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -767,32 +794,32 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
                 name srcbucket_mapjoin_part
                 partition_columns ds
                 serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940308
+                transient_lastDdlTime 1284588531
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin_part
             name: srcbucket_mapjoin_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -802,20 +829,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940338
+                totalSize 8983
+                transient_lastDdlTime 1284588576
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -831,9 +866,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -844,12 +879,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940338
+              totalSize 8983
+              transient_lastDdlTime 1284588576
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -860,12 +899,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940338
+                totalSize 8983
+                transient_lastDdlTime 1284588576
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -874,7 +917,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-19-08_806_3545018008696802629/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-09-52_403_3621061894597063114/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -885,15 +928,20 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 464
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940338
+                  totalSize 8983
+                  transient_lastDdlTime 1284588576
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -931,11 +979,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-19_260_1730483222544165928/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-09_333_7087063211316319159/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-19_260_1730483222544165928/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-09_333_7087063211316319159/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -1020,11 +1068,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-36_956_5377515740348568787/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-36_454_3398532928519497449/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-36_956_5377515740348568787/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-36_454_3398532928519497449/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1087,14 +1135,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-43_601_3699579635282471240/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-46_924_3034697927453182381/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-19-43_601_3699579635282471240/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-10-46_924_3034697927453182381/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/input_part10.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part10.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part10.q.out	(working copy)
@@ -29,6 +29,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -78,7 +79,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: part_special
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE part_special PARTITION(ds='2008 04 08', ts = '10:11:12=455')
 SELECT 1, 2 FROM src LIMIT 1
 PREHOOK: type: QUERY
@@ -112,12 +116,15 @@
 Partition Value:    	[2008 04 08, 10:11:12=455]	 
 Database:           	default             	 
 Table:              	part_special        	 
-CreateTime:         	Tue Sep 14 08:24:14 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:55:13 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/part_special/ds=2008 04 08/ts=10%3A11%3A12%3D455	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/part_special/ds=2008 04 08/ts=10%3A11%3A12%3D455	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477854          
+	numFiles            	1                   
+	transient_lastDdlTime	1285052113          
+	numRows             	1                   
+	totalSize           	4                   
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -133,11 +140,11 @@
 PREHOOK: query: SELECT * FROM part_special WHERE ds='2008 04 08' AND ts = '10:11:12=455'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@part_special@ds=2008 04 08/ts=10%3A11%3A12%3D455
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-24-14_529_9115667855216344763/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-55-13_931_8974375359528209894/-mr-10000
 POSTHOOK: query: SELECT * FROM part_special WHERE ds='2008 04 08' AND ts = '10:11:12=455'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@part_special@ds=2008 04 08/ts=10%3A11%3A12%3D455
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-24-14_529_9115667855216344763/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-55-13_931_8974375359528209894/-mr-10000
 POSTHOOK: Lineage: part_special PARTITION(ds=2008 04 08,ts=10:11:12=455).a SIMPLE []
 POSTHOOK: Lineage: part_special PARTITION(ds=2008 04 08,ts=10:11:12=455).b SIMPLE []
 1	2	2008 04 08	10:11:12=455
Index: ql/src/test/results/clientpositive/input_testxpath2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_testxpath2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testxpath2.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -54,14 +55,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-07_393_2718672217539809970/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-38_276_8743056158306983792/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -74,9 +75,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-07_393_2718672217539809970/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-38_276_8743056158306983792/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -118,11 +122,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-12_826_697390232727734110/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-44_566_8338997060674744971/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-12_826_697390232727734110/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-44_566_8338997060674744971/-mr-10000
 POSTHOOK: Lineage: dest1.lint_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.lintstring_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.mstringstring_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/mapreduce8.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce8.q.out	(working copy)
@@ -25,6 +25,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -113,7 +114,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.*, src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -141,11 +145,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-23-04_818_871247711340607825/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-00_970_4631962200725249952/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-23-04_818_871247711340607825/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-04-00_970_4631962200725249952/-mr-10000
 POSTHOOK: Lineage: dest1.k SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/union10.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/union10.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/union10.q.out_0.17	(working copy)
@@ -28,13 +28,14 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-6, Stage-7
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-1, Stage-7, Stage-8
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 is a root stage
   Stage-7 is a root stage
+  Stage-8 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -80,7 +81,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_13-38-46_962_8522402125517331101/10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-35-28_035_6997518029237523999/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -104,7 +105,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-38-46_962_8522402125517331101/10004 
+        file:/tmp/nzhang/hive_2010-09-15_17-35-28_035_6997518029237523999/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -128,7 +129,7 @@
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
-        file:/tmp/jssarma/hive_2010-07-21_13-38-46_962_8522402125517331101/10005 
+        file:/tmp/nzhang/hive_2010-09-15_17-35-28_035_6997518029237523999/-mr-10005 
           Union
             Select Operator
               expressions:
@@ -153,14 +154,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: tmptable
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-38-46_962_8522402125517331101/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-35-28_035_6997518029237523999/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -173,9 +174,12 @@
               name: tmptable
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_13-38-46_962_8522402125517331101/10003 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-35-28_035_6997518029237523999/-ext-10003 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -198,7 +202,7 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: tmptable
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery2:unionsrc-subquery1-subquery2:s2 
@@ -238,7 +242,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s3 
@@ -302,11 +306,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-38-59_753_3964700298494974564/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-35-51_602_4379629688816539336/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_13-38-59_753_3964700298494974564/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-35-51_602_4379629688816539336/-mr-10000
 POSTHOOK: Lineage: tmptable.key EXPRESSION []
 POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src)s2.null, (src)s3.null, ]
 tst1	500
Index: ql/src/test/results/clientpositive/sample1.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample1.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: true
               predicate:
@@ -72,8 +74,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -83,21 +86,22 @@
                               columns.types int:string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                               name dest1
                               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282111161
+                              transient_lastDdlTime 1284510196
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,13 +115,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -128,32 +132,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -163,24 +167,28 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111161
+                transient_lastDdlTime 1284510196
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -191,21 +199,22 @@
                     columns.types int:string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111161
+                    transient_lastDdlTime 1284510196
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-21_563_2569025846206463532/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-23-16_395_984946228972103832/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -216,12 +225,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111161
+              transient_lastDdlTime 1284510196
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -232,12 +241,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string dt, string hr}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111161
+                transient_lastDdlTime 1284510196
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -262,11 +271,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-25_590_4024449388674227858/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-22_919_5124595871759891270/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-25_590_4024449388674227858/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-22_919_5124595871759891270/-mr-10000
 POSTHOOK: Lineage: dest1.dt SIMPLE [(srcpart)s.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)s.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)s.FieldSchema(name:key, type:string, comment:default), ]
@@ -774,11 +783,11 @@
 PREHOOK: query: select count(1) from srcbucket
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcbucket
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-25_855_4417130944079527899/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-23_308_4156736564340444071/-mr-10000
 POSTHOOK: query: select count(1) from srcbucket
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcbucket
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-25_855_4417130944079527899/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-23-23_308_4156736564340444071/-mr-10000
 POSTHOOK: Lineage: dest1.dt SIMPLE [(srcpart)s.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)s.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)s.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby6_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby6_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby6_map_skew.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -65,7 +66,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-59_936_7763915855557835948/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-17-02_295_2564025665394865331/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -107,6 +108,8 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT DISTINCT substr(src.value,5,1)
@@ -122,11 +125,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-07_795_164139484799324490/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-11_277_817938108745862478/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-12-07_795_164139484799324490/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-11_277_817938108745862478/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/groupby1_limit.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby1_limit.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby1_limit.q.out	(working copy)
@@ -16,6 +16,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -80,7 +81,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-07-58_856_3839035257241506046/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-13-25_960_7399358690321555883/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -118,7 +119,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT src.key, sum(substr(src.value,5)) GROUP BY src.key LIMIT 5
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -132,11 +136,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-07_221_6317663221836689086/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-36_134_6079751361669392445/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-08-07_221_6317663221836689086/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-13-36_134_6079751361669392445/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/input13.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input13.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input13.q.out_0.17	(working copy)
@@ -32,22 +32,25 @@
 
 STAGE DEPENDENCIES:
   Stage-4 is a root stage
-  Stage-7 depends on stages: Stage-4 , consists of Stage-6, Stage-5
+  Stage-8 depends on stages: Stage-4 , consists of Stage-7, Stage-6
+  Stage-7
+  Stage-0 depends on stages: Stage-7, Stage-6
+  Stage-5 depends on stages: Stage-0
   Stage-6
-  Stage-0 depends on stages: Stage-6, Stage-5
-  Stage-5
-  Stage-10 depends on stages: Stage-4 , consists of Stage-9, Stage-8
-  Stage-9
-  Stage-1 depends on stages: Stage-9, Stage-8
-  Stage-8
-  Stage-13 depends on stages: Stage-4 , consists of Stage-12, Stage-11
-  Stage-12
-  Stage-2 depends on stages: Stage-12, Stage-11
+  Stage-12 depends on stages: Stage-4 , consists of Stage-11, Stage-10
   Stage-11
+  Stage-1 depends on stages: Stage-11, Stage-10
+  Stage-9 depends on stages: Stage-1
+  Stage-10
   Stage-16 depends on stages: Stage-4 , consists of Stage-15, Stage-14
   Stage-15
-  Stage-3 depends on stages: Stage-15, Stage-14
+  Stage-2 depends on stages: Stage-15, Stage-14
+  Stage-13 depends on stages: Stage-2
   Stage-14
+  Stage-19 depends on stages: Stage-4 , consists of Stage-18, Stage-17
+  Stage-18
+  Stage-3 depends on stages: Stage-18, Stage-17
+  Stage-17
 
 STAGE PLANS:
   Stage: Stage-4
@@ -146,14 +149,14 @@
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Conditional Operator
 
-  Stage: Stage-6
+  Stage: Stage-7
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -166,9 +169,12 @@
               name: dest1
 
   Stage: Stage-5
+    Stats-Aggr Operator
+
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10007 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10007 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -191,14 +197,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
 
-  Stage: Stage-10
+  Stage: Stage-12
     Conditional Operator
 
-  Stage: Stage-9
+  Stage: Stage-11
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -210,10 +216,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-8
+  Stage: Stage-9
+    Stats-Aggr Operator
+
+  Stage: Stage-10
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10008 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10008 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -236,14 +245,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
 
-  Stage: Stage-13
+  Stage: Stage-16
     Conditional Operator
 
-  Stage: Stage-12
+  Stage: Stage-15
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10004
 
   Stage: Stage-2
     Move Operator
@@ -258,10 +267,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest3
 
-  Stage: Stage-11
+  Stage: Stage-13
+    Stats-Aggr Operator
+
+  Stage: Stage-14
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10009 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10009 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -282,14 +294,14 @@
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest3
 
-  Stage: Stage-16
+  Stage: Stage-19
     Conditional Operator
 
-  Stage: Stage-15
+  Stage: Stage-18
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10006
+          destination: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10006
 
   Stage: Stage-3
     Move Operator
@@ -297,10 +309,10 @@
           hdfs directory: true
           destination: ../build/ql/test/data/warehouse/dest4.out
 
-  Stage: Stage-14
+  Stage: Stage-17
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-42-14_916_4627462906286154354/-ext-10010 
+        file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-43-40_689_2281559257037339532/-ext-10010 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -350,11 +362,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-19_843_3168947862547762965/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-50_255_5579460870552016345/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-19_843_3168947862547762965/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-50_255_5579460870552016345/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -447,11 +459,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-20_356_1457870921078810750/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-50_854_3221631354937580162/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-20_356_1457870921078810750/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-50_854_3221631354937580162/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -565,11 +577,11 @@
 PREHOOK: query: SELECT dest3.* FROM dest3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-20_869_5121758791192196339/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-51_496_6100593517727083503/-mr-10000
 POSTHOOK: query: SELECT dest3.* FROM dest3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-42-20_869_5121758791192196339/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-43-51_496_6100593517727083503/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/reduce_deduplicate.q.out
===================================================================
--- ql/src/test/results/clientpositive/reduce_deduplicate.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/reduce_deduplicate.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -48,9 +50,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -61,12 +63,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284513860
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -77,12 +79,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284513860
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -98,8 +100,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-48-55_864_1750582395196822547/10000
+              directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-24_563_3727298773264353660/-ext-10000
               NumFilesPerFileSink: 2
+              Stats Publishing Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-24_563_3727298773264353660/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -110,22 +113,23 @@
                     columns.types string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket5_1
+                    location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket5_1
                     name bucket5_1
                     serialization.ddl struct bucket5_1 { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279738135
+                    transient_lastDdlTime 1284514224
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket5_1
               TotalFiles: 2
+              GatherStats: true
               MultiFileSpray: true
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-48-55_864_1750582395196822547/10000
+          source: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-24_563_3727298773264353660/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -136,17 +140,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket5_1
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket5_1
                 name bucket5_1
                 serialization.ddl struct bucket5_1 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279738135
+                transient_lastDdlTime 1284514224
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket5_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-48-55_864_1750582395196822547/10001
+          tmp directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-24_563_3727298773264353660/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-24_563_3727298773264353660/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket5_1
 select * from src cluster by key
 PREHOOK: type: QUERY
@@ -162,22 +170,22 @@
 PREHOOK: query: select sum(hash(key)),sum(hash(value)) from bucket5_1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket5_1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-58_496_2658667578750181431/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-32_208_7104739965069811942/-mr-10000
 POSTHOOK: query: select sum(hash(key)),sum(hash(value)) from bucket5_1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket5_1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-48-58_496_2658667578750181431/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-32_208_7104739965069811942/-mr-10000
 POSTHOOK: Lineage: bucket5_1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket5_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 21025334	36210398070
 PREHOOK: query: select sum(hash(key)),sum(hash(value)) from src
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-49-01_108_5850998193164493516/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-39_290_5210415227500445052/-mr-10000
 POSTHOOK: query: select sum(hash(key)),sum(hash(value)) from src
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-49-01_108_5850998193164493516/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-39_290_5210415227500445052/-mr-10000
 POSTHOOK: Lineage: bucket5_1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket5_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 21025334	36210398070
@@ -235,6 +243,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -243,6 +252,7 @@
         s2:s:complex_tbl_2 
           TableScan
             alias: complex_tbl_2
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -344,8 +354,10 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-49-03_763_2468601734060096330/10000
+                  directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-44_238_5377741092673845894/-ext-10000
                   NumFilesPerFileSink: 1
+                  Static Partition Specification: ds=2010-03-29/
+                  Stats Publishing Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-44_238_5377741092673845894/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -355,16 +367,17 @@
                         columns.types string:string:int:string:bigint:string:string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/complex_tbl_1
+                        location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/complex_tbl_1
                         name complex_tbl_1
                         partition_columns ds
                         serialization.ddl struct complex_tbl_1 { string aid, string bid, i32 t, string ctime, i64 etime, string l, string et}
                         serialization.format 1
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1279738143
+                        transient_lastDdlTime 1284514244
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: complex_tbl_1
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
 
   Stage: Stage-0
@@ -373,7 +386,7 @@
           partition:
             ds 2010-03-29
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-49-03_763_2468601734060096330/10000
+          source: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-44_238_5377741092673845894/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -383,15 +396,19 @@
                 columns.types string:string:int:string:bigint:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/complex_tbl_1
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/complex_tbl_1
                 name complex_tbl_1
                 partition_columns ds
                 serialization.ddl struct complex_tbl_1 { string aid, string bid, i32 t, string ctime, i64 etime, string l, string et}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279738143
+                transient_lastDdlTime 1284514244
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: complex_tbl_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-49-03_763_2468601734060096330/10001
+          tmp directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-44_238_5377741092673845894/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-30-44_238_5377741092673845894/-ext-10000/
 
+
Index: ql/src/test/results/clientpositive/cast1.q.out
===================================================================
--- ql/src/test/results/clientpositive/cast1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/cast1.q.out	(working copy)
@@ -14,10 +14,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -60,14 +61,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-34_692_694206865057596318/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-58_873_7254645115593805621/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -80,9 +81,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-34_692_694206865057596318/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-58_873_7254645115593805621/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -111,11 +115,11 @@
 PREHOOK: query: select dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-08-38_735_1272179232772384366/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-02-05_020_7988700677189658723/-mr-10000
 POSTHOOK: query: select dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-08-38_735_1272179232772384366/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-02-05_020_7988700677189658723/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION []
 POSTHOOK: Lineage: dest1.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/join25.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join25.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join25.q.out_0.17	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-56-08_786_3510585172574717667/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-00_435_4677744146307758476/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-56-08_786_3510585172574717667/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-00_435_4677744146307758476/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -203,11 +207,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-56-15_193_8616791771520376915/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-07_735_8899542613625316721/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-56-15_193_8616791771520376915/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-07_735_8899542613625316721/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_part2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_part2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part2.q.out_0.17	(working copy)
@@ -23,14 +23,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -39,6 +41,7 @@
         srcpart 
           TableScan
             alias: srcpart
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -69,8 +72,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -80,15 +84,16 @@
                           columns.types int:string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282157979
+                          transient_lastDdlTime 1284591077
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
             Filter Operator
               isSamplingPred: false
@@ -120,8 +125,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 2
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10002/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -131,22 +137,23 @@
                           columns.types int:string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                           name dest2
                           serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282157979
+                          transient_lastDdlTime 1284591077
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest2
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [srcpart]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -160,13 +167,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -177,17 +184,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -201,13 +208,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157844
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -218,32 +225,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157844
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -253,20 +260,24 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157979
+                transient_lastDdlTime 1284591077
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10001
 
   Stage: Stage-3
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10000/
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -284,9 +295,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10004 
           Partition
             base file name: -ext-10004
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -297,12 +308,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157979
+              transient_lastDdlTime 1284591077
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -313,12 +324,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157979
+                transient_lastDdlTime 1284591077
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -327,7 +338,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -338,32 +349,33 @@
                   columns.types int:string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282157979
+                  transient_lastDdlTime 1284591077
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10002
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10002
 
   Stage: Stage-1
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10002
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10002
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -373,20 +385,24 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                 name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157979
+                transient_lastDdlTime 1284591077
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10003
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10003
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10002/
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -404,9 +420,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10005 
           Partition
             base file name: -ext-10005
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -417,12 +433,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
               name dest2
               serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282157979
+              transient_lastDdlTime 1284591077
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -433,12 +449,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                 name dest2
                 serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282157979
+                transient_lastDdlTime 1284591077
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
             name: dest2
@@ -447,7 +463,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_11-59-39_770_6413652707936318756/-ext-10002
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-17_954_5413919463216840393/-ext-10002
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -458,15 +474,16 @@
                   columns.types int:string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2
                   name dest2
                   serialization.ddl struct dest2 { i32 key, string value, string hr, string ds}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282157979
+                  transient_lastDdlTime 1284591077
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest2
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -497,11 +514,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-55_239_911542356968328679/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-36_017_2837312050989319610/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-55_239_911542356968328679/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-36_017_2837312050989319610/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -597,11 +614,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-58_880_8814469358506550633/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-39_818_738689464583340884/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2 sort by key,value,ds,hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_11-59-58_880_8814469358506550633/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-39_818_738689464583340884/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udf_reverse.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/udf_reverse.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_reverse.q.out_0.17	(working copy)
@@ -25,10 +25,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-03-14_995_869171074390535180/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-26-50_417_5622415055768450176/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-03-14_995_869171074390535180/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-26-50_417_5622415055768450176/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -107,11 +111,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-19_004_6417962732702330578/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-57_119_8603092068666710597/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-19_004_6417962732702330578/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-57_119_8603092068666710597/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 832_lav
 
@@ -168,10 +172,10 @@
 PREHOOK: query: SELECT count(1) FROM dest1 WHERE reverse(dest1.name) = _UTF-8 0xE993AEE982B5
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-20_202_5715101206513526870/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-59_121_860697298160951330/-mr-10000
 POSTHOOK: query: SELECT count(1) FROM dest1 WHERE reverse(dest1.name) = _UTF-8 0xE993AEE982B5
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-03-20_202_5715101206513526870/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-59_121_860697298160951330/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 1
Index: ql/src/test/results/clientpositive/stats1.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats1.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats1.q.out	(revision 0)
@@ -0,0 +1,236 @@
+PREHOOK: query: create table tmptable(key string, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table tmptable(key string, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@tmptable
+PREHOOK: query: EXPLAIN
+INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN
+INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_UNION (TOK_QUERY (TOK_FROM (TOK_TABREF src s1)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR 'tst1' key) (TOK_SELEXPR (TOK_FUNCTION TOK_STRING (TOK_FUNCTION count 1)) value)))) (TOK_QUERY (TOK_FROM (TOK_TABREF src1 s2)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL s2) key) key) (TOK_SELEXPR (. (TOK_TABLE_OR_COL s2) value) value))))) unionsrc)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB tmptable)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL unionsrc) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL unionsrc) value)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-2 depends on stages: Stage-1, Stage-4
+  Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
+  Stage-4 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        null-subquery1:unionsrc-subquery1:s1 
+          TableScan
+            alias: s1
+            Select Operator
+              Group By Operator
+                aggregations:
+                      expr: count(1)
+                bucketGroup: false
+                mode: hash
+                outputColumnNames: _col0
+                Reduce Output Operator
+                  sort order: 
+                  tag: -1
+                  value expressions:
+                        expr: _col0
+                        type: bigint
+      Reduce Operator Tree:
+        Group By Operator
+          aggregations:
+                expr: count(VALUE._col0)
+          bucketGroup: false
+          mode: mergepartial
+          outputColumnNames: _col0
+          Select Operator
+            expressions:
+                  expr: 'tst1'
+                  type: string
+                  expr: UDFToString(_col0)
+                  type: string
+            outputColumnNames: _col0, _col1
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              table:
+                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+
+  Stage: Stage-2
+    Map Reduce
+      Alias -> Map Operator Tree:
+        file:/tmp/nzhang/hive_2010-09-21_01-07-36_945_8793978588452762951/-mr-10002 
+          Union
+            Select Operator
+              expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: tmptable
+        file:/tmp/nzhang/hive_2010-09-21_01-07-36_945_8793978588452762951/-mr-10003 
+          Union
+            Select Operator
+              expressions:
+                    expr: _col0
+                    type: string
+                    expr: _col1
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 1
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    name: tmptable
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: tmptable
+
+  Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
+    Map Reduce
+      Alias -> Map Operator Tree:
+        null-subquery2:unionsrc-subquery2:s2 
+          TableScan
+            alias: s2
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                table:
+                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
+
+
+PREHOOK: query: INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Input: default@src1
+PREHOOK: Output: default@tmptable
+POSTHOOK: query: INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Input: default@src1
+POSTHOOK: Output: default@tmptable
+POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: SELECT * FROM tmptable x SORT BY x.key, x.value
+PREHOOK: type: QUERY
+PREHOOK: Input: default@tmptable
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-49_791_893860610419295712/-mr-10000
+POSTHOOK: query: SELECT * FROM tmptable x SORT BY x.key, x.value
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@tmptable
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-07-49_791_893860610419295712/-mr-10000
+POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
+	
+	
+	
+	
+	val_165
+	val_193
+	val_265
+	val_27
+	val_409
+	val_484
+128	
+146	val_146
+150	val_150
+213	val_213
+224	
+238	val_238
+255	val_255
+273	val_273
+278	val_278
+311	val_311
+369	
+401	val_401
+406	val_406
+66	val_66
+98	val_98
+tst1	500
+PREHOOK: query: DESCRIBE EXTENDED tmptable
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: DESCRIBE EXTENDED tmptable
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: tmptable.key EXPRESSION [(src1)s2.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: tmptable.value EXPRESSION [(src)s1.null, (src1)s2.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	None                
+value               	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:36 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/tmptable	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	0                   
+	numFiles            	2                   
+	transient_lastDdlTime	1285056469          
+	numRows             	26                  
+	totalSize           	225                 
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/ddltime.q.out
===================================================================
--- ql/src/test/results/clientpositive/ddltime.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/ddltime.q.out	(working copy)
@@ -15,15 +15,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 08:14:46 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:14 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284477286          
+	transient_lastDdlTime	1285050674          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -60,15 +60,19 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 08:14:46 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:14 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numPartitions       	0                   
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284477290          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050681          
+	numRows             	500                 
+	totalSize           	5812                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -109,15 +113,19 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 08:14:46 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:14 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numPartitions       	0                   
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284477290          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050688          
+	numRows             	500                 
+	totalSize           	5812                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -162,15 +170,19 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 08:14:46 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:14 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numPartitions       	0                   
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284477296          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050696          
+	numRows             	500                 
+	totalSize           	5812                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -218,15 +230,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 08:14:57 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:36 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t2	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t2	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284477297          
+	transient_lastDdlTime	1285050696          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -282,12 +294,15 @@
 Partition Value:    	[2010-06-21, 1]     	 
 Database:           	default             	 
 Table:              	t2                  	 
-CreateTime:         	Tue Sep 14 08:15:00 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:43 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t2/ds=2010-06-21/hr=1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t2/ds=2010-06-21/hr=1	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477300          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050703          
+	numRows             	489                 
+	totalSize           	5722                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -315,9 +330,9 @@
 POSTHOOK: Lineage: t1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 PREHOOK: query: desc extended T2 partition (ds = '2010-06-21', hr = '1')
 PREHOOK: type: DESCTABLE
 POSTHOOK: query: desc extended T2 partition (ds = '2010-06-21', hr = '1')
@@ -329,9 +344,9 @@
 POSTHOOK: Lineage: t1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 col_name            	data_type           	comment             
 	 	 
 key                 	string              	default             
@@ -347,12 +362,15 @@
 Partition Value:    	[2010-06-21, 1]     	 
 Database:           	default             	 
 Table:              	t2                  	 
-CreateTime:         	Tue Sep 14 08:15:00 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:43 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t2/ds=2010-06-21/hr=1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t2/ds=2010-06-21/hr=1	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477300          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050711          
+	numRows             	489                 
+	totalSize           	5722                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -382,9 +400,9 @@
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-01,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-01,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 PREHOOK: query: desc extended T2 partition(ds='2010-06-01', hr='1')
 PREHOOK: type: DESCTABLE
 POSTHOOK: query: desc extended T2 partition(ds='2010-06-01', hr='1')
@@ -398,9 +416,9 @@
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-01,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-01,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
-POSTHOOK: Lineage: t2 PARTITION(ds=2010-06-21,hr=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 col_name            	data_type           	comment             
 	 	 
 key                 	string              	default             
@@ -416,12 +434,15 @@
 Partition Value:    	[2010-06-01, 1]     	 
 Database:           	default             	 
 Table:              	t2                  	 
-CreateTime:         	Tue Sep 14 08:15:08 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:31:58 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/t2/ds=2010-06-01/hr=1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/t2/ds=2010-06-01/hr=1	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284477308          
+	numFiles            	1                   
+	transient_lastDdlTime	1285050718          
+	numRows             	489                 
+	totalSize           	5722                
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
Index: ql/src/test/results/clientpositive/transform_ppr2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/transform_ppr2.q.out_0.17	(revision 0)
+++ ql/src/test/results/clientpositive/transform_ppr2.q.out_0.17	(revision 0)
@@ -0,0 +1,395 @@
+PREHOOK: query: EXPLAIN EXTENDED
+FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue)
+  WHERE src.ds = '2008-04-08' 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
+PREHOOK: type: QUERY
+POSTHOOK: query: EXPLAIN EXTENDED
+FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue)
+  WHERE src.ds = '2008-04-08' 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart src)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TRANSFORM (TOK_EXPLIST (. (TOK_TABLE_OR_COL src) ds) (. (TOK_TABLE_OR_COL src) key) (. (TOK_TABLE_OR_COL src) value)) TOK_SERDE TOK_RECORDWRITER '/bin/cat' TOK_SERDE TOK_RECORDREADER (TOK_ALIASLIST ds tkey tvalue)))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL src) ds) '2008-04-08')) (TOK_CLUSTERBY (TOK_TABLE_OR_COL tkey)))) tmap)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL tmap) tkey)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL tmap) tvalue))) (TOK_WHERE (< (. (TOK_TABLE_OR_COL tmap) tkey) 100))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        tmap:src 
+          TableScan
+            alias: src
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: (ds = '2008-04-08')
+                  type: boolean
+              Filter Operator
+                isSamplingPred: false
+                predicate:
+                    expr: (ds = '2008-04-08')
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: ds
+                        type: string
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2
+                  Transform Operator
+                    command: /bin/cat
+                    output info:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        properties:
+                          columns _col0,_col1,_col2
+                          columns.types string,string,string
+                          field.delim 9
+                          serialization.format 9
+                    Reduce Output Operator
+                      key expressions:
+                            expr: _col1
+                            type: string
+                      sort order: +
+                      Map-reduce partition columns:
+                            expr: _col1
+                            type: string
+                      tag: -1
+                      value expressions:
+                            expr: _col0
+                            type: string
+                            expr: _col1
+                            type: string
+                            expr: _col2
+                            type: string
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+          Partition
+            base file name: hr=11
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 11
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+          Partition
+            base file name: hr=12
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+              hr 12
+            properties:
+              bucket_count -1
+              columns key,value
+              columns.types string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+              name srcpart
+              partition_columns ds/hr
+              serialization.ddl struct srcpart { string key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284588329
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value
+                columns.types string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
+                name srcpart
+                partition_columns ds/hr
+                serialization.ddl struct srcpart { string key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284588329
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcpart
+            name: srcpart
+      Reduce Operator Tree:
+        Extract
+          Filter Operator
+            isSamplingPred: false
+            predicate:
+                expr: (_col1 < 100)
+                type: boolean
+            Select Operator
+              expressions:
+                    expr: _col1
+                    type: string
+                    expr: _col2
+                    type: string
+              outputColumnNames: _col0, _col1
+              File Output Operator
+                compressed: false
+                GlobalTableId: 0
+                directory: file:/tmp/nzhang/hive_2010-09-15_17-09-57_137_3472461582427948800/-ext-10001
+                NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-09-57_137_3472461582427948800/-ext-10001/
+                table:
+                    input format: org.apache.hadoop.mapred.TextInputFormat
+                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    properties:
+                      columns _col0,_col1
+                      columns.types string:string
+                      serialization.format 1
+                TotalFiles: 1
+                GatherStats: false
+                MultiFileSpray: false
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  WHERE src.ds = '2008-04-08' 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-57_241_6172961698186584468/-mr-10000
+POSTHOOK: query: FROM (
+  FROM srcpart src
+  SELECT TRANSFORM(src.ds, src.key, src.value)
+         USING '/bin/cat' AS (ds, tkey, tvalue) 
+  WHERE src.ds = '2008-04-08' 
+  CLUSTER BY tkey 
+) tmap
+SELECT tmap.tkey, tmap.tvalue WHERE tmap.tkey < 100
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-57_241_6172961698186584468/-mr-10000
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+0	val_0
+10	val_10
+10	val_10
+11	val_11
+11	val_11
+12	val_12
+12	val_12
+12	val_12
+12	val_12
+15	val_15
+15	val_15
+15	val_15
+15	val_15
+17	val_17
+17	val_17
+18	val_18
+18	val_18
+18	val_18
+18	val_18
+19	val_19
+19	val_19
+2	val_2
+2	val_2
+20	val_20
+20	val_20
+24	val_24
+24	val_24
+24	val_24
+24	val_24
+26	val_26
+26	val_26
+26	val_26
+26	val_26
+27	val_27
+27	val_27
+28	val_28
+28	val_28
+30	val_30
+30	val_30
+33	val_33
+33	val_33
+34	val_34
+34	val_34
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+35	val_35
+37	val_37
+37	val_37
+37	val_37
+37	val_37
+4	val_4
+4	val_4
+41	val_41
+41	val_41
+42	val_42
+42	val_42
+42	val_42
+42	val_42
+43	val_43
+43	val_43
+44	val_44
+44	val_44
+47	val_47
+47	val_47
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+5	val_5
+51	val_51
+51	val_51
+51	val_51
+51	val_51
+53	val_53
+53	val_53
+54	val_54
+54	val_54
+57	val_57
+57	val_57
+58	val_58
+58	val_58
+58	val_58
+58	val_58
+64	val_64
+64	val_64
+65	val_65
+65	val_65
+66	val_66
+66	val_66
+67	val_67
+67	val_67
+67	val_67
+67	val_67
+69	val_69
+69	val_69
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+70	val_70
+72	val_72
+72	val_72
+72	val_72
+72	val_72
+74	val_74
+74	val_74
+76	val_76
+76	val_76
+76	val_76
+76	val_76
+77	val_77
+77	val_77
+78	val_78
+78	val_78
+8	val_8
+8	val_8
+80	val_80
+80	val_80
+82	val_82
+82	val_82
+83	val_83
+83	val_83
+83	val_83
+83	val_83
+84	val_84
+84	val_84
+84	val_84
+84	val_84
+85	val_85
+85	val_85
+86	val_86
+86	val_86
+87	val_87
+87	val_87
+9	val_9
+9	val_9
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+90	val_90
+92	val_92
+92	val_92
+95	val_95
+95	val_95
+95	val_95
+95	val_95
+96	val_96
+96	val_96
+97	val_97
+97	val_97
+97	val_97
+97	val_97
+98	val_98
+98	val_98
+98	val_98
+98	val_98
Index: ql/src/test/results/clientpositive/bucketmapjoin4.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin4.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin4.q.out_0.17	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -130,8 +132,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -141,15 +144,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282940548
+                          transient_lastDdlTime 1284588884
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -161,6 +165,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -194,8 +199,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -205,29 +211,30 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940548
+                              transient_lastDdlTime 1284588884
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -239,12 +246,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940544
+              transient_lastDdlTime 1284588880
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -256,31 +263,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940544
+                transient_lastDdlTime 1284588880
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -290,20 +297,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940548
+                transient_lastDdlTime 1284588884
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -319,9 +330,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -332,12 +343,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940548
+              transient_lastDdlTime 1284588884
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -348,12 +359,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940548
+                transient_lastDdlTime 1284588884
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -362,7 +373,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-22-28_815_2194229907693568005/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-14-44_844_4278508565495162911/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -373,15 +384,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940548
+                  transient_lastDdlTime 1284588884
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -405,11 +417,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-36_487_5530889340709868410/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-58_041_5540762083768439940/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-36_487_5530889340709868410/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-14-58_041_5540762083768439940/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -456,11 +468,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-51_020_1463379581902051085/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-21_016_7424850202163160544/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-51_020_1463379581902051085/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-21_016_7424850202163160544/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -499,14 +511,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-57_686_7096755867545611891/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-32_565_6027299689540836518/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-22-57_686_7096755867545611891/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-32_565_6027299689540836518/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -549,10 +561,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -561,6 +574,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -594,8 +608,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -605,15 +620,20 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
+                          numFiles 1
+                          numPartitions 0
+                          numRows 464
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282940570
+                          totalSize 8983
+                          transient_lastDdlTime 1284588920
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -625,6 +645,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -658,8 +679,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -669,29 +691,34 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282940570
+                              totalSize 8983
+                              transient_lastDdlTime 1284588920
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -703,12 +730,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940544
+              transient_lastDdlTime 1284588880
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -720,31 +747,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940544
+                transient_lastDdlTime 1284588880
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -754,20 +781,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940570
+                totalSize 8983
+                transient_lastDdlTime 1284588920
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -783,9 +818,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002 [pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -796,12 +831,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282940570
+              totalSize 8983
+              transient_lastDdlTime 1284588920
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -812,12 +851,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282940570
+                totalSize 8983
+                transient_lastDdlTime 1284588920
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -826,7 +869,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-23-01_358_7828412997606473041/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-15-37_597_8524367555348901163/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -837,15 +880,20 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jsichi/open/commit-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                   name bucketmapjoin_tmp_result
+                  numFiles 1
+                  numPartitions 0
+                  numRows 464
                   serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1282940570
+                  totalSize 8983
+                  transient_lastDdlTime 1284588920
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: bucketmapjoin_tmp_result
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -881,11 +929,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-08_662_1573157002606906486/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-50_221_2593633292912035869/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-08_662_1573157002606906486/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-15-50_221_2593633292912035869/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -968,11 +1016,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-23_132_2052671394021903586/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-16-12_740_5148939712495392388/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-23_132_2052671394021903586/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-16-12_740_5148939712495392388/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1035,14 +1083,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-29_702_5070225151054685201/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-16-23_796_2723748082530083678/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-23-29_702_5070225151054685201/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-16-23_796_2723748082530083678/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/ppd_constant_expr.q.out
===================================================================
--- ql/src/test/results/clientpositive/ppd_constant_expr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/ppd_constant_expr.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -55,14 +56,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: ppd_constant_expr
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-05_879_2735844338849084089/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-16-55_565_7273157164106376396/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -75,9 +76,12 @@
               name: ppd_constant_expr
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-05_879_2735844338849084089/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-16-55_565_7273157164106376396/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -104,11 +108,11 @@
 PREHOOK: query: SELECT ppd_constant_expr.* FROM ppd_constant_expr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@ppd_constant_expr
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-09_777_9157981275279385779/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-01_828_7275648177476387111/-mr-10000
 POSTHOOK: query: SELECT ppd_constant_expr.* FROM ppd_constant_expr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@ppd_constant_expr
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-09_777_9157981275279385779/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-17-01_828_7275648177476387111/-mr-10000
 POSTHOOK: Lineage: ppd_constant_expr.c1 EXPRESSION []
 POSTHOOK: Lineage: ppd_constant_expr.c2 EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: ppd_constant_expr.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/rand_partitionpruner3.q.out
===================================================================
--- ql/src/test/results/clientpositive/rand_partitionpruner3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/rand_partitionpruner3.q.out	(working copy)
@@ -20,6 +20,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -39,8 +40,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-48_719_4692112603796210156/10001
+                  directory: file:/tmp/nzhang/hive_2010-09-14_17-20-12_276_1191513914121430187/-ext-10001
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-20-12_276_1191513914121430187/-ext-10001/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -49,12 +51,13 @@
                         columns.types string:string:string:string
                         serialization.format 1
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -68,13 +71,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452566
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -85,13 +88,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452566
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -104,11 +107,11 @@
 PREHOOK: query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-49_084_536470779116955629/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-12_432_7301102441114288148/-mr-10000
 POSTHOOK: query: select a.* from srcpart a where rand(1) < 0.1 and a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-49_084_536470779116955629/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-12_432_7301102441114288148/-mr-10000
 42	val_42	2008-04-08	12
 44	val_44	2008-04-08	12
 26	val_26	2008-04-08	12
@@ -134,6 +137,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -158,8 +162,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-52_720_5401498092270029345/10001
+                    directory: file:/tmp/nzhang/hive_2010-09-14_17-20-15_973_7050064066243689565/-ext-10001
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-20-15_973_7050064066243689565/-ext-10001/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -168,12 +173,13 @@
                           columns.types string:string:string:string
                           serialization.format 1
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [a]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -187,13 +193,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452566
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -204,13 +210,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452566
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -223,11 +229,11 @@
 PREHOOK: query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-53_140_3749880901987270868/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-16_124_4634224567791862138/-mr-10000
 POSTHOOK: query: select a.* from srcpart a where a.ds = '2008-04-08' and not(key > 50 or key < 10) and a.hr like '%2'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-22-53_140_3749880901987270868/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-20-16_124_4634224567791862138/-mr-10000
 27	val_27	2008-04-08	12
 37	val_37	2008-04-08	12
 15	val_15	2008-04-08	12
Index: ql/src/test/results/clientpositive/groupby2_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby2_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby2_noskew.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -91,7 +92,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_g2
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest_g2 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -108,11 +112,11 @@
 PREHOOK: query: SELECT dest_g2.* FROM dest_g2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_g2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-30_093_3545385733611788497/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-45_836_7801785080274735251/-mr-10000
 POSTHOOK: query: SELECT dest_g2.* FROM dest_g2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_g2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-30_093_3545385733611788497/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-45_836_7801785080274735251/-mr-10000
 POSTHOOK: Lineage: dest_g2.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g2.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_g2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join31.q.out
===================================================================
--- ql/src/test/results/clientpositive/join31.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join31.q.out	(working copy)
@@ -22,10 +22,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-4
+  Stage-2 depends on stages: Stage-1, Stage-5
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 is a root stage
+  Stage-4 depends on stages: Stage-0
+  Stage-5 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -85,7 +86,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-33-22_239_7108281462009864168/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-03_429_6963096500471959468/-mr-10002 
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -107,11 +108,11 @@
       Local Work:
         Map Reduce Local Work
           Alias -> Map Local Tables:
-            file:/tmp/jssarma/hive_2010-07-21_11-33-22_239_7108281462009864168/10004 
+            file:/tmp/nzhang/hive_2010-09-14_16-40-03_429_6963096500471959468/-mr-10004 
               Fetch Operator
                 limit: -1
           Alias -> Map Local Operator Tree:
-            file:/tmp/jssarma/hive_2010-07-21_11-33-22_239_7108281462009864168/10004 
+            file:/tmp/nzhang/hive_2010-09-14_16-40-03_429_6963096500471959468/-mr-10004 
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -134,7 +135,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-33-22_239_7108281462009864168/10003 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-03_429_6963096500471959468/-mr-10003 
           Select Operator
             expressions:
                   expr: _col0
@@ -210,6 +211,9 @@
               name: dest_j1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
         subq1:x 
@@ -287,11 +291,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-32_487_8490983650111837625/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-20_215_8713512212643872558/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-33-32_487_8490983650111837625/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-20_215_8713512212643872558/-mr-10000
 POSTHOOK: Lineage: dest_j1.cnt EXPRESSION [(src1)x.null, (src)y.null, ]
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 128	1
Index: ql/src/test/results/clientpositive/input13.q.out
===================================================================
--- ql/src/test/results/clientpositive/input13.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input13.q.out	(working copy)
@@ -32,22 +32,25 @@
 
 STAGE DEPENDENCIES:
   Stage-4 is a root stage
-  Stage-7 depends on stages: Stage-4 , consists of Stage-6, Stage-5
+  Stage-8 depends on stages: Stage-4 , consists of Stage-7, Stage-6
+  Stage-7
+  Stage-0 depends on stages: Stage-7, Stage-6
+  Stage-5 depends on stages: Stage-0
   Stage-6
-  Stage-0 depends on stages: Stage-6, Stage-5
-  Stage-5
-  Stage-10 depends on stages: Stage-4 , consists of Stage-9, Stage-8
-  Stage-9
-  Stage-1 depends on stages: Stage-9, Stage-8
-  Stage-8
-  Stage-13 depends on stages: Stage-4 , consists of Stage-12, Stage-11
-  Stage-12
-  Stage-2 depends on stages: Stage-12, Stage-11
+  Stage-12 depends on stages: Stage-4 , consists of Stage-11, Stage-10
   Stage-11
+  Stage-1 depends on stages: Stage-11, Stage-10
+  Stage-9 depends on stages: Stage-1
+  Stage-10
   Stage-16 depends on stages: Stage-4 , consists of Stage-15, Stage-14
   Stage-15
-  Stage-3 depends on stages: Stage-15, Stage-14
+  Stage-2 depends on stages: Stage-15, Stage-14
+  Stage-13 depends on stages: Stage-2
   Stage-14
+  Stage-19 depends on stages: Stage-4 , consists of Stage-18, Stage-17
+  Stage-18
+  Stage-3 depends on stages: Stage-18, Stage-17
+  Stage-17
 
 STAGE PLANS:
   Stage: Stage-4
@@ -146,14 +149,14 @@
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
 
-  Stage: Stage-7
+  Stage: Stage-8
     Conditional Operator
 
-  Stage: Stage-6
+  Stage: Stage-7
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -166,9 +169,12 @@
               name: dest1
 
   Stage: Stage-5
+    Stats-Aggr Operator
+
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10007 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10007 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -178,14 +184,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
 
-  Stage: Stage-10
+  Stage: Stage-12
     Conditional Operator
 
-  Stage: Stage-9
+  Stage: Stage-11
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -197,10 +203,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-8
+  Stage: Stage-9
+    Stats-Aggr Operator
+
+  Stage: Stage-10
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10008 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10008 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -210,14 +219,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest2
 
-  Stage: Stage-13
+  Stage: Stage-16
     Conditional Operator
 
-  Stage: Stage-12
+  Stage: Stage-15
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10004
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10004
 
   Stage: Stage-2
     Move Operator
@@ -232,10 +241,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest3
 
-  Stage: Stage-11
+  Stage: Stage-13
+    Stats-Aggr Operator
+
+  Stage: Stage-14
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10009 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10009 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -245,14 +257,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest3
 
-  Stage: Stage-16
+  Stage: Stage-19
     Conditional Operator
 
-  Stage: Stage-15
+  Stage: Stage-18
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10006
+          destination: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10006
 
   Stage: Stage-3
     Move Operator
@@ -260,10 +272,10 @@
           hdfs directory: true
           destination: ../build/ql/test/data/warehouse/dest4.out
 
-  Stage: Stage-14
+  Stage: Stage-17
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-50-17_868_874270772309760488/-ext-10010 
+        file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-26-47_955_4620564381440920404/-ext-10010 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -302,11 +314,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-22_603_8204333485013682573/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_288_6309833081797050565/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-22_603_8204333485013682573/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_288_6309833081797050565/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -399,11 +411,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-22_865_5466685897994447699/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_636_3380977971901935333/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-22_865_5466685897994447699/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_636_3380977971901935333/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -517,11 +529,11 @@
 PREHOOK: query: SELECT dest3.* FROM dest3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-23_137_2677954228712032208/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_986_850981660460088519/-mr-10000
 POSTHOOK: query: SELECT dest3.* FROM dest3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest3@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-50-23_137_2677954228712032208/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-26-57_986_850981660460088519/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input36.q.out
===================================================================
--- ql/src/test/results/clientpositive/input36.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input36.q.out	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-43_924_7494455475900551701/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-30-02_540_6872300994248122833/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-43_924_7494455475900551701/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-30-02_540_6872300994248122833/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -131,11 +135,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-47_890_2318595910087161046/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-08_898_294923407373116493/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-47_890_2318595910087161046/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-30-08_898_294923407373116493/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 NULL	NULL
Index: ql/src/test/results/clientpositive/join34.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join34.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join34.q.out_0.17	(working copy)
@@ -28,10 +28,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -40,6 +41,7 @@
         null-subquery1:subq1-subquery1:x 
           TableScan
             alias: x
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -91,8 +93,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -102,19 +105,21 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                   name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1280084734
+                                  transient_lastDdlTime 1284591501
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
         null-subquery2:subq1-subquery2:x1 
           TableScan
             alias: x1
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -166,8 +171,9 @@
                           File Output Operator
                             compressed: false
                             GlobalTableId: 1
-                            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002
                             NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000/
                             table:
                                 input format: org.apache.hadoop.mapred.TextInputFormat
                                 output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -177,15 +183,16 @@
                                   columns.types string:string:string
                                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                   name dest_j1
                                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                                   serialization.format 1
                                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                  transient_lastDdlTime 1280084734
+                                  transient_lastDdlTime 1284591501
                                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                 name: dest_j1
                             TotalFiles: 1
+                            GatherStats: true
                             MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -197,6 +204,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -230,8 +238,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -241,21 +250,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                               name dest_j1
                               serialization.ddl struct dest_j1 { string key, string value, string val2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1280084734
+                              transient_lastDdlTime 1284591501
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dest_j1
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [null-subquery1:subq1-subquery1:x, null-subquery2:subq1-subquery2:x1]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -266,12 +276,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -282,31 +292,31 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -316,20 +326,24 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280084734
+                transient_lastDdlTime 1284591501
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -345,9 +359,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -358,12 +372,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280084734
+              transient_lastDdlTime 1284591501
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -374,12 +388,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280084734
+                transient_lastDdlTime 1284591501
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -388,7 +402,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-05-34_748_1569842255124853512/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-58-21_397_7725619905158839651/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -399,15 +413,16 @@
                   columns.types string:string:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest_j1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                   name dest_j1
                   serialization.ddl struct dest_j1 { string key, string value, string val2}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280084734
+                  transient_lastDdlTime 1284591501
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest_j1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -441,11 +456,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-05-37_961_7723384539503126895/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-28_894_2704001775198055161/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-05-37_961_7723384539503126895/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-58-28_894_2704001775198055161/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)x.FieldSchema(name:value, type:string, comment:default), (src)x1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join28.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join28.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join28.q.out_0.17	(working copy)
@@ -24,10 +24,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -211,14 +212,14 @@
                                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                   name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-17_782_8830717340632746316/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-36_878_5951936849277621389/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -231,9 +232,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/commit-trunk/build/ql/scratchdir/hive_2010-08-27_13-51-17_782_8830717340632746316/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-56-36_878_5951936849277621389/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -284,11 +288,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-51-22_731_8886120749922178144/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-44_438_1346488510484506804/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-27_13-51-22_731_8886120749922178144/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-56-44_438_1346488510484506804/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
 128	val_128
Index: ql/src/test/results/clientpositive/input_part5.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_part5.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part5.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -56,14 +57,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: tmptable
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-00-04_446_4618719138122182282/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-46_450_1918684783084593548/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -76,9 +77,12 @@
               name: tmptable
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-00-04_446_4618719138122182282/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-51-46_450_1918684783084593548/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -125,11 +129,11 @@
 PREHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tmptable
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-00-15_403_8205955260338045253/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-58_873_8053167769070266052/-mr-10000
 POSTHOOK: query: select * from tmptable x sort by x.key,x.value,x.ds,x.hr
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tmptable
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-00-15_403_8205955260338045253/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-51-58_873_8053167769070266052/-mr-10000
 POSTHOOK: Lineage: tmptable.ds SIMPLE [(srcpart)x.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.hr SIMPLE [(srcpart)x.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: tmptable.key SIMPLE [(srcpart)x.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/merge2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/merge2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge2.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,14 +88,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-12_209_1522005743229327785/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-32_113_8330109570578207020/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -107,9 +108,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-12_209_1522005743229327785/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-32_113_8330109570578207020/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -148,11 +152,11 @@
 PREHOOK: query: select * from test1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@test1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-17_385_7037680308600583084/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-22-41_098_9041086019777261275/-mr-10000
 POSTHOOK: query: select * from test1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@test1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-18_12-02-17_385_7037680308600583084/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-22-41_098_9041086019777261275/-mr-10000
 POSTHOOK: Lineage: test1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: test1.val EXPRESSION [(src)src.null, ]
 0	3
@@ -531,10 +535,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -557,14 +562,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-25_918_7677000357202012346/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-54_062_3876893118538364217/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -577,9 +582,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-25_918_7677000357202012346/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-22-54_062_3876893118538364217/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -636,10 +644,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -662,14 +671,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: test1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-35_313_6530703842056834275/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-06_738_1281026642780179550/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -682,9 +691,12 @@
               name: test1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_12-02-35_313_6530703842056834275/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-23-06_738_1281026642780179550/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
Index: ql/src/test/results/clientpositive/mapreduce3.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce3.q.out	(working copy)
@@ -23,6 +23,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -96,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -120,11 +124,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-19-00_231_6836040621291752163/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-18_643_1313974049756076835/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-19-00_231_6836040621291752163/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-18_643_1313974049756076835/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/alter3.q.out
===================================================================
--- ql/src/test/results/clientpositive/alter3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/alter3.q.out	(working copy)
@@ -30,11 +30,11 @@
 PREHOOK: query: select * from alter3 where pcol1='test_part' and pcol2='test_part'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alter3@pcol1=test_part/pcol2=test_part
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-50_246_3059048204030358180/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-08-57_327_5944493503891814458/-mr-10000
 POSTHOOK: query: select * from alter3 where pcol1='test_part' and pcol2='test_part'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter3@pcol1=test_part/pcol2=test_part
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-50_246_3059048204030358180/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-08-57_327_5944493503891814458/-mr-10000
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 1	test_part	test_part
 2	test_part	test_part
@@ -69,17 +69,21 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:00:47 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:08:51 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_renamed	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_renamed	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472850          
-	transient_lastDdlTime	1284472850          
+	numPartitions       	1                   
+	numFiles            	1                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049337          
+	transient_lastDdlTime	1285049337          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -111,12 +115,15 @@
 Partition Value:    	[test_part, test_part]	 
 Database:           	default             	 
 Table:              	alter3_renamed      	 
-CreateTime:         	Tue Sep 14 07:00:50 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:08:56 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_renamed/pcol1=test_part/pcol2=test_part	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_renamed/pcol1=test_part/pcol2=test_part	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284472850          
+	numFiles            	1                   
+	transient_lastDdlTime	1285049337          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -132,11 +139,11 @@
 PREHOOK: query: select * from alter3_renamed where pcol1='test_part' and pcol2='test_part'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@alter3_renamed@pcol1=test_part/pcol2=test_part
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-50_945_3576751943350456783/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-08-58_285_926659329473097768/-mr-10000
 POSTHOOK: query: select * from alter3_renamed where pcol1='test_part' and pcol2='test_part'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@alter3_renamed@pcol1=test_part/pcol2=test_part
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-50_945_3576751943350456783/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-08-58_285_926659329473097768/-mr-10000
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 1	test_part	test_part
 2	test_part	test_part
@@ -187,18 +194,22 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:00:47 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:08:51 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_like_renamed	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_like_renamed	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numPartitions       	1                   
 	EXTERNAL            	FALSE               
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472853          
-	transient_lastDdlTime	1284472853          
+	numFiles            	1                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049344          
+	transient_lastDdlTime	1285049344          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -321,11 +332,11 @@
 PREHOOK: query: SELECT * FROM alter3 WHERE pcol1='test_part' AND pcol2='test_part'
 PREHOOK: type: QUERY
 PREHOOK: Input: alter3_db@alter3@pcol1=test_part/pcol2=test_part
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-56_813_3326597749899975226/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-09-12_328_7205460480200294317/-mr-10000
 POSTHOOK: query: SELECT * FROM alter3 WHERE pcol1='test_part' AND pcol2='test_part'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: alter3_db@alter3@pcol1=test_part/pcol2=test_part
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-56_813_3326597749899975226/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-09-12_328_7205460480200294317/-mr-10000
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: alter3_like PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
@@ -366,17 +377,21 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	alter3_db           	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:00:54 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:09:06 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_db.db/alter3_renamed	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_db.db/alter3_renamed	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472856          
-	transient_lastDdlTime	1284472856          
+	numPartitions       	1                   
+	numFiles            	1                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049352          
+	transient_lastDdlTime	1285049352          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -410,12 +425,15 @@
 Partition Value:    	[test_part, test_part]	 
 Database:           	alter3_db           	 
 Table:              	alter3_renamed      	 
-CreateTime:         	Tue Sep 14 07:00:56 PDT 2010	 
+CreateTime:         	Mon Sep 20 23:09:11 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_db.db/alter3_renamed/pcol1=test_part/pcol2=test_part	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_db.db/alter3_renamed/pcol1=test_part/pcol2=test_part	 
 Partition Parameters:	 	 
-	transient_lastDdlTime	1284472856          
+	numFiles            	1                   
+	transient_lastDdlTime	1285049352          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -431,11 +449,11 @@
 PREHOOK: query: SELECT * FROM alter3_renamed WHERE pcol1='test_part' AND pcol2='test_part'
 PREHOOK: type: QUERY
 PREHOOK: Input: alter3_db@alter3_renamed@pcol1=test_part/pcol2=test_part
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-57_116_2454861448129579790/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-09-13_149_6501372199049102565/-mr-10000
 POSTHOOK: query: SELECT * FROM alter3_renamed WHERE pcol1='test_part' AND pcol2='test_part'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: alter3_db@alter3_renamed@pcol1=test_part/pcol2=test_part
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-00-57_116_2454861448129579790/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-20_23-09-13_149_6501372199049102565/-mr-10000
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: alter3 PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
 POSTHOOK: Lineage: alter3_like PARTITION(pcol1=test_part,pcol2=test_part).col1 SIMPLE [(alter3_src)alter3_src.FieldSchema(name:col1, type:string, comment:null), ]
@@ -494,18 +512,22 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	alter3_db           	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 07:00:54 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Mon Sep 20 23:09:06 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/alter3_db.db/alter3_like_renamed	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/alter3_db.db/alter3_like_renamed	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
+	numPartitions       	1                   
 	EXTERNAL            	FALSE               
-	last_modified_by    	thiruvel            
-	last_modified_time  	1284472859          
-	transient_lastDdlTime	1284472859          
+	numFiles            	1                   
+	last_modified_by    	nzhang              
+	last_modified_time  	1285049360          
+	transient_lastDdlTime	1285049360          
+	numRows             	6                   
+	totalSize           	171                 
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
Index: ql/src/test/results/clientpositive/ctas.q.out
===================================================================
--- ql/src/test/results/clientpositive/ctas.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/ctas.q.out	(working copy)
@@ -6,11 +6,11 @@
 PREHOOK: query: select * from nzhang_Tmp
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_tmp
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-49-56_789_8053581931767422236/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-08-50_551_5274699533452501897/-mr-10000
 POSTHOOK: query: select * from nzhang_Tmp
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_tmp
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-49-56_789_8053581931767422236/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-08-50_551_5274699533452501897/-mr-10000
 PREHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
 PREHOOK: type: CREATETABLE
 POSTHOOK: query: explain create table nzhang_CTAS1 as select key k, value from src sort by k, value limit 10
@@ -64,7 +64,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_11-49-56_885_8970318104409365566/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-08-50_746_7813189274106710723/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -92,7 +92,7 @@
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:///data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/nzhang_ctas1
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_ctas1
 
   Stage: Stage-3
       Create Table Operator:
@@ -116,11 +116,11 @@
 PREHOOK: query: select * from nzhang_CTAS1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-05_215_7362711844632151790/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-08-57_963_8224718269640555492/-mr-10000
 POSTHOOK: query: select * from nzhang_CTAS1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-05_215_7362711844632151790/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-08-57_963_8224718269640555492/-mr-10000
 0	val_0
 0	val_0
 0	val_0
@@ -184,7 +184,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-05_522_404897969004847381/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-08-58_369_8941154562114122989/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -212,7 +212,7 @@
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:///data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/nzhang_ctas2
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_ctas2
 
   Stage: Stage-3
       Create Table Operator:
@@ -236,11 +236,11 @@
 PREHOOK: query: select * from nzhang_ctas2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-10_969_3097102178230917187/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-06_188_7275645807830573530/-mr-10000
 POSTHOOK: query: select * from nzhang_ctas2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-10_969_3097102178230917187/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-06_188_7275645807830573530/-mr-10000
 0	val_0
 0	val_0
 0	val_0
@@ -304,7 +304,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-11_230_7851706392742680650/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-09-06_591_311725779652798393/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -332,7 +332,7 @@
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:///data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/nzhang_ctas3
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_ctas3
 
   Stage: Stage-3
       Create Table Operator:
@@ -357,11 +357,11 @@
 PREHOOK: query: select * from nzhang_ctas3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas3
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-16_423_4984706586442992530/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-14_409_3860619873030897976/-mr-10000
 POSTHOOK: query: select * from nzhang_ctas3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas3
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-16_423_4984706586442992530/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-14_409_3860619873030897976/-mr-10000
 0.0	val_0_con
 0.0	val_0_con
 0.0	val_0_con
@@ -390,11 +390,11 @@
 PREHOOK: query: select * from nzhang_ctas3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas3
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-16_812_7382695559497137315/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-15_055_2704821239289766796/-mr-10000
 POSTHOOK: query: select * from nzhang_ctas3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas3
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-16_812_7382695559497137315/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-15_055_2704821239289766796/-mr-10000
 0.0	val_0_con
 0.0	val_0_con
 0.0	val_0_con
@@ -458,7 +458,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-17_128_289519796406783178/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-09-15_571_515417720676742183/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -486,7 +486,7 @@
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:///data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/nzhang_ctas4
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_ctas4
 
   Stage: Stage-3
       Create Table Operator:
@@ -511,11 +511,11 @@
 PREHOOK: query: select * from nzhang_ctas4
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_ctas4
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-22_425_2648812324905078461/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-22_874_9020816893750253212/-mr-10000
 POSTHOOK: query: select * from nzhang_ctas4
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_ctas4
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_11-50-22_425_2648812324905078461/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-09-22_874_9020816893750253212/-mr-10000
 0	val_0
 0	val_0
 0	val_0
@@ -546,6 +546,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -568,9 +569,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -581,12 +582,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082972
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -597,12 +598,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082972
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -612,7 +613,7 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/jssarma/hive_2010-07-25_11-50-22_687_6004057340342647746/-mr-10002
+              directory: file:/tmp/nzhang/hive_2010-09-14_16-09-23_273_3246979497224742620/-mr-10002
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -622,12 +623,13 @@
                     columns.types string,string
                     escape.delim \
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-22_687_6004057340342647746/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-09-23_273_3246979497224742620/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -643,9 +645,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-22_687_6004057340342647746/-mr-10002 [file:/tmp/jssarma/hive_2010-07-25_11-50-22_687_6004057340342647746/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-14_16-09-23_273_3246979497224742620/-mr-10002 [file:/tmp/nzhang/hive_2010-09-14_16-09-23_273_3246979497224742620/-mr-10002]
       Path -> Partition:
-        file:/tmp/jssarma/hive_2010-07-25_11-50-22_687_6004057340342647746/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-09-23_273_3246979497224742620/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -667,8 +669,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-50-22_687_6004057340342647746/-ext-10001
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-09-23_273_3246979497224742620/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-09-23_273_3246979497224742620/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -680,14 +683,15 @@
 
                     serialization.format ,
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_11-50-22_687_6004057340342647746/-ext-10001
-          destination: pfile:///data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/nzhang_ctas5
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-09-23_273_3246979497224742620/-ext-10001
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_ctas5
 
   Stage: Stage-3
       Create Table Operator:
Index: ql/src/test/results/clientpositive/stats10.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats10.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats10.q.out	(revision 0)
@@ -0,0 +1,569 @@
+PREHOOK: query: CREATE TABLE bucket3_1(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE bucket3_1(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucket3_1
+PREHOOK: query: explain
+insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF src)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucket3_1 (TOK_PARTSPEC (TOK_PARTVAL ds '1')))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Reduce Output Operator
+                sort order: 
+                Map-reduce partition columns:
+                      expr: UDFToInteger(_col0)
+                      type: int
+                tag: -1
+                value expressions:
+                      expr: _col0
+                      type: string
+                      expr: _col1
+                      type: string
+      Reduce Operator Tree:
+        Extract
+          Select Operator
+            expressions:
+                  expr: UDFToInteger(_col0)
+                  type: int
+                  expr: _col1
+                  type: string
+            outputColumnNames: _col0, _col1
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: bucket3_1
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 1
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucket3_1
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+
+
+PREHOOK: query: insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@bucket3_1@ds=1
+POSTHOOK: query: insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@bucket3_1@ds=1
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@bucket3_1@ds=1
+POSTHOOK: query: insert overwrite table bucket3_1 partition (ds='1')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@bucket3_1@ds=1
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: insert overwrite table bucket3_1 partition (ds='2')
+select * from src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@bucket3_1@ds=2
+POSTHOOK: query: insert overwrite table bucket3_1 partition (ds='2')
+select * from src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@bucket3_1@ds=2
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: select * from bucket3_1 tablesample (bucket 1 out of 2) s where ds = '1' order by key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucket3_1@ds=1
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-08-16_021_199922498876438567/-mr-10000
+POSTHOOK: query: select * from bucket3_1 tablesample (bucket 1 out of 2) s where ds = '1' order by key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucket3_1@ds=1
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_01-08-16_021_199922498876438567/-mr-10000
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+0	val_0	1
+0	val_0	1
+0	val_0	1
+2	val_2	1
+4	val_4	1
+8	val_8	1
+10	val_10	1
+12	val_12	1
+12	val_12	1
+18	val_18	1
+18	val_18	1
+20	val_20	1
+24	val_24	1
+24	val_24	1
+26	val_26	1
+26	val_26	1
+28	val_28	1
+30	val_30	1
+34	val_34	1
+42	val_42	1
+42	val_42	1
+44	val_44	1
+54	val_54	1
+58	val_58	1
+58	val_58	1
+64	val_64	1
+66	val_66	1
+70	val_70	1
+70	val_70	1
+70	val_70	1
+72	val_72	1
+72	val_72	1
+74	val_74	1
+76	val_76	1
+76	val_76	1
+78	val_78	1
+80	val_80	1
+82	val_82	1
+84	val_84	1
+84	val_84	1
+86	val_86	1
+90	val_90	1
+90	val_90	1
+90	val_90	1
+92	val_92	1
+96	val_96	1
+98	val_98	1
+98	val_98	1
+100	val_100	1
+100	val_100	1
+104	val_104	1
+104	val_104	1
+114	val_114	1
+116	val_116	1
+118	val_118	1
+118	val_118	1
+120	val_120	1
+120	val_120	1
+126	val_126	1
+128	val_128	1
+128	val_128	1
+128	val_128	1
+134	val_134	1
+134	val_134	1
+136	val_136	1
+138	val_138	1
+138	val_138	1
+138	val_138	1
+138	val_138	1
+146	val_146	1
+146	val_146	1
+150	val_150	1
+152	val_152	1
+152	val_152	1
+156	val_156	1
+158	val_158	1
+160	val_160	1
+162	val_162	1
+164	val_164	1
+164	val_164	1
+166	val_166	1
+168	val_168	1
+170	val_170	1
+172	val_172	1
+172	val_172	1
+174	val_174	1
+174	val_174	1
+176	val_176	1
+176	val_176	1
+178	val_178	1
+180	val_180	1
+186	val_186	1
+190	val_190	1
+192	val_192	1
+194	val_194	1
+196	val_196	1
+200	val_200	1
+200	val_200	1
+202	val_202	1
+208	val_208	1
+208	val_208	1
+208	val_208	1
+214	val_214	1
+216	val_216	1
+216	val_216	1
+218	val_218	1
+222	val_222	1
+224	val_224	1
+224	val_224	1
+226	val_226	1
+228	val_228	1
+230	val_230	1
+230	val_230	1
+230	val_230	1
+230	val_230	1
+230	val_230	1
+238	val_238	1
+238	val_238	1
+242	val_242	1
+242	val_242	1
+244	val_244	1
+248	val_248	1
+252	val_252	1
+256	val_256	1
+256	val_256	1
+258	val_258	1
+260	val_260	1
+262	val_262	1
+266	val_266	1
+272	val_272	1
+272	val_272	1
+274	val_274	1
+278	val_278	1
+278	val_278	1
+280	val_280	1
+280	val_280	1
+282	val_282	1
+282	val_282	1
+284	val_284	1
+286	val_286	1
+288	val_288	1
+288	val_288	1
+292	val_292	1
+296	val_296	1
+298	val_298	1
+298	val_298	1
+298	val_298	1
+302	val_302	1
+306	val_306	1
+308	val_308	1
+310	val_310	1
+316	val_316	1
+316	val_316	1
+316	val_316	1
+318	val_318	1
+318	val_318	1
+318	val_318	1
+322	val_322	1
+322	val_322	1
+332	val_332	1
+336	val_336	1
+338	val_338	1
+342	val_342	1
+342	val_342	1
+344	val_344	1
+344	val_344	1
+348	val_348	1
+348	val_348	1
+348	val_348	1
+348	val_348	1
+348	val_348	1
+356	val_356	1
+360	val_360	1
+362	val_362	1
+364	val_364	1
+366	val_366	1
+368	val_368	1
+374	val_374	1
+378	val_378	1
+382	val_382	1
+382	val_382	1
+384	val_384	1
+384	val_384	1
+384	val_384	1
+386	val_386	1
+392	val_392	1
+394	val_394	1
+396	val_396	1
+396	val_396	1
+396	val_396	1
+400	val_400	1
+402	val_402	1
+404	val_404	1
+404	val_404	1
+406	val_406	1
+406	val_406	1
+406	val_406	1
+406	val_406	1
+414	val_414	1
+414	val_414	1
+418	val_418	1
+424	val_424	1
+424	val_424	1
+430	val_430	1
+430	val_430	1
+430	val_430	1
+432	val_432	1
+436	val_436	1
+438	val_438	1
+438	val_438	1
+438	val_438	1
+444	val_444	1
+446	val_446	1
+448	val_448	1
+452	val_452	1
+454	val_454	1
+454	val_454	1
+454	val_454	1
+458	val_458	1
+458	val_458	1
+460	val_460	1
+462	val_462	1
+462	val_462	1
+466	val_466	1
+466	val_466	1
+466	val_466	1
+468	val_468	1
+468	val_468	1
+468	val_468	1
+468	val_468	1
+470	val_470	1
+472	val_472	1
+478	val_478	1
+478	val_478	1
+480	val_480	1
+480	val_480	1
+480	val_480	1
+482	val_482	1
+484	val_484	1
+490	val_490	1
+492	val_492	1
+492	val_492	1
+494	val_494	1
+496	val_496	1
+498	val_498	1
+498	val_498	1
+498	val_498	1
+PREHOOK: query: explain analyze table bucket3_1 partition (ds) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table bucket3_1 partition (ds) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE bucket3_1 (TOK_PARTSPEC (TOK_PARTVAL ds))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        bucket3_1 
+          TableScan
+            alias: bucket3_1
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table bucket3_1 partition (ds) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@bucket3_1@ds=1
+PREHOOK: Input: default@bucket3_1@ds=2
+PREHOOK: Output: default@bucket3_1
+PREHOOK: Output: default@bucket3_1@ds=1
+PREHOOK: Output: default@bucket3_1@ds=2
+POSTHOOK: query: analyze table bucket3_1 partition (ds) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@bucket3_1@ds=1
+POSTHOOK: Input: default@bucket3_1@ds=2
+POSTHOOK: Output: default@bucket3_1
+POSTHOOK: Output: default@bucket3_1@ds=1
+POSTHOOK: Output: default@bucket3_1@ds=2
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended bucket3_1 partition (ds='1')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended bucket3_1 partition (ds='1')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[1]                 	 
+Database:           	default             	 
+Table:              	bucket3_1           	 
+CreateTime:         	Tue Sep 21 01:08:01 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket3_1/ds=1	 
+Partition Parameters:	 	 
+	numFiles            	2                   
+	transient_lastDdlTime	1285056506          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	2                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended bucket3_1 partition (ds='2')
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended bucket3_1 partition (ds='2')
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2]                 	 
+Database:           	default             	 
+Table:              	bucket3_1           	 
+CreateTime:         	Tue Sep 21 01:08:15 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket3_1/ds=2	 
+Partition Parameters:	 	 
+	numFiles            	2                   
+	transient_lastDdlTime	1285056506          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	2                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended bucket3_1
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended bucket3_1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: bucket3_1 PARTITION(ds=2).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	int                 	None                
+value               	string              	None                
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 01:07:54 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucket3_1	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	numFiles            	4                   
+	transient_lastDdlTime	1285056506          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	2                   	 
+Bucket Columns:     	[key]               	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/groupby4_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby4_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby4_map_skew.q.out	(working copy)
@@ -15,6 +15,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -72,7 +73,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT count(1)
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
@@ -85,10 +89,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-45_768_6762297488771007246/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-56_131_6804042793044840174/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-09-45_768_6762297488771007246/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-56_131_6804042793044840174/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.null, ]
 500
Index: ql/src/test/results/clientpositive/bucket4.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucket4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucket4.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -48,9 +50,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -61,12 +63,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284513860
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -77,12 +79,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284513860
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -98,8 +100,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-26_887_4786734363166528929/10000
+              directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-23_792_6277370088719829339/-ext-10000
               NumFilesPerFileSink: 2
+              Stats Publishing Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-23_792_6277370088719829339/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -111,22 +114,23 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket4_1
+                    location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket4_1
                     name bucket4_1
                     serialization.ddl struct bucket4_1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279735766
+                    transient_lastDdlTime 1284513863
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket4_1
               TotalFiles: 2
+              GatherStats: true
               MultiFileSpray: true
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-26_887_4786734363166528929/10000
+          source: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-23_792_6277370088719829339/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -138,17 +142,21 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket4_1
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket4_1
                 name bucket4_1
                 serialization.ddl struct bucket4_1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735766
+                transient_lastDdlTime 1284513863
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket4_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-09-26_887_4786734363166528929/10001
+          tmp directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-23_792_6277370088719829339/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-23_792_6277370088719829339/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket4_1
 select * from src
 PREHOOK: type: QUERY
@@ -213,11 +221,11 @@
 PREHOOK: query: select * from bucket4_1 tablesample (bucket 1 out of 2) s
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket4_1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-29_642_3068318549775797820/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-32_425_2483781603651828525/-mr-10000
 POSTHOOK: query: select * from bucket4_1 tablesample (bucket 1 out of 2) s
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket4_1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-09-29_642_3068318549775797820/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-32_425_2483781603651828525/-mr-10000
 POSTHOOK: Lineage: bucket4_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket4_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/groupby7_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby7_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby7_noskew.q.out	(working copy)
@@ -24,8 +24,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -110,9 +112,12 @@
               name: dest1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-25_163_6927899004048250148/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-23_922_8552184341646841192/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -168,7 +173,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, sum(SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -190,11 +198,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-36_109_3486923483688099286/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-38_217_226143875133827262/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-36_109_3486923483688099286/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-38_217_226143875133827262/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -511,11 +519,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-36_230_2911270483153203866/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-38_684_5084956866699197121/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-36_230_2911270483153203866/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-38_684_5084956866699197121/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby6_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby6_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby6_map.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -78,7 +79,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT DISTINCT substr(src.value,5,1)
 PREHOOK: type: QUERY
@@ -93,11 +97,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-22_287_8134358453872792628/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-00_898_5682148816002518734/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-09-22_287_8134358453872792628/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-17-00_898_5682148816002518734/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0
 1
Index: ql/src/test/results/clientpositive/join37.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/join37.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/join37.q.out_0.17	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-59-23_084_5025868117733478455/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-59-25_835_2193452055127028776/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_12-59-23_084_5025868117733478455/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-59-25_835_2193452055127028776/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -203,11 +207,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-59-28_143_4579787448027407977/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-59-33_182_3156434052257975655/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-59-28_143_4579787448027407977/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-59-33_182_3156434052257975655/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udtf_explode.q.out
===================================================================
--- ql/src/test/results/clientpositive/udtf_explode.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udtf_explode.q.out	(working copy)
@@ -26,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: array(1,2,3)
@@ -37,8 +38,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-20_579_1032637901953811782/-ext-10001
+                    directory: file:/tmp/nzhang/hive_2010-09-15_17-34-12_472_461078458690479492/-ext-10001
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-34-12_472_461078458690479492/-ext-10001/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -47,12 +49,13 @@
                           columns.types int
                           serialization.format 1
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -63,12 +66,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282715837
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -79,12 +82,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282715837
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -113,6 +116,7 @@
         a:src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: array(1,2,3)
@@ -129,9 +133,9 @@
                           type: int
       Needs Tagging: false
       Path -> Alias:
-        pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src [a:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a:src]
       Path -> Partition:
-        pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -142,12 +146,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282715837
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -158,12 +162,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/carl/Projects/hive-base/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282715837
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -187,7 +191,7 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-mr-10002
+                  directory: file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-mr-10002
                   NumFilesPerFileSink: 1
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -197,12 +201,13 @@
                         columns.types int,bigint
                         escape.delim \
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
 
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -217,9 +222,9 @@
                     type: bigint
       Needs Tagging: false
       Path -> Alias:
-        file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-mr-10002 [file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-mr-10002]
+        file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-mr-10002 [file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-mr-10002]
       Path -> Partition:
-        file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -255,8 +260,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_070_3243714428136533506/-ext-10001
+              directory: file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-34-12_511_3699113220853694956/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -265,6 +271,7 @@
                     columns.types int:bigint
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -275,33 +282,33 @@
 PREHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_203_3823746274402933485/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-12_563_1523905309826369917/-mr-10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-22_203_3823746274402933485/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-12_563_1523905309826369917/-mr-10000
 1
 2
 3
 PREHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-30_768_8764239289780414796/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-16_104_3527117414764259158/-mr-10000
 POSTHOOK: query: SELECT explode(array(1,2,3)) AS (myCol) FROM src LIMIT 3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-30_768_8764239289780414796/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-16_104_3527117414764259158/-mr-10000
 1
 2
 3
 PREHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-34_517_4011176611215961822/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-19_634_506308003652349415/-mr-10000
 POSTHOOK: query: SELECT a.myCol, count(1) FROM (SELECT explode(array(1,2,3)) AS myCol FROM src LIMIT 3) a GROUP BY a.myCol
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/var/folders/b7/b7UUwNZdF1KKHtM+5la6f++++TI/-Tmp-/carl/hive_2010-08-24_22-57-34_517_4011176611215961822/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-34-19_634_506308003652349415/-mr-10000
 1	1
 2	1
 3	1
Index: ql/src/test/results/clientpositive/merge3.q.out
===================================================================
--- ql/src/test/results/clientpositive/merge3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/merge3.q.out	(working copy)
@@ -66,6 +66,7 @@
         merge_src 
           TableScan
             alias: merge_src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -76,8 +77,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 1
-                directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002
+                directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -86,12 +88,13 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src [merge_src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src [merge_src]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src 
           Partition
             base file name: merge_src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -102,12 +105,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src
               name merge_src
               serialization.ddl struct merge_src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971668
+              transient_lastDdlTime 1284509125
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -118,12 +121,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src
                 name merge_src
                 serialization.ddl struct merge_src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971668
+                transient_lastDdlTime 1284509125
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src
             name: merge_src
@@ -135,15 +138,15 @@
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10001
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10001
 
   Stage: Stage-0
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10001
-          destination: pfile:///data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src2
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10001
+          destination: pfile:///data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src2
 
   Stage: Stage-5
       Create Table Operator:
@@ -159,11 +162,11 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10001
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10001
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -173,12 +176,13 @@
                     columns.types string:string
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-47-54_439_6852513231271626844/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-34_772_3930999175752285186/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -212,11 +216,11 @@
 PREHOOK: query: select * from merge_src2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-02_291_5152914863270003771/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-05-42_636_2818761556740634416/-mr-10000
 POSTHOOK: query: select * from merge_src2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-02_291_5152914863270003771/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-05-42_636_2818761556740634416/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -2249,10 +2253,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -2261,6 +2266,7 @@
         merge_src_part 
           TableScan
             alias: merge_src_part
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -2283,8 +2289,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2295,23 +2302,28 @@
                           columns.types string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                           name merge_src_part2
+                          numFiles 4
+                          numPartitions 2
+                          numRows 2000
                           partition_columns ds
                           serialization.ddl struct merge_src_part2 { string key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1283971682
+                          totalSize 23248
+                          transient_lastDdlTime 1284509143
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: merge_src_part2
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [merge_src_part]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [merge_src_part]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2324,13 +2336,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971668
+              totalSize 23248
+              transient_lastDdlTime 1284509134
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2341,17 +2357,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971668
+                totalSize 23248
+                transient_lastDdlTime 1284509134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2364,13 +2384,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971668
+              totalSize 23248
+              transient_lastDdlTime 1284509134
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2381,26 +2405,30 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971668
+                totalSize 23248
+                transient_lastDdlTime 1284509134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -2408,7 +2436,7 @@
           partition:
             ds 
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -2419,25 +2447,33 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971682
+                totalSize 23248
+                transient_lastDdlTime 1284509143
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2449,22 +2485,27 @@
                     columns.types string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                     name merge_src_part2
+                    numFiles 4
+                    numPartitions 2
+                    numRows 2000
                     partition_columns ds
                     serialization.ddl struct merge_src_part2 { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1283971682
+                    totalSize 23248
+                    transient_lastDdlTime 1284509143
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: merge_src_part2
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-02_839_155834899782197272/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-43_139_4663113902659897013/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2476,13 +2517,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
               name merge_src_part2
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part2 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971682
+              totalSize 23248
+              transient_lastDdlTime 1284509143
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -2494,13 +2539,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971682
+                totalSize 23248
+                transient_lastDdlTime 1284509143
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
             name: merge_src_part2
@@ -2546,12 +2595,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-08
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-09
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-11_708_6923131075189797354/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-05-55_958_2550901900768022933/-mr-10000
 POSTHOOK: query: select * from merge_src_part2 where ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-08
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-09
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-11_708_6923131075189797354/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-05-55_958_2550901900768022933/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -4612,10 +4661,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -4624,6 +4674,7 @@
         s:merge_src_part 
           TableScan
             alias: merge_src_part
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -4658,10 +4709,10 @@
                           type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [s:merge_src_part]
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [s:merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 [s:merge_src_part]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 [s:merge_src_part]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-08 
           Partition
             base file name: ds=2008-04-08
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4674,13 +4725,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971668
+              totalSize 23248
+              transient_lastDdlTime 1284509134
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4691,17 +4746,21 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971668
+                totalSize 23248
+                transient_lastDdlTime 1284509134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part/ds=2008-04-09 
           Partition
             base file name: ds=2008-04-09
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4714,13 +4773,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
               name merge_src_part
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971668
+              totalSize 23248
+              transient_lastDdlTime 1284509134
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4731,13 +4794,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part
                 name merge_src_part
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971668
+                totalSize 23248
+                transient_lastDdlTime 1284509134
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part
             name: merge_src_part
@@ -4755,8 +4822,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -4767,27 +4835,32 @@
                     columns.types string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                     name merge_src_part2
+                    numFiles 4
+                    numPartitions 2
+                    numRows 2000
                     partition_columns ds
                     serialization.ddl struct merge_src_part2 { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1283971693
+                    totalSize 23248
+                    transient_lastDdlTime 1284509157
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: merge_src_part2
               TotalFiles: 1
+              GatherStats: true
               MultiFileSpray: false
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -4795,7 +4868,7 @@
           partition:
             ds 
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -4806,25 +4879,33 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971693
+                totalSize 23248
+                transient_lastDdlTime 1284509157
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4836,22 +4917,27 @@
                     columns.types string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                     name merge_src_part2
+                    numFiles 4
+                    numPartitions 2
+                    numRows 2000
                     partition_columns ds
                     serialization.ddl struct merge_src_part2 { string key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1283971693
+                    totalSize 23248
+                    transient_lastDdlTime 1284509157
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: merge_src_part2
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-13_311_4634740969138216475/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-05-57_081_6030095372534174430/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4863,13 +4949,17 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
               name merge_src_part2
+              numFiles 4
+              numPartitions 2
+              numRows 2000
               partition_columns ds
               serialization.ddl struct merge_src_part2 { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283971693
+              totalSize 23248
+              transient_lastDdlTime 1284509157
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -4881,13 +4971,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/merge_src_part2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/merge_src_part2
                 name merge_src_part2
+                numFiles 4
+                numPartitions 2
+                numRows 2000
                 partition_columns ds
                 serialization.ddl struct merge_src_part2 { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283971693
+                totalSize 23248
+                transient_lastDdlTime 1284509157
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: merge_src_part2
             name: merge_src_part2
@@ -4941,12 +5035,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-08
 PREHOOK: Input: default@merge_src_part2@ds=2008-04-09
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-24_614_5926416412056888638/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-11_803_8918669679801656706/-mr-10000
 POSTHOOK: query: select * from merge_src_part2 where ds is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-08
 POSTHOOK: Input: default@merge_src_part2@ds=2008-04-09
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-24_614_5926416412056888638/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-11_803_8918669679801656706/-mr-10000
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-08).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: merge_src_part PARTITION(ds=2008-04-09).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/join5.q.out
===================================================================
--- ql/src/test/results/clientpositive/join5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join5.q.out	(working copy)
@@ -39,6 +39,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -169,7 +170,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
  FROM 
   (
@@ -209,11 +213,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-20-21_468_7228840395114661280/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-41_389_6784091755620486642/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-20-21_468_7228840395114661280/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-43-41_389_6784091755620486642/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(src)src1.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/outer_join_ppr.q.out
===================================================================
--- ql/src/test/results/clientpositive/outer_join_ppr.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/outer_join_ppr.q.out	(working copy)
@@ -30,6 +30,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -47,6 +48,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -65,13 +67,13 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -82,12 +84,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -98,16 +100,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -121,13 +123,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -138,17 +140,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -162,13 +164,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -179,17 +181,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -203,13 +205,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284969417
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -220,17 +222,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284969417
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -244,13 +246,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1284969417
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -261,13 +263,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/amarsri/workspace/hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1284969417
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -302,8 +304,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-21-27_620_7830111987780351854/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-35_793_1387048173001883243/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-35_793_1387048173001883243/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -312,6 +315,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -332,7 +336,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-21-27_783_281010121981553022/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-36_074_492288488901989767/-mr-10000
 POSTHOOK: query: FROM 
   src a
  FULL OUTER JOIN 
@@ -346,7 +350,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-21-27_783_281010121981553022/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-36_074_492288488901989767/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
@@ -391,6 +395,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -408,6 +413,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Reduce Output Operator
               key expressions:
                     expr: key
@@ -426,13 +432,13 @@
                     type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [a]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -443,12 +449,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1285105506
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -459,16 +465,16 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1285105506
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -482,13 +488,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -499,17 +505,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -523,13 +529,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -540,17 +546,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -564,13 +570,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -581,17 +587,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -605,13 +611,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861471
+              transient_lastDdlTime 1285105497
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -622,13 +628,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861471
+                transient_lastDdlTime 1285105497
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -660,8 +666,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_16-21-32_388_6011123055029150164/-ext-10001
+                directory: file:/tmp/nzhang/hive_2010-09-21_14-45-43_282_4537623029582452473/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-21_14-45-43_282_4537623029582452473/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -670,6 +677,7 @@
                       columns.types string:string:string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -690,7 +698,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-21-32_555_1412573489698439156/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-43_544_7990319034982476830/-mr-10000
 POSTHOOK: query: FROM 
   src a
  FULL OUTER JOIN 
@@ -704,7 +712,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_16-21-32_555_1412573489698439156/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-45-43_544_7990319034982476830/-mr-10000
 17	val_17	17	val_17
 17	val_17	17	val_17
 18	val_18	18	val_18
Index: ql/src/test/results/clientpositive/union18.q.out
===================================================================
--- ql/src/test/results/clientpositive/union18.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union18.q.out	(working copy)
@@ -31,16 +31,18 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-3 depends on stages: Stage-2, Stage-10
-  Stage-6 depends on stages: Stage-3 , consists of Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-2, Stage-12
+  Stage-7 depends on stages: Stage-3 , consists of Stage-6, Stage-5
+  Stage-6
+  Stage-0 depends on stages: Stage-6, Stage-5
+  Stage-4 depends on stages: Stage-0
   Stage-5
-  Stage-0 depends on stages: Stage-5, Stage-4
-  Stage-4
-  Stage-9 depends on stages: Stage-3 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
-  Stage-10 is a root stage
+  Stage-11 depends on stages: Stage-3 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
+  Stage-12 is a root stage
 
 STAGE PLANS:
   Stage: Stage-2
@@ -86,7 +88,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-08-19_12-12-19_985_2304811563647905709/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-37_542_6761558048897189363/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -120,7 +122,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
-        file:/tmp/nzhang/hive_2010-08-19_12-12-19_985_2304811563647905709/-mr-10007 
+        file:/tmp/nzhang/hive_2010-09-14_18-18-37_542_6761558048897189363/-mr-10007 
           Union
             Select Operator
               expressions:
@@ -155,14 +157,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest2
 
-  Stage: Stage-6
+  Stage: Stage-7
     Conditional Operator
 
-  Stage: Stage-5
+  Stage: Stage-6
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-12-19_985_2304811563647905709/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-18-37_542_6761558048897189363/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -175,9 +177,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-12-19_985_2304811563647905709/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-18-37_542_6761558048897189363/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -187,14 +192,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-12-19_985_2304811563647905709/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-18-37_542_6761558048897189363/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -206,10 +211,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-12-19_985_2304811563647905709/-ext-10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-18-37_542_6761558048897189363/-ext-10006 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -219,7 +227,7 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest2
 
-  Stage: Stage-10
+  Stage: Stage-12
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:unionsrc-subquery2:s2 
@@ -266,11 +274,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-38_957_568387192306866959/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-59_320_7540698004597928372/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1 SORT BY DEST1.key, DEST1.value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-38_957_568387192306866959/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-18-59_320_7540698004597928372/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
@@ -780,11 +788,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-43_612_5396388280176830607/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-02_936_6629428561300506578/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2 SORT BY DEST2.key, DEST2.val1, DEST2.val2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-12-43_612_5396388280176830607/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-19-02_936_6629428561300506578/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)s1.null, (src)s2.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)s2.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udf_10_trims.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/udf_10_trims.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_10_trims.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -54,14 +55,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-30-46_211_1766538299546866671/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-15-16_699_716014843371726095/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -74,9 +75,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-30-46_211_1766538299546866671/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-15-16_699_716014843371726095/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
Index: ql/src/test/results/clientpositive/input31.q.out
===================================================================
--- ql/src/test/results/clientpositive/input31.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input31.q.out	(working copy)
@@ -22,6 +22,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -87,7 +88,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: tst_dest31
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: insert overwrite table dest31
 select count(1) from srcbucket
 PREHOOK: type: QUERY
@@ -102,10 +106,10 @@
 PREHOOK: query: select * from tst_dest31
 PREHOOK: type: QUERY
 PREHOOK: Input: default@tst_dest31
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-51_528_6418079216640080758/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-26_305_5661069967494933383/-mr-10000
 POSTHOOK: query: select * from tst_dest31
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@tst_dest31
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-51_528_6418079216640080758/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-29-26_305_5661069967494933383/-mr-10000
 POSTHOOK: Lineage: tst_dest31.a EXPRESSION [(srcbucket)srcbucket.null, ]
 493
Index: ql/src/test/results/clientpositive/udf_reverse.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf_reverse.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_reverse.q.out	(working copy)
@@ -25,10 +25,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-42_570_7333525114286974901/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-07-56_504_5735007519186185582/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-11-42_570_7333525114286974901/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-07-56_504_5735007519186185582/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -96,11 +100,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-46_795_7550846614950284993/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-08-02_955_1225176762104026693/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-46_795_7550846614950284993/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-08-02_955_1225176762104026693/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 832_lav
 
@@ -157,10 +161,10 @@
 PREHOOK: query: SELECT count(1) FROM dest1 WHERE reverse(dest1.name) = _UTF-8 0xE993AEE982B5
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-47_648_6528733847998631993/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-08-04_622_5813029493421295737/-mr-10000
 POSTHOOK: query: SELECT count(1) FROM dest1 WHERE reverse(dest1.name) = _UTF-8 0xE993AEE982B5
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-11-47_648_6528733847998631993/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_18-08-04_622_5813029493421295737/-mr-10000
 POSTHOOK: Lineage: dest1.len EXPRESSION [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
 1
Index: ql/src/test/results/clientpositive/input34.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input34.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input34.q.out_0.17	(working copy)
@@ -26,10 +26,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -73,14 +74,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-14-49_988_3196421863820227467/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-46-47_315_8713638811011992179/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -93,9 +94,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-14-49_988_3196421863820227467/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-46-47_315_8713638811011992179/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -144,11 +148,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-14-54_604_2541788615457514489/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-46-54_126_411422434684573282/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-14-54_604_2541788615457514489/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-46-54_126_411422434684573282/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/binary_output_format.q.out
===================================================================
--- ql/src/test/results/clientpositive/binary_output_format.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/binary_output_format.q.out	(working copy)
@@ -54,10 +54,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -66,6 +67,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -88,8 +90,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 1
-                  directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002
+                  directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10000/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
@@ -99,22 +102,23 @@
                         columns.types string
                         file.inputformat org.apache.hadoop.mapred.TextInputFormat
                         file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                        location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                        location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                         name dest1
                         serialization.ddl struct dest1 { string mydata}
                         serialization.format 1
                         serialization.last.column.takes.rest true
                         serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                        transient_lastDdlTime 1282110635
+                        transient_lastDdlTime 1284504589
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest1
                   TotalFiles: 1
+                  GatherStats: true
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -125,12 +129,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110633
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -141,31 +145,31 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110633
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
@@ -175,25 +179,29 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string mydata}
                 serialization.format 1
                 serialization.last.column.takes.rest true
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110635
+                transient_lastDdlTime 1284504589
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -204,22 +212,23 @@
                     columns.types string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { string mydata}
                     serialization.format 1
                     serialization.last.column.takes.rest true
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110635
+                    transient_lastDdlTime 1284504589
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-50-35_972_2557311704730912733/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-49-49_443_6434706686449438212/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -230,13 +239,13 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { string mydata}
               serialization.format 1
               serialization.last.column.takes.rest true
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110635
+              transient_lastDdlTime 1284504589
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -247,13 +256,13 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { string mydata}
                 serialization.format 1
                 serialization.last.column.takes.rest true
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110635
+                transient_lastDdlTime 1284504589
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -292,12 +301,12 @@
 SELECT * FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-50-40_250_2785932063894683721/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-49-55_383_330923899053574056/-mr-10000
 POSTHOOK: query: -- Test the result
 SELECT * FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-50-40_250_2785932063894683721/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-49-55_383_330923899053574056/-mr-10000
 POSTHOOK: Lineage: dest1.mydata SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
 86	val_86
Index: ql/src/test/results/clientpositive/multi_insert.q.out
===================================================================
--- ql/src/test/results/clientpositive/multi_insert.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/multi_insert.q.out	(working copy)
@@ -24,7 +24,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -82,6 +84,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -92,7 +97,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -114,11 +122,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-31_140_408153388431420454/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-48_360_7953762035746547555/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-31_140_408153388431420454/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-48_360_7953762035746547555/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi2.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -136,11 +144,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-34_565_3781095733171262946/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-51_771_8783183293277206129/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-34_565_3781095733171262946/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-06-51_771_8783183293277206129/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi2.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -173,14 +181,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -228,14 +238,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-37_960_7019885533125445720/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-06-55_632_2674460654496933955/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -248,9 +258,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-37_960_7019885533125445720/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-06-55_632_2674460654496933955/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -260,14 +273,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-37_960_7019885533125445720/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-06-55_632_2674460654496933955/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -279,10 +292,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-48-37_960_7019885533125445720/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-06-55_632_2674460654496933955/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -318,11 +334,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-42_412_1170633204972932042/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-03_879_3895728757416914263/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-42_412_1170633204972932042/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-03_879_3895728757416914263/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
@@ -344,11 +360,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-45_763_5479993978027191761/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-07_346_6746106485662953432/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-45_763_5479993978027191761/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-07_346_6746106485662953432/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
@@ -390,7 +406,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -448,6 +466,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -458,7 +479,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -488,11 +512,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-53_390_1496432989382326411/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-18_515_3457355393974663217/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-53_390_1496432989382326411/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-18_515_3457355393974663217/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -518,11 +542,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-56_756_201654693279703699/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-21_917_512990937016178322/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-48-56_756_201654693279703699/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-21_917_512990937016178322/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -571,14 +595,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -626,14 +652,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-00_176_6281419673711922916/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-07-25_343_7959271322926254276/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -646,9 +672,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-00_176_6281419673711922916/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-07-25_343_7959271322926254276/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -658,14 +687,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-00_176_6281419673711922916/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-07-25_343_7959271322926254276/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -677,10 +706,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-00_176_6281419673711922916/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-07-25_343_7959271322926254276/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -724,11 +756,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-04_617_771346073947439653/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-33_918_4809641701424690942/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-04_617_771346073947439653/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-33_918_4809641701424690942/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -758,11 +790,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-08_004_8497688845623423902/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-37_380_7772013364074968547/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-08_004_8497688845623423902/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-37_380_7772013364074968547/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -820,8 +852,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -926,9 +960,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-08_11-49-11_372_6760243603000094371/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_17-07-40_802_8868350862677882659/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -978,7 +1015,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10 group by key, value
 insert overwrite table src_multi2 select * where key > 10 and key < 20 group by key, value
@@ -1016,11 +1056,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-19_241_4482349853651717318/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-53_919_7663690847493758997/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-19_241_4482349853651717318/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-53_919_7663690847493758997/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1050,11 +1090,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-22_691_5332657061833015800/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-57_490_6080507292036060377/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-22_691_5332657061833015800/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-07-57_490_6080507292036060377/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1116,15 +1156,17 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 depends on stages: Stage-2
-  Stage-9 depends on stages: Stage-6 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
+  Stage-7 depends on stages: Stage-2
+  Stage-11 depends on stages: Stage-7 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1218,14 +1260,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-26_076_4560863739653462938/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-01_023_3963425209968278997/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -1238,9 +1280,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-26_076_4560863739653462938/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-01_023_3963425209968278997/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -1250,10 +1295,10 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-08_11-49-26_076_4560863739653462938/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-14_17-08-01_023_3963425209968278997/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1293,14 +1338,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi2
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-26_076_4560863739653462938/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-01_023_3963425209968278997/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -1312,10 +1357,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-26_076_4560863739653462938/-ext-10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-01_023_3963425209968278997/-ext-10006 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -1367,11 +1415,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-34_227_8027514505131711662/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-14_413_7522438004697427536/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-34_227_8027514505131711662/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-14_413_7522438004697427536/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1405,11 +1453,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-37_603_3188940703758528665/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-17_953_5778321600107239234/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-37_603_3188940703758528665/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-17_953_5778321600107239234/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1480,8 +1528,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1586,9 +1636,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-08_11-49-40_955_545837270613951770/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-14_17-08-21_377_1827405192033515593/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1638,7 +1691,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from src
 insert overwrite table src_multi1 select * where key < 10 group by key, value
 insert overwrite table src_multi2 select * where key > 10 and key < 20 group by key, value
@@ -1684,11 +1740,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-48_540_8456363806132424052/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-34_489_4945629790959108979/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-48_540_8456363806132424052/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-34_489_4945629790959108979/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1726,11 +1782,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-51_869_2652647599896531556/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-37_914_4018953913282915169/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-49-51_869_2652647599896531556/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-37_914_4018953913282915169/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -1808,15 +1864,17 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-6 depends on stages: Stage-2
-  Stage-9 depends on stages: Stage-6 , consists of Stage-8, Stage-7
-  Stage-8
-  Stage-1 depends on stages: Stage-8, Stage-7
-  Stage-7
+  Stage-7 depends on stages: Stage-2
+  Stage-11 depends on stages: Stage-7 , consists of Stage-10, Stage-9
+  Stage-10
+  Stage-1 depends on stages: Stage-10, Stage-9
+  Stage-8 depends on stages: Stage-1
+  Stage-9
 
 STAGE PLANS:
   Stage: Stage-2
@@ -1910,14 +1968,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-55_241_3567543209701813700/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-41_433_7001879836883681733/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -1930,9 +1988,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-55_241_3567543209701813700/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-41_433_7001879836883681733/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -1942,10 +2003,10 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-6
+  Stage: Stage-7
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/nzhang/hive_2010-09-08_11-49-55_241_3567543209701813700/-mr-10005 
+        file:/tmp/nzhang/hive_2010-09-14_17-08-41_433_7001879836883681733/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -1985,14 +2046,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi2
 
-  Stage: Stage-9
+  Stage: Stage-11
     Conditional Operator
 
-  Stage: Stage-8
+  Stage: Stage-10
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-55_241_3567543209701813700/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-41_433_7001879836883681733/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -2004,10 +2065,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-7
+  Stage: Stage-8
+    Stats-Aggr Operator
+
+  Stage: Stage-9
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-49-55_241_3567543209701813700/-ext-10006 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-08-41_433_7001879836883681733/-ext-10006 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -2067,11 +2131,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-03_079_8531959109144658995/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-55_889_658737220991587687/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-03_079_8531959109144658995/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-55_889_658737220991587687/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2113,11 +2177,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-06_488_55514686473669450/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-59_415_7402581530462627245/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-06_488_55514686473669450/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-08-59_415_7402581530462627245/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2204,7 +2268,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -2319,6 +2385,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -2329,7 +2398,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from (select * from src  union all select * from src) s
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -2383,11 +2455,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-14_155_2946380734145038539/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-10_720_6010441005119219252/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-14_155_2946380734145038539/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-10_720_6010441005119219252/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2447,11 +2519,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-17_544_7626453465948145276/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-14_168_2552421292011602066/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-17_544_7626453465948145276/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-14_168_2552421292011602066/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2557,14 +2629,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -2669,14 +2743,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-21_024_3082231325676704620/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-17_639_542994900721500417/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -2689,9 +2763,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-21_024_3082231325676704620/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-17_639_542994900721500417/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -2701,14 +2778,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-21_024_3082231325676704620/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-17_639_542994900721500417/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -2720,10 +2797,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-21_024_3082231325676704620/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-17_639_542994900721500417/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -2791,11 +2871,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-25_618_5592276031368737141/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-25_884_6431166930291232652/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-25_618_5592276031368737141/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-25_884_6431166930291232652/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2859,11 +2939,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-29_030_5331520731644742115/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-29_897_6290521718057232673/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-29_030_5331520731644742115/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-29_897_6290521718057232673/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -2978,7 +3058,9 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
   Stage-1 depends on stages: Stage-2
+  Stage-4 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -3093,6 +3175,9 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
+
   Stage: Stage-1
     Move Operator
       tables:
@@ -3103,7 +3188,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: from (select * from src  union all select * from src) s
 insert overwrite table src_multi1 select * where key < 10
 insert overwrite table src_multi2 select * where key > 10 and key < 20
@@ -3165,11 +3253,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-36_787_2151577805016606292/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-41_225_2946007877854426595/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-36_787_2151577805016606292/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-41_225_2946007877854426595/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3237,11 +3325,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-40_190_4485616316665087301/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-44_726_6586471843451209756/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-40_190_4485616316665087301/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-44_726_6586471843451209756/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3363,14 +3451,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -3475,14 +3565,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: src_multi2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-43_616_3748893713824339469/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-48_169_7249129799893741096/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -3495,9 +3585,12 @@
               name: src_multi1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-43_616_3748893713824339469/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-48_169_7249129799893741096/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -3507,14 +3600,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: src_multi1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-43_616_3748893713824339469/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-48_169_7249129799893741096/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -3526,10 +3619,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src_multi2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-09-08_11-50-43_616_3748893713824339469/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-09-48_169_7249129799893741096/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -3605,11 +3701,11 @@
 PREHOOK: query: select * from src_multi1 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-48_153_8333575735946910490/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-56_473_8688197416844196261/-mr-10000
 POSTHOOK: query: select * from src_multi1 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-48_153_8333575735946910490/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-09-56_473_8688197416844196261/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -3681,11 +3777,11 @@
 PREHOOK: query: select * from src_multi2 order by key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src_multi2
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-51_551_8227839750501945135/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-00_115_2198989029090707740/-mr-10000
 POSTHOOK: query: select * from src_multi2 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src_multi2
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-08_11-50-51_551_8227839750501945135/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-10-00_115_2198989029090707740/-mr-10000
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: src_multi1.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input1_limit.q.out
===================================================================
--- ql/src/test/results/clientpositive/input1_limit.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input1_limit.q.out	(working copy)
@@ -24,8 +24,10 @@
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
   Stage-0 depends on stages: Stage-2
-  Stage-3 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-3
+  Stage-3 depends on stages: Stage-0
+  Stage-4 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-4
+  Stage-5 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -102,9 +104,12 @@
               name: dest1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-26-57_854_4999061439601735218/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-27-43_327_5531352914747684136/-mr-10004 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -142,7 +147,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-5
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT src.key, src.value WHERE src.key < 100 LIMIT 10
 INSERT OVERWRITE TABLE dest2 SELECT src.key, src.value WHERE src.key < 100 LIMIT 5
@@ -164,11 +172,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-03_051_2929820140133939709/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-57_097_3000842764364386080/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-03_051_2929820140133939709/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-57_097_3000842764364386080/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -186,11 +194,11 @@
 PREHOOK: query: SELECT dest2.* FROM dest2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-03_103_6672174195466398495/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-57_468_4760818015574288815/-mr-10000
 POSTHOOK: query: SELECT dest2.* FROM dest2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-27-03_103_6672174195466398495/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-57_468_4760818015574288815/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby8.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby8.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby8.q.out	(working copy)
@@ -25,8 +25,10 @@
   Stage-2 is a root stage
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
-  Stage-4 depends on stages: Stage-2
-  Stage-1 depends on stages: Stage-4
+  Stage-4 depends on stages: Stage-0
+  Stage-5 depends on stages: Stage-2
+  Stage-1 depends on stages: Stage-5
+  Stage-6 depends on stages: Stage-1
 
 STAGE PLANS:
   Stage: Stage-2
@@ -83,7 +85,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-35_495_1525844913151750631/10004 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-40_304_4606940462728948984/-mr-10004 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -140,9 +142,12 @@
               name: dest1
 
   Stage: Stage-4
+    Stats-Aggr Operator
+
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-35_495_1525844913151750631/10005 
+        file:/tmp/nzhang/hive_2010-09-14_16-18-40_304_4606940462728948984/-mr-10005 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -198,7 +203,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest2
 
+  Stage: Stage-6
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM SRC
 INSERT OVERWRITE TABLE DEST1 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
 INSERT OVERWRITE TABLE DEST2 SELECT SRC.key, COUNT(DISTINCT SUBSTR(SRC.value,5)) GROUP BY SRC.key
@@ -220,11 +228,11 @@
 PREHOOK: query: SELECT DEST1.* FROM DEST1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-50_178_7631776146204700392/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-56_883_5144962281935265521/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-50_178_7631776146204700392/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-56_883_5144962281935265521/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -541,11 +549,11 @@
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-50_238_5305743036214225078/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-57_294_6850699314032102301/-mr-10000
 POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-10-50_238_5305743036214225078/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-18-57_294_6850699314032102301/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest2.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/udf_reflect.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf_reflect.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_reflect.q.out	(working copy)
@@ -44,6 +44,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: reflect('java.lang.String','valueOf',1)
@@ -65,8 +66,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/tmp/edward/hive_2010-08-28_17-57-13_337_8190255539843975720/-ext-10001
+                  directory: file:/tmp/nzhang/hive_2010-09-15_17-26-36_357_6265400288274412023/-ext-10001
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-26-36_357_6265400288274412023/-ext-10001/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -75,12 +77,13 @@
                         columns.types string:string:string:string:string:string:string
                         serialization.format 1
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/home/edward/hive-trunk/build/ql/test/data/warehouse/src [src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        pfile:/home/edward/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -91,12 +94,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/home/edward/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1283043430
+              transient_lastDdlTime 1284588338
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -107,12 +110,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/home/edward/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1283043430
+                transient_lastDdlTime 1284588338
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -132,7 +135,7 @@
 FROM src LIMIT 1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/tmp/edward/hive_2010-08-28_17-57-13_827_84846656517328687/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-36_401_5084178290925314023/-mr-10000
 POSTHOOK: query: SELECT reflect("java.lang.String", "valueOf", 1),
        reflect("java.lang.String", "isEmpty"),
        reflect("java.lang.Math", "max", 2, 3),
@@ -143,5 +146,5 @@
 FROM src LIMIT 1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/tmp/edward/hive_2010-08-28_17-57-13_827_84846656517328687/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-26-36_401_5084178290925314023/-mr-10000
 1	true	3	2	3	2.7182818284590455	1.0
Index: ql/src/test/results/clientpositive/case_sensitivity.q.out
===================================================================
--- ql/src/test/results/clientpositive/case_sensitivity.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/case_sensitivity.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -52,14 +53,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-23_173_4531182890449211467/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-51_651_73893113624741501/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -72,9 +73,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-52-23_173_4531182890449211467/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-51_651_73893113624741501/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -100,11 +104,11 @@
 PREHOOK: query: SELECT DEST1.* FROM Dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-27_091_3662268608951366403/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-57_616_3343383676178573885/-mr-10000
 POSTHOOK: query: SELECT DEST1.* FROM Dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-52-27_091_3662268608951366403/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-01-57_616_3343383676178573885/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 2	1
Index: ql/src/test/results/clientpositive/input6.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input6.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input6.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -52,14 +53,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-15-57_156_9177796295825676170/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-29_277_5666322891758807419/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -72,9 +73,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-15-57_156_9177796295825676170/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-29_277_5666322891758807419/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -113,10 +117,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-01_628_7891694624479542164/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-35_411_4968551683155783860/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-01_628_7891694624479542164/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-35_411_4968551683155783860/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby2_map_skew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby2_map_skew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby2_map_skew.q.out	(working copy)
@@ -18,6 +18,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -84,7 +85,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-06_025_8810814480160003748/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-14-27_634_8249679785940336881/-mr-10002 
             Reduce Output Operator
               key expressions:
                     expr: _col0
@@ -147,7 +148,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT substr(src.key,1,1), count(DISTINCT substr(src.value,5)), concat(substr(src.key,1,1),sum(substr(src.value,5))) GROUP BY substr(src.key,1,1)
 PREHOOK: type: QUERY
@@ -164,11 +168,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-16_404_1866468645936966003/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-37_566_5462951779954403325/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-16_404_1866468645936966003/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-37_566_5462951779954403325/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin_negative2.q.out	(working copy)
@@ -60,10 +60,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -72,6 +73,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -105,8 +107,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -116,15 +119,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282244913
+                          transient_lastDdlTime 1284505310
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -136,6 +140,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -169,8 +174,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -180,21 +186,22 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282244913
+                              transient_lastDdlTime 1284505310
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -206,12 +213,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244911
+              transient_lastDdlTime 1284505305
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -223,31 +230,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244911
+                transient_lastDdlTime 1284505305
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -257,24 +264,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244913
+                transient_lastDdlTime 1284505310
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -285,21 +296,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282244913
+                    transient_lastDdlTime 1284505310
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-08-33_925_5914485664635248090/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-01-50_250_8645820883627828082/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -310,12 +322,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282244913
+              transient_lastDdlTime 1284505310
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -326,12 +338,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282244913
+                transient_lastDdlTime 1284505310
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
Index: ql/src/test/results/clientpositive/udf1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/udf1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf1.q.out_0.17	(working copy)
@@ -34,10 +34,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -106,14 +107,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-35-28_911_1700146549667793404/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-13-36_697_9008750126488507302/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -126,9 +127,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-35-28_911_1700146549667793404/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-13-36_697_9008750126488507302/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -231,11 +235,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-35-33_495_4581479245160947463/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-13-44_189_2884012276482831572/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-35-33_495_4581479245160947463/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-13-44_189_2884012276482831572/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c10 EXPRESSION []
 POSTHOOK: Lineage: dest1.c11 EXPRESSION []
Index: ql/src/test/results/clientpositive/groupby3_map.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby3_map.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby3_map.q.out	(working copy)
@@ -35,6 +35,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -166,7 +167,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT
   sum(substr(src.value,5)),
@@ -207,11 +211,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-38_629_5098069129422470787/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-06_424_4947731759684744412/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-38_629_5098069129422470787/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-15-06_424_4947731759684744412/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample7.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample7.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample7.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -57,8 +59,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -68,21 +71,22 @@
                             columns.types int:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                             name dest1
                             serialization.ddl struct dest1 { i32 key, string value}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282111191
+                            transient_lastDdlTime 1284510325
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -94,12 +98,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110630
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -111,31 +115,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110630
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -145,24 +149,28 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111191
+                transient_lastDdlTime 1284510325
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -173,21 +181,22 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111191
+                    transient_lastDdlTime 1284510325
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-51_115_6679065540058160658/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-25-25_949_8398069099491911720/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -198,12 +207,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111191
+              transient_lastDdlTime 1284510325
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -214,12 +223,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111191
+                transient_lastDdlTime 1284510325
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -242,11 +251,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-55_318_6266393435192332482/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-31_960_8165631533406459791/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-55_318_6266393435192332482/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-25-31_960_8165631533406459791/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 468	val_469
Index: ql/src/test/results/clientpositive/input_testxpath.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_testxpath.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testxpath.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -46,14 +47,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-59_659_3573439640460092154/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-30_737_9084984602588830891/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -66,9 +67,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-59_659_3573439640460092154/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-30_737_9084984602588830891/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -110,11 +114,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-04_769_316117582977318055/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-36_753_9038569867185229430/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-17-04_769_316117582977318055/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-36_753_9038569867185229430/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.mapvalue EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/join28.q.out
===================================================================
--- ql/src/test/results/clientpositive/join28.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join28.q.out	(working copy)
@@ -24,10 +24,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -211,14 +212,14 @@
                                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                   name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-47_738_5089187786455782370/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-39-10_819_1600312528863286394/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -231,9 +232,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-58-47_738_5089187786455782370/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-39-10_819_1600312528863286394/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -271,11 +275,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-58-52_535_7242516801546424528/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-19_032_8638055362103004417/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-58-52_535_7242516801546424528/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-39-19_032_8638055362103004417/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
 128	val_128
Index: ql/src/test/results/clientpositive/transform_ppr1.q.out
===================================================================
--- ql/src/test/results/clientpositive/transform_ppr1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/transform_ppr1.q.out	(working copy)
@@ -30,6 +30,7 @@
         tmap:src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: ds
@@ -67,12 +68,12 @@
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [tmap:src]
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 [tmap:src]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -86,13 +87,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453620
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -103,17 +104,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453620
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -127,13 +128,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453620
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -144,17 +145,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453620
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -168,13 +169,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453620
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -185,17 +186,17 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453620
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-09/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -209,13 +210,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266453620
+              transient_lastDdlTime 1284588329
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -226,13 +227,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266453620
+                transient_lastDdlTime 1284588329
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -253,8 +254,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-23_096_3472292510704843335/10001
+                directory: file:/tmp/nzhang/hive_2010-09-15_17-09-49_113_6975059842786318267/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-15_17-09-49_113_6975059842786318267/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -263,6 +265,7 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -282,7 +285,7 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-23_570_1086582197068265009/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-49_237_3543567544677490790/-mr-10000
 POSTHOOK: query: FROM (
   FROM srcpart src
   SELECT TRANSFORM(src.ds, src.key, src.value)
@@ -295,7 +298,7 @@
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-40-23_570_1086582197068265009/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_17-09-49_237_3543567544677490790/-mr-10000
 0	val_0
 0	val_0
 0	val_0
Index: ql/src/test/results/clientpositive/create_escape.q.out
===================================================================
--- ql/src/test/results/clientpositive/create_escape.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/create_escape.q.out	(working copy)
@@ -26,15 +26,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Tue Sep 14 08:12:01 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 07:28:36 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/table1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/table1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284477121          
+	transient_lastDdlTime	1285079316          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -45,8 +45,8 @@
 Bucket Columns:     	[]                  	 
 Sort Columns:       	[]                  	 
 Storage Desc Params:	 	 
+	escape.delim        	\\                  
 	serialization.format	\t                  
-	escape.delim        	\\                  
 	field.delim         	\t                  
 	 	 
 PREHOOK: query: INSERT OVERWRITE TABLE table1 SELECT key, '\\\t\\' FROM src WHERE key = 86
@@ -62,11 +62,11 @@
 PREHOOK: query: SELECT * FROM table1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@table1
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-12-04_486_8603373820009984461/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_07-28-42_009_3448389970814289659/-mr-10000
 POSTHOOK: query: SELECT * FROM table1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@table1
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_08-12-04_486_8603373820009984461/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_07-28-42_009_3448389970814289659/-mr-10000
 POSTHOOK: Lineage: table1.a SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: table1.b SIMPLE []
 86	\	\
Index: ql/src/test/results/clientpositive/input5.q.out
===================================================================
--- ql/src/test/results/clientpositive/input5.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input5.q.out	(working copy)
@@ -27,6 +27,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -89,7 +90,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src_thrift
   SELECT TRANSFORM(src_thrift.lint, src_thrift.lintstring)
@@ -115,11 +119,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-34_703_4759762565770710527/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-21_789_4017947778315716401/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-12-34_703_4759762565770710527/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-32-21_789_4017947778315716401/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), (src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 [0,0,0]	[{"myint":0,"mystring":"0","underscore_int":0}]
Index: ql/src/test/results/clientpositive/regexp_extract.q.out
===================================================================
--- ql/src/test/results/clientpositive/regexp_extract.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/regexp_extract.q.out	(working copy)
@@ -30,6 +30,7 @@
         tmap:src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -68,9 +69,9 @@
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [tmap:src]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -81,12 +82,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452696
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -97,12 +98,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452696
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -123,8 +124,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-24-57_663_4177765762635704360/10001
+                directory: file:/tmp/nzhang/hive_2010-09-14_17-22-34_668_2056813096308329710/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-22-34_668_2056813096308329710/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -133,6 +135,7 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -149,7 +152,7 @@
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)',1) WHERE tmap.key < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-24-58_014_3453128355432517924/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-34_791_2473896929847962683/-mr-10000
 POSTHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value, 1+2, 3+4)
@@ -159,7 +162,7 @@
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)',1) WHERE tmap.key < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-24-58_014_3453128355432517924/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-34_791_2473896929847962683/-mr-10000
 0	0	3
 0	0	3
 0	0	3
@@ -276,6 +279,7 @@
         tmap:src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -314,9 +318,9 @@
                         type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src [tmap:src]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [tmap:src]
       Path -> Partition:
-        file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -327,12 +331,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1266452696
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -343,12 +347,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/data/users/njain/hive1/hive1/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1266452696
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -369,8 +373,9 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-25-02_334_2989637351021783973/10001
+                directory: file:/tmp/nzhang/hive_2010-09-14_17-22-38_507_8896713942915944466/-ext-10001
                 NumFilesPerFileSink: 1
+                Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_17-22-38_507_8896713942915944466/-ext-10001/
                 table:
                     input format: org.apache.hadoop.mapred.TextInputFormat
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -379,6 +384,7 @@
                       columns.types string:string
                       serialization.format 1
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
 
   Stage: Stage-0
@@ -395,7 +401,7 @@
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)') WHERE tmap.key < 100
 PREHOOK: type: QUERY
 PREHOOK: Input: default@src
-PREHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-25-02_705_4248816567500013329/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-38_622_4580748835136954647/-mr-10000
 POSTHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value, 1+2, 3+4)
@@ -405,7 +411,7 @@
 SELECT tmap.key, regexp_extract(tmap.value, 'val_(\\d+\\t\\d+)') WHERE tmap.key < 100
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
-POSTHOOK: Output: file:/data/users/njain/hive1/hive1/build/ql/scratchdir/hive_2010-02-17_16-25-02_705_4248816567500013329/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-22-38_622_4580748835136954647/-mr-10000
 0	0	3
 0	0	3
 0	0	3
Index: ql/src/test/results/clientpositive/stats7.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats7.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats7.q.out	(revision 0)
@@ -0,0 +1,233 @@
+PREHOOK: query: create table analyze_srcpart like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table analyze_srcpart like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@analyze_srcpart
+PREHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_srcpart (TOK_PARTSPEC (TOK_PARTVAL ds '2008-04-08') (TOK_PARTVAL hr))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_srcpart 
+          TableScan
+            alias: analyze_srcpart
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_srcpart
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+PREHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: query: analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_srcpart
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 11]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:14 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=11	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056743          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12)
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Partition Information	 	 
+Partition Value:    	[2008-04-08, 12]    	 
+Database:           	default             	 
+Table:              	analyze_srcpart     	 
+CreateTime:         	Tue Sep 21 01:12:15 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart/ds=2008-04-08/hr=12	 
+Partition Parameters:	 	 
+	numFiles            	1                   
+	transient_lastDdlTime	1285056743          
+	numRows             	500                 
+	totalSize           	5812                
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: describe extended analyze_srcpart
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_srcpart
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_srcpart PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 01:12:03 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_srcpart	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	2                   
+	EXTERNAL            	FALSE               
+	numFiles            	2                   
+	transient_lastDdlTime	1285056743          
+	numRows             	1000                
+	totalSize           	11624               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/input_testsequencefile.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_testsequencefile.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testsequencefile.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest4_sequencefile
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-48_203_6058550366021037210/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-03_384_4135258393076562174/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest4_sequencefile
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-48_203_6058550366021037210/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-03_384_4135258393076562174/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -99,11 +103,11 @@
 PREHOOK: query: SELECT dest4_sequencefile.* FROM dest4_sequencefile
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest4_sequencefile
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-52_054_1678193855449019517/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-10_600_1028485578391523559/-mr-10000
 POSTHOOK: query: SELECT dest4_sequencefile.* FROM dest4_sequencefile
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest4_sequencefile
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-52_054_1678193855449019517/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-10_600_1028485578391523559/-mr-10000
 POSTHOOK: Lineage: dest4_sequencefile.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest4_sequencefile.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/load_dyn_part14.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part14.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part14.q.out_0.17	(working copy)
@@ -20,15 +20,15 @@
 	 	 
 # Detailed Table Information	 	 
 Database:           	default             	 
-Owner:              	thiruvel            	 
-CreateTime:         	Thu Sep 16 12:42:09 PDT 2010	 
+Owner:              	nzhang              	 
+CreateTime:         	Tue Sep 21 08:18:52 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive.unsecure/build/ql/test/data/warehouse/nzhang_part14	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part14	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
-	transient_lastDdlTime	1284666129          
+	transient_lastDdlTime	1285082332          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -66,10 +66,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-2 depends on stages: Stage-1, Stage-3, Stage-4
+  Stage-2 depends on stages: Stage-1, Stage-4, Stage-5
   Stage-0 depends on stages: Stage-2
-  Stage-3 is a root stage
+  Stage-3 depends on stages: Stage-0
   Stage-4 is a root stage
+  Stage-5 is a root stage
 
 STAGE PLANS:
   Stage: Stage-1
@@ -107,7 +108,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/thiruvel/hive_2010-09-16_12-42-09_696_2036788336692204021/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_08-18-52_887_7592187800387913855/-mr-10002 
           Union
             Select Operator
               expressions:
@@ -124,7 +125,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part14
-        file:/tmp/thiruvel/hive_2010-09-16_12-42-09_696_2036788336692204021/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-21_08-18-52_887_7592187800387913855/-mr-10003 
           Union
             Select Operator
               expressions:
@@ -141,7 +142,7 @@
                     output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: nzhang_part14
-        file:/tmp/thiruvel/hive_2010-09-16_12-42-09_696_2036788336692204021/-mr-10004 
+        file:/tmp/nzhang/hive_2010-09-21_08-18-52_887_7592187800387913855/-mr-10004 
           Union
             Select Operator
               expressions:
@@ -172,6 +173,9 @@
               name: nzhang_part14
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery2:t-subquery2:src 
@@ -203,7 +207,7 @@
                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
 
-  Stage: Stage-4
+  Stage: Stage-5
     Map Reduce
       Alias -> Map Operator Tree:
         null-subquery1-subquery1:t-subquery1-subquery1:src 
@@ -273,13 +277,13 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part14@value= 
 PREHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-42-19_572_4169203793189444575/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-19-12_540_8445609877851421931/-mr-10000
 POSTHOOK: query: select * from nzhang_part14 where value <> 'a'
 order by key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part14@value= 
 POSTHOOK: Input: default@nzhang_part14@value=__HIVE_DEFAULT_PARTITION__
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-16_12-42-19_572_4169203793189444575/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_08-19-12_540_8445609877851421931/-mr-10000
 POSTHOOK: Lineage: nzhang_part14 PARTITION(value= ).key EXPRESSION []
 POSTHOOK: Lineage: nzhang_part14 PARTITION(value=__HIVE_DEFAULT_PARTITION__).key EXPRESSION []
 k1	__HIVE_DEFAULT_PARTITION__
Index: ql/src/test/results/clientpositive/input9.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input9.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input9.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-03_955_72262551464317021/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-51_711_5193252935014809060/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -79,9 +80,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-03_955_72262551464317021/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-49-51_711_5193252935014809060/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -120,10 +124,10 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-09_207_4536897829428976296/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-57_871_1295465611570813885/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-16-09_207_4536897829428976296/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-49-57_871_1295465611570813885/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SIMPLE []
Index: ql/src/test/results/clientpositive/bucketizedhiveinputformat.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketizedhiveinputformat.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketizedhiveinputformat.q.out	(working copy)
@@ -35,6 +35,7 @@
   Stage-2 depends on stages: Stage-1
   Stage-3 depends on stages: Stage-2
   Stage-0 depends on stages: Stage-3
+  Stage-4 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -155,7 +156,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-10-19_047_380113812021070738/10003 
+        hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-24-39_720_7348805745281253844/-mr-10003 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -184,7 +185,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: t2
 
+  Stage: Stage-4
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE T2 SELECT * FROM (
 SELECT tmp1.name as name FROM (
   SELECT name, 'MMM' AS n FROM T1) tmp1 
@@ -263,11 +267,11 @@
 PREHOOK: query: SELECT COUNT(1) FROM T2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t2
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-11-40_372_2216491831322314327/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-27-09_461_719019531461293886/-mr-10000
 POSTHOOK: query: SELECT COUNT(1) FROM T2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t2
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-11-40_372_2216491831322314327/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-27-09_461_719019531461293886/-mr-10000
 POSTHOOK: Lineage: t2.name SIMPLE [(t1)t1.FieldSchema(name:name, type:string, comment:null), ]
 5000000
 PREHOOK: query: CREATE TABLE T3(name STRING) STORED AS TEXTFILE
@@ -347,10 +351,10 @@
 PREHOOK: query: SELECT COUNT(1) FROM T3
 PREHOOK: type: QUERY
 PREHOOK: Input: default@t3
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-11-52_373_3173950263104621965/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-27-33_849_2287170328982872863/-mr-10000
 POSTHOOK: query: SELECT COUNT(1) FROM T3
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@t3
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-11-52_373_3173950263104621965/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-27-33_849_2287170328982872863/-mr-10000
 POSTHOOK: Lineage: t2.name SIMPLE [(t1)t1.FieldSchema(name:name, type:string, comment:null), ]
 1000
Index: ql/src/test/results/clientpositive/udf3.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf3.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -93,7 +94,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src INSERT OVERWRITE TABLE dest1 SELECT count(CAST('' AS INT)), sum(CAST('' AS INT)), avg(CAST('' AS INT)), 
 min(CAST('' AS INT)), max(CAST('' AS INT))
 PREHOOK: type: QUERY
@@ -112,11 +116,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-30-25_319_6045119930597103250/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-56-05_977_1141232485951012411/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-30-25_319_6045119930597103250/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-56-05_977_1141232485951012411/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.null, ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.null, ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.null, ]
Index: ql/src/test/results/clientpositive/input_testxpath.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_testxpath.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testxpath.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -46,14 +47,14 @@
                     serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                     name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-14_236_3719097571824191978/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-12_088_6842128863792560414/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -66,9 +67,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-14_236_3719097571824191978/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-12_088_6842128863792560414/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -95,11 +99,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-18_664_305257251335293226/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-17_892_423080491144130898/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-18_664_305257251335293226/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-17_892_423080491144130898/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.mapvalue EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/join14.q.out
===================================================================
--- ql/src/test/results/clientpositive/join14.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join14.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -110,7 +111,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src JOIN srcpart ON src.key = srcpart.key AND srcpart.ds = '2008-04-08' and src.key > 100
 INSERT OVERWRITE TABLE dest1 SELECT src.key, srcpart.value
 PREHOOK: type: QUERY
@@ -130,11 +134,11 @@
 PREHOOK: query: select dest1.* from dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-57-17_999_3604615124362926210/-mr-10000
+PREHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-09_368_5727898878579800601/-mr-10000
 POSTHOOK: query: select dest1.* from dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-57-17_999_3604615124362926210/-mr-10000
+POSTHOOK: Output: file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-37-09_368_5727898878579800601/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 103	val_103
Index: ql/src/test/results/clientpositive/sample2.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample2.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample2.q.out_0.17	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -52,8 +54,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -63,21 +66,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1280085933
+                          transient_lastDdlTime 1284594099
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -89,12 +93,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -106,31 +110,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -140,20 +144,24 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085933
+                transient_lastDdlTime 1284594099
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -167,9 +175,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -180,12 +188,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280085933
+              transient_lastDdlTime 1284594099
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -196,12 +204,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085933
+                transient_lastDdlTime 1284594099
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -210,7 +218,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-33_273_8350261897659205035/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-41-39_155_4579433987848970380/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -221,15 +229,16 @@
                   columns.types int:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280085933
+                  transient_lastDdlTime 1284594099
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -248,11 +257,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-36_421_6085788360382062607/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-46_534_2695308682674974136/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-36_421_6085788360382062607/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-41-46_534_2695308682674974136/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 474	val_475
Index: ql/src/test/results/clientpositive/join37.q.out
===================================================================
--- ql/src/test/results/clientpositive/join37.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join37.q.out	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -135,14 +136,14 @@
                               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                               name: dest_j1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-52_907_866633669530868405/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-55_090_7852258381958275908/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -155,9 +156,12 @@
               name: dest_j1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-52_907_866633669530868405/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-41-55_090_7852258381958275908/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -188,11 +192,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-57_616_2049257293103293523/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-42-02_401_8110052503148408708/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-57_616_2049257293103293523/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-42-02_401_8110052503148408708/-mr-10000
 POSTHOOK: Lineage: dest_j1.key EXPRESSION [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 SIMPLE [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(src1)x.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/groupby3.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby3.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby3.q.out	(working copy)
@@ -36,6 +36,7 @@
   Stage-1 is a root stage
   Stage-2 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-2
+  Stage-3 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -83,7 +84,7 @@
   Stage: Stage-2
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jssarma/hive_2010-07-21_11-23-30_013_9206830132841854931/10002 
+        file:/tmp/nzhang/hive_2010-09-14_16-14-47_199_724415113430484508/-mr-10002 
             Reduce Output Operator
               sort order: 
               tag: -1
@@ -182,7 +183,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-3
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1 SELECT 
   sum(substr(src.value,5)), 
@@ -223,11 +227,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-35_334_4005630322306317272/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-57_582_5542086282376615391/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-23-35_334_4005630322306317272/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-14-57_582_5542086282376615391/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c2 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.c3 EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/bucketmapjoin4.q.out
===================================================================
--- ql/src/test/results/clientpositive/bucketmapjoin4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/bucketmapjoin4.q.out	(working copy)
@@ -85,10 +85,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -97,6 +98,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -130,8 +132,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -141,15 +144,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282861882
+                          transient_lastDdlTime 1284505068
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -161,6 +165,7 @@
             b 
               TableScan
                 alias: b
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -194,8 +199,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -205,29 +211,30 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861882
+                              transient_lastDdlTime 1284505068
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 b {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                b {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -239,12 +246,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861877
+              transient_lastDdlTime 1284505061
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -256,31 +263,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861877
+                transient_lastDdlTime 1284505061
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -290,24 +297,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861882
+                transient_lastDdlTime 1284505068
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -318,21 +329,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861882
+                    transient_lastDdlTime 1284505068
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-22_510_8047018522141779961/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-57-48_424_1970489996852752921/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -343,12 +355,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861882
+              transient_lastDdlTime 1284505068
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -359,12 +371,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861882
+                transient_lastDdlTime 1284505068
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -390,11 +402,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-29_484_1206327158732357255/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-59_596_661055811113352643/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-29_484_1206327158732357255/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-57-59_596_661055811113352643/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin)b.FieldSchema(name:value, type:string, comment:null), ]
@@ -441,11 +453,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-43_349_1218996968253937500/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-20_532_4131677837767246501/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-43_349_1218996968253937500/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-20_532_4131677837767246501/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -484,14 +496,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-49_725_5297129701120453460/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-31_183_5909440248209423381/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-49_725_5297129701120453460/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-31_183_5909440248209423381/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -534,10 +546,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -546,6 +559,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -579,8 +593,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -590,15 +605,20 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                           name bucketmapjoin_tmp_result
+                          numFiles 1
+                          numPartitions 0
+                          numRows 464
                           serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282861903
+                          totalSize 8983
+                          transient_lastDdlTime 1284505100
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: bucketmapjoin_tmp_result
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -610,6 +630,7 @@
             a 
               TableScan
                 alias: a
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -643,8 +664,9 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002
                         NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -654,29 +676,34 @@
                               columns.types string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                               name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
                               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282861903
+                              totalSize 8983
+                              transient_lastDdlTime 1284505100
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: bucketmapjoin_tmp_result
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
           Bucket Mapjoin Context:
               Alias Bucket Base File Name Mapping:
                 a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
               Alias Bucket File Name Mapping:
-                a {pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
               Alias Bucket Output File Name Mapping:
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
-                pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
           Partition
             base file name: srcbucket_mapjoin
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -688,12 +715,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
               name srcbucket_mapjoin
               serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861877
+              transient_lastDdlTime 1284505061
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -705,31 +732,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
                 name srcbucket_mapjoin
                 serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861877
+                transient_lastDdlTime 1284505061
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket_mapjoin
             name: srcbucket_mapjoin
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -739,24 +766,32 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861903
+                totalSize 8983
+                transient_lastDdlTime 1284505100
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -767,21 +802,26 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                     name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 464
                     serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282861903
+                    totalSize 8983
+                    transient_lastDdlTime 1284505100
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucketmapjoin_tmp_result
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-31-53_021_93189871321207259/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_15-58-36_141_5221440347310438999/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -792,12 +832,16 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
               name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
               serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861903
+              totalSize 8983
+              transient_lastDdlTime 1284505100
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -808,12 +852,16 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                 name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
                 serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861903
+                totalSize 8983
+                transient_lastDdlTime 1284505100
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucketmapjoin_tmp_result
             name: bucketmapjoin_tmp_result
@@ -851,11 +899,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-59_933_2233538912359490176/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-48_113_4754411707278279463/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-31-59_933_2233538912359490176/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-58-48_113_4754411707278279463/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
@@ -938,11 +986,11 @@
 PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_tmp_result
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-13_787_1620251253710582073/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-59-09_083_1925925122457264175/-mr-10000
 POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_tmp_result
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-13_787_1620251253710582073/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-59-09_083_1925925122457264175/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
@@ -1005,14 +1053,14 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucketmapjoin_hash_result_1
 PREHOOK: Input: default@bucketmapjoin_hash_result_2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-20_167_2165681320829401159/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-59-20_133_505629120542659538/-mr-10000
 POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
 from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
 on a.key = b.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucketmapjoin_hash_result_1
 POSTHOOK: Input: default@bucketmapjoin_hash_result_2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-32-20_167_2165681320829401159/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_15-59-20_133_505629120542659538/-mr-10000
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
 POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
Index: ql/src/test/results/clientpositive/union22.q.out
===================================================================
--- ql/src/test/results/clientpositive/union22.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/union22.q.out	(working copy)
@@ -85,6 +85,7 @@
   Stage-1 is a root stage
   Stage-3 depends on stages: Stage-1
   Stage-0 depends on stages: Stage-3
+  Stage-4 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -93,6 +94,7 @@
         null-subquery2:subq-subquery2:a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -116,7 +118,7 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/tmp/amarsri/hive_2010-09-19_21-43-26_623_1491853205147444436/-mr-10002
+                  directory: file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002
                   NumFilesPerFileSink: 1
                   table:
                       input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -126,6 +128,7 @@
                         columns.types string,string,string,string
                         escape.delim \
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -137,6 +140,7 @@
             null-subquery2:subq-subquery2:b:dst_union22_delta 
               TableScan
                 alias: dst_union22_delta
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -174,7 +178,7 @@
                         File Output Operator
                           compressed: false
                           GlobalTableId: 0
-                          directory: file:/tmp/jsichi/hive_2010-08-26_17-09-26_366_7362686340086914056/-mr-10002
+                          directory: file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002
                           NumFilesPerFileSink: 1
                           table:
                               input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -184,12 +188,13 @@
                                 columns.types string,string,string,string
                                 escape.delim \
                           TotalFiles: 1
+                          GatherStats: false
                           MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22/ds=1 [null-subquery2:subq-subquery2:a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22/ds=1 [null-subquery2:subq-subquery2:a]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22/ds=1 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22/ds=1 
           Partition
             base file name: ds=1
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -202,13 +207,17 @@
               columns.types string:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22
               name dst_union22
+              numFiles 1
+              numPartitions 1
+              numRows 500
               partition_columns ds
               serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282867758
+              totalSize 11624
+              transient_lastDdlTime 1285105581
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -219,13 +228,17 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22
                 name dst_union22
+                numFiles 1
+                numPartitions 1
+                numRows 500
                 partition_columns ds
                 serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282867758
+                totalSize 11624
+                transient_lastDdlTime 1285105581
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22
             name: dst_union22
@@ -233,7 +246,7 @@
   Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_17-09-26_366_7362686340086914056/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002 
           Select Operator
             expressions:
                   expr: _col0
@@ -276,8 +289,10 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_17-09-26_366_7362686340086914056/-ext-10000
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000
                       NumFilesPerFileSink: 1
+                      Static Partition Specification: ds=2/
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -287,20 +302,26 @@
                             columns.types string:string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22
                             name dst_union22
+                            numFiles 1
+                            numPartitions 1
+                            numRows 500
                             partition_columns ds
                             serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282867758
+                            totalSize 11624
+                            transient_lastDdlTime 1285105581
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dst_union22
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
         null-subquery1:subq-subquery1:dst_union22_delta 
           TableScan
             alias: dst_union22_delta
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -337,8 +358,10 @@
                       File Output Operator
                         compressed: false
                         GlobalTableId: 1
-                        directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_17-09-26_366_7362686340086914056/-ext-10000
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000
                         NumFilesPerFileSink: 1
+                        Static Partition Specification: ds=2/
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000/
                         table:
                             input format: org.apache.hadoop.mapred.TextInputFormat
                             output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -348,23 +371,28 @@
                               columns.types string:string:string:string
                               file.inputformat org.apache.hadoop.mapred.TextInputFormat
                               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22
                               name dst_union22
+                              numFiles 1
+                              numPartitions 1
+                              numRows 500
                               partition_columns ds
                               serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                               serialization.format 1
                               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                              transient_lastDdlTime 1282867758
+                              totalSize 11624
+                              transient_lastDdlTime 1285105581
                             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                             name: dst_union22
                         TotalFiles: 1
+                        GatherStats: true
                         MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jsichi/hive_2010-08-26_17-09-26_366_7362686340086914056/-mr-10002 [file:/tmp/jsichi/hive_2010-08-26_17-09-26_366_7362686340086914056/-mr-10002]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22_delta/ds=1 [null-subquery1:subq-subquery1:dst_union22_delta]
+        file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002 [file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22_delta/ds=1 [null-subquery1:subq-subquery1:dst_union22_delta]
       Path -> Partition:
-        file:/tmp/jsichi/hive_2010-08-26_17-09-26_366_7362686340086914056/-mr-10002 
+        file:/tmp/nzhang/hive_2010-09-21_14-46-27_944_8496687190593309577/-mr-10002 
           Partition
             base file name: -mr-10002
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -380,7 +408,7 @@
                 columns _col0,_col1,_col10,_col11
                 columns.types string,string,string,string
                 escape.delim \
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22_delta/ds=1 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22_delta/ds=1 
           Partition
             base file name: ds=1
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -393,13 +421,17 @@
               columns.types string:string:string:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22_delta
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22_delta
               name dst_union22_delta
+              numFiles 1
+              numPartitions 1
+              numRows 500
               partition_columns ds
               serialization.ddl struct dst_union22_delta { string k0, string k1, string k2, string k3, string k4, string k5}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282867759
+              totalSize 17436
+              transient_lastDdlTime 1285105587
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -410,13 +442,17 @@
                 columns.types string:string:string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22_delta
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22_delta
                 name dst_union22_delta
+                numFiles 1
+                numPartitions 1
+                numRows 500
                 partition_columns ds
                 serialization.ddl struct dst_union22_delta { string k0, string k1, string k2, string k3, string k4, string k5}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282867759
+                totalSize 17436
+                transient_lastDdlTime 1285105587
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22_delta
             name: dst_union22_delta
@@ -427,7 +463,7 @@
           partition:
             ds 2
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_17-09-26_366_7362686340086914056/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -437,18 +473,26 @@
                 columns.types string:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dst_union22
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dst_union22
                 name dst_union22
+                numFiles 1
+                numPartitions 1
+                numRows 500
                 partition_columns ds
                 serialization.ddl struct dst_union22 { string k1, string k2, string k3, string k4}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282867758
+                totalSize 11624
+                transient_lastDdlTime 1285105581
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dst_union22
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_17-09-26_366_7362686340086914056/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10001
 
+  Stage: Stage-4
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_14-46-27_944_8496687190593309577/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table dst_union22 partition (ds='2')
 select * from
 (
@@ -496,11 +540,11 @@
 PREHOOK: query: select * from dst_union22 where ds = '2' order by k1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dst_union22@ds=2
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_17-09-33_354_7230169091871487696/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-38_439_7599989320643509508/-mr-10000
 POSTHOOK: query: select * from dst_union22 where ds = '2' order by k1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dst_union22@ds=2
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_17-09-33_354_7230169091871487696/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_14-46-38_439_7599989320643509508/-mr-10000
 POSTHOOK: Lineage: dst_union22 PARTITION(ds=1).k1 SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dst_union22 PARTITION(ds=1).k2 SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dst_union22 PARTITION(ds=1).k3 SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/load_dyn_part1.q.out
===================================================================
--- ql/src/test/results/clientpositive/load_dyn_part1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/load_dyn_part1.q.out	(working copy)
@@ -34,15 +34,15 @@
 # Detailed Table Information	 	 
 Database:           	default             	 
 Owner:              	null                	 
-CreateTime:         	Tue Sep 14 07:09:12 PDT 2010	 
+CreateTime:         	Tue Sep 21 00:13:39 PDT 2010	 
 LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
 Protect Mode:       	None                	 
 Retention:          	0                   	 
-Location:           	pfile:/home/thiruvel/projects/hive/hive/build/ql/test/data/warehouse/nzhang_part1	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/nzhang_part1	 
 Table Type:         	MANAGED_TABLE       	 
 Table Parameters:	 	 
 	EXTERNAL            	FALSE               
-	transient_lastDdlTime	1284473352          
+	transient_lastDdlTime	1285053219          
 	 	 
 # Storage Information	 	 
 SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
@@ -70,14 +70,16 @@
 
 STAGE DEPENDENCIES:
   Stage-2 is a root stage
-  Stage-5 depends on stages: Stage-2 , consists of Stage-4, Stage-3
+  Stage-6 depends on stages: Stage-2 , consists of Stage-5, Stage-4
+  Stage-5
+  Stage-0 depends on stages: Stage-5, Stage-4
+  Stage-3 depends on stages: Stage-0
   Stage-4
-  Stage-0 depends on stages: Stage-4, Stage-3
-  Stage-3
-  Stage-8 depends on stages: Stage-2 , consists of Stage-7, Stage-6
-  Stage-7
-  Stage-1 depends on stages: Stage-7, Stage-6
-  Stage-6
+  Stage-10 depends on stages: Stage-2 , consists of Stage-9, Stage-8
+  Stage-9
+  Stage-1 depends on stages: Stage-9, Stage-8
+  Stage-7 depends on stages: Stage-1
+  Stage-8
 
 STAGE PLANS:
   Stage: Stage-2
@@ -131,14 +133,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: nzhang_part2
 
-  Stage: Stage-5
+  Stage: Stage-6
     Conditional Operator
 
-  Stage: Stage-4
+  Stage: Stage-5
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-09-12_547_2766535231598964607/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-13-39_317_150757677956835790/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -154,9 +156,12 @@
               name: nzhang_part1
 
   Stage: Stage-3
+    Stats-Aggr Operator
+
+  Stage: Stage-4
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-09-12_547_2766535231598964607/-ext-10004 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-13-39_317_150757677956835790/-ext-10004 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -166,14 +171,14 @@
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: nzhang_part1
 
-  Stage: Stage-8
+  Stage: Stage-10
     Conditional Operator
 
-  Stage: Stage-7
+  Stage: Stage-9
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-09-12_547_2766535231598964607/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-13-39_317_150757677956835790/-ext-10002
 
   Stage: Stage-1
     Move Operator
@@ -188,10 +193,13 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: nzhang_part2
 
-  Stage: Stage-6
+  Stage: Stage-7
+    Stats-Aggr Operator
+
+  Stage: Stage-8
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/home/thiruvel/projects/hive/hive/build/ql/scratchdir/hive_2010-09-14_07-09-12_547_2766535231598964607/-ext-10005 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_00-13-39_317_150757677956835790/-ext-10005 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -262,12 +270,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
 PREHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-09-18_593_3192732830429365525/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-13-55_874_723157656430223192/-mr-10000
 POSTHOOK: query: select * from nzhang_part1 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@nzhang_part1@ds=2008-04-08/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-09-18_593_3192732830429365525/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-13-55_874_723157656430223192/-mr-10000
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
@@ -1280,12 +1288,12 @@
 PREHOOK: type: QUERY
 PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
 PREHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
-PREHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-09-18_830_3512781667183170568/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-13-56_688_509916876298638236/-mr-10000
 POSTHOOK: query: select * from nzhang_part2 where ds is not null and hr is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=11
 POSTHOOK: Input: default@nzhang_part2@ds=2008-12-31/hr=12
-POSTHOOK: Output: file:/tmp/thiruvel/hive_2010-09-14_07-09-18_830_3512781667183170568/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-21_00-13-56_688_509916876298638236/-mr-10000
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: nzhang_part1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/sample2.q.out
===================================================================
--- ql/src/test/results/clientpositive/sample2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample2.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -32,6 +33,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -52,8 +54,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -63,21 +66,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282111170
+                          transient_lastDdlTime 1284510248
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt [s]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
           Partition
             base file name: srcbucket0.txt
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -89,12 +93,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110630
+              transient_lastDdlTime 1284504426
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -106,31 +110,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110630
+                transient_lastDdlTime 1284504426
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -140,24 +144,28 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111170
+                transient_lastDdlTime 1284510248
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -168,21 +176,22 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282111170
+                    transient_lastDdlTime 1284510248
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-30_585_8615571049557870849/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-24-08_796_3592086051996573769/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -193,12 +202,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282111170
+              transient_lastDdlTime 1284510248
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -209,12 +218,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282111170
+                transient_lastDdlTime 1284510248
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -235,11 +244,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-34_645_7000475762533763584/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-15_725_5572548852641754603/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-59-34_645_7000475762533763584/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-24-15_725_5572548852641754603/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 474	val_475
Index: ql/src/test/results/clientpositive/sample5.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/sample5.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/sample5.q.out_0.17	(working copy)
@@ -18,10 +18,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -30,6 +31,7 @@
         s 
           TableScan
             alias: s
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -50,8 +52,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -61,21 +64,22 @@
                           columns.types int:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                           name dest1
                           serialization.ddl struct dest1 { i32 key, string value}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1280085943
+                          transient_lastDdlTime 1284594121
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket [s]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket [s]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket 
           Partition
             base file name: srcbucket
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -87,12 +91,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
               name srcbucket
               serialization.ddl struct srcbucket { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280082970
+              transient_lastDdlTime 1284588335
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -104,31 +108,31 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/srcbucket
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket
                 name srcbucket
                 serialization.ddl struct srcbucket { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280082970
+                transient_lastDdlTime 1284588335
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcbucket
             name: srcbucket
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002
-          destination: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -138,20 +142,24 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085943
+                transient_lastDdlTime 1284594121
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -165,9 +173,9 @@
                     type: string
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002 [pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -178,12 +186,12 @@
               columns.types int:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280085943
+              transient_lastDdlTime 1284594121
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -194,12 +202,12 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280085943
+                transient_lastDdlTime 1284594121
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -208,7 +216,7 @@
           File Output Operator
             compressed: false
             GlobalTableId: 0
-            directory: pfile:/data/users/jssarma/hive_trunk/build/ql/scratchdir/hive_2010-07-25_12-25-43_743_7780563301202909046/-ext-10000
+            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-42-01_964_1825724553884089767/-ext-10000
             NumFilesPerFileSink: 1
             table:
                 input format: org.apache.hadoop.mapred.TextInputFormat
@@ -219,15 +227,16 @@
                   columns.types int:string
                   file.inputformat org.apache.hadoop.mapred.TextInputFormat
                   file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  location pfile:/data/users/jssarma/hive_trunk/build/ql/test/data/warehouse/dest1
+                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                   name dest1
                   serialization.ddl struct dest1 { i32 key, string value}
                   serialization.format 1
                   serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                  transient_lastDdlTime 1280085943
+                  transient_lastDdlTime 1284594121
                 serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                 name: dest1
             TotalFiles: 1
+            GatherStats: false
             MultiFileSpray: false
 
 
@@ -246,11 +255,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-49_227_7788070611447574019/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-14_188_518309180339714401/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1 SORT BY key, value
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-25_12-25-49_227_7788070611447574019/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-42-14_188_518309180339714401/-mr-10000
 POSTHOOK: Lineage: dest1.key SIMPLE [(srcbucket)s.FieldSchema(name:key, type:int, comment:null), ]
 POSTHOOK: Lineage: dest1.value SIMPLE [(srcbucket)s.FieldSchema(name:value, type:string, comment:null), ]
 0	val_0
Index: ql/src/test/results/clientpositive/stats2.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats2.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats2.q.out	(revision 0)
@@ -0,0 +1,250 @@
+PREHOOK: query: create table analyze_t1 like srcpart
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table analyze_t1 like srcpart
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@analyze_t1
+PREHOOK: query: explain
+insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null
+PREHOOK: type: QUERY
+POSTHOOK: query: explain
+insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_TABREF srcpart)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB analyze_t1 (TOK_PARTSPEC (TOK_PARTVAL ds) (TOK_PARTVAL hr)))) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (TOK_FUNCTION TOK_ISNOTNULL (TOK_TABLE_OR_COL ds)))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 depends on stages: Stage-1
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        srcpart 
+          TableScan
+            alias: srcpart
+            Filter Operator
+              predicate:
+                  expr: ds is not null
+                  type: boolean
+              Filter Operator
+                predicate:
+                    expr: ds is not null
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: key
+                        type: string
+                        expr: value
+                        type: string
+                        expr: ds
+                        type: string
+                        expr: hr
+                        type: string
+                  outputColumnNames: _col0, _col1, _col2, _col3
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 1
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                        name: analyze_t1
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          partition:
+            ds 
+            hr 
+          replace: true
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: analyze_t1
+
+
+PREHOOK: query: insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: query: insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: desc extended analyze_t1
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: desc extended analyze_t1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 22:40:47 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_t1	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	EXTERNAL            	FALSE               
+	transient_lastDdlTime	1285134047          
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
+PREHOOK: query: explain analyze table analyze_t1 partition (ds, hr) compute statistics
+PREHOOK: type: null
+POSTHOOK: query: explain analyze table analyze_t1 partition (ds, hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_ANALYZE (TOK_TABTYPE analyze_t1 (TOK_PARTSPEC (TOK_PARTVAL ds) (TOK_PARTVAL hr))))
+
+STAGE DEPENDENCIES:
+  Stage-0 is a root stage
+  Stage-1 depends on stages: Stage-0
+
+STAGE PLANS:
+  Stage: Stage-0
+    Map Reduce
+      Alias -> Map Operator Tree:
+        analyze_t1 
+          TableScan
+            alias: analyze_t1
+
+  Stage: Stage-1
+    Stats-Aggr Operator
+
+
+PREHOOK: query: analyze table analyze_t1 partition (ds, hr) compute statistics
+PREHOOK: type: null
+PREHOOK: Input: default@analyze_t1@ds=2008-04-08/hr=11
+PREHOOK: Input: default@analyze_t1@ds=2008-04-08/hr=12
+PREHOOK: Input: default@analyze_t1@ds=2008-04-09/hr=11
+PREHOOK: Input: default@analyze_t1@ds=2008-04-09/hr=12
+PREHOOK: Output: default@analyze_t1
+PREHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=11
+PREHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=12
+PREHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=11
+PREHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=12
+POSTHOOK: query: analyze table analyze_t1 partition (ds, hr) compute statistics
+POSTHOOK: type: null
+POSTHOOK: Input: default@analyze_t1@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@analyze_t1@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@analyze_t1@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@analyze_t1@ds=2008-04-09/hr=12
+POSTHOOK: Output: default@analyze_t1
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=11
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-08/hr=12
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=11
+POSTHOOK: Output: default@analyze_t1@ds=2008-04-09/hr=12
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: describe extended analyze_t1
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe extended analyze_t1
+POSTHOOK: type: DESCTABLE
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-08,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=11).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).key SIMPLE [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: analyze_t1 PARTITION(ds=2008-04-09,hr=12).value SIMPLE [(srcpart)srcpart.FieldSchema(name:value, type:string, comment:default), ]
+col_name            	data_type           	comment             
+	 	 
+key                 	string              	default             
+value               	string              	default             
+	 	 
+# Partition Information	 	 
+col_name            	data_type           	comment             
+	 	 
+ds                  	string              	None                
+hr                  	string              	None                
+	 	 
+# Detailed Table Information	 	 
+Database:           	default             	 
+Owner:              	null                	 
+CreateTime:         	Tue Sep 21 22:40:47 PDT 2010	 
+LastAccessTime:     	Wed Dec 31 16:00:00 PST 1969	 
+Protect Mode:       	None                	 
+Retention:          	0                   	 
+Location:           	pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/analyze_t1	 
+Table Type:         	MANAGED_TABLE       	 
+Table Parameters:	 	 
+	numPartitions       	4                   
+	EXTERNAL            	FALSE               
+	numFiles            	4                   
+	transient_lastDdlTime	1285134063          
+	numRows             	2000                
+	totalSize           	23248               
+	 	 
+# Storage Information	 	 
+SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
+InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
+OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
+Compressed:         	No                  	 
+Num Buckets:        	-1                  	 
+Bucket Columns:     	[]                  	 
+Sort Columns:       	[]                  	 
+Storage Desc Params:	 	 
+	serialization.format	1                   
+	 	 
Index: ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out
===================================================================
--- ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/disable_merge_for_bucketing.q.out	(working copy)
@@ -17,6 +17,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -25,6 +26,7 @@
         src 
           TableScan
             alias: src
+            GatherStats: false
             Select Operator
               expressions:
                     expr: key
@@ -45,9 +47,9 @@
                       type: string
       Needs Tagging: false
       Path -> Alias:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src [src]
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src [src]
       Path -> Partition:
-        file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src 
+        hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -58,12 +60,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+              location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1279735685
+              transient_lastDdlTime 1284513860
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -74,12 +76,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/src
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279735685
+                transient_lastDdlTime 1284513860
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -95,8 +97,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 1
-              directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-21-24_032_5058530528484682613/10000
+              directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-42_287_2408678463704361301/-ext-10000
               NumFilesPerFileSink: 2
+              Stats Publishing Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-42_287_2408678463704361301/-ext-10000/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -107,22 +110,23 @@
                     columns.types int:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket2_1
+                    location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket2_1
                     name bucket2_1
                     serialization.ddl struct bucket2_1 { i32 key, string value}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1279736484
+                    transient_lastDdlTime 1284514182
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: bucket2_1
               TotalFiles: 2
+              GatherStats: true
               MultiFileSpray: true
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-21-24_032_5058530528484682613/10000
+          source: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-42_287_2408678463704361301/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -133,17 +137,21 @@
                 columns.types int:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/test/data/warehouse/bucket2_1
+                location hdfs://localhost.localdomain:62850/build/ql/test/data/warehouse/bucket2_1
                 name bucket2_1
                 serialization.ddl struct bucket2_1 { i32 key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1279736484
+                transient_lastDdlTime 1284514182
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: bucket2_1
-          tmp directory: file:/mnt/vol/devrs004.snc1/jssarma/projects/hive_trunk/build/ql/scratchdir/hive_2010-07-21_11-21-24_032_5058530528484682613/10001
+          tmp directory: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-42_287_2408678463704361301/-ext-10001
 
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-42_287_2408678463704361301/-ext-10000/
 
+
 PREHOOK: query: insert overwrite table bucket2_1
 select * from src
 PREHOOK: type: QUERY
@@ -221,11 +229,11 @@
 PREHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@bucket2_1
-PREHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-21-26_856_8066476091371346194/10000
+PREHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-50_845_1808342515669240016/-mr-10000
 POSTHOOK: query: select * from bucket2_1 tablesample (bucket 1 out of 2) s order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@bucket2_1
-POSTHOOK: Output: file:/tmp/jssarma/hive_2010-07-21_11-21-26_856_8066476091371346194/10000
+POSTHOOK: Output: hdfs://localhost.localdomain:62850/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-29-50_845_1808342515669240016/-mr-10000
 POSTHOOK: Lineage: bucket2_1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: bucket2_1.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/quote1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/quote1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/quote1.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -59,14 +60,14 @@
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-26-07_718_7391802451805086474/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-37-41_859_8495731890416087402/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -81,9 +82,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-26-07_718_7391802451805086474/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_16-37-41_859_8495731890416087402/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -171,11 +175,11 @@
 PREHOOK: query: SELECT `int`.`location`, `int`.`type`, `int`.`table` FROM dest1 `int` WHERE `int`.`table` = '2008-04-08'
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1@table=2008-04-08
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-26-12_969_4532161059633752072/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-37-48_451_6351211037432823469/-mr-10000
 POSTHOOK: query: SELECT `int`.`location`, `int`.`type`, `int`.`table` FROM dest1 `int` WHERE `int`.`table` = '2008-04-08'
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1@table=2008-04-08
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-26-12_969_4532161059633752072/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_16-37-48_451_6351211037432823469/-mr-10000
 POSTHOOK: Lineage: dest1 PARTITION(table=2008-04-08).location EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1 PARTITION(table=2008-04-08).type SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238	2008-04-08
Index: ql/src/test/results/clientpositive/input_testxpath2.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_testxpath2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testxpath2.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -54,14 +55,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-19_197_4553185487836170797/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-19_076_8349888760517126679/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -74,9 +75,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-19_12-09-19_197_4553185487836170797/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-35-19_076_8349888760517126679/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
@@ -103,11 +107,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-23_618_2185354237688855928/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-24_958_6888819878366321399/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-19_12-09-23_618_2185354237688855928/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-35-24_958_6888819878366321399/-mr-10000
 POSTHOOK: Lineage: dest1.lint_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lint, type:array<int>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.lintstring_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:lintstring, type:array<org.apache.hadoop.hive.serde2.thrift.test.IntString>, comment:from deserializer), ]
 POSTHOOK: Lineage: dest1.mstringstring_size EXPRESSION [(src_thrift)src_thrift.FieldSchema(name:mstringstring, type:map<string,string>, comment:from deserializer), ]
Index: ql/src/test/results/clientpositive/udf_10_trims.q.out
===================================================================
--- ql/src/test/results/clientpositive/udf_10_trims.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/udf_10_trims.q.out	(working copy)
@@ -20,10 +20,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -54,14 +55,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-59_497_5597204290024544271/-ext-10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-57-19_255_7754784838144044480/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -74,9 +75,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-59-59_497_5597204290024544271/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_17-57-19_255_7754784838144044480/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
Index: ql/src/test/results/clientpositive/combine2.q.out
===================================================================
--- ql/src/test/results/clientpositive/combine2.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/combine2.q.out	(working copy)
@@ -135,7 +135,7 @@
 PREHOOK: Input: default@combine2@value=val_8
 PREHOOK: Input: default@combine2@value=val_9
 PREHOOK: Input: default@combine2@value=|
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-28_042_8085154637044190373/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-01_026_5759207694536624992/-mr-10000
 POSTHOOK: query: select key, value from combine2 where value is not null order by key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@combine2@value=2010-04-21 09%3A45%3A00
@@ -146,7 +146,7 @@
 POSTHOOK: Input: default@combine2@value=val_8
 POSTHOOK: Input: default@combine2@value=val_9
 POSTHOOK: Input: default@combine2@value=|
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-28_042_8085154637044190373/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-01_026_5759207694536624992/-mr-10000
 POSTHOOK: Lineage: combine2 PARTITION(value=2010-04-21 09:45:00).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_0).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -195,6 +195,7 @@
         combine2 
           TableScan
             alias: combine2
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -220,16 +221,16 @@
                             type: bigint
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=2010-04-21 09%3A45%3A00 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_0 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_2 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_4 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_5 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_8 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_9 [combine2]
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=| [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=2010-04-21 09%3A45%3A00 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_0 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_2 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_4 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_5 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_8 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_9 [combine2]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=| [combine2]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=2010-04-21 09%3A45%3A00 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=2010-04-21 09%3A45%3A00 
           Partition
             base file name: value=2010-04-21 09%3A45%3A00
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -242,13 +243,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -259,17 +264,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_0 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_0 
           Partition
             base file name: value=val_0
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -282,13 +291,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -299,17 +312,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_2 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_2 
           Partition
             base file name: value=val_2
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -322,13 +339,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -339,17 +360,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_4 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_4 
           Partition
             base file name: value=val_4
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -362,13 +387,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -379,17 +408,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_5 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_5 
           Partition
             base file name: value=val_5
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -402,13 +435,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -419,17 +456,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_8 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_8 
           Partition
             base file name: value=val_8
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -442,13 +483,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -459,17 +504,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=val_9 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=val_9 
           Partition
             base file name: value=val_9
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -482,13 +531,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -499,17 +552,21 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2/value=| 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2/value=| 
           Partition
             base file name: value=|
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -522,13 +579,17 @@
               columns.types string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
               name combine2
+              numFiles 8
+              numPartitions 8
+              numRows 12
               partition_columns value
               serialization.ddl struct combine2 { string key}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282862120
+              totalSize 26
+              transient_lastDdlTime 1284505440
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -539,13 +600,17 @@
                 columns.types string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/combine2
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/combine2
                 name combine2
+                numFiles 8
+                numPartitions 8
+                numRows 12
                 partition_columns value
                 serialization.ddl struct combine2 { string key}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282862120
+                totalSize 26
+                transient_lastDdlTime 1284505440
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: combine2
             name: combine2
@@ -564,8 +629,9 @@
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: file:/tmp/jsichi/hive_2010-08-26_15-35-34_459_5389863301551402910/-ext-10001
+              directory: file:/tmp/nzhang/hive_2010-09-14_16-04-09_079_9198921748154908814/-ext-10001
               NumFilesPerFileSink: 1
+              Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-04-09_079_9198921748154908814/-ext-10001/
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -574,6 +640,7 @@
                     columns.types bigint
                     serialization.format 1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
 
   Stage: Stage-0
@@ -591,7 +658,7 @@
 PREHOOK: Input: default@combine2@value=val_8
 PREHOOK: Input: default@combine2@value=val_9
 PREHOOK: Input: default@combine2@value=|
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-34_737_7254387281263806727/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-09_387_5053968817874885539/-mr-10000
 POSTHOOK: query: select count(1) from combine2 where value is not null
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@combine2@value=2010-04-21 09%3A45%3A00
@@ -602,7 +669,7 @@
 POSTHOOK: Input: default@combine2@value=val_8
 POSTHOOK: Input: default@combine2@value=val_9
 POSTHOOK: Input: default@combine2@value=|
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-34_737_7254387281263806727/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-09_387_5053968817874885539/-mr-10000
 POSTHOOK: Lineage: combine2 PARTITION(value=2010-04-21 09:45:00).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_0).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
@@ -709,14 +776,14 @@
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-42_237_8954112902391689238/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-17_692_1377258316716766979/-mr-10000
 POSTHOOK: query: select ds, count(1) from srcpart where ds is not null group by ds
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
 POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-35-42_237_8954112902391689238/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-04-17_692_1377258316716766979/-mr-10000
 POSTHOOK: Lineage: combine2 PARTITION(value=2010-04-21 09:45:00).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_0).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: combine2 PARTITION(value=val_2).key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input14.q.out
===================================================================
--- ql/src/test/results/clientpositive/input14.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input14.q.out	(working copy)
@@ -27,6 +27,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -100,7 +101,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM (
   FROM src
   SELECT TRANSFORM(src.key, src.value)
@@ -126,11 +130,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-55_010_7742676298933690964/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-06_191_2622126223441202018/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-13-55_010_7742676298933690964/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-27-06_191_2622126223441202018/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	val_0
Index: ql/src/test/results/clientpositive/join32.q.out
===================================================================
--- ql/src/test/results/clientpositive/join32.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/join32.q.out	(working copy)
@@ -19,20 +19,22 @@
   (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_JOIN (TOK_TABREF src1 x) (TOK_TABREF src y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key))) (TOK_TABREF srcpart z) (and (and (= (. (TOK_TABLE_OR_COL x) value) (. (TOK_TABLE_OR_COL z) value)) (= (. (TOK_TABLE_OR_COL z) ds) '2008-04-08')) (= (. (TOK_TABLE_OR_COL z) hr) 11)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest_j1)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST x z))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL z) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL y) value)))))
 
 STAGE DEPENDENCIES:
-  Stage-5 is a root stage
-  Stage-1 depends on stages: Stage-5
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-6 is a root stage
+  Stage-1 depends on stages: Stage-6
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
-  Stage: Stage-5
+  Stage: Stage-6
     Map Reduce
       Alias -> Map Operator Tree:
         y 
           TableScan
             alias: y
+            GatherStats: false
             Common Join Operator
               condition map:
                    Inner Join 0 to 1
@@ -48,7 +50,7 @@
               File Output Operator
                 compressed: false
                 GlobalTableId: 0
-                directory: file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003
+                directory: file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003
                 NumFilesPerFileSink: 1
                 table:
                     input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -58,6 +60,7 @@
                       columns.types string,string,string
                       escape.delim \
                 TotalFiles: 1
+                GatherStats: false
                 MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -69,6 +72,7 @@
             x 
               TableScan
                 alias: x
+                GatherStats: false
                 Common Join Operator
                   condition map:
                        Inner Join 0 to 1
@@ -84,7 +88,7 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 0
-                    directory: file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003
+                    directory: file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003
                     NumFilesPerFileSink: 1
                     table:
                         input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -94,12 +98,13 @@
                           columns.types string,string,string
                           escape.delim \
                     TotalFiles: 1
+                    GatherStats: false
                     MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src [y]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src [y]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src 
           Partition
             base file name: src
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -110,12 +115,12 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
               name src
               serialization.ddl struct src { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282861477
+              transient_lastDdlTime 1284504429
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -126,12 +131,12 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/src
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src
                 name src
                 serialization.ddl struct src { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282861477
+                transient_lastDdlTime 1284504429
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: src
             name: src
@@ -139,7 +144,7 @@
   Stage: Stage-1
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003 
           Select Operator
             expressions:
                   expr: _col0
@@ -182,8 +187,9 @@
                   File Output Operator
                     compressed: false
                     GlobalTableId: 1
-                    directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002
+                    directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002
                     NumFilesPerFileSink: 1
+                    Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000/
                     table:
                         input format: org.apache.hadoop.mapred.TextInputFormat
                         output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -193,15 +199,16 @@
                           columns.types string:string:string
                           file.inputformat org.apache.hadoop.mapred.TextInputFormat
                           file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                          location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                           name dest_j1
                           serialization.ddl struct dest_j1 { string key, string value, string val2}
                           serialization.format 1
                           serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                          transient_lastDdlTime 1282863579
+                          transient_lastDdlTime 1284507624
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest_j1
                     TotalFiles: 1
+                    GatherStats: true
                     MultiFileSpray: false
       Local Work:
         Map Reduce Local Work
@@ -213,6 +220,7 @@
             z 
               TableScan
                 alias: z
+                GatherStats: false
                 Filter Operator
                   isSamplingPred: false
                   predicate:
@@ -261,8 +269,9 @@
                             File Output Operator
                               compressed: false
                               GlobalTableId: 1
-                              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002
+                              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002
                               NumFilesPerFileSink: 1
+                              Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000/
                               table:
                                   input format: org.apache.hadoop.mapred.TextInputFormat
                                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -272,21 +281,22 @@
                                     columns.types string:string:string
                                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                                     name dest_j1
                                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                                     serialization.format 1
                                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                                    transient_lastDdlTime 1282863579
+                                    transient_lastDdlTime 1284507624
                                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                                   name: dest_j1
                               TotalFiles: 1
+                              GatherStats: true
                               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003 [file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003]
+        file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003 [file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003]
       Path -> Partition:
-        file:/tmp/jsichi/hive_2010-08-26_15-59-39_400_2108121170071807592/-mr-10003 
+        file:/tmp/nzhang/hive_2010-09-14_16-40-24_670_614734799076435404/-mr-10003 
           Partition
             base file name: -mr-10003
             input format: org.apache.hadoop.mapred.SequenceFileInputFormat
@@ -303,21 +313,21 @@
                 columns.types string,string,string
                 escape.delim \
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002
-          destination: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -327,24 +337,28 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863579
+                transient_lastDdlTime 1284507624
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
-          tmp directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -355,21 +369,22 @@
                     columns.types string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                     name dest_j1
                     serialization.ddl struct dest_j1 { string key, string value, string val2}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282863579
+                    transient_lastDdlTime 1284507624
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest_j1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002 [pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/jsichi/open/hive-trunk/build/ql/scratchdir/hive_2010-08-26_15-59-39_400_2108121170071807592/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-40-24_670_614734799076435404/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -380,12 +395,12 @@
               columns.types string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
               name dest_j1
               serialization.ddl struct dest_j1 { string key, string value, string val2}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282863579
+              transient_lastDdlTime 1284507624
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -396,12 +411,12 @@
                 columns.types string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/jsichi/open/hive-trunk/build/ql/test/data/warehouse/dest_j1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest_j1
                 name dest_j1
                 serialization.ddl struct dest_j1 { string key, string value, string val2}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282863579
+                transient_lastDdlTime 1284507624
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest_j1
             name: dest_j1
@@ -431,11 +446,11 @@
 PREHOOK: query: select * from dest_j1 x order by x.key
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest_j1
-PREHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-59-45_924_802354274907767943/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-34_819_6730779352355044928/-mr-10000
 POSTHOOK: query: select * from dest_j1 x order by x.key
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest_j1
-POSTHOOK: Output: file:/tmp/jsichi/hive_2010-08-26_15-59-45_924_802354274907767943/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-40-34_819_6730779352355044928/-mr-10000
 POSTHOOK: Lineage: dest_j1.key SIMPLE [(src1)x.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.val2 EXPRESSION [(src)y.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest_j1.value SIMPLE [(srcpart)z.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_part1.q.out
===================================================================
--- ql/src/test/results/clientpositive/input_part1.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_part1.q.out	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -28,6 +29,7 @@
         srcpart 
           TableScan
             alias: srcpart
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -63,8 +65,9 @@
                     File Output Operator
                       compressed: false
                       GlobalTableId: 1
-                      directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002
                       NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10000/
                       table:
                           input format: org.apache.hadoop.mapred.TextInputFormat
                           output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -74,21 +77,22 @@
                             columns.types int:string:string:string
                             file.inputformat org.apache.hadoop.mapred.TextInputFormat
                             file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                            location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                             name dest1
                             serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                             serialization.format 1
                             serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                            transient_lastDdlTime 1282110789
+                            transient_lastDdlTime 1284507230
                           serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                           name: dest1
                       TotalFiles: 1
+                      GatherStats: true
                       MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 [srcpart]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12 
           Partition
             base file name: hr=12
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -102,13 +106,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110625
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -119,32 +123,32 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110625
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002
-          destination: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10000
 
   Stage: Stage-0
     Move Operator
       tables:
           replace: true
-          source: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10000
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10000
           table:
               input format: org.apache.hadoop.mapred.TextInputFormat
               output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -154,24 +158,28 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110789
+                transient_lastDdlTime 1284507230
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
-          tmp directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10001
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10001
 
   Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10000/
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002 
             File Output Operator
               compressed: false
               GlobalTableId: 0
-              directory: pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10000
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10000
               NumFilesPerFileSink: 1
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
@@ -182,21 +190,22 @@
                     columns.types int:string:string:string
                     file.inputformat org.apache.hadoop.mapred.TextInputFormat
                     file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                     name dest1
                     serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                     serialization.format 1
                     serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                    transient_lastDdlTime 1282110789
+                    transient_lastDdlTime 1284507230
                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                   name: dest1
               TotalFiles: 1
+              GatherStats: false
               MultiFileSpray: false
       Needs Tagging: false
       Path -> Alias:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002 [pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002]
       Path -> Partition:
-        pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-17_22-53-09_768_7504078731687419116/-ext-10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_16-33-50_555_5826471825623042341/-ext-10002 
           Partition
             base file name: -ext-10002
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -207,12 +216,12 @@
               columns.types int:string:string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
               name dest1
               serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1282110789
+              transient_lastDdlTime 1284507230
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -223,12 +232,12 @@
                 columns.types int:string:string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1
                 name dest1
                 serialization.ddl struct dest1 { i32 key, string value, string hr, string ds}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1282110789
+                transient_lastDdlTime 1284507230
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
             name: dest1
@@ -251,11 +260,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-14_079_94148126129411057/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-56_460_8215799956158163112/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/tmp/nzhang/hive_2010-08-17_22-53-14_079_94148126129411057/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-33-56_460_8215799956158163112/-mr-10000
 POSTHOOK: Lineage: dest1.ds SIMPLE [(srcpart)srcpart.FieldSchema(name:ds, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.hr SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
 POSTHOOK: Lineage: dest1.key EXPRESSION [(srcpart)srcpart.FieldSchema(name:key, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/cast1.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/cast1.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/cast1.q.out_0.17	(working copy)
@@ -14,10 +14,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -60,14 +61,14 @@
                         serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                         name: dest1
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-07-01_059_6211226289021668764/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-19-03_144_6863717580553730818/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -80,9 +81,12 @@
               name: dest1
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-07-01_059_6211226289021668764/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-19-03_144_6863717580553730818/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -134,11 +138,11 @@
 PREHOOK: query: select dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-07-06_343_4192856580978495449/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-19-09_266_7178118598470671659/-mr-10000
 POSTHOOK: query: select dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_2/build/ql/scratchdir/hive_2010-04-05_18-07-06_343_4192856580978495449/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-19-09_266_7178118598470671659/-mr-10000
 POSTHOOK: Lineage: dest1.c1 EXPRESSION []
 POSTHOOK: Lineage: dest1.c2 EXPRESSION []
 POSTHOOK: Lineage: dest1.c3 EXPRESSION []
Index: ql/src/test/results/clientpositive/mapreduce4.q.out
===================================================================
--- ql/src/test/results/clientpositive/mapreduce4.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/mapreduce4.q.out	(working copy)
@@ -25,6 +25,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -103,7 +104,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: FROM src
 INSERT OVERWRITE TABLE dest1
 MAP src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
@@ -129,11 +133,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-21_594_8556003819517494303/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-26_971_151682627493120411/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-18-21_594_8556003819517494303/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_17-03-26_971_151682627493120411/-mr-10000
 POSTHOOK: Lineage: dest1.key SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.one SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.ten SCRIPT [(src)src.FieldSchema(name:key, type:string, comment:default), (src)src.FieldSchema(name:value, type:string, comment:default), ]
Index: ql/src/test/results/clientpositive/input_testsequencefile.q.out_0.17
===================================================================
--- ql/src/test/results/clientpositive/input_testsequencefile.q.out_0.17	(revision 1000592)
+++ ql/src/test/results/clientpositive/input_testsequencefile.q.out_0.17	(working copy)
@@ -16,10 +16,11 @@
 
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
-  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
   Stage-3
-  Stage-0 depends on stages: Stage-3, Stage-2
-  Stage-2
 
 STAGE PLANS:
   Stage: Stage-1
@@ -51,14 +52,14 @@
                       serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                       name: dest4_sequencefile
 
-  Stage: Stage-4
+  Stage: Stage-5
     Conditional Operator
 
-  Stage: Stage-3
+  Stage: Stage-4
     Move Operator
       files:
           hdfs directory: true
-          destination: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-13-45_382_5554362484000987602/10000
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-22_667_5909431875573959785/-ext-10000
 
   Stage: Stage-0
     Move Operator
@@ -71,9 +72,12 @@
               name: dest4_sequencefile
 
   Stage: Stage-2
+    Stats-Aggr Operator
+
+  Stage: Stage-3
     Map Reduce
       Alias -> Map Operator Tree:
-        file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-13-45_382_5554362484000987602/10002 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_15-52-22_667_5909431875573959785/-ext-10002 
             Reduce Output Operator
               sort order: 
               Map-reduce partition columns:
@@ -112,11 +116,11 @@
 PREHOOK: query: SELECT dest4_sequencefile.* FROM dest4_sequencefile
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest4_sequencefile
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-13-49_831_520446839437800648/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-29_156_8928447853233319985/-mr-10000
 POSTHOOK: query: SELECT dest4_sequencefile.* FROM dest4_sequencefile
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest4_sequencefile
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_0/build/ql/scratchdir/hive_2010-04-05_18-13-49_831_520446839437800648/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-15_15-52-29_156_8928447853233319985/-mr-10000
 POSTHOOK: Lineage: dest4_sequencefile.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest4_sequencefile.value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 238	val_238
Index: ql/src/test/results/clientpositive/stats11.q.out
===================================================================
--- ql/src/test/results/clientpositive/stats11.q.out	(revision 0)
+++ ql/src/test/results/clientpositive/stats11.q.out	(revision 0)
@@ -0,0 +1,1140 @@
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin_part
+PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2
+PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
+PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+PREHOOK: type: LOAD
+POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
+PREHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+PREHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+PREHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+PREHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin_part b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST b))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL b) ds) "2008-04-08"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        a 
+          TableScan
+            alias: a
+            GatherStats: false
+            Common Join Operator
+              condition map:
+                   Inner Join 0 to 1
+              condition expressions:
+                0 {key} {value}
+                1 {value} {ds}
+              handleSkewJoin: false
+              keys:
+                0 [Column[key]]
+                1 [Column[key]]
+              outputColumnNames: _col0, _col1, _col5, _col6
+              Position of Big Table: 0
+              Select Operator
+                expressions:
+                      expr: _col0
+                      type: int
+                      expr: _col1
+                      type: string
+                      expr: _col5
+                      type: string
+                      expr: _col6
+                      type: string
+                outputColumnNames: _col0, _col1, _col5, _col6
+                Filter Operator
+                  isSamplingPred: false
+                  predicate:
+                      expr: (_col6 = '2008-04-08')
+                      type: boolean
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: int
+                          expr: _col1
+                          type: string
+                          expr: _col5
+                          type: string
+                    outputColumnNames: _col0, _col1, _col2
+                    File Output Operator
+                      compressed: false
+                      GlobalTableId: 1
+                      directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002
+                      NumFilesPerFileSink: 1
+                      Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000/
+                      table:
+                          input format: org.apache.hadoop.mapred.TextInputFormat
+                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                          properties:
+                            bucket_count -1
+                            columns key,value1,value2
+                            columns.types string:string:string
+                            file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                            file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                            name bucketmapjoin_tmp_result
+                            serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                            serialization.format 1
+                            serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            transient_lastDdlTime 1284665725
+                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                          name: bucketmapjoin_tmp_result
+                      TotalFiles: 1
+                      GatherStats: true
+                      MultiFileSpray: false
+      Local Work:
+        Map Reduce Local Work
+          Alias -> Map Local Tables:
+            b 
+              Fetch Operator
+                limit: -1
+          Alias -> Map Local Operator Tree:
+            b 
+              TableScan
+                alias: b
+                GatherStats: false
+                Filter Operator
+                  isSamplingPred: false
+                  predicate:
+                      expr: (ds = '2008-04-08')
+                      type: boolean
+                  Common Join Operator
+                    condition map:
+                         Inner Join 0 to 1
+                    condition expressions:
+                      0 {key} {value}
+                      1 {value} {ds}
+                    handleSkewJoin: false
+                    keys:
+                      0 [Column[key]]
+                      1 [Column[key]]
+                    outputColumnNames: _col0, _col1, _col5, _col6
+                    Position of Big Table: 0
+                    Select Operator
+                      expressions:
+                            expr: _col0
+                            type: int
+                            expr: _col1
+                            type: string
+                            expr: _col5
+                            type: string
+                            expr: _col6
+                            type: string
+                      outputColumnNames: _col0, _col1, _col5, _col6
+                      Filter Operator
+                        isSamplingPred: false
+                        predicate:
+                            expr: (_col6 = '2008-04-08')
+                            type: boolean
+                        Select Operator
+                          expressions:
+                                expr: _col0
+                                type: int
+                                expr: _col1
+                                type: string
+                                expr: _col5
+                                type: string
+                          outputColumnNames: _col0, _col1, _col2
+                          File Output Operator
+                            compressed: false
+                            GlobalTableId: 1
+                            directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002
+                            NumFilesPerFileSink: 1
+                            Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000/
+                            table:
+                                input format: org.apache.hadoop.mapred.TextInputFormat
+                                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                properties:
+                                  bucket_count -1
+                                  columns key,value1,value2
+                                  columns.types string:string:string
+                                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                  location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                  name bucketmapjoin_tmp_result
+                                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                                  serialization.format 1
+                                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                  transient_lastDdlTime 1284665725
+                                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                name: bucketmapjoin_tmp_result
+                            TotalFiles: 1
+                            GatherStats: true
+                            MultiFileSpray: false
+          Bucket Mapjoin Context:
+              Alias Bucket Base File Name Mapping:
+                b {srcbucket20.txt=[srcbucket20.txt, srcbucket22.txt], srcbucket21.txt=[srcbucket21.txt, srcbucket23.txt]}
+              Alias Bucket File Name Mapping:
+                b {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt, pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt]}
+              Alias Bucket Output File Name Mapping:
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin 
+          Partition
+            base file name: srcbucket_mapjoin
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count 2
+              bucket_field_name key
+              columns key,value
+              columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+              name srcbucket_mapjoin
+              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284665721
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count 2
+                bucket_field_name key
+                columns key,value
+                columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin
+                name srcbucket_mapjoin
+                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284665721
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcbucket_mapjoin
+            name: srcbucket_mapjoin
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284665725
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10000
+              NumFilesPerFileSink: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    bucket_count -1
+                    columns key,value1,value2
+                    columns.types string:string:string
+                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    name bucketmapjoin_tmp_result
+                    serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    transient_lastDdlTime 1284665725
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: bucketmapjoin_tmp_result
+              TotalFiles: 1
+              GatherStats: false
+              MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-35-25_811_5921577067687191235/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value1,value2
+              columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              name bucketmapjoin_tmp_result
+              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284665725
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284665725
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+            name: bucketmapjoin_tmp_result
+
+
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-35-39_042_2292053960549391675/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-35-39_042_2292053960549391675/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-01_326_1394559857977869870/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-01_326_1394559857977869870/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_hash_result_1
+PREHOOK: Input: default@bucketmapjoin_hash_result_2
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-11_686_145028380865003759/-mr-10000
+POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_hash_result_1
+POSTHOOK: Input: default@bucketmapjoin_hash_result_2
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-11_686_145028380865003759/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+0	0	0
+PREHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+POSTHOOK: query: explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin_part b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value))) (TOK_WHERE (= (. (TOK_TABLE_OR_COL b) ds) "2008-04-08"))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-5 depends on stages: Stage-1 , consists of Stage-4, Stage-3
+  Stage-4
+  Stage-0 depends on stages: Stage-4, Stage-3
+  Stage-2 depends on stages: Stage-0
+  Stage-3
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        b 
+          TableScan
+            alias: b
+            GatherStats: false
+            Filter Operator
+              isSamplingPred: false
+              predicate:
+                  expr: (ds = '2008-04-08')
+                  type: boolean
+              Common Join Operator
+                condition map:
+                     Inner Join 0 to 1
+                condition expressions:
+                  0 {key} {value}
+                  1 {value} {ds}
+                handleSkewJoin: false
+                keys:
+                  0 [Column[key]]
+                  1 [Column[key]]
+                outputColumnNames: _col0, _col1, _col5, _col6
+                Position of Big Table: 1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: int
+                        expr: _col1
+                        type: string
+                        expr: _col5
+                        type: string
+                        expr: _col6
+                        type: string
+                  outputColumnNames: _col0, _col1, _col5, _col6
+                  Filter Operator
+                    isSamplingPred: false
+                    predicate:
+                        expr: (_col6 = '2008-04-08')
+                        type: boolean
+                    Select Operator
+                      expressions:
+                            expr: _col0
+                            type: int
+                            expr: _col1
+                            type: string
+                            expr: _col5
+                            type: string
+                      outputColumnNames: _col0, _col1, _col2
+                      File Output Operator
+                        compressed: false
+                        GlobalTableId: 1
+                        directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002
+                        NumFilesPerFileSink: 1
+                        Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000/
+                        table:
+                            input format: org.apache.hadoop.mapred.TextInputFormat
+                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                            properties:
+                              bucket_count -1
+                              columns key,value1,value2
+                              columns.types string:string:string
+                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                              name bucketmapjoin_tmp_result
+                              numFiles 1
+                              numPartitions 0
+                              numRows 464
+                              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                              serialization.format 1
+                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                              totalSize 8983
+                              transient_lastDdlTime 1284665761
+                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                            name: bucketmapjoin_tmp_result
+                        TotalFiles: 1
+                        GatherStats: true
+                        MultiFileSpray: false
+      Local Work:
+        Map Reduce Local Work
+          Alias -> Map Local Tables:
+            a 
+              Fetch Operator
+                limit: -1
+          Alias -> Map Local Operator Tree:
+            a 
+              TableScan
+                alias: a
+                GatherStats: false
+                Common Join Operator
+                  condition map:
+                       Inner Join 0 to 1
+                  condition expressions:
+                    0 {key} {value}
+                    1 {value} {ds}
+                  handleSkewJoin: false
+                  keys:
+                    0 [Column[key]]
+                    1 [Column[key]]
+                  outputColumnNames: _col0, _col1, _col5, _col6
+                  Position of Big Table: 1
+                  Select Operator
+                    expressions:
+                          expr: _col0
+                          type: int
+                          expr: _col1
+                          type: string
+                          expr: _col5
+                          type: string
+                          expr: _col6
+                          type: string
+                    outputColumnNames: _col0, _col1, _col5, _col6
+                    Filter Operator
+                      isSamplingPred: false
+                      predicate:
+                          expr: (_col6 = '2008-04-08')
+                          type: boolean
+                      Select Operator
+                        expressions:
+                              expr: _col0
+                              type: int
+                              expr: _col1
+                              type: string
+                              expr: _col5
+                              type: string
+                        outputColumnNames: _col0, _col1, _col2
+                        File Output Operator
+                          compressed: false
+                          GlobalTableId: 1
+                          directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002
+                          NumFilesPerFileSink: 1
+                          Stats Publishing Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000/
+                          table:
+                              input format: org.apache.hadoop.mapred.TextInputFormat
+                              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                              properties:
+                                bucket_count -1
+                                columns key,value1,value2
+                                columns.types string:string:string
+                                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                                name bucketmapjoin_tmp_result
+                                numFiles 1
+                                numPartitions 0
+                                numRows 464
+                                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                                serialization.format 1
+                                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                                totalSize 8983
+                                transient_lastDdlTime 1284665761
+                              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                              name: bucketmapjoin_tmp_result
+                          TotalFiles: 1
+                          GatherStats: true
+                          MultiFileSpray: false
+          Bucket Mapjoin Context:
+              Alias Bucket Base File Name Mapping:
+                a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt], srcbucket22.txt=[srcbucket20.txt], srcbucket23.txt=[srcbucket21.txt]}
+              Alias Bucket File Name Mapping:
+                a {pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt=[pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
+              Alias Bucket Output File Name Mapping:
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket20.txt 0
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket21.txt 1
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket22.txt 2
+                pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08/srcbucket23.txt 3
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 [b]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part/ds=2008-04-08 
+          Partition
+            base file name: ds=2008-04-08
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            partition values:
+              ds 2008-04-08
+            properties:
+              bucket_count 4
+              bucket_field_name key
+              columns key,value
+              columns.types int:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+              name srcbucket_mapjoin_part
+              partition_columns ds
+              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              transient_lastDdlTime 1284665721
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count 4
+                bucket_field_name key
+                columns key,value
+                columns.types int:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket_mapjoin_part
+                name srcbucket_mapjoin_part
+                partition_columns ds
+                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                transient_lastDdlTime 1284665721
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: srcbucket_mapjoin_part
+            name: srcbucket_mapjoin_part
+
+  Stage: Stage-5
+    Conditional Operator
+
+  Stage: Stage-4
+    Move Operator
+      files:
+          hdfs directory: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002
+          destination: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000
+
+  Stage: Stage-0
+    Move Operator
+      tables:
+          replace: true
+          source: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000
+          table:
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 8983
+                transient_lastDdlTime 1284665761
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+          tmp directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10001
+
+  Stage: Stage-2
+    Stats-Aggr Operator
+      Stats Aggregation Key Prefix: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000/
+
+  Stage: Stage-3
+    Map Reduce
+      Alias -> Map Operator Tree:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002 
+            File Output Operator
+              compressed: false
+              GlobalTableId: 0
+              directory: pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10000
+              NumFilesPerFileSink: 1
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    bucket_count -1
+                    columns key,value1,value2
+                    columns.types string:string:string
+                    file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                    file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                    location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                    name bucketmapjoin_tmp_result
+                    numFiles 1
+                    numPartitions 0
+                    numRows 464
+                    serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    totalSize 8983
+                    transient_lastDdlTime 1284665761
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: bucketmapjoin_tmp_result
+              TotalFiles: 1
+              GatherStats: false
+              MultiFileSpray: false
+      Needs Tagging: false
+      Path -> Alias:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002 [pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002]
+      Path -> Partition:
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-16_12-36-16_572_898242702780671781/-ext-10002 
+          Partition
+            base file name: -ext-10002
+            input format: org.apache.hadoop.mapred.TextInputFormat
+            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+            properties:
+              bucket_count -1
+              columns key,value1,value2
+              columns.types string:string:string
+              file.inputformat org.apache.hadoop.mapred.TextInputFormat
+              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+              name bucketmapjoin_tmp_result
+              numFiles 1
+              numPartitions 0
+              numRows 464
+              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+              serialization.format 1
+              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              totalSize 8983
+              transient_lastDdlTime 1284665761
+            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+          
+              input format: org.apache.hadoop.mapred.TextInputFormat
+              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+              properties:
+                bucket_count -1
+                columns key,value1,value2
+                columns.types string:string:string
+                file.inputformat org.apache.hadoop.mapred.TextInputFormat
+                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
+                name bucketmapjoin_tmp_result
+                numFiles 1
+                numPartitions 0
+                numRows 464
+                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
+                serialization.format 1
+                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                totalSize 8983
+                transient_lastDdlTime 1284665761
+              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              name: bucketmapjoin_tmp_result
+            name: bucketmapjoin_tmp_result
+
+
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-29_599_6490705534837936982/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-29_599_6490705534837936982/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_1
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcbucket_mapjoin
+PREHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+PREHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08"
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcbucket_mapjoin
+POSTHOOK: Input: default@srcbucket_mapjoin_part@ds=2008-04-08
+POSTHOOK: Output: default@bucketmapjoin_tmp_result
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-53_220_7463746957700915088/-mr-10000
+POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-36-53_220_7463746957700915088/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+464
+PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_tmp_result
+PREHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_tmp_result
+POSTHOOK: Output: default@bucketmapjoin_hash_result_2
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+PREHOOK: type: QUERY
+PREHOOK: Input: default@bucketmapjoin_hash_result_1
+PREHOOK: Input: default@bucketmapjoin_hash_result_2
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-37-03_681_8960608162191818904/-mr-10000
+POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@bucketmapjoin_hash_result_1
+POSTHOOK: Input: default@bucketmapjoin_hash_result_2
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-16_12-37-03_681_8960608162191818904/-mr-10000
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_1.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.key EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:key, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value1 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value1, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_hash_result_2.value2 EXPRESSION [(bucketmapjoin_tmp_result)bucketmapjoin_tmp_result.FieldSchema(name:value2, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.key SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:key, type:int, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value1 SIMPLE [(srcbucket_mapjoin)a.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+POSTHOOK: Lineage: bucketmapjoin_tmp_result.value2 SIMPLE [(srcbucket_mapjoin_part)b.FieldSchema(name:value, type:string, comment:null), ]
+0	0	0
Index: ql/src/test/results/clientpositive/groupby5_noskew.q.out
===================================================================
--- ql/src/test/results/clientpositive/groupby5_noskew.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/groupby5_noskew.q.out	(working copy)
@@ -21,6 +21,7 @@
 STAGE DEPENDENCIES:
   Stage-1 is a root stage
   Stage-0 depends on stages: Stage-1
+  Stage-2 depends on stages: Stage-0
 
 STAGE PLANS:
   Stage: Stage-1
@@ -91,7 +92,10 @@
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: dest1
 
+  Stage: Stage-2
+    Stats-Aggr Operator
 
+
 PREHOOK: query: INSERT OVERWRITE TABLE dest1 
 SELECT src.key, sum(substr(src.value,5)) 
 FROM src
@@ -111,11 +115,11 @@
 PREHOOK: query: SELECT dest1.* FROM dest1
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest1
-PREHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-56_263_5526779934262853594/10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-42_015_4352351780658798312/-mr-10000
 POSTHOOK: query: SELECT dest1.* FROM dest1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
-POSTHOOK: Output: file:/data/users/athusoo/apache_workspaces/hive_trunk_ws1/.ptest_1/build/ql/scratchdir/hive_2010-04-05_18-11-56_263_5526779934262853594/10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-16-42_015_4352351780658798312/-mr-10000
 POSTHOOK: Lineage: dest1.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
 POSTHOOK: Lineage: dest1.value EXPRESSION [(src)src.FieldSchema(name:value, type:string, comment:default), ]
 0	0.0
Index: ql/src/test/results/clientpositive/input23.q.out
===================================================================
--- ql/src/test/results/clientpositive/input23.q.out	(revision 1000592)
+++ ql/src/test/results/clientpositive/input23.q.out	(working copy)
@@ -18,6 +18,7 @@
         a 
           TableScan
             alias: a
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -38,6 +39,7 @@
         b 
           TableScan
             alias: b
+            GatherStats: false
             Filter Operator
               isSamplingPred: false
               predicate:
@@ -57,9 +59,9 @@
                       type: string
       Needs Tagging: true
       Path -> Alias:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 [a]
       Path -> Partition:
-        pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
+        pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11 
           Partition
             base file name: hr=11
             input format: org.apache.hadoop.mapred.TextInputFormat
@@ -73,13 +75,13 @@
               columns.types string:string
               file.inputformat org.apache.hadoop.mapred.TextInputFormat
               file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-              location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+              location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
               name srcpart
               partition_columns ds/hr
               serialization.ddl struct srcpart { string key, string value}
               serialization.format 1
               serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-              transient_lastDdlTime 1280430361
+              transient_lastDdlTime 1284504421
             serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           
               input format: org.apache.hadoop.mapred.TextInputFormat
@@ -90,13 +92,13 @@
                 columns.types string:string
                 file.inputformat org.apache.hadoop.mapred.TextInputFormat
                 file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                location pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart
+                location pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart
                 name srcpart
                 partition_columns ds/hr
                 serialization.ddl struct srcpart { string key, string value}
                 serialization.format 1
                 serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                transient_lastDdlTime 1280430361
+                transient_lastDdlTime 1284504421
               serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
               name: srcpart
             name: srcpart
@@ -137,8 +139,9 @@
                 File Output Operator
                   compressed: false
                   GlobalTableId: 0
-                  directory: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-46-14_501_4797994147601093208/-ext-10001
+                  directory: file:/tmp/nzhang/hive_2010-09-14_16-28-22_487_1236018290365812724/-ext-10001
                   NumFilesPerFileSink: 1
+                  Stats Publishing Key Prefix: file:/tmp/nzhang/hive_2010-09-14_16-28-22_487_1236018290365812724/-ext-10001/
                   table:
                       input format: org.apache.hadoop.mapred.TextInputFormat
                       output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
@@ -147,6 +150,7 @@
                         columns.types string:string:string:string:string:string:string:string
                         serialization.format 1
                   TotalFiles: 1
+                  GatherStats: false
                   MultiFileSpray: false
 
   Stage: Stage-0
@@ -157,8 +161,8 @@
 PREHOOK: query: select * from srcpart a join srcpart b where a.ds = '2008-04-08' and a.hr = '11' and b.ds = '2008-04-08' and b.hr = '14' limit 5
 PREHOOK: type: QUERY
 PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
-PREHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-46-14_647_2733353193176720746/-mr-10000
+PREHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-28-22_685_3035031630294775174/-mr-10000
 POSTHOOK: query: select * from srcpart a join srcpart b where a.ds = '2008-04-08' and a.hr = '11' and b.ds = '2008-04-08' and b.hr = '14' limit 5
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
-POSTHOOK: Output: file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_12-46-14_647_2733353193176720746/-mr-10000
+POSTHOOK: Output: file:/tmp/nzhang/hive_2010-09-14_16-28-22_685_3035031630294775174/-mr-10000
Index: ql/src/test/results/compiler/plan/join2.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join2.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join2.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
@@ -8,7 +8,39 @@
       <void property="childTasks"> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
-         <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+         <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+          <void property="childTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+              <void property="id"> 
+               <string>Stage-5</string> 
+              </void> 
+              <void property="parentTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object idref="MoveTask0"/> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="work"> 
+               <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                <void property="aggKey"> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-56_863_827918457303958748/-ext-10000/</string> 
+                </void> 
+               </object> 
+              </void> 
+             </object> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="feedSubscribers"> 
+           <object class="java.util.LinkedList"> 
+            <void method="add"> 
+             <object idref="StatsTask0"/> 
+            </void> 
+           </object> 
+          </void> 
           <void property="id"> 
            <string>Stage-2</string> 
           </void> 
@@ -30,7 +62,7 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-16_408_7811625023359789610/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-56_863_827918457303958748/-ext-10000</string> 
               </void> 
               <void property="table"> 
                <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -83,11 +115,11 @@
                   </void> 
                   <void method="put"> 
                    <string>location</string> 
-                   <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                   </void> 
                   <void method="put"> 
                    <string>transient_lastDdlTime</string> 
-                   <string>1280428396</string> 
+                   <string>1285060136</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -97,7 +129,7 @@
                </object> 
               </void> 
               <void property="tmpDir"> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-16_408_7811625023359789610/-ext-10001</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-56_863_827918457303958748/-ext-10001</string> 
               </void> 
              </object> 
             </void> 
@@ -175,11 +207,11 @@
              </void> 
              <void method="put"> 
               <string>location</string> 
-              <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+              <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
              </void> 
              <void method="put"> 
               <string>transient_lastDdlTime</string> 
-              <string>1280428393</string> 
+              <string>1285060133</string> 
              </void> 
             </object> 
            </void> 
@@ -781,6 +813,9 @@
           </void> 
          </object> 
         </void> 
+        <void property="gatheringStats"> 
+         <boolean>true</boolean> 
+        </void> 
         <void property="keyDesc"> 
          <object idref="TableDesc2"/> 
         </void> 
@@ -793,7 +828,7 @@
         <void property="pathToAliases"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-33-16_408_7811625023359789610/-mr-10002</string> 
+           <string>file:/tmp/nzhang/hive_2010-09-21_02-08-56_863_827918457303958748/-mr-10002</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>$INTNAME</string> 
@@ -801,7 +836,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <string>src3</string> 
@@ -813,7 +848,7 @@
         <void property="pathToPartitionInfo"> 
          <object class="java.util.LinkedHashMap"> 
           <void method="put"> 
-           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-33-16_408_7811625023359789610/-mr-10002</string> 
+           <string>file:/tmp/nzhang/hive_2010-09-21_02-08-56_863_827918457303958748/-mr-10002</string> 
            <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
             <void property="baseFileName"> 
              <string>-mr-10002</string> 
@@ -862,7 +897,7 @@
            </object> 
           </void> 
           <void method="put"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
            <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
             <void property="baseFileName"> 
              <string>src</string> 
@@ -919,11 +954,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428393</string> 
+               <string>1285060133</string> 
               </void> 
              </object> 
             </void> 
@@ -969,11 +1004,17 @@
                      <int>1</int> 
                     </void> 
                     <void property="dirName"> 
-                     <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-16_408_7811625023359789610/-ext-10000</string> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-56_863_827918457303958748/-ext-10000</string> 
                     </void> 
+                    <void property="gatherStats"> 
+                     <boolean>true</boolean> 
+                    </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-56_863_827918457303958748/-ext-10000/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object idref="TableDesc0"/> 
                     </void> 
@@ -1467,11 +1508,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428393</string> 
+          <string>1285060133</string> 
          </void> 
         </object> 
        </void> 
@@ -1554,11 +1595,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428393</string> 
+          <string>1285060133</string> 
          </void> 
         </object> 
        </void> 
@@ -2136,7 +2177,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -2151,7 +2192,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -2208,11 +2249,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428393</string> 
+           <string>1285060133</string> 
           </void> 
          </object> 
         </void> 
@@ -2251,7 +2292,7 @@
           <void property="conf"> 
            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
             <void property="dirName"> 
-             <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-33-16_408_7811625023359789610/-mr-10002</string> 
+             <string>file:/tmp/nzhang/hive_2010-09-21_02-08-56_863_827918457303958748/-mr-10002</string> 
             </void> 
             <void property="numFiles"> 
              <int>1</int> 
Index: ql/src/test/results/compiler/plan/input2.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input2.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input2.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-8</string> 
+       <string>Stage-9</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-6</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-6</string> 
+                   <string>Stage-7</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342354</string> 
+                                   <string>1285059963</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10006</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342354</string> 
+                           <string>1285059963</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-7</string> 
+           <string>Stage-8</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -423,7 +455,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-11</string> 
+       <string>Stage-13</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -433,6 +465,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask3" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-10</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask3"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10002/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask1"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-3</string> 
               </void> 
@@ -451,14 +515,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-9</string> 
+                   <string>Stage-11</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
                        <object id="TableScanOperator1" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -467,7 +531,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10002</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10002</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -519,7 +583,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -527,7 +591,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342354</string> 
+                                   <string>1285059963</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -634,10 +698,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -646,7 +710,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10007</string> 
@@ -700,11 +764,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342354</string> 
+                           <string>1285059963</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -754,13 +818,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10002</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc1"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10003</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10003</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -771,7 +835,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-10</string> 
+           <string>Stage-12</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork1" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -781,10 +845,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10002</string> 
               </void> 
              </object> 
             </void> 
@@ -810,7 +874,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList1"/> 
@@ -836,7 +900,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-14</string> 
+       <string>Stage-17</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -846,6 +910,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask5" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-14</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask5"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10004/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask2"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-4</string> 
               </void> 
@@ -864,14 +960,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-12</string> 
+                   <string>Stage-15</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
                        <object id="TableScanOperator2" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -880,7 +976,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10004</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10004</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -936,7 +1032,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -944,7 +1040,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342354</string> 
+                                   <string>1285059963</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -1051,10 +1147,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -1063,7 +1159,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10008</string> 
@@ -1117,11 +1213,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342354</string> 
+                           <string>1285059963</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1180,13 +1276,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10004</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10004</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10005</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10005</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1197,7 +1293,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-13</string> 
+           <string>Stage-16</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork2" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1207,10 +1303,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10004</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10004</string> 
               </void> 
              </object> 
             </void> 
@@ -1236,7 +1332,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList2"/> 
@@ -1322,11 +1418,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282342352</string> 
+          <string>1285059961</string> 
          </void> 
         </object> 
        </void> 
@@ -1378,11 +1474,17 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10006</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10000/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc0"/> 
                       </void> 
@@ -1672,11 +1774,17 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10007</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10002/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc1"/> 
                       </void> 
@@ -2012,11 +2120,20 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-34_710_5196005867245551470/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10008</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="staticSpec"> 
+                       <string>ds=2008-04-08/hr=12/</string> 
+                      </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-04_198_2442027476693137276/-ext-10004/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc2"/> 
                       </void> 
@@ -2342,10 +2459,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -2357,7 +2477,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -2414,11 +2534,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282342352</string> 
+           <string>1285059961</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/join3.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join3.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join3.q.xml	(working copy)
@@ -1,10 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
     <void method="add"> 
-     <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+     <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+      <void property="childTasks"> 
+       <object class="java.util.ArrayList"> 
+        <void method="add"> 
+         <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+          <void property="id"> 
+           <string>Stage-4</string> 
+          </void> 
+          <void property="parentTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object idref="MoveTask0"/> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="work"> 
+           <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+            <void property="aggKey"> 
+             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-09-09_886_3678610769088312403/-ext-10000/</string> 
+            </void> 
+           </object> 
+          </void> 
+         </object> 
+        </void> 
+       </object> 
+      </void> 
+      <void property="feedSubscribers"> 
+       <object class="java.util.LinkedList"> 
+        <void method="add"> 
+         <object idref="StatsTask0"/> 
+        </void> 
+       </object> 
+      </void> 
       <void property="id"> 
        <string>Stage-2</string> 
       </void> 
@@ -26,7 +58,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-26_795_8741871014422720580/-ext-10000</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-09-09_886_3678610769088312403/-ext-10000</string> 
           </void> 
           <void property="table"> 
            <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -79,11 +111,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428406</string> 
+               <string>1285060149</string> 
               </void> 
              </object> 
             </void> 
@@ -93,7 +125,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-26_795_8741871014422720580/-ext-10001</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-09-09_886_3678610769088312403/-ext-10001</string> 
           </void> 
          </object> 
         </void> 
@@ -164,11 +196,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428404</string> 
+          <string>1285060147</string> 
          </void> 
         </object> 
        </void> 
@@ -251,11 +283,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428404</string> 
+          <string>1285060147</string> 
          </void> 
         </object> 
        </void> 
@@ -338,11 +370,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428404</string> 
+          <string>1285060147</string> 
          </void> 
         </object> 
        </void> 
@@ -1153,6 +1185,9 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="keyDesc"> 
      <object idref="TableDesc3"/> 
     </void> 
@@ -1165,7 +1200,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -1183,7 +1218,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1240,11 +1275,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428404</string> 
+           <string>1285060147</string> 
           </void> 
          </object> 
         </void> 
@@ -1290,11 +1325,17 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-26_795_8741871014422720580/-ext-10000</string> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-09-09_886_3678610769088312403/-ext-10000</string> 
                 </void> 
+                <void property="gatherStats"> 
+                 <boolean>true</boolean> 
+                </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-09-09_886_3678610769088312403/-ext-10000/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object idref="TableDesc0"/> 
                 </void> 
Index: ql/src/test/results/compiler/plan/input3.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input3.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input3.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-7</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342368</string> 
+                                   <string>1285059987</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10007</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342368</string> 
+                           <string>1285059987</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-8</string> 
+           <string>Stage-9</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -423,7 +455,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-12</string> 
+       <string>Stage-14</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -433,6 +465,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask3" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-11</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask3"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10002/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask1"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-3</string> 
               </void> 
@@ -451,14 +515,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-10</string> 
+                   <string>Stage-12</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
                        <object id="TableScanOperator1" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -467,7 +531,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10002</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10002</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -519,7 +583,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -527,7 +591,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342368</string> 
+                                   <string>1285059987</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -634,10 +698,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -646,7 +710,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10008</string> 
@@ -700,11 +764,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342368</string> 
+                           <string>1285059987</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -754,13 +818,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10002</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc1"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10003</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10003</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -771,7 +835,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-11</string> 
+           <string>Stage-13</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork1" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -781,10 +845,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10002</string> 
               </void> 
              </object> 
             </void> 
@@ -810,7 +874,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList1"/> 
@@ -836,7 +900,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-15</string> 
+       <string>Stage-18</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -846,6 +910,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask5" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-15</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask5"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10004/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask2"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-4</string> 
               </void> 
@@ -864,14 +960,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-13</string> 
+                   <string>Stage-16</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
                        <object id="TableScanOperator2" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -880,7 +976,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10004</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10004</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -936,7 +1032,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -944,7 +1040,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282342368</string> 
+                                   <string>1285059987</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -1051,10 +1147,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -1063,7 +1159,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10009</string> 
@@ -1117,11 +1213,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342368</string> 
+                           <string>1285059987</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1180,13 +1276,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10004</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10004</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10005</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10005</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1197,7 +1293,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-14</string> 
+           <string>Stage-17</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork2" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1207,10 +1303,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10004</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10004</string> 
               </void> 
              </object> 
             </void> 
@@ -1236,7 +1332,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList2"/> 
@@ -1262,7 +1358,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-18</string> 
+       <string>Stage-21</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList3" class="java.util.ArrayList"> 
@@ -1290,14 +1386,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-16</string> 
+                   <string>Stage-19</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork3" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
                        <object id="TableScanOperator3" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -1306,7 +1402,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10006</string> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10006</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -1428,10 +1524,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -1440,7 +1536,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10010</string> 
@@ -1513,7 +1609,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10006</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10006</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../../../../build/contrib/hive/ql/test/data/warehouse/dest4.out</string> 
@@ -1527,7 +1623,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-17</string> 
+           <string>Stage-20</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork3" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1537,10 +1633,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10006</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10006</string> 
               </void> 
              </object> 
             </void> 
@@ -1566,7 +1662,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList3"/> 
@@ -1652,11 +1748,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282342365</string> 
+          <string>1285059985</string> 
          </void> 
         </object> 
        </void> 
@@ -1708,11 +1804,17 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10007</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10000/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc0"/> 
                       </void> 
@@ -2002,11 +2104,17 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10008</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10002/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc1"/> 
                       </void> 
@@ -2342,11 +2450,20 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10009</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="staticSpec"> 
+                       <string>ds=2008-04-08/hr=12/</string> 
+                      </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10004/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc2"/> 
                       </void> 
@@ -2676,11 +2793,14 @@
                        <int>4</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-12-48_747_4732045378158390017/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10010</string> 
                       </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-27_658_374598079086710545/-ext-10006/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc3"/> 
                       </void> 
@@ -2985,10 +3105,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -3000,7 +3123,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -3057,11 +3180,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282342365</string> 
+           <string>1285059985</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/join4.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join4.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join4.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428421</string> 
+          <string>1284515249</string> 
          </void> 
         </object> 
        </void> 
@@ -149,11 +149,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428421</string> 
+          <string>1284515249</string> 
          </void> 
         </object> 
        </void> 
@@ -1697,7 +1697,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1712,7 +1712,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1769,11 +1769,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428421</string> 
+           <string>1284515249</string> 
           </void> 
          </object> 
         </void> 
@@ -1820,11 +1820,14 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-33-44_273_7704263600537075966/-ext-10001</string> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-47-32_993_1776803441709697433/-ext-10001</string> 
                     </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-47-32_993_1776803441709697433/-ext-10001/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                       <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/input4.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input4.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input4.q.xml	(working copy)
@@ -1,10 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
     <void method="add"> 
-     <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+     <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+      <void property="childTasks"> 
+       <object class="java.util.ArrayList"> 
+        <void method="add"> 
+         <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+          <void property="id"> 
+           <string>Stage-4</string> 
+          </void> 
+          <void property="parentTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object idref="MoveTask0"/> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="work"> 
+           <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+            <void property="aggKey"> 
+             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-39_512_5913554628239417814/-ext-10000/</string> 
+            </void> 
+           </object> 
+          </void> 
+         </object> 
+        </void> 
+       </object> 
+      </void> 
+      <void property="feedSubscribers"> 
+       <object class="java.util.LinkedList"> 
+        <void method="add"> 
+         <object idref="StatsTask0"/> 
+        </void> 
+       </object> 
+      </void> 
       <void property="id"> 
        <string>Stage-2</string> 
       </void> 
@@ -26,7 +58,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-17_258_7402649458676219691/-ext-10000</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-39_512_5913554628239417814/-ext-10000</string> 
           </void> 
           <void property="table"> 
            <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -79,11 +111,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428276</string> 
+               <string>1285059999</string> 
               </void> 
              </object> 
             </void> 
@@ -93,7 +125,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-17_258_7402649458676219691/-ext-10001</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-39_512_5913554628239417814/-ext-10001</string> 
           </void> 
          </object> 
         </void> 
@@ -164,11 +196,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428274</string> 
+          <string>1285059996</string> 
          </void> 
         </object> 
        </void> 
@@ -792,6 +824,9 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="keyDesc"> 
      <object idref="TableDesc1"/> 
     </void> 
@@ -801,7 +836,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src</string> 
@@ -813,7 +848,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -870,11 +905,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428274</string> 
+           <string>1285059996</string> 
           </void> 
          </object> 
         </void> 
@@ -924,11 +959,17 @@
                      <int>1</int> 
                     </void> 
                     <void property="dirName"> 
-                     <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-17_258_7402649458676219691/-ext-10000</string> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-39_512_5913554628239417814/-ext-10000</string> 
                     </void> 
+                    <void property="gatherStats"> 
+                     <boolean>true</boolean> 
+                    </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-39_512_5913554628239417814/-ext-10000/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object idref="TableDesc0"/> 
                     </void> 
Index: ql/src/test/results/compiler/plan/join5.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join5.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join5.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428432</string> 
+          <string>1284515264</string> 
          </void> 
         </object> 
        </void> 
@@ -149,11 +149,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428432</string> 
+          <string>1284515264</string> 
          </void> 
         </object> 
        </void> 
@@ -1697,7 +1697,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1712,7 +1712,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1769,11 +1769,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428432</string> 
+           <string>1284515264</string> 
           </void> 
          </object> 
         </void> 
@@ -1820,11 +1820,14 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-33-55_679_4766407629267536508/-ext-10001</string> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-47-47_516_7090031919646730769/-ext-10001</string> 
                     </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-47-47_516_7090031919646730769/-ext-10001/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                       <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/input5.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input5.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input5.q.xml	(working copy)
@@ -1,10 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
     <void method="add"> 
-     <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+     <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+      <void property="childTasks"> 
+       <object class="java.util.ArrayList"> 
+        <void method="add"> 
+         <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+          <void property="id"> 
+           <string>Stage-4</string> 
+          </void> 
+          <void property="parentTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object idref="MoveTask0"/> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="work"> 
+           <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+            <void property="aggKey"> 
+             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-51_132_3822544942867535047/-ext-10000/</string> 
+            </void> 
+           </object> 
+          </void> 
+         </object> 
+        </void> 
+       </object> 
+      </void> 
+      <void property="feedSubscribers"> 
+       <object class="java.util.LinkedList"> 
+        <void method="add"> 
+         <object idref="StatsTask0"/> 
+        </void> 
+       </object> 
+      </void> 
       <void property="id"> 
        <string>Stage-2</string> 
       </void> 
@@ -26,7 +58,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-28_833_2501166853352335770/-ext-10000</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-51_132_3822544942867535047/-ext-10000</string> 
           </void> 
           <void property="table"> 
            <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -79,11 +111,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428287</string> 
+               <string>1285060010</string> 
               </void> 
              </object> 
             </void> 
@@ -93,7 +125,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-28_833_2501166853352335770/-ext-10001</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-51_132_3822544942867535047/-ext-10001</string> 
           </void> 
          </object> 
         </void> 
@@ -168,11 +200,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428287</string> 
+          <string>1285060010</string> 
          </void> 
         </object> 
        </void> 
@@ -886,6 +918,9 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="keyDesc"> 
      <object idref="TableDesc1"/> 
     </void> 
@@ -895,7 +930,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src_thrift</string> 
@@ -907,7 +942,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src_thrift</string> 
@@ -968,11 +1003,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428287</string> 
+           <string>1285060010</string> 
           </void> 
          </object> 
         </void> 
@@ -1018,11 +1053,17 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-31-28_833_2501166853352335770/-ext-10000</string> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-51_132_3822544942867535047/-ext-10000</string> 
                 </void> 
+                <void property="gatherStats"> 
+                 <boolean>true</boolean> 
+                </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-06-51_132_3822544942867535047/-ext-10000/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object idref="TableDesc0"/> 
                 </void> 
Index: ql/src/test/results/compiler/plan/join6.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join6.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join6.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428444</string> 
+          <string>1284515278</string> 
          </void> 
         </object> 
        </void> 
@@ -149,11 +149,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428444</string> 
+          <string>1284515278</string> 
          </void> 
         </object> 
        </void> 
@@ -1697,7 +1697,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1712,7 +1712,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1769,11 +1769,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428444</string> 
+           <string>1284515278</string> 
           </void> 
          </object> 
         </void> 
@@ -1820,11 +1820,14 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-34-06_582_4634593079540338600/-ext-10001</string> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-48-02_399_2638901779928643400/-ext-10001</string> 
                     </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-48-02_399_2638901779928643400/-ext-10001/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                       <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/input_testxpath2.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input_testxpath2.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input_testxpath2.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -66,11 +66,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428374</string> 
+          <string>1284515195</string> 
          </void> 
         </object> 
        </void> 
@@ -123,11 +123,14 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-32-55_229_6309081763005434975/-ext-10001</string> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-46-36_762_8341983365749825606/-ext-10001</string> 
                           </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-46-36_762_8341983365749825606/-ext-10001/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                             <void property="deserializerClass"> 
@@ -920,7 +923,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -932,7 +935,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src_thrift</string> 
@@ -993,11 +996,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428374</string> 
+           <string>1284515195</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input6.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input6.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input6.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147547</string> 
+                                   <string>1285060022</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147547</string> 
+                           <string>1285060022</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -483,11 +515,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147545</string> 
+          <string>1285060020</string> 
          </void> 
         </object> 
        </void> 
@@ -543,11 +575,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-05-48_363_8755334440910760130/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-02_793_2672435322479052705/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -945,10 +983,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -960,7 +1001,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -1017,11 +1058,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147545</string> 
+           <string>1285060020</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/join7.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join7.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join7.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428454</string> 
+          <string>1284515293</string> 
          </void> 
         </object> 
        </void> 
@@ -149,11 +149,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428454</string> 
+          <string>1284515293</string> 
          </void> 
         </object> 
        </void> 
@@ -236,11 +236,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428454</string> 
+          <string>1284515293</string> 
          </void> 
         </object> 
        </void> 
@@ -2527,7 +2527,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -2545,7 +2545,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -2602,11 +2602,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428454</string> 
+           <string>1284515293</string> 
           </void> 
          </object> 
         </void> 
@@ -2653,11 +2653,14 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-34-17_232_5474968231933889523/-ext-10001</string> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-48-17_254_2157660357617513137/-ext-10001</string> 
                     </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-48-17_254_2157660357617513137/-ext-10001/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                       <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/input7.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input7.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input7.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147561</string> 
+                                   <string>1285060037</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147561</string> 
+                           <string>1285060037</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -483,11 +515,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147559</string> 
+          <string>1285060033</string> 
          </void> 
         </object> 
        </void> 
@@ -535,11 +567,17 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-01_670_5776501343765801683/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10002</string> 
                   </void> 
+                  <void property="gatherStats"> 
+                   <boolean>true</boolean> 
+                  </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-17_978_6054548314372730709/-ext-10000/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object idref="TableDesc0"/> 
                   </void> 
@@ -785,10 +823,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -800,7 +841,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -857,11 +898,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147559</string> 
+           <string>1285060033</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input2.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input2.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input2.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-8</string> 
+       <string>Stage-9</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-6</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-6</string> 
+                   <string>Stage-7</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10006</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342646</string> 
+                           <string>1285088529</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342646</string> 
+                                 <string>1285088529</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -592,13 +624,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -609,7 +641,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-7</string> 
+           <string>Stage-8</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -619,10 +651,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -648,7 +680,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -674,7 +706,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-11</string> 
+       <string>Stage-13</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -684,6 +716,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask3" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-10</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask3"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10002/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask1"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-3</string> 
               </void> 
@@ -702,14 +766,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-9</string> 
+                   <string>Stage-11</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
                        <object id="TableScanOperator1" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -946,10 +1010,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -958,7 +1022,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10007</string> 
@@ -1012,11 +1076,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342646</string> 
+                           <string>1285088529</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1055,7 +1119,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10002</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10002</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -1107,7 +1171,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -1115,7 +1179,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342646</string> 
+                                 <string>1285088529</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -1252,13 +1316,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10002</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc5"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10003</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10003</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1269,7 +1333,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-10</string> 
+           <string>Stage-12</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork1" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1279,10 +1343,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10002</string> 
               </void> 
              </object> 
             </void> 
@@ -1308,7 +1372,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList1"/> 
@@ -1334,7 +1398,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-14</string> 
+       <string>Stage-17</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -1344,6 +1408,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask5" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-14</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask5"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10004/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask2"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-4</string> 
               </void> 
@@ -1362,14 +1458,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-12</string> 
+                   <string>Stage-15</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
                        <object id="TableScanOperator2" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -1606,10 +1702,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -1618,7 +1714,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10008</string> 
@@ -1672,11 +1768,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342646</string> 
+                           <string>1285088529</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1715,7 +1811,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10004</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10004</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -1771,7 +1867,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -1779,7 +1875,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342646</string> 
+                                 <string>1285088529</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -1929,13 +2025,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10004</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10004</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc8"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10005</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10005</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1946,7 +2042,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-13</string> 
+           <string>Stage-16</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork2" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1956,10 +2052,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10004</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10004</string> 
               </void> 
              </object> 
             </void> 
@@ -1985,7 +2081,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList2"/> 
@@ -2071,11 +2167,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282342643</string> 
+          <string>1285088527</string> 
          </void> 
         </object> 
        </void> 
@@ -2127,11 +2223,17 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10006</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10006</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10000/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc2"/> 
                       </void> 
@@ -2417,11 +2519,17 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10007</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10002/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc5"/> 
                       </void> 
@@ -2757,11 +2865,20 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-26_585_4907699827582916983/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10008</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="staticSpec"> 
+                       <string>ds=2008-04-08/hr=12/</string> 
+                      </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-10_127_1924681203256742581/-ext-10004/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc8"/> 
                       </void> 
@@ -3087,10 +3204,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -3102,7 +3222,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -3159,11 +3279,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282342643</string> 
+           <string>1285088527</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input8.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input8.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input8.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428319</string> 
+          <string>1284515127</string> 
          </void> 
         </object> 
        </void> 
@@ -111,11 +111,14 @@
                 <void property="conf"> 
                  <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                   <void property="dirName"> 
-                   <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-32-01_241_722568681933551707/-ext-10001</string> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-45-29_655_5775586697213224493/-ext-10001</string> 
                   </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-45-29_655_5775586697213224493/-ext-10001/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                     <void property="deserializerClass"> 
@@ -550,7 +553,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -562,7 +565,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -619,11 +622,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428319</string> 
+           <string>1284515127</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/join8.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join8.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join8.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428466</string> 
+          <string>1284515308</string> 
          </void> 
         </object> 
        </void> 
@@ -149,11 +149,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428466</string> 
+          <string>1284515308</string> 
          </void> 
         </object> 
        </void> 
@@ -1697,7 +1697,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>c:a:src1</string> 
@@ -1712,7 +1712,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1769,11 +1769,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428466</string> 
+           <string>1284515308</string> 
           </void> 
          </object> 
         </void> 
@@ -1824,11 +1824,14 @@
                       <void property="conf"> 
                        <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                         <void property="dirName"> 
-                         <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-34-28_793_5549220000529260542/-ext-10001</string> 
+                         <string>file:/tmp/nzhang/hive_2010-09-14_18-48-32_346_3067613000298838276/-ext-10001</string> 
                         </void> 
                         <void property="numFiles"> 
                          <int>1</int> 
                         </void> 
+                        <void property="statsAggPrefix"> 
+                         <string>file:/tmp/nzhang/hive_2010-09-14_18-48-32_346_3067613000298838276/-ext-10001/</string> 
+                        </void> 
                         <void property="tableInfo"> 
                          <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                           <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/input_testsequencefile.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input_testsequencefile.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input_testsequencefile.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147616</string> 
+                                   <string>1285060087</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147616</string> 
+                           <string>1285060087</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -483,11 +515,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147613</string> 
+          <string>1285060084</string> 
          </void> 
         </object> 
        </void> 
@@ -535,11 +567,17 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-56_572_723992170322974871/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10002</string> 
                   </void> 
+                  <void property="gatherStats"> 
+                   <boolean>true</boolean> 
+                  </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-07_519_2166152562536467500/-ext-10000/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object idref="TableDesc0"/> 
                   </void> 
@@ -790,10 +828,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -805,7 +846,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -862,11 +903,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147613</string> 
+           <string>1285060084</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/union.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/union.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/union.q.xml	(working copy)
@@ -41,7 +41,7 @@
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +50,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10000</string> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -186,10 +186,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -198,7 +198,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10001</string> 
@@ -271,7 +271,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10000</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10000</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -295,10 +295,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10000</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -324,7 +324,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -410,11 +410,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147984</string> 
+          <string>1284515530</string> 
          </void> 
         </object> 
        </void> 
@@ -497,11 +497,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147984</string> 
+          <string>1284515530</string> 
          </void> 
         </object> 
        </void> 
@@ -565,11 +565,14 @@
                                    <int>1</int> 
                                   </void> 
                                   <void property="dirName"> 
-                                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-13-08_058_7663964971495656896/-ext-10001</string> 
+                                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10001</string> 
                                   </void> 
                                   <void property="numFiles"> 
                                    <int>1</int> 
                                   </void> 
+                                  <void property="statsAggPrefix"> 
+                                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-52-14_290_2068509297375943199/-ext-10000/</string> 
+                                  </void> 
                                   <void property="tableInfo"> 
                                    <object idref="TableDesc0"/> 
                                   </void> 
@@ -1598,7 +1601,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>null-subquery1:unioninput-subquery1:src</string> 
@@ -1613,7 +1616,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1670,11 +1673,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147984</string> 
+           <string>1284515530</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input9.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input9.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input9.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147587</string> 
+                                   <string>1285060062</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147587</string> 
+                           <string>1285060062</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -483,11 +515,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147585</string> 
+          <string>1285060060</string> 
          </void> 
         </object> 
        </void> 
@@ -543,11 +575,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-06-28_303_6253140973665490005/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-07-42_896_1688606472347731264/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -959,10 +997,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -974,7 +1015,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -1031,11 +1072,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147585</string> 
+           <string>1285060060</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input6.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input6.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input6.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348023</string> 
+                           <string>1285088595</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348023</string> 
+                                 <string>1285088595</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -592,13 +624,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -609,7 +641,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -619,10 +651,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -648,7 +680,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -734,11 +766,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348021</string> 
+          <string>1285088593</string> 
          </void> 
         </object> 
        </void> 
@@ -794,11 +826,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-03_859_7548580601516208695/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-16_017_3769455226481301869/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1196,10 +1234,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -1211,7 +1252,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -1268,11 +1309,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348021</string> 
+           <string>1285088593</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input_testsequencefile.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input_testsequencefile.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input_testsequencefile.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348092</string> 
+                           <string>1285088668</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest4_sequencefile</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348092</string> 
+                                 <string>1285088668</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -592,13 +624,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -609,7 +641,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -619,10 +651,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -648,7 +680,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -734,11 +766,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348089</string> 
+          <string>1285088664</string> 
          </void> 
         </object> 
        </void> 
@@ -786,11 +818,17 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-48-12_934_9100142830321810955/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10002</string> 
                   </void> 
+                  <void property="gatherStats"> 
+                   <boolean>true</boolean> 
+                  </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-04-28_825_4862332993110522962/-ext-10000/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object idref="TableDesc2"/> 
                   </void> 
@@ -1041,10 +1079,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1056,7 +1097,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1113,11 +1154,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348089</string> 
+           <string>1285088664</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/udf1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/udf1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/udf1.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428563</string> 
+          <string>1284515450</string> 
          </void> 
         </object> 
        </void> 
@@ -119,11 +119,14 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-36-05_931_7419020417472725956/-ext-10001</string> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-50-54_460_2854737475405552490/-ext-10001</string> 
                           </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-50-54_460_2854737475405552490/-ext-10001/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                             <void property="deserializerClass"> 
@@ -1823,7 +1826,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1835,7 +1838,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1892,11 +1895,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428563</string> 
+           <string>1284515450</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/udf4.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/udf4.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/udf4.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428575</string> 
+          <string>1284515470</string> 
          </void> 
         </object> 
        </void> 
@@ -111,11 +111,14 @@
                 <void property="conf"> 
                  <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                   <void property="dirName"> 
-                   <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-36-16_270_5974993682577917215/-ext-10001</string> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-51-10_695_8552333714232132191/-ext-10001</string> 
                   </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-51-10_695_8552333714232132191/-ext-10001/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                     <void property="deserializerClass"> 
@@ -1635,7 +1638,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>dest1</string> 
@@ -1647,7 +1650,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>dest1</string> 
@@ -1704,11 +1707,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428575</string> 
+           <string>1284515470</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input_testxpath.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input_testxpath.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input_testxpath.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -66,11 +66,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428364</string> 
+          <string>1284515181</string> 
          </void> 
         </object> 
        </void> 
@@ -115,11 +115,14 @@
                 <void property="conf"> 
                  <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                   <void property="dirName"> 
-                   <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-32-45_063_2743394562997908149/-ext-10001</string> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-46-23_177_3030485151715837750/-ext-10001</string> 
                   </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-46-23_177_3030485151715837750/-ext-10001/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                     <void property="deserializerClass"> 
@@ -655,7 +658,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -667,7 +670,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src_thrift</string> 
@@ -728,11 +731,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src_thrift</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428364</string> 
+           <string>1284515181</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/udf6.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/udf6.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/udf6.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428583</string> 
+          <string>1284515482</string> 
          </void> 
         </object> 
        </void> 
@@ -111,11 +111,14 @@
                 <void property="conf"> 
                  <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                   <void property="dirName"> 
-                   <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-36-26_046_9042300921461782115/-ext-10001</string> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-51-27_061_6114610854850063770/-ext-10001</string> 
                   </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>file:/tmp/nzhang/hive_2010-09-14_18-51-27_061_6114610854850063770/-ext-10001/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                     <void property="deserializerClass"> 
@@ -490,7 +493,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -502,7 +505,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -559,11 +562,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428583</string> 
+           <string>1284515482</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input_part1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input_part1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input_part1.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -75,11 +75,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428332</string> 
+          <string>1284515144</string> 
          </void> 
         </object> 
        </void> 
@@ -132,11 +132,14 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-32-22_247_7387614374769260367/-ext-10001</string> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-45-56_033_5530819907161289974/-ext-10001</string> 
                           </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-45-56_033_5530819907161289974/-ext-10001/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                             <void property="deserializerClass"> 
@@ -1056,7 +1059,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>srcpart</string> 
@@ -1068,7 +1071,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=12</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>hr=12</string> 
@@ -1138,11 +1141,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428332</string> 
+           <string>1284515144</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/groupby1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby1.q.xml	(working copy)
@@ -1,10 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
     <void method="add"> 
-     <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+     <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+      <void property="childTasks"> 
+       <object class="java.util.ArrayList"> 
+        <void method="add"> 
+         <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+          <void property="id"> 
+           <string>Stage-4</string> 
+          </void> 
+          <void property="parentTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object idref="MoveTask0"/> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="work"> 
+           <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+            <void property="aggKey"> 
+             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-44_592_4545947762604807971/-ext-10000/</string> 
+            </void> 
+           </object> 
+          </void> 
+         </object> 
+        </void> 
+       </object> 
+      </void> 
+      <void property="feedSubscribers"> 
+       <object class="java.util.LinkedList"> 
+        <void method="add"> 
+         <object idref="StatsTask0"/> 
+        </void> 
+       </object> 
+      </void> 
       <void property="id"> 
        <string>Stage-2</string> 
       </void> 
@@ -26,7 +58,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-29-33_800_2301810670430516448/-ext-10000</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-44_592_4545947762604807971/-ext-10000</string> 
           </void> 
           <void property="table"> 
            <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -79,11 +111,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428173</string> 
+               <string>1285059884</string> 
               </void> 
              </object> 
             </void> 
@@ -93,7 +125,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-29-33_800_2301810670430516448/-ext-10001</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-44_592_4545947762604807971/-ext-10001</string> 
           </void> 
          </object> 
         </void> 
@@ -164,11 +196,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428171</string> 
+          <string>1285059881</string> 
          </void> 
         </object> 
        </void> 
@@ -766,6 +798,9 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="keyDesc"> 
      <object idref="TableDesc1"/> 
     </void> 
@@ -775,7 +810,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -787,7 +822,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -844,11 +879,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428171</string> 
+           <string>1285059881</string> 
           </void> 
          </object> 
         </void> 
@@ -894,11 +929,17 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-29-33_800_2301810670430516448/-ext-10000</string> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-44_592_4545947762604807971/-ext-10000</string> 
                 </void> 
+                <void property="gatherStats"> 
+                 <boolean>true</boolean> 
+                </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-44_592_4545947762604807971/-ext-10000/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object idref="TableDesc0"/> 
                 </void> 
Index: ql/src/test/results/compiler/plan/udf_case.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/udf_case.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/udf_case.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428593</string> 
+          <string>1284515499</string> 
          </void> 
         </object> 
        </void> 
@@ -115,11 +115,14 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-36-35_720_8123425694890521692/-ext-10001</string> 
+                       <string>file:/tmp/nzhang/hive_2010-09-14_18-51-42_745_6167539490084767001/-ext-10001</string> 
                       </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>file:/tmp/nzhang/hive_2010-09-14_18-51-42_745_6167539490084767001/-ext-10001/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                         <void property="deserializerClass"> 
@@ -587,7 +590,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -599,7 +602,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -656,11 +659,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428593</string> 
+           <string>1284515499</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/groupby2.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby2.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby2.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428182</string> 
+          <string>1284514967</string> 
          </void> 
         </object> 
        </void> 
@@ -912,7 +912,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -924,7 +924,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -981,11 +981,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428182</string> 
+           <string>1284514967</string> 
           </void> 
          </object> 
         </void> 
@@ -1028,11 +1028,14 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-29-44_468_1659933548455097006/-ext-10001</string> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-42-50_072_3573059188041183865/-ext-10001</string> 
                 </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-42-50_072_3573059188041183865/-ext-10001/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                   <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/sample3.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample3.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample3.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348292</string> 
+                           <string>1285088866</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348292</string> 
+                                 <string>1285088866</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348285</string> 
+          <string>1285088859</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-33_366_1938874611311105391/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-47_275_3150568201273641742/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1440,10 +1478,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1455,7 +1496,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket</string> 
@@ -1516,11 +1557,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348285</string> 
+           <string>1285088859</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/subq.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/subq.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/subq.q.xml	(working copy)
@@ -41,7 +41,7 @@
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +50,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10000</string> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -186,10 +186,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -198,7 +198,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10001</string> 
@@ -271,7 +271,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10000</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10000</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -295,10 +295,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10000</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -324,7 +324,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -410,11 +410,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147892</string> 
+          <string>1284515434</string> 
          </void> 
         </object> 
        </void> 
@@ -474,11 +474,14 @@
                                <int>1</int> 
                               </void> 
                               <void property="dirName"> 
-                               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-36_131_240909767222021922/-ext-10001</string> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10001</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
                               </void> 
+                              <void property="statsAggPrefix"> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-14_18-50-38_446_2777297993519581268/-ext-10000/</string> 
+                              </void> 
                               <void property="tableInfo"> 
                                <object idref="TableDesc0"/> 
                               </void> 
@@ -1049,7 +1052,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>unioninput:src</string> 
@@ -1061,7 +1064,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1118,11 +1121,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147892</string> 
+           <string>1284515434</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/groupby3.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby3.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby3.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428192</string> 
+          <string>1284514978</string> 
          </void> 
         </object> 
        </void> 
@@ -1106,7 +1106,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1118,7 +1118,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1175,11 +1175,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428192</string> 
+           <string>1284514978</string> 
           </void> 
          </object> 
         </void> 
@@ -1222,11 +1222,14 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-29-54_746_162436749727596868/-ext-10001</string> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-01_226_2591686613684987491/-ext-10001</string> 
                 </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-01_226_2591686613684987491/-ext-10001/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                   <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/groupby4.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby4.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby4.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428203</string> 
+          <string>1284514990</string> 
          </void> 
         </object> 
        </void> 
@@ -583,7 +583,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -595,7 +595,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -652,11 +652,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428203</string> 
+           <string>1284514990</string> 
           </void> 
          </object> 
         </void> 
@@ -699,11 +699,14 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-30-05_693_3783786933944995344/-ext-10001</string> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-12_775_3230378318165156313/-ext-10001</string> 
                 </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-12_775_3230378318165156313/-ext-10001/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                   <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/sample5.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample5.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample5.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348323</string> 
+                           <string>1285088898</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348323</string> 
+                                 <string>1285088898</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348316</string> 
+          <string>1285088891</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-04_186_6650848930367124424/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-18_929_3156111736810636947/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1414,10 +1452,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1429,7 +1470,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket</string> 
@@ -1490,11 +1531,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348316</string> 
+           <string>1285088891</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/groupby5.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby5.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby5.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428213</string> 
+          <string>1284515001</string> 
          </void> 
         </object> 
        </void> 
@@ -673,7 +673,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -685,7 +685,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -742,11 +742,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428213</string> 
+           <string>1284515001</string> 
           </void> 
          </object> 
         </void> 
@@ -789,11 +789,14 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-30-15_900_4818679564611712713/-ext-10001</string> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-24_463_8299229933466697551/-ext-10001</string> 
                 </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-24_463_8299229933466697551/-ext-10001/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                   <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/groupby6.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/groupby6.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/groupby6.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428223</string> 
+          <string>1284515013</string> 
          </void> 
         </object> 
        </void> 
@@ -583,7 +583,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -595,7 +595,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -652,11 +652,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428223</string> 
+           <string>1284515013</string> 
           </void> 
          </object> 
         </void> 
@@ -699,11 +699,14 @@
               <void property="conf"> 
                <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                 <void property="dirName"> 
-                 <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-30-26_002_5306711662774174602/-ext-10001</string> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-35_954_6906067546886929928/-ext-10001</string> 
                 </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>file:/tmp/nzhang/hive_2010-09-14_18-43-35_954_6906067546886929928/-ext-10001/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                   <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/sample7.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample7.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample7.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348354</string> 
+                           <string>1285088930</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348354</string> 
+                                 <string>1285088930</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348346</string> 
+          <string>1285088922</string> 
          </void> 
         </object> 
        </void> 
@@ -806,11 +838,17 @@
                                <int>1</int> 
                               </void> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-34_947_1865117936135905102/-ext-10002</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10002</string> 
                               </void> 
+                              <void property="gatherStats"> 
+                               <boolean>true</boolean> 
+                              </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
                               </void> 
+                              <void property="statsAggPrefix"> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-50_607_823079248822088974/-ext-10000/</string> 
+                              </void> 
                               <void property="tableInfo"> 
                                <object idref="TableDesc2"/> 
                               </void> 
@@ -1587,10 +1625,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1602,7 +1643,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1663,11 +1704,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348346</string> 
+           <string>1285088922</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/case_sensitivity.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/case_sensitivity.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/case_sensitivity.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147375</string> 
+                                   <string>1285059859</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147375</string> 
+                           <string>1285059859</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147374</string> 
+          <string>1285059858</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-02-55_878_2394926215289210955/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-04-19_598_2303560956024146796/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1188,10 +1226,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -1203,7 +1244,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src_thrift</string> 
@@ -1264,11 +1305,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147374</string> 
+           <string>1285059858</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input1.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input1.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input1.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342632</string> 
+                           <string>1285088518</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342632</string> 
+                                 <string>1285088518</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -592,13 +624,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -609,7 +641,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -619,10 +651,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -648,7 +680,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -734,11 +766,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282342630</string> 
+          <string>1285088516</string> 
          </void> 
         </object> 
        </void> 
@@ -794,11 +826,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-13_163_8062922511351309149/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-01-58_847_2744656327474639597/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1240,10 +1278,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1255,7 +1296,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1312,11 +1353,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282342630</string> 
+           <string>1285088516</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input3.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input3.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input3.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-9</string> 
+       <string>Stage-10</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-7</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-7</string> 
+                   <string>Stage-8</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10007</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342659</string> 
+                           <string>1285088555</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342659</string> 
+                                 <string>1285088555</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -592,13 +624,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -609,7 +641,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-8</string> 
+           <string>Stage-9</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -619,10 +651,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -648,7 +680,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -674,7 +706,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-12</string> 
+       <string>Stage-14</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList1" class="java.util.ArrayList"> 
@@ -684,6 +716,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask3" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask1" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-11</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask3"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10002/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask1"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-3</string> 
               </void> 
@@ -702,14 +766,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-10</string> 
+                   <string>Stage-12</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork1" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
                        <object id="TableScanOperator1" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -946,10 +1010,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -958,7 +1022,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10008</string> 
@@ -1012,11 +1076,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342659</string> 
+                           <string>1285088555</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1055,7 +1119,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10002</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10002</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -1107,7 +1171,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest2</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest2</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -1115,7 +1179,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342659</string> 
+                                 <string>1285088555</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -1252,13 +1316,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10002</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc5"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10003</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10003</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1269,7 +1333,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-11</string> 
+           <string>Stage-13</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork1" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1279,10 +1343,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10002</string> 
               </void> 
              </object> 
             </void> 
@@ -1308,7 +1372,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList1"/> 
@@ -1334,7 +1398,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-15</string> 
+       <string>Stage-18</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList2" class="java.util.ArrayList"> 
@@ -1344,6 +1408,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask5" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask2" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-15</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask5"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10004/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask2"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-4</string> 
               </void> 
@@ -1362,14 +1458,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-13</string> 
+                   <string>Stage-16</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork2" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
                        <object id="TableScanOperator2" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -1606,10 +1702,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -1618,7 +1714,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10009</string> 
@@ -1672,11 +1768,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282342659</string> 
+                           <string>1285088555</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -1715,7 +1811,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10004</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10004</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -1771,7 +1867,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest3</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest3</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -1779,7 +1875,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282342659</string> 
+                                 <string>1285088555</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -1929,13 +2025,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10004</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10004</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc8"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10005</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10005</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -1946,7 +2042,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-14</string> 
+           <string>Stage-17</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork2" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -1956,10 +2052,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10004</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10004</string> 
               </void> 
              </object> 
             </void> 
@@ -1985,7 +2081,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList2"/> 
@@ -2011,7 +2107,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-18</string> 
+       <string>Stage-21</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList3" class="java.util.ArrayList"> 
@@ -2039,14 +2135,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-16</string> 
+                   <string>Stage-19</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork3" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
                        <object id="TableScanOperator3" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -2257,10 +2353,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -2269,7 +2365,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10010</string> 
@@ -2328,7 +2424,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10006</string> 
+                             <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10006</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -2483,7 +2579,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10006</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10006</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../../../../build/contrib/hive/ql/test/data/warehouse/dest4.out</string> 
@@ -2497,7 +2593,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-17</string> 
+           <string>Stage-20</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork3" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -2507,10 +2603,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10006</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10006</string> 
               </void> 
              </object> 
             </void> 
@@ -2536,7 +2632,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList3"/> 
@@ -2622,11 +2718,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282342656</string> 
+          <string>1285088552</string> 
          </void> 
         </object> 
        </void> 
@@ -2678,11 +2774,17 @@
                        <int>1</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10007</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10007</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10000/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc2"/> 
                       </void> 
@@ -2968,11 +3070,17 @@
                        <int>2</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10008</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10008</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10002/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc5"/> 
                       </void> 
@@ -3308,11 +3416,20 @@
                        <int>3</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10009</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10009</string> 
                       </void> 
+                      <void property="gatherStats"> 
+                       <boolean>true</boolean> 
+                      </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="staticSpec"> 
+                       <string>ds=2008-04-08/hr=12/</string> 
+                      </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10004/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc8"/> 
                       </void> 
@@ -3642,11 +3759,14 @@
                        <int>4</int> 
                       </void> 
                       <void property="dirName"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_15-17-39_733_1550739822811727074/-ext-10010</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10010</string> 
                       </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-02-35_729_3507422370084469386/-ext-10006/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object idref="TableDesc11"/> 
                       </void> 
@@ -3951,10 +4071,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -3966,7 +4089,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -4023,11 +4146,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282342656</string> 
+           <string>1285088552</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/case_sensitivity.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/case_sensitivity.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/case_sensitivity.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282347840</string> 
+                           <string>1285088418</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282347840</string> 
+                                 <string>1285088418</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282347839</string> 
+          <string>1285088417</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-44-01_085_1032648554893141218/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-00-19_120_6474203930551686491/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1439,10 +1477,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src_thrift</string> 
@@ -1454,7 +1495,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src_thrift</string> 
@@ -1515,11 +1556,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src_thrift</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282347839</string> 
+           <string>1285088417</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input7.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input7.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input7.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348036</string> 
+                           <string>1285088608</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348036</string> 
+                                 <string>1285088608</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -738,11 +770,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348034</string> 
+          <string>1285088606</string> 
          </void> 
         </object> 
        </void> 
@@ -790,11 +822,17 @@
                    <int>1</int> 
                   </void> 
                   <void property="dirName"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-17_313_8086148963528608797/-ext-10002</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10002</string> 
                   </void> 
+                  <void property="gatherStats"> 
+                   <boolean>true</boolean> 
+                  </void> 
                   <void property="numFiles"> 
                    <int>1</int> 
                   </void> 
+                  <void property="statsAggPrefix"> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-29_367_4390306235888113810/-ext-10000/</string> 
+                  </void> 
                   <void property="tableInfo"> 
                    <object idref="TableDesc2"/> 
                   </void> 
@@ -1036,10 +1074,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -1051,7 +1092,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -1108,11 +1149,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348034</string> 
+           <string>1285088606</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input9.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/input9.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input9.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348063</string> 
+                           <string>1285088637</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348063</string> 
+                                 <string>1285088637</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -738,11 +770,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348061</string> 
+          <string>1285088633</string> 
          </void> 
         </object> 
        </void> 
@@ -798,11 +830,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-47-44_316_8486615849625275140/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-03-57_447_6858952930237380842/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1210,10 +1248,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src1</string> 
@@ -1225,7 +1266,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src1</string> 
@@ -1282,11 +1323,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src1</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src1</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348061</string> 
+           <string>1285088633</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/union.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/union.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/union.q.xml_0.17	(working copy)
@@ -41,7 +41,7 @@
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +286,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +298,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10001</string> 
@@ -357,7 +357,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10000</string> 
+                             <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -522,7 +522,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10000</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10000</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -546,10 +546,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10000</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -575,7 +575,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -661,11 +661,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348486</string> 
+          <string>1284598814</string> 
          </void> 
         </object> 
        </void> 
@@ -748,11 +748,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348486</string> 
+          <string>1284598814</string> 
          </void> 
         </object> 
        </void> 
@@ -816,11 +816,14 @@
                                    <int>1</int> 
                                   </void> 
                                   <void property="dirName"> 
-                                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-54-51_498_1473056589669651473/-ext-10001</string> 
+                                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10001</string> 
                                   </void> 
                                   <void property="numFiles"> 
                                    <int>1</int> 
                                   </void> 
+                                  <void property="statsAggPrefix"> 
+                                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_18-00-18_591_8384444860759139471/-ext-10000/</string> 
+                                  </void> 
                                   <void property="tableInfo"> 
                                    <object idref="TableDesc2"/> 
                                   </void> 
@@ -1849,7 +1852,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>null-subquery1:unioninput-subquery1:src</string> 
@@ -1864,7 +1867,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1921,11 +1924,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348486</string> 
+           <string>1284598814</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/udf_when.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/udf_when.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/udf_when.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428603</string> 
+          <string>1284515514</string> 
          </void> 
         </object> 
        </void> 
@@ -115,11 +115,14 @@
                     <void property="conf"> 
                      <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                       <void property="dirName"> 
-                       <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-36-46_279_4238044052234466202/-ext-10001</string> 
+                       <string>file:/tmp/nzhang/hive_2010-09-14_18-51-58_453_8247403108084638215/-ext-10001</string> 
                       </void> 
                       <void property="numFiles"> 
                        <int>1</int> 
                       </void> 
+                      <void property="statsAggPrefix"> 
+                       <string>file:/tmp/nzhang/hive_2010-09-14_18-51-58_453_8247403108084638215/-ext-10001/</string> 
+                      </void> 
                       <void property="tableInfo"> 
                        <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                         <void property="deserializerClass"> 
@@ -707,7 +710,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -719,7 +722,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -776,11 +779,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428603</string> 
+           <string>1284515514</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/input20.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input20.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input20.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428254</string> 
+          <string>1284515048</string> 
          </void> 
         </object> 
        </void> 
@@ -776,7 +776,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>tmap:src</string> 
@@ -788,7 +788,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -845,11 +845,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428254</string> 
+           <string>1284515048</string> 
           </void> 
          </object> 
         </void> 
@@ -896,11 +896,14 @@
                   <void property="conf"> 
                    <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                     <void property="dirName"> 
-                     <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-30-56_349_6711984307612414245/-ext-10001</string> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-44-11_152_844232193871874926/-ext-10001</string> 
                     </void> 
                     <void property="numFiles"> 
                      <int>1</int> 
                     </void> 
+                    <void property="statsAggPrefix"> 
+                     <string>file:/tmp/nzhang/hive_2010-09-14_18-44-11_152_844232193871874926/-ext-10001/</string> 
+                    </void> 
                     <void property="tableInfo"> 
                      <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                       <void property="deserializerClass"> 
Index: ql/src/test/results/compiler/plan/sample1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample1.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -75,11 +75,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428470</string> 
+          <string>1284515314</string> 
          </void> 
         </object> 
        </void> 
@@ -136,11 +136,14 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-34-41_580_2222138714722247932/-ext-10001</string> 
+                               <string>file:/tmp/nzhang/hive_2010-09-14_18-48-47_892_6453851150463177553/-ext-10001</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
                               </void> 
+                              <void property="statsAggPrefix"> 
+                               <string>file:/tmp/nzhang/hive_2010-09-14_18-48-47_892_6453851150463177553/-ext-10001/</string> 
+                              </void> 
                               <void property="tableInfo"> 
                                <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                                 <void property="deserializerClass"> 
@@ -1118,7 +1121,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1130,7 +1133,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart/ds=2008-04-08/hr=11</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>hr=11</string> 
@@ -1200,11 +1203,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/srcpart</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcpart</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428470</string> 
+           <string>1284515314</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample2.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample2.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample2.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147802</string> 
+                                   <string>1285060243</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147802</string> 
+                           <string>1285060243</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147792</string> 
+          <string>1285060237</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-02_829_1470770394033415321/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-44_185_5401188744280914370/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1166,10 +1204,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1181,7 +1222,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1242,11 +1283,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147792</string> 
+           <string>1285060237</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample3.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample3.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample3.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147817</string> 
+                                   <string>1285060257</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147817</string> 
+                           <string>1285060257</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147810</string> 
+          <string>1285060250</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-18_260_2780203968077330289/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-10-57_647_405762212419440823/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1189,10 +1227,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1204,7 +1245,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket</string> 
@@ -1265,11 +1306,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147810</string> 
+           <string>1285060250</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample4.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample4.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample4.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147833</string> 
+                                   <string>1285060270</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147833</string> 
+                           <string>1285060270</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147825</string> 
+          <string>1285060264</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-33_587_6252476421872903664/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-11_180_771742911999355110/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1166,10 +1204,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1181,7 +1222,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1242,11 +1283,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147825</string> 
+           <string>1285060264</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample5.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample5.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample5.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147848</string> 
+                                   <string>1285060284</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147848</string> 
+                           <string>1285060284</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147840</string> 
+          <string>1285060277</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-10-49_020_8457677170213334221/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-24_753_6858739678998337081/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1163,10 +1201,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1178,7 +1219,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket</string> 
@@ -1239,11 +1280,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147840</string> 
+           <string>1285060277</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample6.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample6.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample6.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147864</string> 
+                                   <string>1285060297</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147864</string> 
+                           <string>1285060297</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147856</string> 
+          <string>1285060291</string> 
          </void> 
         </object> 
        </void> 
@@ -547,11 +579,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-04_588_1172694897595912742/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-38_200_7540636160285639234/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -1166,10 +1204,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1181,7 +1222,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1242,11 +1283,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147856</string> 
+           <string>1285060291</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample7.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/sample7.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample7.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147880</string> 
+                                   <string>1285060311</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147880</string> 
+                           <string>1285060311</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -487,11 +519,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147872</string> 
+          <string>1285060304</string> 
          </void> 
         </object> 
        </void> 
@@ -551,11 +583,17 @@
                                <int>1</int> 
                               </void> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-11-20_474_252025360588708716/-ext-10002</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10002</string> 
                               </void> 
+                              <void property="gatherStats"> 
+                               <boolean>true</boolean> 
+                              </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
                               </void> 
+                              <void property="statsAggPrefix"> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-11-52_069_8910463466880345384/-ext-10000/</string> 
+                              </void> 
                               <void property="tableInfo"> 
                                <object idref="TableDesc0"/> 
                               </void> 
@@ -1336,10 +1374,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1351,7 +1392,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1412,11 +1453,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147872</string> 
+           <string>1285060304</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample2.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample2.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample2.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348277</string> 
+                           <string>1285088851</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348277</string> 
+                                 <string>1285088851</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348269</string> 
+          <string>1285088844</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-17_867_4718721143802355836/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-07-32_022_5375526079135961895/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1417,10 +1455,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1432,7 +1473,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1493,11 +1534,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348269</string> 
+           <string>1285088844</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample4.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample4.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample4.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348308</string> 
+                           <string>1285088883</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348308</string> 
+                                 <string>1285088883</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348300</string> 
+          <string>1285088874</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-51-48_752_3614522563859082051/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-03_748_6650875267744141369/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1417,10 +1455,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1432,7 +1473,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1493,11 +1534,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348300</string> 
+           <string>1285088874</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/cast1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/cast1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/cast1.q.xml	(working copy)
@@ -1,5 +1,5 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="id"> 
    <string>Stage-3</string> 
@@ -62,11 +62,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428161</string> 
+          <string>1284514942</string> 
          </void> 
         </object> 
        </void> 
@@ -119,11 +119,14 @@
                         <void property="conf"> 
                          <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                           <void property="dirName"> 
-                           <string>file:/var/folders/6g/6grtCwPMEf4sqHUPpy6xQG9ByHg/-Tmp-/heyongqiang/hive_2010-07-29_11-29-23_517_8145414449245074216/-ext-10001</string> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-42-27_556_1287140404332430285/-ext-10001</string> 
                           </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>file:/tmp/nzhang/hive_2010-09-14_18-42-27_556_1287140404332430285/-ext-10001/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
                             <void property="deserializerClass"> 
@@ -1054,7 +1057,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1066,7 +1069,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1123,11 +1126,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428161</string> 
+           <string>1284514942</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/sample6.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/sample6.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/sample6.q.xml_0.17	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +318,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +330,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -352,11 +384,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282348338</string> 
+                           <string>1285088914</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -395,7 +427,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10000</string> 
+                             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -447,7 +479,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>location</string> 
-                                 <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                 </void> 
                                 <void method="put"> 
                                  <string>file.outputformat</string> 
@@ -455,7 +487,7 @@
                                 </void> 
                                 <void method="put"> 
                                  <string>transient_lastDdlTime</string> 
-                                 <string>1282348338</string> 
+                                 <string>1285088914</string> 
                                 </void> 
                                </object> 
                               </void> 
@@ -596,13 +628,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc2"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -613,7 +645,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -623,10 +655,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -652,7 +684,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -742,11 +774,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348331</string> 
+          <string>1285088906</string> 
          </void> 
         </object> 
        </void> 
@@ -802,11 +834,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-19_418_6323669109719903992/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_10-08-35_320_8317730037446711716/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc2"/> 
                           </void> 
@@ -1417,10 +1455,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>s</string> 
@@ -1432,7 +1473,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>srcbucket0.txt</string> 
@@ -1493,11 +1534,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/srcbucket</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348331</string> 
+           <string>1285088906</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/subq.q.xml_0.17
===================================================================
--- ql/src/test/results/compiler/plan/subq.q.xml_0.17	(revision 1000592)
+++ ql/src/test/results/compiler/plan/subq.q.xml_0.17	(working copy)
@@ -41,7 +41,7 @@
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -286,10 +286,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+                         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -298,7 +298,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+                       <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10001</string> 
@@ -357,7 +357,7 @@
                           <void property="conf"> 
                            <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                             <void property="dirName"> 
-                             <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10000</string> 
+                             <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10000</string> 
                             </void> 
                             <void property="numFiles"> 
                              <int>1</int> 
@@ -522,7 +522,7 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10000</string> 
+                   <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10000</string> 
                   </void> 
                   <void property="targetDir"> 
                    <string>../build/ql/test/data/warehouse/union.out</string> 
@@ -546,10 +546,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
               </void> 
               <void property="targetDir"> 
-               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10000</string> 
+               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -575,7 +575,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+         <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -661,11 +661,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282348367</string> 
+          <string>1284598721</string> 
          </void> 
         </object> 
        </void> 
@@ -725,11 +725,14 @@
                                <int>1</int> 
                               </void> 
                               <void property="dirName"> 
-                               <string>file:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-20_16-52-50_943_4223490131176161180/-ext-10001</string> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10001</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
                               </void> 
+                              <void property="statsAggPrefix"> 
+                               <string>file:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-15_17-58-45_570_8869995300393587731/-ext-10000/</string> 
+                              </void> 
                               <void property="tableInfo"> 
                                <object idref="TableDesc2"/> 
                               </void> 
@@ -1300,7 +1303,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>unioninput:src</string> 
@@ -1312,7 +1315,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1369,11 +1372,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282348367</string> 
+           <string>1284598721</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/results/compiler/plan/join1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/join1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/join1.q.xml	(working copy)
@@ -1,10 +1,42 @@
 <?xml version="1.0" encoding="UTF-8"?> 
-<java version="1.6.0_15" class="java.beans.XMLDecoder"> 
+<java version="1.6.0_14" class="java.beans.XMLDecoder"> 
  <object id="MapRedTask0" class="org.apache.hadoop.hive.ql.exec.MapRedTask"> 
   <void property="childTasks"> 
    <object class="java.util.ArrayList"> 
     <void method="add"> 
-     <object class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+     <object id="MoveTask0" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+      <void property="childTasks"> 
+       <object class="java.util.ArrayList"> 
+        <void method="add"> 
+         <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+          <void property="id"> 
+           <string>Stage-4</string> 
+          </void> 
+          <void property="parentTasks"> 
+           <object class="java.util.ArrayList"> 
+            <void method="add"> 
+             <object idref="MoveTask0"/> 
+            </void> 
+           </object> 
+          </void> 
+          <void property="work"> 
+           <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+            <void property="aggKey"> 
+             <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-44_330_5518096478382566490/-ext-10000/</string> 
+            </void> 
+           </object> 
+          </void> 
+         </object> 
+        </void> 
+       </object> 
+      </void> 
+      <void property="feedSubscribers"> 
+       <object class="java.util.LinkedList"> 
+        <void method="add"> 
+         <object idref="StatsTask0"/> 
+        </void> 
+       </object> 
+      </void> 
       <void property="id"> 
        <string>Stage-2</string> 
       </void> 
@@ -26,7 +58,7 @@
            <boolean>true</boolean> 
           </void> 
           <void property="sourceDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-05_758_213252720732930549/-ext-10000</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-44_330_5518096478382566490/-ext-10000</string> 
           </void> 
           <void property="table"> 
            <object id="TableDesc0" class="org.apache.hadoop.hive.ql.plan.TableDesc"> 
@@ -79,11 +111,11 @@
               </void> 
               <void method="put"> 
                <string>location</string> 
-               <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/dest1</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
               </void> 
               <void method="put"> 
                <string>transient_lastDdlTime</string> 
-               <string>1280428385</string> 
+               <string>1285060123</string> 
               </void> 
              </object> 
             </void> 
@@ -93,7 +125,7 @@
            </object> 
           </void> 
           <void property="tmpDir"> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-05_758_213252720732930549/-ext-10001</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-44_330_5518096478382566490/-ext-10001</string> 
           </void> 
          </object> 
         </void> 
@@ -164,11 +196,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428383</string> 
+          <string>1285060121</string> 
          </void> 
         </object> 
        </void> 
@@ -251,11 +283,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1280428383</string> 
+          <string>1285060121</string> 
          </void> 
         </object> 
        </void> 
@@ -832,6 +864,9 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="keyDesc"> 
      <object idref="TableDesc2"/> 
     </void> 
@@ -844,7 +879,7 @@
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src2</string> 
@@ -859,7 +894,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -916,11 +951,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1280428383</string> 
+           <string>1285060121</string> 
           </void> 
          </object> 
         </void> 
@@ -966,11 +1001,17 @@
                  <int>1</int> 
                 </void> 
                 <void property="dirName"> 
-                 <string>pfile:/Users/heyongqiang/Documents/workspace/Hive-2/build/ql/scratchdir/hive_2010-07-29_11-33-05_758_213252720732930549/-ext-10000</string> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-44_330_5518096478382566490/-ext-10000</string> 
                 </void> 
+                <void property="gatherStats"> 
+                 <boolean>true</boolean> 
+                </void> 
                 <void property="numFiles"> 
                  <int>1</int> 
                 </void> 
+                <void property="statsAggPrefix"> 
+                 <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-08-44_330_5518096478382566490/-ext-10000/</string> 
+                </void> 
                 <void property="tableInfo"> 
                  <object idref="TableDesc0"/> 
                 </void> 
Index: ql/src/test/results/compiler/plan/input1.q.xml
===================================================================
--- ql/src/test/results/compiler/plan/input1.q.xml	(revision 1000592)
+++ ql/src/test/results/compiler/plan/input1.q.xml	(working copy)
@@ -6,7 +6,7 @@
     <void method="add"> 
      <object class="org.apache.hadoop.hive.ql.exec.ConditionalTask"> 
       <void property="id"> 
-       <string>Stage-6</string> 
+       <string>Stage-7</string> 
       </void> 
       <void property="listTasks"> 
        <object id="ArrayList0" class="java.util.ArrayList"> 
@@ -16,6 +16,38 @@
            <object class="java.util.ArrayList"> 
             <void method="add"> 
              <object id="MoveTask1" class="org.apache.hadoop.hive.ql.exec.MoveTask"> 
+              <void property="childTasks"> 
+               <object class="java.util.ArrayList"> 
+                <void method="add"> 
+                 <object id="StatsTask0" class="org.apache.hadoop.hive.ql.exec.StatsTask"> 
+                  <void property="id"> 
+                   <string>Stage-4</string> 
+                  </void> 
+                  <void property="parentTasks"> 
+                   <object class="java.util.ArrayList"> 
+                    <void method="add"> 
+                     <object idref="MoveTask1"/> 
+                    </void> 
+                   </object> 
+                  </void> 
+                  <void property="work"> 
+                   <object class="org.apache.hadoop.hive.ql.plan.StatsWork"> 
+                    <void property="aggKey"> 
+                     <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10000/</string> 
+                    </void> 
+                   </object> 
+                  </void> 
+                 </object> 
+                </void> 
+               </object> 
+              </void> 
+              <void property="feedSubscribers"> 
+               <object class="java.util.LinkedList"> 
+                <void method="add"> 
+                 <object idref="StatsTask0"/> 
+                </void> 
+               </object> 
+              </void> 
               <void property="id"> 
                <string>Stage-2</string> 
               </void> 
@@ -34,14 +66,14 @@
                    </object> 
                   </void> 
                   <void property="id"> 
-                   <string>Stage-4</string> 
+                   <string>Stage-5</string> 
                   </void> 
                   <void property="work"> 
                    <object id="MapredWork0" class="org.apache.hadoop.hive.ql.plan.MapredWork"> 
                     <void property="aliasToWork"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
                        <object id="TableScanOperator0" class="org.apache.hadoop.hive.ql.exec.TableScanOperator"> 
                         <void property="childOperators"> 
                          <object class="java.util.ArrayList"> 
@@ -50,7 +82,7 @@
                             <void property="conf"> 
                              <object class="org.apache.hadoop.hive.ql.plan.FileSinkDesc"> 
                               <void property="dirName"> 
-                               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10000</string> 
+                               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10000</string> 
                               </void> 
                               <void property="numFiles"> 
                                <int>1</int> 
@@ -102,7 +134,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>location</string> 
-                                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                                   </void> 
                                   <void method="put"> 
                                    <string>file.outputformat</string> 
@@ -110,7 +142,7 @@
                                   </void> 
                                   <void method="put"> 
                                    <string>transient_lastDdlTime</string> 
-                                   <string>1282147470</string> 
+                                   <string>1285059952</string> 
                                   </void> 
                                  </object> 
                                 </void> 
@@ -221,10 +253,10 @@
                     <void property="pathToAliases"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
                        <object class="java.util.ArrayList"> 
                         <void method="add"> 
-                         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+                         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
                         </void> 
                        </object> 
                       </void> 
@@ -233,7 +265,7 @@
                     <void property="pathToPartitionInfo"> 
                      <object class="java.util.LinkedHashMap"> 
                       <void method="put"> 
-                       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+                       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
                        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
                         <void property="baseFileName"> 
                          <string>-ext-10002</string> 
@@ -287,11 +319,11 @@
                           </void> 
                           <void method="put"> 
                            <string>location</string> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/dest1</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/dest1</string> 
                           </void> 
                           <void method="put"> 
                            <string>transient_lastDdlTime</string> 
-                           <string>1282147470</string> 
+                           <string>1285059952</string> 
                           </void> 
                          </object> 
                         </void> 
@@ -341,13 +373,13 @@
                    <boolean>true</boolean> 
                   </void> 
                   <void property="sourceDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10000</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10000</string> 
                   </void> 
                   <void property="table"> 
                    <object idref="TableDesc0"/> 
                   </void> 
                   <void property="tmpDir"> 
-                   <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10001</string> 
+                   <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10001</string> 
                   </void> 
                  </object> 
                 </void> 
@@ -358,7 +390,7 @@
            </object> 
           </void> 
           <void property="id"> 
-           <string>Stage-5</string> 
+           <string>Stage-6</string> 
           </void> 
           <void property="work"> 
            <object id="MoveWork0" class="org.apache.hadoop.hive.ql.plan.MoveWork"> 
@@ -368,10 +400,10 @@
                <boolean>true</boolean> 
               </void> 
               <void property="sourceDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
               </void> 
               <void property="targetDir"> 
-               <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10000</string> 
+               <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10000</string> 
               </void> 
              </object> 
             </void> 
@@ -397,7 +429,7 @@
       <void property="resolverCtx"> 
        <object class="org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx"> 
         <void property="dir"> 
-         <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+         <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
         </void> 
         <void property="listTasks"> 
          <object idref="ArrayList0"/> 
@@ -483,11 +515,11 @@
          </void> 
          <void method="put"> 
           <string>location</string> 
-          <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+          <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
          </void> 
          <void method="put"> 
           <string>transient_lastDdlTime</string> 
-          <string>1282147468</string> 
+          <string>1285059950</string> 
          </void> 
         </object> 
        </void> 
@@ -543,11 +575,17 @@
                            <int>1</int> 
                           </void> 
                           <void property="dirName"> 
-                           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/scratchdir/hive_2010-08-18_09-04-30_887_2948287895711467357/-ext-10002</string> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10002</string> 
                           </void> 
+                          <void property="gatherStats"> 
+                           <boolean>true</boolean> 
+                          </void> 
                           <void property="numFiles"> 
                            <int>1</int> 
                           </void> 
+                          <void property="statsAggPrefix"> 
+                           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/scratchdir/hive_2010-09-21_02-05-53_127_8730853387776623391/-ext-10000/</string> 
+                          </void> 
                           <void property="tableInfo"> 
                            <object idref="TableDesc0"/> 
                           </void> 
@@ -989,10 +1027,13 @@
       </void> 
      </object> 
     </void> 
+    <void property="gatheringStats"> 
+     <boolean>true</boolean> 
+    </void> 
     <void property="pathToAliases"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="java.util.ArrayList"> 
         <void method="add"> 
          <string>src</string> 
@@ -1004,7 +1045,7 @@
     <void property="pathToPartitionInfo"> 
      <object class="java.util.LinkedHashMap"> 
       <void method="put"> 
-       <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+       <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
        <object class="org.apache.hadoop.hive.ql.plan.PartitionDesc"> 
         <void property="baseFileName"> 
          <string>src</string> 
@@ -1061,11 +1102,11 @@
           </void> 
           <void method="put"> 
            <string>location</string> 
-           <string>pfile:/data/users/nzhang/work/870/apache-hive/build/ql/test/data/warehouse/src</string> 
+           <string>pfile:/data/users/nzhang/work/784/apache-hive/build/ql/test/data/warehouse/src</string> 
           </void> 
           <void method="put"> 
            <string>transient_lastDdlTime</string> 
-           <string>1282147468</string> 
+           <string>1285059950</string> 
           </void> 
          </object> 
         </void> 
Index: ql/src/test/queries/clientpositive/stats8.q
===================================================================
--- ql/src/test/queries/clientpositive/stats8.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats8.q	(revision 0)
@@ -0,0 +1,33 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+
+create table analyze_srcpart like srcpart;
+insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null;
+
+explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics;
+analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics;
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
+describe extended analyze_srcpart;
+
+explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics;
+analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics;
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
+
+explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics;
+analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=11) compute statistics;
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11);
+
+explain analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics;
+analyze table analyze_srcpart PARTITION(ds='2008-04-09',hr=12) compute statistics;
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12);
+
+explain analyze table analyze_srcpart PARTITION(ds, hr) compute statistics;
+analyze table analyze_srcpart PARTITION(ds, hr) compute statistics;
+
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11);
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12);
+describe extended analyze_srcpart;
Index: ql/src/test/queries/clientpositive/stats9.q
===================================================================
--- ql/src/test/queries/clientpositive/stats9.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats9.q	(revision 0)
@@ -0,0 +1,9 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+
+create table analyze_srcbucket like srcbucket;
+insert overwrite table analyze_srcbucket select * from srcbucket;
+
+explain analyze table analyze_srcbucket compute statistics;
+analyze table analyze_srcbucket compute statistics;
+describe extended analyze_srcbucket;
Index: ql/src/test/queries/clientpositive/stats0.q
===================================================================
--- ql/src/test/queries/clientpositive/stats0.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats0.q	(revision 0)
@@ -0,0 +1,70 @@
+set hive.stats.autogather=true;
+set datanucleus.cache.collections=false;
+
+set hive.merge.mapfiles=false;
+set hive.merge.mapredfiles=false;
+
+CREATE TABLE stats_non_partitioned (key string, value string);
+
+explain extended
+insert overwrite table stats_non_partitioned
+select * from src;
+
+insert overwrite table stats_non_partitioned
+select * from src;
+
+desc extended stats_non_partitioned;
+
+select * from stats_non_partitioned;
+
+
+CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string);
+
+explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src;
+
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src;
+
+show partitions stats_partitioned;
+select * from stats_partitioned where ds is not null;
+
+describe extended stats_partitioned partition (ds='1');
+describe extended stats_partitioned;
+
+
+set hive.merge.mapfiles=true;
+set hive.merge.mapredfiles=true;
+
+drop table stats_non_partitioned;
+drop table stats_partitioned;
+
+CREATE TABLE stats_non_partitioned (key string, value string);
+
+explain extended
+insert overwrite table stats_non_partitioned
+select * from src;
+
+insert overwrite table stats_non_partitioned
+select * from src;
+
+desc extended stats_non_partitioned;
+
+select * from stats_non_partitioned;
+
+
+CREATE TABLE stats_partitioned(key string, value string) partitioned by (ds string);
+
+explain
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src;
+
+insert overwrite table stats_partitioned partition (ds='1')
+select * from src;
+
+show partitions stats_partitioned;
+select * from stats_partitioned where ds is not null;
+
+describe extended stats_partitioned partition (ds='1');
+describe extended stats_partitioned;
Index: ql/src/test/queries/clientpositive/stats1.q
===================================================================
--- ql/src/test/queries/clientpositive/stats1.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats1.q	(revision 0)
@@ -0,0 +1,24 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+set hive.merge.mapfiles=false;
+set hive.merge.mapredfiles=false;
+set hive.map.aggr=true;
+
+create table tmptable(key string, value string);
+
+EXPLAIN
+INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc;
+
+INSERT OVERWRITE TABLE tmptable
+SELECT unionsrc.key, unionsrc.value 
+FROM (SELECT 'tst1' AS key, cast(count(1) AS string) AS value FROM src s1
+      UNION  ALL  
+      SELECT s2.key AS key, s2.value AS value FROM src1 s2) unionsrc;
+
+SELECT * FROM tmptable x SORT BY x.key, x.value;
+
+DESCRIBE EXTENDED tmptable;
Index: ql/src/test/queries/clientpositive/stats10.q
===================================================================
--- ql/src/test/queries/clientpositive/stats10.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats10.q	(revision 0)
@@ -0,0 +1,28 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+set hive.enforce.bucketing = true;
+set hive.exec.reducers.max = 1;
+
+CREATE TABLE bucket3_1(key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS;
+
+explain
+insert overwrite table bucket3_1 partition (ds='1')
+select * from src;
+
+insert overwrite table bucket3_1 partition (ds='1')
+select * from src;
+
+insert overwrite table bucket3_1 partition (ds='1')
+select * from src;
+
+insert overwrite table bucket3_1 partition (ds='2')
+select * from src;
+
+select * from bucket3_1 tablesample (bucket 1 out of 2) s where ds = '1' order by key;
+
+explain analyze table bucket3_1 partition (ds) compute statistics;
+analyze table bucket3_1 partition (ds) compute statistics;
+
+describe extended bucket3_1 partition (ds='1');
+describe extended bucket3_1 partition (ds='2');
+describe extended bucket3_1;
Index: ql/src/test/queries/clientpositive/stats2.q
===================================================================
--- ql/src/test/queries/clientpositive/stats2.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats2.q	(revision 0)
@@ -0,0 +1,21 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.merge.mapfiles=false;
+
+create table analyze_t1 like srcpart;
+
+
+explain
+insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null;
+
+insert overwrite table analyze_t1 partition (ds, hr) select * from srcpart where ds is not null;
+
+desc extended analyze_t1;
+
+explain analyze table analyze_t1 partition (ds, hr) compute statistics;
+
+analyze table analyze_t1 partition (ds, hr) compute statistics;
+
+describe extended analyze_t1;
Index: ql/src/test/queries/clientpositive/stats11.q
===================================================================
--- ql/src/test/queries/clientpositive/stats11.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats11.q	(revision 0)
@@ -0,0 +1,86 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+
+CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE;
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin;
+load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin;
+
+CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE;
+load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08');
+
+CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE;
+load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08');
+load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08');
+
+create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint);
+create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint);
+
+set hive.optimize.bucketmapjoin = true;
+create table bucketmapjoin_tmp_result (key string , value1 string, value2 string);
+
+explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+select count(1) from bucketmapjoin_tmp_result;
+
+insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result;
+
+set hive.optimize.bucketmapjoin = false;
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(b)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+select count(1) from bucketmapjoin_tmp_result;
+insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result;
+
+
+select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key;
+
+
+set hive.optimize.bucketmapjoin = true;
+explain extended
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+select count(1) from bucketmapjoin_tmp_result;
+
+
+insert overwrite table bucketmapjoin_hash_result_1
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result;
+
+set hive.optimize.bucketmapjoin = false;
+insert overwrite table bucketmapjoin_tmp_result 
+select /*+mapjoin(a)*/ a.key, a.value, b.value 
+from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
+on a.key=b.key where b.ds="2008-04-08";
+
+select count(1) from bucketmapjoin_tmp_result;
+insert overwrite table bucketmapjoin_hash_result_2
+select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result;
+
+select a.key-b.key, a.value1-b.value1, a.value2-b.value2
+from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
+on a.key = b.key;
Index: ql/src/test/queries/clientpositive/stats3.q
===================================================================
--- ql/src/test/queries/clientpositive/stats3.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats3.q	(revision 0)
@@ -0,0 +1,27 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+drop table hive_test_src;
+drop table hive_test_dst;
+
+create table hive_test_src ( col1 string ) stored as textfile ;
+load data local inpath '../data/files/test.dat' overwrite into table hive_test_src ;
+
+create table hive_test_dst ( col1 string ) partitioned by ( pcol1 string , pcol2 string) stored as sequencefile;
+insert overwrite table hive_test_dst partition ( pcol1='test_part', pCol2='test_Part') select col1 from hive_test_src ;
+select * from hive_test_dst where pcol1='test_part' and pcol2='test_Part';
+
+select count(1) from hive_test_dst;
+
+insert overwrite table hive_test_dst partition ( pCol1='test_part', pcol2='test_Part') select col1 from hive_test_src ;
+select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
+
+select count(1) from hive_test_dst;
+
+select * from hive_test_dst where pcol1='test_part';
+select * from hive_test_dst where pcol1='test_part' and pcol2='test_part';
+select * from hive_test_dst where pcol1='test_Part';
+
+describe extended hive_test_dst;
+
+drop table hive_test_src;
+drop table hive_test_dst;
Index: ql/src/test/queries/clientpositive/stats4.q
===================================================================
--- ql/src/test/queries/clientpositive/stats4.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats4.q	(revision 0)
@@ -0,0 +1,40 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=true;
+
+show partitions srcpart;
+
+drop table nzhang_part1;
+drop table nzhang_part2;
+
+create table if not exists nzhang_part1 like srcpart;
+create table if not exists nzhang_part2 like srcpart;
+
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.exec.dynamic.partition=true;
+
+explain
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08';
+
+from srcpart
+insert overwrite table nzhang_part1 partition (ds, hr) select key, value, ds, hr where ds <= '2008-04-08'
+insert overwrite table nzhang_part2 partition(ds='2008-12-31', hr) select key, value, hr where ds > '2008-04-08';
+
+
+show partitions nzhang_part1;
+show partitions nzhang_part2;
+
+select * from nzhang_part1 where ds is not null and hr is not null;
+select * from nzhang_part2 where ds is not null and hr is not null;
+
+describe extended nzhang_part1 partition(ds='2008-04-08',hr=11);
+describe extended nzhang_part1 partition(ds='2008-04-08',hr=12);
+describe extended nzhang_part2 partition(ds='2008-12-31',hr=11);
+describe extended nzhang_part2 partition(ds='2008-12-31',hr=12);
+
+describe extended nzhang_part1;
+describe extended nzhang_part2;
+
+drop table nzhang_part1;
+drop table nzhang_part2;
Index: ql/src/test/queries/clientpositive/stats5.q
===================================================================
--- ql/src/test/queries/clientpositive/stats5.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats5.q	(revision 0)
@@ -0,0 +1,10 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+
+create table analyze_src as select * from src;
+
+explain analyze table analyze_src compute statistics;
+
+analyze table analyze_src compute statistics;
+
+describe extended analyze_src;
Index: ql/src/test/queries/clientpositive/stats6.q
===================================================================
--- ql/src/test/queries/clientpositive/stats6.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats6.q	(revision 0)
@@ -0,0 +1,17 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+
+create table analyze_srcpart like srcpart;
+insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null;
+
+analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=11) compute statistics;
+analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr=12) compute statistics;
+
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=11);
+describe extended analyze_srcpart PARTITION(ds='2008-04-09',hr=12);
+
+describe extended analyze_srcpart;
Index: ql/src/test/queries/clientpositive/scriptfile1.q
===================================================================
--- ql/src/test/queries/clientpositive/scriptfile1.q	(revision 1000592)
+++ ql/src/test/queries/clientpositive/scriptfile1.q	(working copy)
@@ -1,4 +1,4 @@
-CREATE TABLE dest1(key INT, value STRING);
+CREATE TABLE scriptfile1_dest1(key INT, value STRING);
 
 ADD FILE src/test/scripts/testgrep;
 
@@ -8,6 +8,6 @@
          USING 'testgrep' AS (tkey, tvalue) 
   CLUSTER BY tkey 
 ) tmap
-INSERT OVERWRITE TABLE dest1 SELECT tmap.tkey, tmap.tvalue;
+INSERT OVERWRITE TABLE scriptfile1_dest1 SELECT tmap.tkey, tmap.tvalue;
 
-SELECT dest1.* FROM dest1;
+SELECT scriptfile1_dest1.* FROM scriptfile1_dest1;
Index: ql/src/test/queries/clientpositive/stats7.q
===================================================================
--- ql/src/test/queries/clientpositive/stats7.q	(revision 0)
+++ ql/src/test/queries/clientpositive/stats7.q	(revision 0)
@@ -0,0 +1,16 @@
+set datanucleus.cache.collections=false;
+set hive.stats.autogather=false;
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+
+create table analyze_srcpart like srcpart;
+insert overwrite table analyze_srcpart partition (ds, hr) select * from srcpart where ds is not null;
+
+explain analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics;
+
+analyze table analyze_srcpart PARTITION(ds='2008-04-08',hr) compute statistics;
+
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=11);
+describe extended analyze_srcpart PARTITION(ds='2008-04-08',hr=12);
+
+describe extended analyze_srcpart;
Index: ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java	(working copy)
@@ -31,7 +31,10 @@
 import org.apache.hadoop.hive.ql.lib.NodeProcessorCtx;
 import org.apache.hadoop.hive.ql.optimizer.GenMRProcContext.GenMapRedCtx;
 import org.apache.hadoop.hive.ql.parse.ParseContext;
+import org.apache.hadoop.hive.ql.parse.QBParseInfo;
 import org.apache.hadoop.hive.ql.parse.SemanticException;
+import org.apache.hadoop.hive.ql.plan.MapredWork;
+import org.apache.hadoop.hive.ql.plan.StatsWork;
 
 /**
  * Processor for the rule - table scan.
@@ -53,13 +56,11 @@
     TableScanOperator op = (TableScanOperator) nd;
     GenMRProcContext ctx = (GenMRProcContext) opProcCtx;
     ParseContext parseCtx = ctx.getParseCtx();
-    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = ctx
-        .getMapCurrCtx();
+    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = ctx.getMapCurrCtx();
 
-    // create a dummy task
-    Task<? extends Serializable> currTask =
-      TaskFactory.get(GenMapRedUtils.getMapRedWork(parseCtx.getConf()),
-                      parseCtx.getConf());
+    // create a dummy MapReduce task
+    MapredWork currWork = GenMapRedUtils.getMapRedWork(parseCtx.getConf());
+    Task<? extends Serializable> currTask = TaskFactory.get(currWork, parseCtx.getConf());
     Operator<? extends Serializable> currTopOp = op;
     ctx.setCurrTask(currTask);
     ctx.setCurrTopOp(currTopOp);
@@ -70,6 +71,22 @@
         String currAliasId = alias;
         ctx.setCurrAliasId(currAliasId);
         mapCurrCtx.put(op, new GenMapRedCtx(currTask, currTopOp, currAliasId));
+
+        QBParseInfo parseInfo = parseCtx.getQB().getParseInfo();
+        if (parseInfo.isAnalyzeCommand()) {
+
+          //   ANALYZE TABLE T [PARTITION (...)] COMPUTE STATISTICS;
+          // The plan consists of a simple MapRedTask followed by a StatsTask.
+          // The MR task is just a simple TableScanOperator
+
+          StatsWork statsWork = new StatsWork(parseCtx.getQB().getParseInfo().getTableSpec());
+          statsWork.setAggKey(op.getConf().getStatsAggPrefix());
+          Task<StatsWork> statsTask = TaskFactory.get(statsWork, parseCtx.getConf());
+          currTask.addDependentTask(statsTask);
+          ctx.getRootTasks().add(currTask);
+          currWork.setGatheringStats(true);
+          GenMapRedUtils.setTaskPlan(currAliasId, currTopOp, currWork, false, ctx);
+        }
         return null;
       }
     }
Index: ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java	(working copy)
@@ -35,6 +35,7 @@
 import org.apache.hadoop.hive.ql.exec.ConditionalTask;
 import org.apache.hadoop.hive.ql.exec.FileSinkOperator;
 import org.apache.hadoop.hive.ql.exec.MapJoinOperator;
+import org.apache.hadoop.hive.ql.exec.MapRedTask;
 import org.apache.hadoop.hive.ql.exec.MoveTask;
 import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.OperatorFactory;
@@ -67,6 +68,7 @@
 import org.apache.hadoop.hive.ql.plan.PartitionDesc;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.ReduceSinkDesc;
+import org.apache.hadoop.hive.ql.plan.StatsWork;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
 import org.apache.hadoop.hive.ql.plan.TableScanDesc;
 import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
@@ -95,7 +97,13 @@
     ParseContext parseCtx = ctx.getParseCtx();
     boolean chDir = false;
     Task<? extends Serializable> currTask = ctx.getCurrTask();
+    FileSinkOperator fsOp = (FileSinkOperator) nd;
+    boolean isInsertTable = // is INSERT OVERWRITE TABLE
+      fsOp.getConf().getTableInfo().getTableName() != null &&
+      parseCtx.getQB().getParseInfo().isInsertToTable();
+    HiveConf hconf = parseCtx.getConf();
 
+
     // Has the user enabled merging of files for map-only jobs or for all jobs
     if ((ctx.getMvTask() != null) && (!ctx.getMvTask().isEmpty())) {
       List<Task<? extends Serializable>> mvTasks = ctx.getMvTask();
@@ -107,18 +115,25 @@
           || (!ctx.getSeenFileSinkOps().contains(nd))) {
 
         // no need of merging if the move is to a local file system
-        MoveTask mvTask = (MoveTask) findMoveTask(mvTasks,
-            (FileSinkOperator) nd);
+        MoveTask mvTask = (MoveTask) findMoveTask(mvTasks, fsOp);
+
+        if (isInsertTable &&
+            hconf.getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+          addStatsTask(fsOp, mvTask, currTask, parseCtx.getConf());
+        }
+
         if ((mvTask != null) && !mvTask.isLocal()) {
           // There are separate configuration parameters to control whether to
           // merge for a map-only job
           // or for a map-reduce job
-          if ((parseCtx.getConf().getBoolVar(
-              HiveConf.ConfVars.HIVEMERGEMAPFILES) && (((MapredWork) currTask
-              .getWork()).getReducer() == null))
-              || (parseCtx.getConf().getBoolVar(
-              HiveConf.ConfVars.HIVEMERGEMAPREDFILES) && (((MapredWork) currTask
-              .getWork()).getReducer() != null))) {
+          MapredWork currWork = (MapredWork) currTask.getWork();
+          boolean mergeMapOnly =
+            hconf.getBoolVar(HiveConf.ConfVars.HIVEMERGEMAPFILES) &&
+            currWork.getReducer() == null;
+          boolean mergeMapRed =
+            hconf.getBoolVar(HiveConf.ConfVars.HIVEMERGEMAPREDFILES) &&
+            currWork.getReducer() != null;
+          if (mergeMapOnly || mergeMapRed) {
             chDir = true;
           }
         }
@@ -135,6 +150,38 @@
     return null;
   }
 
+  /**
+   * Add the StatsTask as a dependent task of the MoveTask
+   * because StatsTask will change the Table/Partition metadata. For atomicity, we
+   * should not change it before the data is actually there done by MoveTask.
+   * @param nd the FileSinkOperator whose results are taken care of by the MoveTask.
+   * @param mvTask The MoveTask that moves the FileSinkOperator's results.
+   * @param currTask The MapRedTask that the FileSinkOperator belongs to.
+   * @param hconf HiveConf
+   */
+  private void addStatsTask(FileSinkOperator nd, MoveTask mvTask,
+      Task<? extends Serializable> currTask, HiveConf hconf) {
+
+    MoveWork mvWork = ((MoveTask)mvTask).getWork();
+    StatsWork statsWork = new StatsWork(mvWork.getLoadTableWork());
+    MapredWork mrWork = (MapredWork) currTask.getWork();
+
+    // AggKey in StatsWork is used for stats aggregation while StatsAggPrefix
+    // in FileSinkDesc is used for stats publishing. They should be consistent.
+    statsWork.setAggKey(((FileSinkOperator)nd).getConf().getStatsAggPrefix());
+    Task<? extends Serializable> statsTask = TaskFactory.get(statsWork, hconf);
+
+    // mark the MapredWork and FileSinkOperator for gathering stats
+    nd.getConf().setGatherStats(true);
+    mrWork.setGatheringStats(true);
+    // mrWork.addDestinationTable(nd.getConf().getTableInfo().getTableName());
+
+    // subscribe feeds from the MoveTask so that MoveTask can forward the list
+    // of dynamic partition list to the StatsTask
+    mvTask.addDependentTask(statsTask);
+    statsTask.subscribeFeed(mvTask);
+  }
+
   private void createMapReduce4Merge(FileSinkOperator fsOp, GenMRProcContext ctx, String finalName)
       throws SemanticException {
     Task<? extends Serializable> currTask = ctx.getCurrTask();
@@ -170,8 +217,7 @@
 
     // Add the extract operator to get the value fields
     RowResolver out_rwsch = new RowResolver();
-    RowResolver interim_rwsch = ctx.getParseCtx().getOpParseCtx().get(fsOp)
-        .getRR();
+    RowResolver interim_rwsch = ctx.getParseCtx().getOpParseCtx().get(fsOp).getRR();
     Integer pos = Integer.valueOf(0);
     for (ColumnInfo colInfo : interim_rwsch.getColumnInfos()) {
       String[] info = interim_rwsch.reverseLookup(colInfo.getInternalName());
@@ -182,23 +228,25 @@
 
     Operator<ExtractDesc> extract = OperatorFactory.getAndMakeChild(new ExtractDesc(
         new ExprNodeColumnDesc(TypeInfoFactory.stringTypeInfo,
-        Utilities.ReduceField.VALUE.toString(), "", false)),
-        new RowSchema(out_rwsch.getColumnInfos()));
+            Utilities.ReduceField.VALUE.toString(), "", false)),
+            new RowSchema(out_rwsch.getColumnInfos()));
 
     TableDesc ts = (TableDesc) fsConf.getTableInfo().clone();
-    fsConf
-        .getTableInfo()
-        .getProperties()
-        .remove(
+    fsConf.getTableInfo().getProperties().remove(
         org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_PARTITION_COLUMNS);
-    FileSinkOperator newOutput = (FileSinkOperator) OperatorFactory
-        .getAndMakeChild(new FileSinkDesc(finalName, ts, parseCtx.getConf()
-        .getBoolVar(HiveConf.ConfVars.COMPRESSRESULT)), inputRS, extract);
 
+    FileSinkDesc newFSD = new FileSinkDesc(finalName, ts, parseCtx.getConf()
+        .getBoolVar(HiveConf.ConfVars.COMPRESSRESULT));
+    FileSinkOperator newOutput = (FileSinkOperator) OperatorFactory.
+      getAndMakeChild(newFSD, inputRS, extract);
+
     HiveConf conf = parseCtx.getConf();
     MapredWork cplan = createMergeTask(conf, tsMerge, fsConf);
     cplan.setReducer(extract);
 
+    // NOTE: we should gather stats in MR1 (rather than the merge MR job)
+    // since it is unknown if the merge MR will be triggered at execution time.
+    
     MoveWork dummyMv = new MoveWork(null, null, null,
         new LoadFileDesc(fsConf.getDirName(), finalName, true, null, null), false);
 
@@ -320,11 +368,14 @@
     //
     // 2. Constructing a conditional task consisting of a move task and a map reduce task
     //
+    MapRedTask currTask = (MapRedTask) ctx.getCurrTask();
     MoveWork dummyMv = new MoveWork(null, null, null,
         new LoadFileDesc(fsInputDesc.getDirName(), finalName, true, null, null), false);
     MapredWork cplan = createMergeTask(ctx.getConf(), tsMerge, fsInputDesc);
     // use CombineHiveInputFormat for map-only merging
     cplan.setInputformat("org.apache.hadoop.hive.ql.io.CombineHiveInputFormat");
+    // NOTE: we should gather stats in MR1 rather than MR2 at merge job since we don't
+    // know if merge MR2 will be triggered at execution time
     ConditionalTask cndTsk = createCondTask(ctx.getConf(), ctx.getCurrTask(), dummyMv, cplan,
         fsInputDesc.getDirName());
 
@@ -358,20 +409,25 @@
    * @param conf
    * @param topOp the table scan operator that is the root of the MapReduce task.
    * @param fsDesc the file sink descriptor that serves as the input to this merge task.
+   * @param parentMR the parent MapReduce work
+   * @param parentFS the last FileSinkOperator in the parent MapReduce work
    * @return the MapredWork
    */
   private MapredWork createMergeTask(HiveConf conf, Operator<? extends Serializable> topOp,
       FileSinkDesc fsDesc) {
+
     ArrayList<String> aliases = new ArrayList<String>();
     String inputDir = fsDesc.getDirName();
     TableDesc tblDesc = fsDesc.getTableInfo();
     aliases.add(inputDir); // dummy alias: just use the input path
+
     // constructing the default MapredWork
     MapredWork cplan = GenMapRedUtils.getMapRedWork(conf);
     cplan.getPathToAliases().put(inputDir, aliases);
     cplan.getPathToPartitionInfo().put(inputDir, new PartitionDesc(tblDesc, null));
     cplan.setNumReduceTasks(0);
     cplan.getAliasToWork().put(inputDir, topOp);
+
     return cplan;
   }
   /**
@@ -489,8 +545,8 @@
 
     Operator<? extends Serializable> currTopOp = ctx.getCurrTopOp();
     String currAliasId = ctx.getCurrAliasId();
-    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap = ctx
-        .getOpTaskMap();
+    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap =
+      ctx.getOpTaskMap();
     List<Operator<? extends Serializable>> seenOps = ctx.getSeenOps();
     List<Task<? extends Serializable>> rootTasks = ctx.getRootTasks();
 
Index: ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java	(working copy)
@@ -59,16 +59,16 @@
 import org.apache.hadoop.hive.ql.parse.SemanticException;
 import org.apache.hadoop.hive.ql.plan.FetchWork;
 import org.apache.hadoop.hive.ql.plan.FileSinkDesc;
+import org.apache.hadoop.hive.ql.plan.FilterDesc.sampleDesc;
 import org.apache.hadoop.hive.ql.plan.MapJoinDesc;
 import org.apache.hadoop.hive.ql.plan.MapredLocalWork;
+import org.apache.hadoop.hive.ql.plan.MapredLocalWork.BucketMapJoinContext;
 import org.apache.hadoop.hive.ql.plan.MapredWork;
 import org.apache.hadoop.hive.ql.plan.PartitionDesc;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.ReduceSinkDesc;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
 import org.apache.hadoop.hive.ql.plan.TableScanDesc;
-import org.apache.hadoop.hive.ql.plan.FilterDesc.sampleDesc;
-import org.apache.hadoop.hive.ql.plan.MapredLocalWork.BucketMapJoinContext;
 
 /**
  * General utility common functions for the Processor to convert operator into
@@ -92,13 +92,12 @@
   public static void initPlan(ReduceSinkOperator op, GenMRProcContext opProcCtx)
       throws SemanticException {
     Operator<? extends Serializable> reducer = op.getChildOperators().get(0);
-    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx
-        .getMapCurrCtx();
+    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx.getMapCurrCtx();
     GenMapRedCtx mapredCtx = mapCurrCtx.get(op.getParentOperators().get(0));
     Task<? extends Serializable> currTask = mapredCtx.getCurrTask();
     MapredWork plan = (MapredWork) currTask.getWork();
-    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap = opProcCtx
-        .getOpTaskMap();
+    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap =
+      opProcCtx.getOpTaskMap();
     Operator<? extends Serializable> currTopOp = opProcCtx.getCurrTopOp();
 
     opTaskMap.put(reducer, currTask);
@@ -149,16 +148,15 @@
       GenMRProcContext opProcCtx, boolean readInputMapJoin,
       boolean readInputUnion, boolean setReducer, int pos, boolean createLocalPlan)
       throws SemanticException {
-    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx
-        .getMapCurrCtx();
+    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx.getMapCurrCtx();
     assert (((pos == -1) && (readInputMapJoin)) || (pos != -1));
     int parentPos = (pos == -1) ? 0 : pos;
     GenMapRedCtx mapredCtx = mapCurrCtx.get(op.getParentOperators().get(
         parentPos));
     Task<? extends Serializable> currTask = mapredCtx.getCurrTask();
     MapredWork plan = (MapredWork) currTask.getWork();
-    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap = opProcCtx
-        .getOpTaskMap();
+    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>>  opTaskMap =
+      opProcCtx.getOpTaskMap();
     Operator<? extends Serializable> currTopOp = opProcCtx.getCurrTopOp();
 
     // The mapjoin has already been encountered. Some context must be stored
@@ -166,12 +164,11 @@
     if (readInputMapJoin) {
       AbstractMapJoinOperator<? extends MapJoinDesc> currMapJoinOp = opProcCtx.getCurrMapJoinOp();
       assert currMapJoinOp != null;
-      boolean local = ((pos == -1) || (pos == (currMapJoinOp.getConf())
-          .getPosBigTable())) ? false : true;
+      boolean local = ((pos == -1) || (pos == (currMapJoinOp.getConf()).getPosBigTable())) ?
+          false : true;
 
       if (setReducer) {
-        Operator<? extends Serializable> reducer = op.getChildOperators()
-            .get(0);
+        Operator<? extends Serializable> reducer = op.getChildOperators().get(0);
         plan.setReducer(reducer);
         opTaskMap.put(reducer, currTask);
         if (reducer.getClass() == JoinOperator.class) {
@@ -291,13 +288,12 @@
   public static void initUnionPlan(ReduceSinkOperator op,
       GenMRProcContext opProcCtx) throws SemanticException {
     Operator<? extends Serializable> reducer = op.getChildOperators().get(0);
-    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx
-        .getMapCurrCtx();
+    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx.getMapCurrCtx();
     GenMapRedCtx mapredCtx = mapCurrCtx.get(op.getParentOperators().get(0));
     Task<? extends Serializable> currTask = mapredCtx.getCurrTask();
     MapredWork plan = (MapredWork) currTask.getWork();
-    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap = opProcCtx
-        .getOpTaskMap();
+    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap =
+      opProcCtx.getOpTaskMap();
 
     opTaskMap.put(reducer, currTask);
     plan.setReducer(reducer);
@@ -369,7 +365,8 @@
   public static void joinPlan(Operator<? extends Serializable> op,
       Task<? extends Serializable> oldTask, Task<? extends Serializable> task,
       GenMRProcContext opProcCtx, int pos, boolean split,
-      boolean readMapJoinData, boolean readUnionData, boolean createLocalWork) throws SemanticException {
+      boolean readMapJoinData, boolean readUnionData, boolean createLocalWork)
+      throws SemanticException {
     Task<? extends Serializable> currTask = task;
     MapredWork plan = (MapredWork) currTask.getWork();
     Operator<? extends Serializable> currTopOp = opProcCtx.getCurrTopOp();
@@ -469,7 +466,7 @@
    *          processing context
    */
   public static void splitPlan(ReduceSinkOperator op, GenMRProcContext opProcCtx)
-      throws SemanticException {
+  throws SemanticException {
     // Generate a new task
     ParseContext parseCtx = opProcCtx.getParseCtx();
     MapredWork cplan = getMapRedWork(parseCtx.getConf());
@@ -483,8 +480,8 @@
 
     cplan.setNumReduceTasks(new Integer(desc.getNumReducers()));
 
-    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap = opProcCtx
-        .getOpTaskMap();
+    HashMap<Operator<? extends Serializable>, Task<? extends Serializable>> opTaskMap =
+      opProcCtx.getOpTaskMap();
     opTaskMap.put(reducer, redTask);
     Task<? extends Serializable> currTask = opProcCtx.getCurrTask();
 
@@ -587,8 +584,9 @@
           continue;
         }
         String path = p.toString();
-        if (LOG.isDebugEnabled())
+        if (LOG.isDebugEnabled()) {
           LOG.debug("Adding " + path + " of table" + alias_id);
+        }
 
         partDir.add(p);
         try {
@@ -616,8 +614,9 @@
         }
         plan.getPathToAliases().get(path).add(alias_id);
         plan.getPathToPartitionInfo().put(path, prtDesc);
-        if (LOG.isDebugEnabled())
+        if (LOG.isDebugEnabled()) {
           LOG.debug("Information added for path " + path);
+        }
       }
 
       assert plan.getAliasToWork().get(alias_id) == null;
@@ -635,11 +634,9 @@
       assert localPlan.getAliasToFetchWork().get(alias_id) == null;
       localPlan.getAliasToWork().put(alias_id, topOp);
       if (tblDir == null) {
-        localPlan.getAliasToFetchWork()
-            .put(
+        localPlan.getAliasToFetchWork().put(
             alias_id,
-            new FetchWork(FetchWork.convertPathToStringArray(partDir),
-            partDesc));
+            new FetchWork(FetchWork.convertPathToStringArray(partDir), partDesc));
       } else {
         localPlan.getAliasToFetchWork().put(alias_id,
             new FetchWork(tblDir.toString(), tblDesc));
@@ -718,8 +715,7 @@
       }
       tagToSchema.set(tag, rs.getConf().getValueSerializeInfo());
     } else {
-      List<Operator<? extends Serializable>> children = topOp
-          .getChildOperators();
+      List<Operator<? extends Serializable>> children = topOp.getChildOperators();
       if (children != null) {
         for (Operator<? extends Serializable> op : children) {
           setKeyAndValueDesc(plan, op);
@@ -741,7 +737,7 @@
     work.setTagToValueDesc(new ArrayList<TableDesc>());
     work.setReducer(null);
     work.setHadoopSupportsSplittable(
-      conf.getBoolVar(HiveConf.ConfVars.HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE));
+        conf.getBoolVar(HiveConf.ConfVars.HIVE_COMBINE_INPUT_FORMAT_SUPPORTS_SPLITTABLE));
     return work;
   }
 
@@ -814,7 +810,7 @@
 
     // replace the reduce child with this operator
     List<Operator<? extends Serializable>> childOpList = parent
-        .getChildOperators();
+    .getChildOperators();
     for (int pos = 0; pos < childOpList.size(); pos++) {
       if (childOpList.get(pos) == op) {
         childOpList.set(pos, fs_op);
@@ -823,11 +819,12 @@
     }
 
     List<Operator<? extends Serializable>> parentOpList =
-        new ArrayList<Operator<? extends Serializable>>();
+      new ArrayList<Operator<? extends Serializable>>();
     parentOpList.add(parent);
     fs_op.setParentOperators(parentOpList);
 
     // create a dummy tableScan operator on top of op
+    // TableScanOperator is implicitly created here for each MapOperator
     Operator<? extends Serializable> ts_op = putOpInsertMap(OperatorFactory
         .get(TableScanDesc.class, parent.getSchema()), null, parseCtx);
 
@@ -836,8 +833,7 @@
     ts_op.setChildOperators(childOpList);
     op.getParentOperators().set(posn, ts_op);
 
-    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx
-        .getMapCurrCtx();
+    Map<Operator<? extends Serializable>, GenMapRedCtx> mapCurrCtx = opProcCtx.getMapCurrCtx();
     mapCurrCtx.put(ts_op, new GenMapRedCtx(childTask, null, null));
 
     String streamDesc = taskTmpDir;
@@ -961,5 +957,4 @@
   private GenMapRedUtils() {
     // prevent instantiation
   }
-
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java	(working copy)
@@ -22,6 +22,7 @@
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.LinkedList;
 import java.util.List;
 
 import org.apache.commons.logging.Log;
@@ -57,6 +58,14 @@
   protected transient TaskHandle taskHandle;
   protected transient HashMap<String, Long> taskCounters;
   protected transient DriverContext driverContext;
+
+  // Descendants tasks who subscribe feeds from this task
+  protected transient List<Task<? extends Serializable>> feedSubscribers;
+
+  public static enum FeedType {
+    DYNAMIC_PARTITIONS, // list of dynamic partitions
+  };
+
   // Bean methods
 
   protected List<Task<? extends Serializable>> childTasks;
@@ -317,4 +326,59 @@
     }
   }
 
-}
+  /**
+   * Subscribe the feed of publisher. To prevent cycles, a task can only subscribe to its ancestor.
+   * Feed is a generic form of execution-time feedback (type, value) pair from one task to another
+   * task. Examples include dynamic partitions (which are only available at execution time).
+   * The MoveTask may pass the list of dynamic partitions to the StatsTask since after the
+   * MoveTask the list of dynamic partitions are lost (MoveTask moves them to the table's
+   * destination directory which is mixed with old partitions).
+   *
+   * @param publisher this feed provider.
+   */
+  public void subscribeFeed(Task<? extends Serializable> publisher) {
+    if (publisher != this && publisher.ancestorOrSelf(this)) {
+      if (publisher.getFeedSubscribers() == null) {
+        publisher.setFeedSubscribers(new LinkedList<Task<? extends Serializable>>());
+      }
+      publisher.getFeedSubscribers().add(this);
+    }
+  }
+
+  // return true if this task is an ancestor of itself of parameter desc
+  private boolean ancestorOrSelf(Task<? extends Serializable> desc) {
+    if (this == desc) {
+      return true;
+    }
+    List<Task<? extends Serializable>> deps = getDependentTasks();
+    if (deps != null) {
+      for (Task<? extends Serializable> d: deps) {
+        if (d.ancestorOrSelf(desc)) {
+          return true;
+        }
+      }
+    }
+    return false;
+  }
+
+  public List<Task<? extends Serializable>> getFeedSubscribers() {
+    return feedSubscribers;
+  }
+
+  public void setFeedSubscribers(List<Task<? extends Serializable>> s) {
+    feedSubscribers = s;
+  }
+
+  // push the feed to its subscribers
+  protected void pushFeed(FeedType feedType, Object feedValue) {
+    if (feedSubscribers != null) {
+      for (Task<? extends Serializable> s: feedSubscribers) {
+        s.receiveFeed(feedType, feedValue);
+      }
+    }
+  }
+
+  // a subscriber accept the feed and do something depending on the Task type
+  protected void receiveFeed(FeedType feedType, Object feedValue) {
+  }
+}
\ No newline at end of file
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/JobCloseFeedBack.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/JobCloseFeedBack.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/JobCloseFeedBack.java	(working copy)
@@ -20,34 +20,40 @@
 
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 
 /**
- * Task implementation.
+ * After this job closed, some data (feedbacks) can be passed to descendant jobs.
+ * Currently the feedbacks is a generic data structure that has a key (FeedBackType)
+ * and an object as value. The type of the object depends on the key.
  **/
 
 public class JobCloseFeedBack {
+
+  // list of feedback types
   public static enum FeedBackType {
-    DYNAMIC_PARTITIONS,
+    DYNAMIC_PARTITIONS, // list of dynamic partitions generated by this MR job
     NONE
   };
 
-  HashMap<FeedBackType, ArrayList<Object>> feedBacks; // one type corresponds to a list of values
+  Map<FeedBackType, List<Object>> feedBacks; // one type corresponds to a list of values
 
   public JobCloseFeedBack() {
-    feedBacks = new HashMap<FeedBackType, ArrayList<Object>>();
+    feedBacks = new HashMap<FeedBackType, List<Object>>();
   }
 
-  public void add(FeedBackType t, Object v) {
-    ArrayList<Object> vals = feedBacks.get(t);
+  public void append(FeedBackType t, Object v) {
+    List<Object> vals = feedBacks.get(t);
     if (vals == null) {
       vals = new ArrayList<Object>();
-    }
+   }
     vals.add(v);
     feedBacks.put(t, vals);
   }
 
-  public ArrayList<Object> get(FeedBackType t) {
+  public List<Object> get(FeedBackType t) {
     return feedBacks.get(t);
   }
 }
\ No newline at end of file
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java	(working copy)
@@ -32,7 +32,6 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.common.FileUtils;
-import org.apache.hadoop.hive.ql.exec.JobCloseFeedBack.FeedBackType;
 import org.apache.hadoop.hive.ql.io.HiveFileFormatUtils;
 import org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat;
 import org.apache.hadoop.hive.ql.io.HiveKey;
@@ -45,6 +44,8 @@
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
 import org.apache.hadoop.hive.ql.plan.api.OperatorType;
+import org.apache.hadoop.hive.ql.stats.StatsPublisher;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
 import org.apache.hadoop.hive.serde2.SerDeException;
 import org.apache.hadoop.hive.serde2.Serializer;
 import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
@@ -59,7 +60,6 @@
 import org.apache.hadoop.io.Writable;
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.util.ReflectionUtils;
-
 /**
  * File Sink operator implementation.
  **/
@@ -100,6 +100,7 @@
     Path[] outPaths;
     Path[] finalPaths;
     RecordWriter[] outWriters;
+    Stat stat;
 
     public FSPaths() {
     }
@@ -109,6 +110,7 @@
       outPaths   = new Path[numFiles];
       finalPaths = new Path[numFiles];
       outWriters = new RecordWriter[numFiles];
+      stat = new Stat();
     }
 
     /**
@@ -169,7 +171,7 @@
             throw new HiveException(e);
           }
         }
-     }
+      }
     }
 
     private void commit(FileSystem fs) throws HiveException {
@@ -192,10 +194,10 @@
         if (outWriters[idx] != null) {
           try {
             outWriters[idx].close(abort);
-          	if (delete) {
-          	  fs.delete(outPaths[idx], true);
-          	}
-          	updateProgress();
+            if (delete) {
+              fs.delete(outPaths[idx], true);
+            }
+            updateProgress();
           } catch (IOException e) {
             throw new HiveException(e);
           }
@@ -258,14 +260,10 @@
   protected transient boolean autoDelete = false;
   protected transient JobConf jc;
   Class<? extends Writable> outputClass;
-  /*
-  String specPath;
-  Path tmpPath;
-  */
   String taskId;
 
   private boolean filesCreated = false;
- @Override
+  @Override
   protected void initializeOp(Configuration hconf) throws HiveException {
     try {
       this.hconf       = hconf;
@@ -324,12 +322,11 @@
       if (!bDynParts) {
         fsp = new FSPaths(specPath);
 
-      	// Create all the files - this is required because empty files need to be created for
-      	// empty buckets
-      	// createBucketFiles(fsp);
-      	valToPaths.put("", fsp); // special entry for non-DP case
+        // Create all the files - this is required because empty files need to be created for
+        // empty buckets
+        // createBucketFiles(fsp);
+        valToPaths.put("", fsp); // special entry for non-DP case
       }
-
       initializeChildren(hconf);
     } catch (HiveException e) {
       throw e;
@@ -428,9 +425,9 @@
         }
         try {
           // The reason to keep these instead of using
-        	// OutputFormat.getRecordWriter() is that
-        	// getRecordWriter does not give us enough control over the file name that
-        	// we create.
+          // OutputFormat.getRecordWriter() is that
+          // getRecordWriter does not give us enough control over the file name that
+          // we create.
           if (!bDynParts) {
             fsp.finalPaths[filesIdx] = HiveFileFormatUtils.getOutputFormatFinalPath(
                 parent, taskId, jc, hiveOutputFormat, isCompressed, fsp.finalPaths[filesIdx]);
@@ -448,21 +445,21 @@
         }
         LOG.info("New Final Path: FS " + fsp.finalPaths[filesIdx]);
 
-      	if (isNativeTable) {
-      	  try {
-      	    // in recent hadoop versions, use deleteOnExit to clean tmp files.
-      	    autoDelete = ShimLoader.getHadoopShims().fileSystemDeleteOnExit(
-      	        fs, fsp.outPaths[filesIdx]);
-      	  } catch (IOException e) {
-      	    throw new HiveException(e);
-      	  }
-      	}
+        if (isNativeTable) {
+          try {
+            // in recent hadoop versions, use deleteOnExit to clean tmp files.
+            autoDelete = ShimLoader.getHadoopShims().fileSystemDeleteOnExit(
+                fs, fsp.outPaths[filesIdx]);
+          } catch (IOException e) {
+            throw new HiveException(e);
+          }
+        }
 
         Utilities.copyTableJobPropertiesToConf(conf.getTableInfo(), jc);
         // only create bucket files only if no dynamic partitions,
         // buckets of dynamic partitions will be created for each newly created partition
         fsp.outWriters[filesIdx] = HiveFileFormatUtils.getHiveRecordWriter(
-              jc, conf.getTableInfo(), outputClass, conf, fsp.outPaths[filesIdx]);
+            jc, conf.getTableInfo(), outputClass, conf, fsp.outPaths[filesIdx]);
         // increment the CREATED_FILES counter
         if (reporter != null) {
           reporter.incrCounter(ProgressCounter.CREATED_FILES, 1);
@@ -547,6 +544,11 @@
         recordValue = serializer.serialize(row, subSetOI);
       } else {
         rowOutWriters = fsp.outWriters;
+
+        if (conf.isGatherStats()) {
+          fsp.stat.increaseNumRows(1);
+        }
+
         // use SerDe to serialize r, and write it out
         recordValue = serializer.serialize(row, inputObjInspectors[0]);
       }
@@ -586,6 +588,7 @@
 
     if (dpDir != null) {
       FSPaths fsp2 = valToPaths.get(dpDir);
+
       if (fsp2 == null) {
         // check # of dp
         if (valToPaths.size() > maxPartitions) {
@@ -599,6 +602,9 @@
         createBucketFiles(fsp2);
         valToPaths.put(dpDir, fsp2);
       }
+      if (conf.isGatherStats()) {
+        fsp2.stat.increaseNumRows(1);
+      }
       rw = fsp2.outWriters;
     } else {
       rw = fsp.outWriters;
@@ -608,6 +614,7 @@
 
   // given the current input row, the mapping for input col info to dp columns, and # of dp cols,
   // return the relative path corresponding to the row.
+  // e.g., ds=2008-04-08/hr=11
   private String getDynPartDirectory(List<String> row, List<String> dpColNames, int numDynParts) {
     assert row.size() == numDynParts && numDynParts == dpColNames.size():
       "data length is different from num of DP columns";
@@ -619,11 +626,12 @@
     errMsg.append("Operator ").append(getOperatorId()).append(" (id=").append(id).append("): ");
     errMsg.append(counterCode > FATAL_ERR_MSG.length - 1 ?
         "fatal error":
-        FATAL_ERR_MSG[(int) counterCode]);
+          FATAL_ERR_MSG[(int) counterCode]);
   }
 
   @Override
   public void closeOp(boolean abort) throws HiveException {
+
     if (!bDynParts && !filesCreated) {
       createBucketFiles(fsp);
     }
@@ -636,6 +644,10 @@
           fsp.commit(fs);
         }
       }
+      // Only publish stats if this operator's flag was set to gather stats
+      if (conf.isGatherStats()) {
+        publishStats();
+      }
     } else {
       // Will come here if an Exception was thrown in map() or reduce().
       // Hadoop always call close() even if an Exception was thrown in map() or
@@ -662,8 +674,6 @@
         String specPath = conf.getDirName();
         DynamicPartitionCtx dpCtx = conf.getDynPartCtx();
         mvFileToFinalPath(specPath, hconf, success, LOG, dpCtx);
-        // send back the root path of corresponding to the DP columns
-        feedBack.add(FeedBackType.DYNAMIC_PARTITIONS, specPath);
       }
     } catch (IOException e) {
       throw new HiveException(e);
@@ -728,9 +738,9 @@
     TableDesc tableInfo = conf.getTableInfo();
     try {
       Serializer serializer = (Serializer) tableInfo.getDeserializerClass().newInstance();
-    	serializer.initialize(null, tableInfo.getProperties());
-    	outputClass = serializer.getSerializedClass();
-    	hiveOutputFormat = conf.getTableInfo().getOutputFileFormatClass().newInstance();
+      serializer.initialize(null, tableInfo.getProperties());
+      outputClass = serializer.getSerializedClass();
+      hiveOutputFormat = conf.getTableInfo().getOutputFileFormatClass().newInstance();
     } catch (SerDeException e) {
       throw new HiveException(e);
     } catch (InstantiationException e) {
@@ -756,6 +766,38 @@
   @Override
   public void augmentPlan() {
     PlanUtils.configureTableJobPropertiesForStorageHandler(
-      getConf().getTableInfo());
+        getConf().getTableInfo());
   }
+
+  private void publishStats() {
+    // Initializing a stats publisher
+    StatsPublisher statsPublisher = Utilities.getStatsPublisher(jc);
+
+    if (statsPublisher == null || !statsPublisher.connect(hconf)) {
+      // just return, stats gathering should not block the main query
+      LOG.error("StatsPublishing error: cannot connect to database");
+      return;
+    }
+
+    String taskID = Utilities.getTaskIdFromFilename(Utilities.getTaskId(hconf));
+    String spSpec = conf.getStaticSpec() != null ? conf.getStaticSpec() : "";
+
+    for (String fspKey : valToPaths.keySet()) {
+      FSPaths fspValue = valToPaths.get(fspKey);
+      String key;
+
+      // construct the key(fileID) to insert into the intermediate stats table
+      if (fspKey == "") {
+        // for non-partitioned/static partitioned table, the key for temp storage is
+        // common key prefix + static partition spec +  taskID
+        key = conf.getStatsAggPrefix() + spSpec + taskID ;
+      } else {
+        // for partitioned table, the key is
+        // common key prefix + static partition spec + DynamicPartSpec + taskID
+        key = conf.getStatsAggPrefix() + spSpec + fspKey + Path.SEPARATOR + taskID;
+      }
+      statsPublisher.publishStat(key, StatsSetupConst.ROW_COUNT, Long.toString(fspValue.stat.getNumRows()));
+    }
+    statsPublisher.closeConnection();
+  }
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/TaskFactory.java	(working copy)
@@ -31,6 +31,7 @@
 import org.apache.hadoop.hive.ql.plan.FunctionWork;
 import org.apache.hadoop.hive.ql.plan.MapredWork;
 import org.apache.hadoop.hive.ql.plan.MoveWork;
+import org.apache.hadoop.hive.ql.plan.StatsWork;
 
 /**
  * TaskFactory implementation.
@@ -67,6 +68,8 @@
         ConditionalTask.class));
     taskvec.add(new taskTuple<MapredWork>(MapredWork.class,
                                           MapRedTask.class));
+    taskvec.add(new taskTuple<StatsWork>(StatsWork.class,
+        StatsTask.class));
   }
 
   private static ThreadLocal<Integer> tid = new ThreadLocal<Integer>() {
@@ -130,7 +133,7 @@
     }
 
     makeChild(ret, tasklist);
-    
+
     return (ret);
   }
 
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java	(working copy)
@@ -18,28 +18,26 @@
 
 package org.apache.hadoop.hive.ql.exec;
 
+import java.io.IOException;
 import java.io.OutputStream;
 import java.io.Serializable;
-import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Properties;
 
 import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.fs.ContentSummary;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
-import org.apache.hadoop.hive.ql.QueryPlan;
+import org.apache.hadoop.hive.ql.Context;
+import org.apache.hadoop.hive.ql.DriverContext;
 import org.apache.hadoop.hive.ql.exec.Utilities.StreamPrinter;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.MapredWork;
-import org.apache.hadoop.hive.ql.plan.api.StageType;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.shims.ShimLoader;
-import org.apache.hadoop.hive.ql.DriverContext;
-import org.apache.hadoop.hive.ql.Context;
-import org.apache.hadoop.fs.ContentSummary;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.mapred.JobConf;
 
 /**
@@ -87,27 +85,28 @@
       if (!ctx.isLocalOnlyExecutionMode() &&
           conf.getBoolVar(HiveConf.ConfVars.LOCALMODEAUTO)) {
 
-        if (inputSummary == null)
+        if (inputSummary == null) {
           inputSummary = Utilities.getInputSummary(driverContext.getCtx(), work, null);
+        }
 
         // at this point the number of reducers is precisely defined in the plan
         int numReducers = work.getNumReduceTasks();
 
         if (LOG.isDebugEnabled()) {
-          LOG.debug("Task: " + getId() + ", Summary: " + 
+          LOG.debug("Task: " + getId() + ", Summary: " +
                     inputSummary.getLength() + "," + inputSummary.getFileCount() + ","
                     + numReducers);
         }
 
-	String reason = MapRedTask.isEligibleForLocalMode(conf, inputSummary, numReducers);
+        String reason = MapRedTask.isEligibleForLocalMode(conf, inputSummary, numReducers);
         if (reason == null) {
-	  // set the JT to local for the duration of this job
+          // set the JT to local for the duration of this job
           ctx.setOriginalTracker(conf.getVar(HiveConf.ConfVars.HADOOPJT));
           conf.setVar(HiveConf.ConfVars.HADOOPJT, "local");
           console.printInfo("Selecting local mode for task: " + getId());
         } else {
           console.printInfo("Cannot run job locally: " + reason);
-	}
+        }
       }
 
       runningViaChild =
@@ -239,8 +238,9 @@
 
         // creating the context can create a bunch of files. So make
         // sure to clear it out
-        if(ctxCreated) 
+        if(ctxCreated) {
           ctx.clear();
+        }
 
       } catch (Exception e) {
         LOG.error("Exception: " + e.getMessage());
@@ -324,9 +324,10 @@
     long bytesPerReducer = conf.getLongVar(HiveConf.ConfVars.BYTESPERREDUCER);
     int maxReducers = conf.getIntVar(HiveConf.ConfVars.MAXREDUCERS);
 
-    if(inputSummary == null)
+    if(inputSummary == null) {
       // compute the summary and stash it away
       inputSummary =  Utilities.getInputSummary(driverContext.getCtx(), work, null);
+    }
 
     long totalInputFileSize = inputSummary.getLength();
 
@@ -355,23 +356,26 @@
     long maxTasks = conf.getIntVar(HiveConf.ConfVars.LOCALMODEMAXTASKS);
 
     // check for max input size
-    if (inputSummary.getLength() > maxBytes)
+    if (inputSummary.getLength() > maxBytes) {
       return "Input Size (= " + inputSummary.getLength() + ") is larger than " +
         HiveConf.ConfVars.LOCALMODEMAXBYTES.varname + " (= " + maxBytes + ")";
+    }
 
     // ideally we would like to do this check based on the number of splits
     // in the absence of an easy way to get the number of splits - do this
     // based on the total number of files (pessimistically assumming that
     // splits are equal to number of files in worst case)
-    if (inputSummary.getFileCount() > maxTasks)
+    if (inputSummary.getFileCount() > maxTasks) {
       return "Number of Input Files (= " + inputSummary.getFileCount() +
-        ") is larger than " + 
+        ") is larger than " +
         HiveConf.ConfVars.LOCALMODEMAXTASKS.varname + "(= " + maxTasks + ")";
+    }
 
     // since local mode only runs with 1 reducers - make sure that the
     // the number of reducers (set by user or inferred) is <=1
-    if (numReducers > 1) 
+    if (numReducers > 1) {
       return "Number of reducers (= " + numReducers + ") is more than 1";
+    }
 
     return null;
   }
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java	(working copy)
@@ -19,10 +19,23 @@
 package org.apache.hadoop.hive.ql.exec;
 
 import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.List;
 
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.common.FileUtils;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.TableScanDesc;
 import org.apache.hadoop.hive.ql.plan.api.OperatorType;
+import org.apache.hadoop.hive.ql.stats.StatsPublisher;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.ObjectInspectorCopyOption;
+import org.apache.hadoop.hive.serde2.objectinspector.StructField;
+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
+import org.apache.hadoop.mapred.JobConf;
 
 /**
  * Table Scan Operator If the data is coming from the map-reduce framework, just
@@ -33,22 +46,108 @@
     Serializable {
   private static final long serialVersionUID = 1L;
 
+  protected transient JobConf jc;
+  private transient Configuration hconf;
+  private transient Stat stat;
+  private transient String partitionSpecs;
+
   /**
-   * Currently, the table scan operator does not do anything special other than
-   * just forwarding the row. Since the table data is always read as part of the
-   * map-reduce framework by the mapper. But, this assumption is not true, i.e
-   * table data is not only read by the mapper, this operator will be enhanced
-   * to read the table.
+   * Other than gathering statistics for the ANALYZE command, the table scan operator
+   * does not do anything special other than just forwarding the row. Since the table
+   * data is always read as part of the map-reduce framework by the mapper. But, this
+   * assumption is not true, i.e table data is not only read by the mapper, this
+   * operator will be enhanced to read the table.
    **/
   @Override
   public void processOp(Object row, int tag) throws HiveException {
+    if (conf != null && conf.isGatherStats()) {
+      gatherStats(row);
+    }
     forward(row, inputObjInspectors[tag]);
   }
 
+  private void gatherStats(Object row) {
+    if (stat == null) { // first row/call
+      stat = new Stat();
+      if (conf.getPartColumns() == null || conf.getPartColumns().size() == 0) {
+        partitionSpecs = "";
+      } else {
+        // Figure out the partition spec from the input.
+        // This is only done once for the first row (when stat == null)
+        // since all rows in the same mapper should be from the same partition.
+        List<Object> writable;
+        List<String> values;
+        int dpStartCol; // the first position of partition column
+        assert inputObjInspectors[0].getCategory() == ObjectInspector.Category.STRUCT:
+          "input object inspector is not struct";
+
+        writable = new ArrayList<Object>(conf.getPartColumns().size());
+        values = new ArrayList<String>(conf.getPartColumns().size());
+        dpStartCol = 0;
+        StructObjectInspector soi = (StructObjectInspector) inputObjInspectors[0];
+        for (StructField sf: soi.getAllStructFieldRefs()) {
+          String fn = sf.getFieldName();
+          if (!conf.getPartColumns().contains(fn)) {
+            dpStartCol++;
+          } else {
+            break;
+          }
+        }
+
+        ObjectInspectorUtils.partialCopyToStandardObject(writable, row, dpStartCol, conf.getPartColumns().size(),
+            (StructObjectInspector) inputObjInspectors[0], ObjectInspectorCopyOption.WRITABLE);
+
+        for (Object o: writable) {
+          assert (o != null && o.toString().length() > 0);
+          values.add(o.toString());
+        }
+        partitionSpecs = FileUtils.makePartName(conf.getPartColumns(), values);
+        LOG.info("Stats Gathering found a new partition spec = " + partitionSpecs);
+      }
+    }
+    stat.increaseNumRows(1);
+  }
+
+  @Override
+  protected void initializeOp(Configuration hconf) throws HiveException {
+    initializeChildren(hconf);
+    if (conf == null) {
+      return;
+    }
+    if (!conf.isGatherStats()) {
+      return;
+    }
+
+    this.hconf = hconf;
+    if (hconf instanceof JobConf) {
+      jc = (JobConf) hconf;
+    } else {
+      // test code path
+      jc = new JobConf(hconf, ExecDriver.class);
+    }
+
+    stat = null;
+    partitionSpecs = null;
+    if (conf.getPartColumns() == null || conf.getPartColumns().size() == 0) {
+      // NON PARTITIONED table
+      return;
+    }
+
+ }
+
+  @Override
+  public void closeOp(boolean abort) throws HiveException {
+    if (conf != null) {
+      if (conf.isGatherStats() && stat != null) {
+        publishStats();
+      }
+    }
+  }
+
   /**
    * The operator name for this operator type. This is used to construct the
    * rule for an operator
-   * 
+   *
    * @return the operator name
    **/
   @Override
@@ -74,4 +173,28 @@
   public int getType() {
     return OperatorType.TABLESCAN;
   }
+
+  private void publishStats() {
+    // Initializing a stats publisher
+    StatsPublisher statsPublisher = Utilities.getStatsPublisher(jc);
+    if (!statsPublisher.connect(jc)) {
+      // just return, stats gathering should not block the main query.
+      LOG.info("StatsPublishing error: cannot connect to database.");
+      return;
+    }
+
+    String key;
+    String taskID = Utilities.getTaskIdFromFilename(Utilities.getTaskId(hconf));
+    if (partitionSpecs.isEmpty()) {
+      // In case of a non-partitioned table, the key for temp storage is just
+      // "tableName + taskID"
+      key = conf.getStatsAggPrefix() + taskID;
+    } else {
+      // In case of a partition, the key for temp storage is
+      // "tableName + partitionSpecs + taskID"
+      key = conf.getStatsAggPrefix() + partitionSpecs + Path.SEPARATOR + taskID;
+    }
+    statsPublisher.publishStat(key, StatsSetupConst.ROW_COUNT, Long.toString(stat.getNumRows()));
+    statsPublisher.closeConnection();
+  }
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/StatsTask.java	(revision 0)
@@ -0,0 +1,448 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.hadoop.hive.ql.exec;
+
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.Warehouse;
+import org.apache.hadoop.hive.ql.Context;
+import org.apache.hadoop.hive.ql.DriverContext;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.metadata.Partition;
+import org.apache.hadoop.hive.ql.metadata.Table;
+import org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.tableSpec;
+import org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx;
+import org.apache.hadoop.hive.ql.plan.LoadTableDesc;
+import org.apache.hadoop.hive.ql.plan.StatsWork;
+import org.apache.hadoop.hive.ql.plan.api.StageType;
+import org.apache.hadoop.hive.ql.stats.StatsAggregator;
+import org.apache.hadoop.hive.ql.stats.StatsFactory;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
+import org.apache.hadoop.util.StringUtils;
+
+/**
+ * StatsTask implementation.
+ **/
+public class StatsTask extends Task<StatsWork> implements Serializable {
+
+  private static final long serialVersionUID = 1L;
+
+  private Table table;
+  private List<LinkedHashMap<String, String>> dpPartSpecs;
+
+  public StatsTask() {
+    super();
+    dpPartSpecs = null;
+  }
+
+  /**
+   *
+   * Partition Level Statistics.
+   *
+   */
+  class PartitionStatistics {
+    int numFiles; // number of files in the partition
+    long numRows;  // number of rows in the partition
+    long size;    // total size in bytes of the partition
+
+    public PartitionStatistics() {
+      numFiles = 0;
+      numRows = 0L;
+      size = 0L;
+    }
+
+    public PartitionStatistics(int nf, long nr, long sz) {
+      numFiles = nf;
+      numRows = nr;
+      size = sz;
+    }
+
+    public int getNumFiles() {
+      return numFiles;
+    }
+
+    public long getNumRows() {
+      return numRows;
+    }
+
+    public long getSize() {
+      return size;
+    }
+
+    public void setNumFiles(int nf) {
+      numFiles = nf;
+    }
+
+    public void setNumRows(long nr) {
+      numRows = nr;
+    }
+
+    public void setSize(long sz) {
+      size = sz;
+    }
+
+    @Override
+    public String toString() {
+      StringBuilder sb = new StringBuilder();
+      sb.append("num_files: ").append(numFiles).append(", ");
+      sb.append("num_rows: ").append(numRows).append(", ");
+      sb.append("total_size: ").append(size);
+      return sb.toString();
+    }
+  }
+
+  /**
+   *
+   * Table Level Statistics.
+   *
+   */
+  class TableStatistics extends PartitionStatistics {
+    int numPartitions; // number of partitions
+
+    public TableStatistics() {
+      super();
+      numPartitions = 0;
+    }
+
+    public void setNumPartitions(int np) {
+      numPartitions = np;
+    }
+
+    public int getNumPartitions() {
+      return numPartitions;
+    }
+
+    /**
+     * Incrementally update the table statistics according to the old and new
+     * partition level statistics.
+     * @param oldStats The old statistics of a partition.
+     * @param newStats The new statistics of a partition.
+     */
+    public void updateStats(PartitionStatistics oldStats, PartitionStatistics newStats) {
+      deletePartitionStats(oldStats);
+      addPartitionStats(newStats);
+    }
+
+    /**
+     * Update the table level statistics when a new partition is added.
+     * @param newStats the new partition statistics.
+     */
+    public void addPartitionStats(PartitionStatistics newStats) {
+      this.numFiles += newStats.getNumFiles();
+      this.numRows += newStats.getNumRows();
+      this.size += newStats.getSize();
+      this.numPartitions++;
+    }
+
+    /**
+     * Update the table level statistics when an old partition is dropped.
+     * @param oldStats the old partition statistics.
+     */
+    public void deletePartitionStats(PartitionStatistics oldStats) {
+      this.numFiles -= oldStats.getNumFiles();
+      this.numRows -= oldStats.getNumRows();
+      this.size -= oldStats.getSize();
+      this.numPartitions--;
+    }
+
+    @Override
+    public String toString() {
+      StringBuilder sb = new StringBuilder();
+      sb.append("num_partitions: ").append(numPartitions).append(", ");
+      sb.append(super.toString());
+      return sb.toString();
+    }
+  }
+
+  @Override
+  protected void receiveFeed(FeedType feedType, Object feedValue) {
+    // this method should be called by MoveTask when there are dynamic partitions generated
+    if (feedType == FeedType.DYNAMIC_PARTITIONS) {
+      assert feedValue instanceof List<?>;
+      dpPartSpecs = (List<LinkedHashMap<String, String>>) feedValue;
+    }
+  }
+
+  @Override
+  public int execute(DriverContext driverContext) {
+
+    // Make sure that it is either an ANALYZE command or an INSERT OVERWRITE command
+    assert (work.getLoadTableDesc() != null && work.getTableSpecs() == null ||
+            work.getLoadTableDesc() == null && work.getTableSpecs() != null);
+    String tableName = "";
+    try {
+      if (work.getLoadTableDesc() != null) {
+        tableName = work.getLoadTableDesc().getTable().getTableName();
+      } else {
+        tableName = work.getTableSpecs().tableName;
+      }
+      table = db.getTable(tableName);
+    }  catch (HiveException e) {
+       LOG.error("Cannot get table " + tableName, e);
+       console.printError("Cannot get table " + tableName, e.toString());
+    }
+    return aggregateStats();
+  }
+
+  @Override
+  public int getType() {
+    return StageType.STATS;
+  }
+
+  @Override
+  public String getName() {
+    return "STATS";
+  }
+
+  @Override
+  protected void localizeMRTmpFilesImpl(Context ctx) {
+    // Nothing to do for StatsTask here.
+  }
+
+  private int aggregateStats() {
+    try {
+      // Stats setup:
+      Warehouse wh = new Warehouse(conf);
+      FileSystem fileSys;
+      FileStatus[] fileStatus;
+
+      // manufacture a StatsAggregator
+      StatsAggregator statsAggregator;
+      String statsImplementationClass = HiveConf.getVar(conf, HiveConf.ConfVars.HIVESTATSDBCLASS);
+      StatsFactory.setImplementation(statsImplementationClass, conf);
+      statsAggregator = StatsFactory.getStatsAggregator();
+      if (!statsAggregator.connect(conf)) {
+        // this should not fail the whole job, return 0 so that the job won't fail.
+        console.printInfo("[WARNING] Could not update table/partition level stats.",
+            "StatsAggregator.connect() failed: stats class = " +
+            statsImplementationClass);
+        return 0;
+      }
+
+
+      TableStatistics tblStats = new TableStatistics();
+
+      //
+      // For partitioned table get the old table statistics for incremental update
+      //
+      if (table.isPartitioned()) {
+        org.apache.hadoop.hive.metastore.api.Table tTable = table.getTTable();
+        Map<String, String> parameters = tTable.getParameters();
+        if (parameters.containsKey(StatsSetupConst.ROW_COUNT)) {
+          tblStats.setNumRows(Long.parseLong(parameters.get(StatsSetupConst.ROW_COUNT)));
+        }
+        if (parameters.containsKey(StatsSetupConst.NUM_PARTITIONS)) {
+          tblStats.setNumPartitions(Integer.parseInt(parameters.get(StatsSetupConst.NUM_PARTITIONS)));
+        }
+        if (parameters.containsKey(StatsSetupConst.NUM_FILES)) {
+          tblStats.setNumFiles(Integer.parseInt(parameters.get(StatsSetupConst.NUM_FILES)));
+        }
+        if (parameters.containsKey(StatsSetupConst.TOTAL_SIZE)) {
+          tblStats.setSize(Long.parseLong(parameters.get(StatsSetupConst.TOTAL_SIZE)));
+        }
+      }
+
+      List<Partition> partitions = getPartitionsList();
+
+      if (partitions == null) {
+        // non-partitioned tables:
+
+        Path tablePath = wh.getDefaultTablePath(table.getDbName(), table.getTableName());
+        fileSys = tablePath.getFileSystem(conf);
+        fileStatus = Utilities.getFileStatusRecurse(tablePath, 1, fileSys);
+        tblStats.setNumFiles(fileStatus.length);
+        long tableSize = 0L;
+        for (int i = 0; i < fileStatus.length; i++) {
+          tableSize += fileStatus[i].getLen();
+        }
+        tblStats.setSize(tableSize);
+
+        // In case of a non-partitioned table, the key for stats temporary store is "rootDir"
+        String rows = statsAggregator.aggregateStats(work.getAggKey(), StatsSetupConst.ROW_COUNT);
+        if (rows != null) {
+          tblStats.setNumRows(Long.parseLong(rows));
+        }
+      } else {
+        // Partitioned table:
+        // Need to get the old stats of the partition
+        // and update the table stats based on the old and new stats.
+        for (Partition partn : partitions) {
+          //
+          // get the new partition stats
+          //
+          PartitionStatistics newPartStats = new PartitionStatistics();
+
+          // In that case of a partition, the key for stats temporary store is "rootDir/[dynamic_partition_specs/]%"
+          String partitionID = work.getAggKey() + Warehouse.makePartName(partn.getSpec());
+
+          String rows = statsAggregator.aggregateStats(partitionID, StatsSetupConst.ROW_COUNT);
+          if (rows != null) {
+            newPartStats.setNumRows(Long.parseLong(rows));
+          }
+
+          fileSys = partn.getPartitionPath().getFileSystem(conf);
+          fileStatus = Utilities.getFileStatusRecurse(partn.getPartitionPath(), 1, fileSys);
+          newPartStats.setNumFiles(fileStatus.length);
+
+          long partitionSize = 0L;
+          for (int i = 0; i < fileStatus.length; i++) {
+            partitionSize += fileStatus[i].getLen();
+          }
+          newPartStats.setSize(partitionSize);
+
+          //
+          // get the old partition stats
+          //
+          org.apache.hadoop.hive.metastore.api.Partition tPart = partn.getTPartition();
+          Map<String, String> parameters = tPart.getParameters();
+
+          boolean hasStats =
+            parameters.containsKey(StatsSetupConst.NUM_FILES) ||
+            parameters.containsKey(StatsSetupConst.ROW_COUNT) ||
+            parameters.containsKey(StatsSetupConst.TOTAL_SIZE);
+
+          int  nf = parameters.containsKey(StatsSetupConst.NUM_FILES) ?
+                    Integer.parseInt(parameters.get(StatsSetupConst.NUM_FILES)) :
+                    0;
+          long nr = parameters.containsKey(StatsSetupConst.ROW_COUNT) ?
+                    Long.parseLong(parameters.get(StatsSetupConst.ROW_COUNT)) :
+                    0L;
+          long sz = parameters.containsKey(StatsSetupConst.TOTAL_SIZE) ?
+                    Integer.parseInt(parameters.get(StatsSetupConst.TOTAL_SIZE)) :
+                    0L;
+          if (hasStats) {
+            PartitionStatistics oldPartStats = new PartitionStatistics(nf, nr, sz);
+            tblStats.updateStats(oldPartStats, newPartStats);
+          } else {
+            tblStats.addPartitionStats(newPartStats);
+          }
+
+          //
+          // update the metastore
+          //
+          parameters.put(StatsSetupConst.ROW_COUNT, Long.toString(newPartStats.getNumRows()));
+          parameters.put(StatsSetupConst.NUM_FILES, Integer.toString(newPartStats.getNumFiles()));
+          parameters.put(StatsSetupConst.TOTAL_SIZE, Long.toString(newPartStats.getSize()));
+
+          tPart.setParameters(parameters);
+          db.alterPartition(table.getTableName(), new Partition(table, tPart));
+
+          console.printInfo("Partition " + table.getTableName() + partn.getSpec() +
+              " stats: [" + newPartStats.toString() + ']');
+        }
+      }
+
+      statsAggregator.closeConnection();
+
+      //
+      // write table stats to metastore
+      //
+      org.apache.hadoop.hive.metastore.api.Table tTable = table.getTTable();
+      Map<String, String> parameters = tTable.getParameters();
+      parameters.put(StatsSetupConst.ROW_COUNT, Long.toString(tblStats.getNumRows()));
+      parameters.put(StatsSetupConst.NUM_PARTITIONS, Integer.toString(tblStats.getNumPartitions()));
+      parameters.put(StatsSetupConst.NUM_FILES, Integer.toString(tblStats.getNumFiles()));
+      parameters.put(StatsSetupConst.TOTAL_SIZE, Long.toString(tblStats.getSize()));
+      tTable.setParameters(parameters);
+
+      db.alterTable(table.getTableName(), new Table(tTable));
+
+      console.printInfo("Table " + table.getTableName() + " stats: [" + tblStats.toString() + ']');
+
+      return 0;
+    }
+    catch (Exception e) {
+      // return 0 since StatsTask should not fail the whole job
+      console.printInfo("[Warning] could not update stats.",
+          "Failed with exception " + e.getMessage() + "\n"
+          + StringUtils.stringifyException(e));
+      return 0;
+    }
+  }
+
+  /**
+   * Get the list of partitions that need to update statistics.
+   * TODO: we should reuse the Partitions generated at compile time
+   * since getting the list of partitions is quite expensive.
+   * @return a list of partitions that need to update statistics.
+   * @throws HiveException
+   */
+  private List<Partition> getPartitionsList() throws HiveException {
+
+    List<Partition> list = new ArrayList<Partition>();
+
+    if (work.getTableSpecs() != null) {
+
+      // ANALYZE command
+      tableSpec tblSpec = work.getTableSpecs();
+      table = tblSpec.tableHandle;
+      if (!table.isPartitioned()) {
+        return null;
+      }
+      // get all partitions that matches with the partition spec
+      List<Partition> partitions = db.getPartitions(table, tblSpec.getPartSpec());
+      for (Partition partn : partitions) {
+        list.add(partn);
+      }
+    } else if (work.getLoadTableDesc() != null) {
+
+      // INSERT OVERWRITE command
+      LoadTableDesc tbd = work.getLoadTableDesc();
+      table = db.getTable(tbd.getTable().getTableName());
+      if (!table.isPartitioned()) {
+        return null;
+      }
+      DynamicPartitionCtx dpCtx = tbd.getDPCtx();
+      if (dpCtx != null && dpCtx.getNumDPCols() > 0) { // dynamic partitions
+        // load the list of DP partitions and return the list of partition specs
+        for (LinkedHashMap<String, String> partSpec: dpPartSpecs) {
+          Partition partn = db.getPartition(table, partSpec, false);
+          list.add(partn);
+        }
+      } else { // static partition
+        Partition partn = db.getPartition(table, tbd.getPartitionSpec(), false);
+        list.add(partn);
+      }
+    }
+    return list;
+  }
+
+  /**
+   * This method is static as it is called from the shutdown hook at the ExecDriver.
+   */
+  public static void cleanUp(String jobID, Configuration config) {
+    StatsAggregator statsAggregator;
+    String statsImplementationClass = HiveConf.getVar(config, HiveConf.ConfVars.HIVESTATSDBCLASS);
+    StatsFactory.setImplementation(statsImplementationClass, config);
+    statsAggregator = StatsFactory.getStatsAggregator();
+    if (statsAggregator.connect(config)) {
+      statsAggregator.cleanUp(jobID + Path.SEPARATOR); // Adding the path separator to avoid an Id being a prefix of another ID
+    }
+  }
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java	(working copy)
@@ -67,6 +67,8 @@
 import org.apache.hadoop.hive.ql.plan.api.StageType;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;
+import org.apache.hadoop.hive.ql.stats.StatsFactory;
+import org.apache.hadoop.hive.ql.stats.StatsPublisher;
 import org.apache.hadoop.hive.shims.ShimLoader;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.Text;
@@ -137,7 +139,9 @@
   public void initialize(HiveConf conf, QueryPlan queryPlan,
       DriverContext driverContext) {
     super.initialize(conf, queryPlan, driverContext);
+
     job = new JobConf(conf, ExecDriver.class);
+
     // NOTE: initialize is only called if it is in non-local mode.
     // In case it's in non-local mode, we need to move the SessionState files
     // and jars to jobConf.
@@ -176,7 +180,7 @@
    * i.e., the JVM shuts down while there are still jobs running.
    */
   private static Map<String, String> runningJobKillURIs =
-      Collections.synchronizedMap(new HashMap<String, String>());
+    Collections.synchronizedMap(new HashMap<String, String>());
 
   /**
    * In Hive, when the user control-c's the command line, any running jobs
@@ -201,8 +205,7 @@
                 conn.setRequestMethod("POST");
                 int retCode = conn.getResponseCode();
                 if (retCode != 200) {
-                  System.err
-                      .println("Got an error trying to kill job with URI: "
+                  System.err.println("Got an error trying to kill job with URI: "
                       + uri + " = " + retCode);
                 }
               } catch (Exception e) {
@@ -312,14 +315,12 @@
     JobClient jc = th.getJobClient();
     RunningJob rj = th.getRunningJob();
     String lastReport = "";
-    SimpleDateFormat dateFormat = new SimpleDateFormat(
-        "yyyy-MM-dd HH:mm:ss,SSS");
+    SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss,SSS");
     long reportTime = System.currentTimeMillis();
     long maxReportInterval = 60 * 1000; // One minute
     boolean fatal = false;
     StringBuilder errMsg = new StringBuilder();
-    long pullInterval = HiveConf.getLongVar(job,
-                                        HiveConf.ConfVars.HIVECOUNTERSPULLINTERVAL);
+    long pullInterval = HiveConf.getLongVar(job, HiveConf.ConfVars.HIVECOUNTERSPULLINTERVAL);
     boolean initializing = true;
     while (!rj.isComplete()) {
       try {
@@ -375,8 +376,7 @@
 
         // write out serialized plan with counters to log file
         // LOG.info(queryPlan);
-        String output = dateFormat.format(Calendar.getInstance().getTime())
-            + report;
+        String output = dateFormat.format(Calendar.getInstance().getTime()) + report;
         SessionState ss = SessionState.get();
         if (ss != null) {
           ss.getHiveHistory().setTaskCounters(SessionState.get().getQueryId(),
@@ -506,7 +506,7 @@
 
     try {
       job.setPartitionerClass((Class<? extends Partitioner>)
-         (Class.forName(HiveConf.getVar(job, HiveConf.ConfVars.HIVEPARTITIONER))));
+          (Class.forName(HiveConf.getVar(job, HiveConf.ConfVars.HIVEPARTITIONER))));
     } catch (ClassNotFoundException e) {
       throw new RuntimeException(e.getMessage());
     }
@@ -527,11 +527,11 @@
 
     // Turn on speculative execution for reducers
     boolean useSpeculativeExecReducers =
-        HiveConf.getBoolVar(job, HiveConf.ConfVars.HIVESPECULATIVEEXECREDUCERS);
+      HiveConf.getBoolVar(job, HiveConf.ConfVars.HIVESPECULATIVEEXECREDUCERS);
     HiveConf.setBoolVar(
-      job,
-      HiveConf.ConfVars.HADOOPSPECULATIVEEXECREDUCERS,
-      useSpeculativeExecReducers);
+        job,
+        HiveConf.ConfVars.HADOOPSPECULATIVEEXECREDUCERS,
+        useSpeculativeExecReducers);
 
     String inpFormat = HiveConf.getVar(job, HiveConf.ConfVars.HIVEINPUTFORMAT);
     if ((inpFormat == null) || (!StringUtils.isNotBlank(inpFormat))) {
@@ -588,10 +588,10 @@
     }
 
     try {
+
       addInputPaths(job, work, emptyScratchDirStr);
 
       Utilities.setMapRedWork(job, work, ctx.getMRTmpFileURI());
-
       // remove the pwd from conf file so that job tracker doesn't show this
       // logs
       String pwd = HiveConf.getVar(job, HiveConf.ConfVars.METASTOREPWD);
@@ -603,13 +603,26 @@
       // make this client wait if job trcker is not behaving well.
       Throttle.checkJobTracker(job, LOG);
 
+      if (work.isGatheringStats()) {
+        // initialize stats publishing table
+        StatsPublisher statsPublisher;
+        String statsImplementationClass = HiveConf.getVar(job, HiveConf.ConfVars.HIVESTATSDBCLASS);
+        if (StatsFactory.setImplementation(statsImplementationClass, job)) {
+          statsPublisher = StatsFactory.getStatsPublisher();
+          statsPublisher.init(job); // creating stats table if not exists
+        }
+      }
+
+      // Finally SUBMIT the JOB!
       rj = jc.submitJob(job);
+
       // replace it back
       if (pwd != null) {
         HiveConf.setVar(job, HiveConf.ConfVars.METASTOREPWD, pwd);
       }
 
       // add to list of running jobs to kill in case of abnormal shutdown
+
       runningJobKillURIs.put(rj.getJobID(), rj.getTrackingURL()
           + "&action=kill");
 
@@ -622,7 +635,7 @@
         statusMesg += " with errors";
         returnVal = 2;
         console.printError(statusMesg);
-        if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.SHOW_JOB_FAIL_DEBUG_INFO)) {
+        if (HiveConf.getBoolVar(job, HiveConf.ConfVars.SHOW_JOB_FAIL_DEBUG_INFO)) {
           showJobFailDebugInfo(job, rj);
         }
       } else {
@@ -661,7 +674,6 @@
     }
 
     // get the list of Dynamic partition paths
-    ArrayList<String> dpPaths = new ArrayList<String>();
     try {
       if (rj != null) {
         JobCloseFeedBack feedBack = new JobCloseFeedBack();
@@ -669,14 +681,6 @@
           for (Operator<? extends Serializable> op : work.getAliasToWork()
               .values()) {
             op.jobClose(job, success, feedBack);
-            ArrayList<Object> dirs = feedBack.get(JobCloseFeedBack.FeedBackType.DYNAMIC_PARTITIONS);
-            if (dirs != null) {
-              for (Object o: dirs) {
-                if (o instanceof String) {
-                  dpPaths.add((String)o);
-                }
-              }
-            }
           }
         }
         if (work.getReducer() != null) {
@@ -689,7 +693,7 @@
         success = false;
         returnVal = 3;
         String mesg = "Job Commit failed with exception '"
-            + Utilities.getNameMessage(e) + "'";
+          + Utilities.getNameMessage(e) + "'";
         console.printError(mesg, "\n"
             + org.apache.hadoop.util.StringUtils.stringifyException(e));
       }
@@ -771,8 +775,7 @@
         String[] taskJobIds = ShimLoader.getHadoopShims().getTaskJobIDs(t);
 
         if (taskJobIds == null) {
-          console.printError("Task attempt info is unavailable in " +
-                             "this Hadoop version");
+          console.printError("Task attempt info is unavailable in this Hadoop version");
           more = false;
           break;
         }
@@ -875,8 +878,7 @@
   }
 
   private static void printUsage() {
-    System.err
-        .println("ExecDriver -plan <plan-file> [-jobconf k1=v1 [-jobconf k2=v2] ...] "
+    System.err.println("ExecDriver -plan <plan-file> [-jobconf k1=v1 [-jobconf k2=v2] ...] "
         + "[-files <file1>[,<file2>] ...]");
     System.exit(1);
   }
@@ -900,22 +902,21 @@
    */
 
   private static void setupChildLog4j(Configuration conf) {
-    URL hive_l4j = ExecDriver.class.getClassLoader().getResource
-      (SessionState.HIVE_EXEC_L4J);
+    URL hive_l4j = ExecDriver.class.getClassLoader().getResource(SessionState.HIVE_EXEC_L4J);
     if(hive_l4j == null) {
       hive_l4j = ExecDriver.class.getClassLoader().getResource
       (SessionState.HIVE_L4J);
     }
 
     if (hive_l4j != null) {
-        // setting queryid so that log4j configuration can use it to generate
-        // per query log file
-        System.setProperty
-          (HiveConf.ConfVars.HIVEQUERYID.toString(),
-           HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID));
-        LogManager.resetConfiguration();
-        PropertyConfigurator.configure(hive_l4j);
-      }
+      // setting queryid so that log4j configuration can use it to generate
+      // per query log file
+      System.setProperty
+      (HiveConf.ConfVars.HIVEQUERYID.toString(),
+          HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYID));
+      LogManager.resetConfiguration();
+      PropertyConfigurator.configure(hive_l4j);
+    }
   }
 
   public static void main(String[] args) throws IOException, HiveException {
@@ -950,8 +951,7 @@
       if (eqIndex != -1) {
         try {
           String key = one.substring(0, eqIndex);
-          String value = URLDecoder.decode(one.substring(eqIndex + 1),
-                                           "UTF-8");
+          String value = URLDecoder.decode(one.substring(eqIndex + 1), "UTF-8");
           conf.set(key, value);
           sb.append(key).append("=").append(value).append("\n");
         } catch (UnsupportedEncodingException e) {
@@ -1004,12 +1004,10 @@
       // see also - code in CliDriver.java
       ClassLoader loader = conf.getClassLoader();
       if (StringUtils.isNotBlank(auxJars)) {
-        loader = Utilities.addToClassPath(loader, StringUtils.split(auxJars,
-                                                                    ","));
+        loader = Utilities.addToClassPath(loader, StringUtils.split(auxJars, ","));
       }
       if (StringUtils.isNotBlank(addedJars)) {
-        loader = Utilities.addToClassPath(loader, StringUtils.split(
-                                                                    addedJars, ","));
+        loader = Utilities.addToClassPath(loader, StringUtils.split(addedJars, ","));
       }
       conf.setClassLoader(loader);
       // Also set this to the Thread ContextClassLoader, so new threads will
@@ -1040,8 +1038,7 @@
     try {
       StringBuilder sb = new StringBuilder();
       Properties deltaP = hconf.getChangedProperties();
-      boolean hadoopLocalMode = hconf.getVar(HiveConf.ConfVars.HADOOPJT).equals(
-          "local");
+      boolean hadoopLocalMode = hconf.getVar(HiveConf.ConfVars.HADOOPJT).equals("local");
       String hadoopSysDir = "mapred.system.dir";
       String hadoopWorkDir = "mapred.local.dir";
 
@@ -1138,7 +1135,7 @@
 
     // toggle the work
     LinkedHashMap<String, ArrayList<String>> pathToAliases = work
-        .getPathToAliases();
+    .getPathToAliases();
     if (isEmptyPath) {
       assert path != null;
       pathToAliases.put(newPath.toUri().toString(), pathToAliases.get(path));
@@ -1152,11 +1149,9 @@
 
     work.setPathToAliases(pathToAliases);
 
-    LinkedHashMap<String, PartitionDesc> pathToPartitionInfo = work
-        .getPathToPartitionInfo();
+    LinkedHashMap<String, PartitionDesc> pathToPartitionInfo = work.getPathToPartitionInfo();
     if (isEmptyPath) {
-      pathToPartitionInfo.put(newPath.toUri().toString(), pathToPartitionInfo
-          .get(path));
+      pathToPartitionInfo.put(newPath.toUri().toString(), pathToPartitionInfo.get(path));
       pathToPartitionInfo.remove(path);
     } else {
       PartitionDesc pDesc = work.getAliasToPartnInfo().get(alias).clone();
@@ -1266,7 +1261,7 @@
       for (List<String> ls: pa.values()) {
         for (String a: ls) {
           ArrayList<Operator<? extends Serializable>> opList = new
-            ArrayList<Operator<? extends Serializable>> ();
+          ArrayList<Operator<? extends Serializable>> ();
           opList.add(work.getAliasToWork().get(a));
 
           while (!opList.isEmpty()) {
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java	(working copy)
@@ -50,6 +50,7 @@
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
@@ -72,6 +73,7 @@
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.PathFilter;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
 import org.apache.hadoop.hive.metastore.api.Order;
 import org.apache.hadoop.hive.ql.Context;
@@ -89,8 +91,10 @@
 import org.apache.hadoop.hive.ql.plan.MapredWork;
 import org.apache.hadoop.hive.ql.plan.PartitionDesc;
 import org.apache.hadoop.hive.ql.plan.PlanUtils;
+import org.apache.hadoop.hive.ql.plan.PlanUtils.ExpressionTypes;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
-import org.apache.hadoop.hive.ql.plan.PlanUtils.ExpressionTypes;
+import org.apache.hadoop.hive.ql.stats.StatsFactory;
+import org.apache.hadoop.hive.ql.stats.StatsPublisher;
 import org.apache.hadoop.hive.serde.Constants;
 import org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe;
 import org.apache.hadoop.hive.shims.ShimLoader;
@@ -313,7 +317,7 @@
     }
   }
 
-  private static String getHiveJobID(Configuration job) {
+  public static String getHiveJobID(Configuration job) {
     String planPath= HiveConf.getVar(job, HiveConf.ConfVars.PLAN);
     if (planPath != null) {
       return (new Path(planPath)).getName();
@@ -354,7 +358,7 @@
       decoder.close();
     }
   }
-  
+
   /**
    * Serialize a single Task.
    */
@@ -1474,6 +1478,60 @@
     return ShimLoader.getHadoopShims().getCombineFileInputFormat() != null;
   }
 
+  /**
+   * Construct a list of full partition spec from Dynamic Partition Context and
+   * the directory names corresponding to these dynamic partitions.
+   */
+  public static List<LinkedHashMap<String, String>> getFullDPSpecs(Configuration conf,
+      DynamicPartitionCtx dpCtx)
+      throws HiveException {
+
+    try {
+      Path loadPath = new Path(dpCtx.getRootPath());
+      FileSystem fs = loadPath.getFileSystem(conf);
+    	int numDPCols = dpCtx.getNumDPCols();
+    	FileStatus[] status = Utilities.getFileStatusRecurse(loadPath, numDPCols, fs);
+
+    	if (status.length == 0) {
+    	  LOG.warn("No partition is genereated by dynamic partitioning");
+    	  return null;
+    	}
+
+    	// partial partition specification
+    	Map<String, String> partSpec = dpCtx.getPartSpec();
+
+    	// list of full partition specification
+    	List<LinkedHashMap<String, String>> fullPartSpecs =
+    	  new ArrayList<LinkedHashMap<String, String>>();
+
+    	// for each dynamically created DP directory, construct a full partition spec
+    	// and load the partition based on that
+    	for (int i= 0; i < status.length; ++i) {
+    	  // get the dynamically created directory
+    	  Path partPath = status[i].getPath();
+    	  assert fs.getFileStatus(partPath).isDir():
+    	    "partitions " + partPath + " is not a directory !";
+
+    	  // generate a full partition specification
+    	  LinkedHashMap<String, String> fullPartSpec = new LinkedHashMap<String, String>(partSpec);
+      	Warehouse.makeSpecFromName(fullPartSpec, partPath);
+      	fullPartSpecs.add(fullPartSpec);
+    	}
+    	return fullPartSpecs;
+    } catch (IOException e) {
+      throw new HiveException(e);
+    }
+  }
+
+  public static StatsPublisher getStatsPublisher(JobConf jc) {
+    String statsImplementationClass = HiveConf.getVar(jc, HiveConf.ConfVars.HIVESTATSDBCLASS);
+    if (StatsFactory.setImplementation(statsImplementationClass, jc)) {
+      return StatsFactory.getStatsPublisher();
+    } else {
+      return null;
+    }
+  }
+
   public static void setColumnNameList(JobConf jobConf, Operator op) {
     RowSchema rowSchema = op.getSchema();
     if (rowSchema == null) {
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/Stat.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/Stat.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/Stat.java	(revision 0)
@@ -0,0 +1,37 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.exec;
+
+public class Stat {
+
+  private long numRows;
+
+  public Stat () {
+    numRows = 0;
+  }
+
+  public void increaseNumRows(long amount) {
+    numRows += amount;
+  }
+
+  public long getNumRows() {
+    return numRows;
+  }
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java	(working copy)
@@ -25,6 +25,7 @@
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.LinkedHashMap;
+import java.util.List;
 import java.util.Map;
 
 import org.apache.hadoop.fs.FileStatus;
@@ -34,8 +35,8 @@
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.ql.Context;
 import org.apache.hadoop.hive.ql.DriverContext;
+import org.apache.hadoop.hive.ql.hooks.LineageInfo.DataContainer;
 import org.apache.hadoop.hive.ql.hooks.WriteEntity;
-import org.apache.hadoop.hive.ql.hooks.LineageInfo.DataContainer;
 import org.apache.hadoop.hive.ql.io.HiveFileFormatUtils;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.metadata.Partition;
@@ -180,7 +181,19 @@
           // deal with dynamic partitions
           DynamicPartitionCtx dpCtx = tbd.getDPCtx();
           if (dpCtx != null && dpCtx.getNumDPCols() > 0) { // dynamic partitions
+
+            List<LinkedHashMap<String, String>> dps = Utilities.getFullDPSpecs(conf, dpCtx);
+
+            // publish DP columns to its subscribers
+            pushFeed(FeedType.DYNAMIC_PARTITIONS, dps);
+
             // load the list of DP partitions and return the list of partition specs
+            // TODO: In a follow-up to HIVE-1361, we should refactor loadDynamicPartitions
+            // to use Utilities.getFullDPSpecs() to get the list of full partSpecs.
+            // After that check the number of DPs created to not exceed the limit and
+            // iterate over it and call loadPartition() here.
+            // The reason we don't do inside HIVE-1361 is the latter is large and we
+            // want to isolate any potential issue it may introduce.
             ArrayList<LinkedHashMap<String, String>> dp =
               db.loadDynamicPartitions(
                   new Path(tbd.getSourceDir()),
@@ -190,6 +203,8 @@
                 	new Path(tbd.getTmpDir()),
                 	dpCtx.getNumDPCols(),
                 	tbd.getHoldDDLTime());
+
+
             // for each partition spec, get the partition
             // and put it to WriteEntity for post-exec hook
             for (LinkedHashMap<String, String> partSpec: dp) {
Index: ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/plan/StatsWork.java	(revision 0)
@@ -0,0 +1,65 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.plan;
+
+import java.io.Serializable;
+
+import org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.tableSpec;
+
+/**
+ * ConditionalStats.
+ *
+ */
+@Explain(displayName = "Stats-Aggr Operator")
+public class StatsWork implements Serializable {
+  private static final long serialVersionUID = 1L;
+
+  private tableSpec tableSpecs;        // source table spec -- for TableScanOperator
+  private LoadTableDesc loadTableDesc; // same as MoveWork.loadTableDesc -- for FileSinkOperator
+  private String aggKey;               // aggregation key prefix
+
+  public StatsWork() {
+  }
+
+  public StatsWork(tableSpec tableSpecs) {
+    this.tableSpecs = tableSpecs;
+  }
+
+  public StatsWork(LoadTableDesc loadTableDesc) {
+    this.loadTableDesc = loadTableDesc;
+  }
+
+  public tableSpec getTableSpecs() {
+    return tableSpecs;
+  }
+
+  public LoadTableDesc getLoadTableDesc() {
+    return loadTableDesc;
+  }
+
+  public void setAggKey(String aggK) {
+    aggKey = aggK;
+  }
+
+  @Explain(displayName = "Stats Aggregation Key Prefix", normalExplain = false)
+  public String getAggKey() {
+    return aggKey;
+  }
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java	(working copy)
@@ -21,6 +21,8 @@
 import java.io.Serializable;
 import java.util.ArrayList;
 
+import org.apache.hadoop.fs.Path;
+
 /**
  * FileSinkDesc.
  *
@@ -29,6 +31,9 @@
 public class FileSinkDesc implements Serializable {
   private static final long serialVersionUID = 1L;
   private String dirName;
+  // normally statsKeyPref will be the same as dirName, but the latter
+  // could be changed in local execution optimization
+  private String statsKeyPref;
   private TableDesc tableInfo;
   private boolean compressed;
   private int destTableId;
@@ -39,6 +44,8 @@
   private ArrayList<ExprNodeDesc> partitionCols;
   private int     numFiles;
   private DynamicPartitionCtx dpCtx;
+  private String staticSpec; // static partition spec ends with a '/'
+  private boolean gatherStats;
 
   public FileSinkDesc() {
   }
@@ -190,4 +197,54 @@
   public DynamicPartitionCtx getDynPartCtx() {
     return this.dpCtx;
   }
+
+  public void setStaticSpec(String staticSpec) {
+    this.staticSpec = staticSpec;
+  }
+
+  @Explain(displayName = "Static Partition Specification", normalExplain = false)
+  public String getStaticSpec() {
+    return staticSpec;
+  }
+
+  public void setGatherStats(boolean gatherStats) {
+    this.gatherStats = gatherStats;
+  }
+
+  @Explain(displayName = "GatherStats", normalExplain = false)
+  public boolean isGatherStats() {
+    return gatherStats;
+  }
+
+  /**
+   * Construct the key prefix used as (intermediate) statistics publishing
+   * and aggregation. During stats publishing phase, this key prefix will be
+   * appended with the optional dynamic partition spec and the task ID. The
+   * whole key uniquely identifies the output of a task for this job. In the
+   * stats aggregation phase, all rows with the same prefix plus dynamic partition
+   * specs (obtained at run-time after MR job finishes) will be serving as the
+   * prefix: all rows with the same prefix (output of all tasks for this job)
+   * will be aggregated.
+   * @return key prefix used for stats publishing and aggregation.
+   */
+  @Explain(displayName = "Stats Publishing Key Prefix", normalExplain = false)
+  public String getStatsAggPrefix() {
+    // dirName uniquely identifies destination directory of a FileSinkOperator.
+    // If more than one FileSinkOperator write to the same partition, this dirName
+    // should be different.
+    return statsKeyPref;
+  }
+
+  /**
+   * Set the stats aggregation key. If the input string is not terminated by Path.SEPARATOR
+   * aggregation key will add one to make it as a directory name.
+   * @param k input directory name.
+   */
+  public void setStatsAggPrefix(String k) {
+    if (k.endsWith(Path.SEPARATOR)) {
+      statsKeyPref = k;
+    } else {
+      statsKeyPref = k + Path.SEPARATOR;
+    }
+  }
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/plan/MapredWork.java	(working copy)
@@ -65,6 +65,7 @@
 
   private MapredLocalWork mapLocalWork;
   private String inputformat;
+  private boolean gatheringStats;
 
   public MapredWork() {
     aliasToPartnInfo = new LinkedHashMap<String, PartitionDesc>();
@@ -321,4 +322,12 @@
   public void setInputformat(String inputformat) {
     this.inputformat = inputformat;
   }
+
+  public void setGatheringStats(boolean gatherStats) {
+    this.gatheringStats = gatherStats;
+  }
+
+  public boolean isGatheringStats() {
+    return this.gatheringStats;
+  }
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/plan/TableScanDesc.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/plan/TableScanDesc.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/plan/TableScanDesc.java	(working copy)
@@ -33,9 +33,22 @@
   private static final long serialVersionUID = 1L;
 
   private String alias;
-  
+
   private List<VirtualColumn> virtualCols;
+  private String statsAggKeyPrefix;   // stats publishing/aggregating key prefix
 
+ /**
+  * A list of the partition columns of the table.
+  * Set by the semantic analyzer only in case of the analyze command.
+  */
+  private List<String> partColumns;
+
+  /**
+   * A boolean variable set to true by the semantic analyzer only in case of the analyze command.
+   *
+   */
+  private boolean gatherStats;
+
   private ExprNodeDesc filterExpr;
 
   public static final String FILTER_EXPR_CONF_STR =
@@ -51,7 +64,7 @@
   public TableScanDesc(final String alias) {
     this.alias = alias;
   }
-  
+
   public TableScanDesc(final String alias, List<VirtualColumn> vcs) {
     this.alias = alias;
     this.virtualCols = vcs;
@@ -75,6 +88,23 @@
     this.alias = alias;
   }
 
+  public void setPartColumns (List<String> partColumns) {
+    this.partColumns = partColumns;
+  }
+
+  public List<String> getPartColumns () {
+    return partColumns;
+  }
+
+  public void setGatherStats(boolean gatherStats) {
+    this.gatherStats = gatherStats;
+  }
+
+  @Explain(displayName = "GatherStats", normalExplain = false)
+  public boolean isGatherStats() {
+    return gatherStats;
+  }
+
   public List<VirtualColumn> getVirtualCols() {
     return virtualCols;
   }
@@ -83,4 +113,12 @@
     this.virtualCols = virtualCols;
   }
 
+  public void setStatsAggPrefix(String k) {
+    statsAggKeyPrefix = k;
+  }
+
+  @Explain(displayName = "Statistics Aggregation Key Prefix", normalExplain = false)
+  public String getStatsAggPrefix() {
+    return statsAggKeyPrefix;
+  }
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/StatsAggregator.java	(revision 0)
@@ -0,0 +1,72 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.stats;
+
+import org.apache.hadoop.conf.Configuration;
+
+/**
+ * An interface for any possible implementation for gathering statistics.
+ */
+
+public interface StatsAggregator {
+
+  /**
+   * This method connects to the temporary storage.
+   * @param hconf HiveConf that contains the connection parameters.
+   * @return true if connection is successful, false otherwise.
+   */
+  public boolean connect(Configuration hconf);
+
+  /**
+   * This method aggregates a given statistic from all tasks (partial stats).
+   * After aggregation, this method also automatically removes all records
+   * that have been aggregated.
+   *
+   * @param keyPrefix a prefix of the keys used in StatsPublisher to publish stats.
+   * Any rows that starts with the same prefix will be aggregated. For example, if
+   * the StatsPublisher uses the following compound key to publish stats:
+   *
+   *     the output directory name (unique per FileSinkOperator) +
+   *     the partition specs (only for dynamic partitions) +
+   *     taskID (last component of task file)
+   *
+   * The keyPrefix for aggregation could be first 2 components. This will aggregates stats
+   * across all tasks for each partition.
+   *
+   * @param statType a string noting the key to be published. Ex: "numRows".
+   * @return a string representation of a long value, null if there are any error/exception.
+   */
+  public String aggregateStats(String keyPrefix, String statType);
+
+  /**
+   * This method closes the connection to the temporary storage.
+   * @return true if close connection is successful, false otherwise.
+   */
+  public boolean closeConnection();
+
+  /**
+   * This method clears the temporary statistics that have been published without being aggregated.
+   * Typically this happens when a job fails, or is forcibly stopped after publishing some statistics.
+   *
+   * @param keyPrefix a prefix of the keys used in StatsPublisher to publish stats. It is the same
+   * as the first parameter in aggregateStats().
+   * @return true if cleanup is successful, false otherwise.
+   */
+  public boolean cleanUp(String keyPrefix);
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsSetupConstants.java	(revision 0)
@@ -0,0 +1,11 @@
+package org.apache.hadoop.hive.ql.stats.jdbc;
+
+public final class JDBCStatsSetupConstants {
+
+    public static final String PART_STAT_TABLE_NAME = "PARTITION_STAT_TBL";
+
+    public static final String PART_STAT_ID_COLUMN_NAME = "ID";
+
+    public static final String PART_STAT_ROW_COUNT_COLUMN_NAME = "ROW_COUNT";
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsPublisher.java	(revision 0)
@@ -0,0 +1,196 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.stats.jdbc;
+
+import java.sql.Connection;
+import java.sql.DatabaseMetaData;
+import java.sql.DriverManager;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.stats.StatsPublisher;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
+
+public class JDBCStatsPublisher implements StatsPublisher {
+
+  private Connection conn;
+  private String connectionString;
+  private Configuration hiveconf;
+  private final Log LOG = LogFactory.getLog(this.getClass().getName());
+  private PreparedStatement selStmt, updStmt, insStmt;
+
+  public JDBCStatsPublisher() {
+    selStmt = updStmt = insStmt = null;
+  }
+
+  public boolean connect(Configuration hiveconf) {
+    try {
+      this.hiveconf = hiveconf;
+      connectionString = HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSDBCONNECTIONSTRING);
+      String driver = HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSJDBCDRIVER);
+      Class.forName(driver).newInstance();
+      DriverManager.setLoginTimeout(3); // stats should not block
+      conn = DriverManager.getConnection(connectionString);
+
+      // prepare the SELECT/UPDATE/INSERT statements
+      String select =
+        "SELECT " + JDBCStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME +
+        " FROM " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " WHERE " + JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " = ?";
+
+      String update =
+        "UPDATE " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " SET " +  JDBCStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME + "= ? " +
+        " WHERE " + JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " = ?";
+
+      String insert =
+        "INSERT INTO " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " VALUES (?, ?)";
+
+      selStmt = conn.prepareStatement(select);
+      updStmt = conn.prepareStatement(update);
+      insStmt = conn.prepareStatement(insert);
+
+      // make the statements non-blocking
+      selStmt.setQueryTimeout(5);
+      updStmt.setQueryTimeout(5);
+      insStmt.setQueryTimeout(5);
+
+      return true;
+    } catch (Exception e) {
+      LOG.error("Error during JDBC connection to " + connectionString + ". ", e);
+      return false;
+    }
+  }
+
+  public boolean publishStat(String fileID, String statType, String value) {
+
+    if (conn == null) {
+      LOG.error("JDBC connection is null. Cannot publish stats without JDBC connection.");
+      return false;
+    }
+
+    if (statType != StatsSetupConst.ROW_COUNT) {
+      LOG.warn("Warning. Invalid statistic. Currently " +
+          "row count is the only supported statistic");
+      return false;
+    }
+    LOG.info("Stats publishing for key " + fileID + ". Value = " + value);
+
+    try {
+
+      // Check to see if a previous task (mapper attempt) had published a previous stat
+      selStmt.setString(1, fileID);
+      ResultSet result = selStmt.executeQuery();
+
+      if (result.next()) {
+        long currval = result.getLong(1);
+        // Only update if the previous value is smaller (i.e. the previous attempt was a fail and
+        // hopefully this attempt is a success (as it has a greater value).
+        if (currval < Long.parseLong(value)) {
+          updStmt.setString(1, value);
+          updStmt.setString(2, fileID);
+          updStmt.executeUpdate();
+        }
+      } else {
+        // No previous attempts.
+        insStmt.setString(1, fileID);
+        insStmt.setString(2, value);
+        insStmt.executeUpdate();
+      }
+      return true;
+    } catch (SQLException e) {
+      LOG.error("Error during publishing statistics. ", e);
+      return false;
+    }
+  }
+
+  public boolean closeConnection() {
+    if (conn == null) {
+      return true;
+    }
+    try {
+      if (insStmt != null) {
+        insStmt.close();
+      }
+      if (updStmt != null) {
+        updStmt.close();
+      }
+      if (selStmt != null) {
+        selStmt.close();
+      }
+
+      conn.close();
+
+      // In case of derby, explicitly shutdown the database otherwise it reports error when
+      // trying to connect to the same JDBC connection string again.
+      if(HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSDBCLASS).equalsIgnoreCase("jdbc:derby")) {
+        try {
+          // The following closes the derby connection. It throws an exception that has to be caught and ignored.
+          DriverManager.getConnection(connectionString + ";shutdown=true");
+        }
+        catch (Exception e) {
+          // Do nothing because we know that an exception is thrown anyway.
+        }
+      }
+      return true;
+    } catch (SQLException e) {
+      LOG.error("Error during JDBC termination. ", e);
+      return false;
+    }
+  }
+
+  public boolean init(Configuration hconf) {
+    try {
+      this.hiveconf = hconf;
+      connectionString = HiveConf.getVar(hconf, HiveConf.ConfVars.HIVESTATSDBCONNECTIONSTRING);
+      String driver = HiveConf.getVar(hconf, HiveConf.ConfVars.HIVESTATSJDBCDRIVER);
+      Class.forName(driver).newInstance();
+      conn = DriverManager.getConnection(connectionString);
+
+      Statement stmt = conn.createStatement();
+
+      // Check if the table exists
+      DatabaseMetaData dbm = conn.getMetaData();
+      ResultSet rs = dbm.getTables(null, null, JDBCStatsSetupConstants.PART_STAT_TABLE_NAME, null);
+      boolean tblExists = rs.next();
+      if (!tblExists) { // Table does not exist, create it
+        String createTable =
+          "CREATE TABLE " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME + " (" +
+          JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " VARCHAR(255), " +
+          JDBCStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME + " BIGINT)";
+
+        stmt.executeUpdate(createTable);
+        stmt.close();
+      }
+
+      closeConnection();
+    } catch (Exception e) {
+      LOG.error("Error during JDBC initialization. ", e);
+      return false;
+    }
+    return true;
+  }
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/jdbc/JDBCStatsAggregator.java	(revision 0)
@@ -0,0 +1,147 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.stats.jdbc;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.ql.stats.StatsAggregator;
+import org.apache.hadoop.hive.ql.stats.StatsSetupConst;
+
+public class JDBCStatsAggregator implements StatsAggregator {
+
+  private Connection conn;
+  private String connectionString;
+  private Configuration hiveconf;
+  private final Log LOG = LogFactory.getLog(this.getClass().getName());
+
+  public boolean connect(Configuration hiveconf) {
+    try {
+      this.hiveconf = hiveconf;
+      connectionString = HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSDBCONNECTIONSTRING);
+      String driver = HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSJDBCDRIVER);
+      Class.forName(driver).newInstance();
+      DriverManager.setLoginTimeout(3); // stats should not block
+      conn = DriverManager.getConnection(connectionString);
+      return true;
+    } catch (Exception e) {
+      LOG.error("Error during JDBC connection. " + e);
+      return false;
+    }
+  }
+
+  @Override
+  public String aggregateStats(String fileID, String statType) {
+
+    LOG.info("Stats Aggregator for key " + fileID);
+
+    if (statType != StatsSetupConst.ROW_COUNT) {
+      LOG.warn("Warning. Invalid statistic. Currently " +
+      "row count is the only supported statistic");
+      return null;
+    }
+
+    try {
+      long retval = 0;
+      Statement stmt = conn.createStatement();
+      String select =
+        "SELECT SUM" + "(" + JDBCStatsSetupConstants.PART_STAT_ROW_COUNT_COLUMN_NAME + ")" +
+        " FROM " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " WHERE " + JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " LIKE '" + fileID + "%'";
+
+      ResultSet result = stmt.executeQuery(select);
+      if (result.next()) {
+        retval = result.getLong(1);
+      } else {
+        LOG.warn("Warning. Nothing published. Nothing aggregated.");
+        return "";
+      }
+      stmt.clearBatch();
+
+      /* Automatic Cleaning:
+          IMPORTANT: Since we publish and aggregate only 1 value (1 column) which is the row count, it
+          is valid to delete the row after aggregation (automatic cleaning) because we know that there is no
+          other values to aggregate.
+          If ;in the future; other values are aggregated and published, then we cannot do cleaning except
+          when we are sure that all values are aggregated, or we can separate the implementation of cleaning
+          through a separate method which the developer has to call it manually in the code.
+       */
+      String delete =
+        "DELETE FROM " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " WHERE " + JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " LIKE '" + fileID + "%'";
+      stmt.executeUpdate(delete);
+      stmt.close();
+
+      LOG.info("Stats aggregator got " + retval);
+
+      return Long.toString(retval);
+    } catch (SQLException e) {
+      LOG.error("Error during publishing aggregation. " + e);
+      return null;
+    }
+  }
+
+  public boolean closeConnection() {
+
+    if (conn == null) {
+      return true;
+    }
+
+    try {
+      conn.close();
+      // In case of derby, explicitly close the database connection
+      if(HiveConf.getVar(hiveconf, HiveConf.ConfVars.HIVESTATSDBCLASS).equalsIgnoreCase("jdbc:derby")) {
+        try {
+          // The following closes the derby connection. It throws an exception that has to be caught and ignored.
+          DriverManager.getConnection(connectionString + ";shutdown=true");
+        }
+        catch (Exception e) {
+          // Do nothing because we know that an exception is thrown anyway.
+        }
+      }
+      return true;
+    } catch (SQLException e) {
+      LOG.error("Error during JDBC termination. " + e);
+      return false;
+    }
+  }
+
+  public boolean cleanUp(String rowID) {
+    try {
+      Statement stmt = conn.createStatement();
+
+      String delete =
+        "DELETE FROM " + JDBCStatsSetupConstants.PART_STAT_TABLE_NAME +
+        " WHERE " + JDBCStatsSetupConstants.PART_STAT_ID_COLUMN_NAME + " LIKE '" + rowID + "%'";
+      stmt.executeUpdate(delete);
+      stmt.close();
+      return closeConnection();
+    } catch (SQLException e) {
+      LOG.error("Error during publishing aggregation. " + e);
+      return false;
+    }
+  }
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/StatsFactory.java	(revision 0)
@@ -0,0 +1,101 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.stats;
+
+import java.io.Serializable;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.common.JavaUtils;
+import org.apache.hadoop.util.ReflectionUtils;
+
+/**
+ * A factory of stats publisher and aggregator implementations of the
+ * StatsPublisher and StatsAggregator interfaces.
+ */
+public final class StatsFactory {
+
+  static final private Log LOG = LogFactory.getLog(StatsFactory.class.getName());
+
+  private static Class <? extends Serializable> publisherImplementation;
+  private static Class <? extends Serializable> aggregatorImplementation;
+  private static Configuration jobConf;
+
+  /**
+   * Sets the paths of the implementation classes of publishing
+   * and aggregation (IStatsPublisher and IStatsAggregator interfaces).
+   * The paths are determined according to a configuration parameter which
+   * is passed as the user input for choosing the implementation as MySQL, HBase, ...
+   */
+  public static boolean setImplementation(String configurationParam, Configuration conf) {
+
+    ClassLoader classLoader = JavaUtils.getClassLoader();
+    if (configurationParam.equals(StatsSetupConst.HBASE_IMPL_CLASS_VAL)) {
+      // Case: hbase
+      try {
+        publisherImplementation = (Class<? extends Serializable>)
+          Class.forName("org.apache.hadoop.hive.hbase.HBaseStatsPublisher", true, classLoader);
+
+        aggregatorImplementation = (Class<? extends Serializable>)
+          Class.forName("org.apache.hadoop.hive.hbase.HBaseStatsAggregator", true, classLoader);
+      } catch (ClassNotFoundException e) {
+        LOG.error("HBase Publisher/Aggregator classes cannot be loaded.", e);
+        return false;
+      }
+    } else if (configurationParam.contains(StatsSetupConst.JDBC_IMPL_CLASS_VAL)) {
+      // Case: jdbc:mysql or jdbc:derby
+      try {
+        publisherImplementation = (Class<? extends Serializable>)
+          Class.forName("org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher", true, classLoader);
+
+        aggregatorImplementation = (Class<? extends Serializable>)
+          Class.forName("org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator", true, classLoader);
+      } catch (ClassNotFoundException e) {
+        LOG.error("JDBC Publisher/Aggregator classes cannot be loaded.", e);
+        return false;
+      }
+    } else {
+      // ERROR
+      return false;
+    }
+
+    jobConf = conf;
+    return true;
+  }
+
+  /**
+   * Returns a Stats publisher implementation class for the IStatsPublisher interface
+   * For example HBaseStatsPublisher for the HBase implementation
+   */
+  public static StatsPublisher getStatsPublisher() {
+
+    return (StatsPublisher) ReflectionUtils.newInstance(publisherImplementation, jobConf);
+  }
+
+  /**
+   * Returns a Stats Aggregator implementation class for the IStatsAggregator interface
+   * For example HBaseStatsAggregator for the HBase implementation
+   */
+  public static StatsAggregator getStatsAggregator() {
+
+    return (StatsAggregator) ReflectionUtils.newInstance(aggregatorImplementation, jobConf);
+  }
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/StatsSetupConst.java	(revision 0)
@@ -0,0 +1,39 @@
+package org.apache.hadoop.hive.ql.stats;
+
+/**
+ * A class that defines the constant strings used by the statistics implementation.
+ */
+
+public class StatsSetupConst {
+
+  /**
+   * The value of the user variable "hive.stats.dbclass" to use HBase implementation.
+   */
+  public static final String HBASE_IMPL_CLASS_VAL = "hbase";
+
+  /**
+   * The value of the user variable "hive.stats.dbclass" to use JDBC implementation.
+   */
+  public static final String JDBC_IMPL_CLASS_VAL = "jdbc";
+
+  /**
+   * The name of the statistic Row Count to be published or gathered.
+   */
+  public static final String ROW_COUNT = "numRows";
+
+  /**
+   * The name of the statistic Row Count to be published or gathered.
+   */
+  public static final String NUM_FILES = "numFiles";
+
+  /**
+   * The name of the statistic Row Count to be published or gathered.
+   */
+  public static final String NUM_PARTITIONS = "numPartitions";
+
+  /**
+   * The name of the statistic Row Count to be published or gathered.
+   */
+  public static final String TOTAL_SIZE = "totalSize";
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/stats/StatsPublisher.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/stats/StatsPublisher.java	(revision 0)
+++ ql/src/java/org/apache/hadoop/hive/ql/stats/StatsPublisher.java	(revision 0)
@@ -0,0 +1,67 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.stats;
+
+import org.apache.hadoop.conf.Configuration;
+
+/**
+ * An interface for any possible implementation for publishing statics.
+ */
+
+public interface StatsPublisher {
+
+  /**
+   * This method does the necessary one-time initializations, possibly creating the tables and
+   * database (if not exist).
+   * This method is usually called in the Hive client side rather than by the mappers/reducers
+   * so that it is initialized only once.
+   * @param hconf HiveConf that contains the configurations parameters used to connect to
+   * intermediate stats database.
+   * @return true if initialization is successful, false otherwise.
+   */
+  public boolean init(Configuration hconf);
+
+  /**
+   * This method connects to the intermediate statistics database.
+   * @param hconf HiveConf that contains the connection parameters.
+   * @return true if connection is successful, false otherwise.
+   */
+  public boolean connect(Configuration hconf);
+
+  /**
+   * This method publishes a given statistic into a disk storage, possibly HBase or MySQL.
+   *
+   * fileID   : a string identification the statistics to be published by all mappers/reducers
+   *            and then gathered. The statID is unique per output partition per task, e.g.,:
+   *                 the output directory name (uniq per FileSinkOperator) +
+   *                 the partition specs (only for dynamic partitions) +
+   *                 taskID (last component of task file)
+   *
+   * statType : a string noting the key to be published. Ex: "numRows".
+   *
+   * value    : an integer noting the value of the published key.
+   */
+  public boolean publishStat(String fileID, String statType, String value);
+
+  /**
+   * This method closes the connection to the temporary storage.
+   */
+  public boolean closeConnection();
+
+}
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/QBParseInfo.java	(working copy)
@@ -28,10 +28,11 @@
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.tableSpec;
 
 /**
  * Implementation of the parse information related to a query block.
- * 
+ *
  **/
 
 public class QBParseInfo {
@@ -46,6 +47,12 @@
   private final Map<String, ASTNode> destToSelExpr;
   private final HashMap<String, ASTNode> destToWhereExpr;
   private final HashMap<String, ASTNode> destToGroupby;
+
+  private boolean isAnalyzeCommand; // used for the analyze command (statistics)
+  private boolean isInsertToTable;  // used for insert overwrite command (statistics)
+
+  private final HashMap<String, tableSpec> tableSpecs; // used for statistics
+
   /**
    * ClusterBy is a short name for both DistributeBy and SortBy.
    */
@@ -100,6 +107,8 @@
     outerQueryLimit = -1;
 
     aliasToLateralViews = new HashMap<String, ArrayList<ASTNode>>();
+
+    tableSpecs = new HashMap<String, BaseSemanticAnalyzer.tableSpec>();
   }
 
   public void setAggregationExprsForClause(String clause,
@@ -137,7 +146,7 @@
 
   /**
    * Set the Cluster By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @param ast
@@ -149,7 +158,7 @@
 
   /**
    * Set the Distribute By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @param ast
@@ -161,7 +170,7 @@
 
   /**
    * Set the Sort By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @param ast
@@ -213,7 +222,7 @@
 
   /**
    * Get the Cluster By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @return the abstract syntax tree
@@ -228,7 +237,7 @@
 
   /**
    * Get the Distribute By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @return the abstract syntax tree
@@ -243,7 +252,7 @@
 
   /**
    * Get the Sort By AST for the clause.
-   * 
+   *
    * @param clause
    *          the name of the clause
    * @return the abstract syntax tree
@@ -397,4 +406,38 @@
     }
     lateralViews.add(lateralView);
   }
+
+  public void setIsAnalyzeCommand(boolean isAnalyzeCommand) {
+    this.isAnalyzeCommand = isAnalyzeCommand;
+  }
+
+  public boolean isAnalyzeCommand() {
+    return isAnalyzeCommand;
+  }
+
+  public void setIsInsertToTable(boolean isInsertToTable) {
+    this.isInsertToTable = isInsertToTable;
+  }
+
+  public boolean isInsertToTable() {
+    return isInsertToTable;
+  }
+
+  public void addTableSpec(String tName, tableSpec tSpec) {
+    tableSpecs.put(tName, tSpec);
+  }
+
+  public tableSpec getTableSpec(String tName) {
+    return tableSpecs.get(tName);
+  }
+
+  /**
+   * This method is used only for the anlayze command to get the partition specs
+   */
+  public tableSpec getTableSpec() {
+
+    Iterator<String> tName = tableSpecs.keySet().iterator();
+    return tableSpecs.get(tName.next());
+  }
+
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/ErrorMsg.java	(working copy)
@@ -167,6 +167,7 @@
   OFFLINE_TABLE_OR_PARTITION("Query against an offline table or partition"),
   OUTERJOIN_USES_FILTERS("The query results could be wrong. " +
   		"Turn on hive.outerjoin.supports.filters"),
+  NEED_PARTITION_SPECIFICATION("Table is partitioned and partition specification is needed"),
       ;
 
   private String mesg;
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g	(working copy)
@@ -182,6 +182,7 @@
 TOK_LEFTSEMIJOIN;
 TOK_LATERAL_VIEW;
 TOK_TABALIAS;
+TOK_ANALYZE;
 }
 
 
@@ -249,6 +250,7 @@
     | dropIndexStatement
     | alterIndexRebuild
     | dropFunctionStatement
+    | analyzeStatement
     | lockStatement
     | unlockStatement
     ;
@@ -621,6 +623,12 @@
     : (KW_DESCRIBE|KW_DESC) (isExtended=KW_EXTENDED)? (parttype=partTypeExpr) -> ^(TOK_DESCTABLE $parttype $isExtended?)
     | (KW_DESCRIBE|KW_DESC) KW_FUNCTION KW_EXTENDED? (name=descFuncNames) -> ^(TOK_DESCFUNCTION $name KW_EXTENDED?)
     ;
+    
+analyzeStatement
+@init { msgs.push("analyze statement"); }
+@after { msgs.pop(); }
+    : KW_ANALYZE KW_TABLE (parttype=partTypeExpr) KW_COMPUTE KW_STATISTICS -> ^(TOK_ANALYZE $parttype)
+    ;
 
 showStatement
 @init { msgs.push("show statement"); }
@@ -1871,6 +1879,8 @@
 KW_TOUCH: 'TOUCH';
 KW_ARCHIVE: 'ARCHIVE';
 KW_UNARCHIVE: 'UNARCHIVE';
+KW_COMPUTE: 'COMPUTE';
+KW_STATISTICS: 'STATISTICS';
 KW_USE: 'USE';
 
 // Operators
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java	(working copy)
@@ -27,7 +27,7 @@
 
 /**
  * Implementation of the query block.
- * 
+ *
  **/
 
 public class QB {
@@ -170,7 +170,7 @@
   }
 
   public boolean isSelectStarQuery() {
-    return qbp.isSelectStarQuery() && aliasToSubq.isEmpty() && !isCTAS();
+    return qbp.isSelectStarQuery() && aliasToSubq.isEmpty() && !isCTAS() && !qbp.isAnalyzeCommand();
   }
 
   public CreateTableDesc getTableDesc() {
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java	(working copy)
@@ -52,8 +52,6 @@
 import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;
 import org.apache.hadoop.hive.serde.Constants;
 import org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;
-import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;
 import org.apache.hadoop.mapred.SequenceFileInputFormat;
 import org.apache.hadoop.mapred.SequenceFileOutputFormat;
 import org.apache.hadoop.mapred.TextInputFormat;
@@ -102,14 +100,14 @@
   protected static final String RCFILE_OUTPUT = RCFileOutputFormat.class
       .getName();
   protected static final String COLUMNAR_SERDE = ColumnarSerDe.class.getName();
-  
+
   class RowFormatParams {
     String fieldDelim = null;
     String fieldEscape = null;
     String collItemDelim = null;
     String mapKeyDelim = null;
     String lineDelim = null;
-    
+
     protected void analyzeRowFormat(AnalyzeCreateCommonVars shared, ASTNode child) throws SemanticException {
       child = (ASTNode) child.getChild(0);
       int numChildRowFormat = child.getChildCount();
@@ -147,17 +145,17 @@
       }
     }
   }
-  
+
   class AnalyzeCreateCommonVars {
     String serde = null;
-    Map<String, String> serdeProps = new HashMap<String, String>();      
+    Map<String, String> serdeProps = new HashMap<String, String>();
   }
 
   class StorageFormat {
     String inputFormat = null;
     String outputFormat = null;
     String storageHandler = null;
-    
+
     protected boolean fillStorageFormat(ASTNode child, AnalyzeCreateCommonVars shared) {
       boolean storageFormat = false;
       switch(child.getToken().getType()) {
@@ -194,7 +192,7 @@
       }
       return storageFormat;
     }
-    
+
     protected void fillDefaultStorageFormat(AnalyzeCreateCommonVars shared) {
       if ((inputFormat == null) && (storageHandler == null)) {
         if ("SequenceFile".equalsIgnoreCase(conf.getVar(HiveConf.ConfVars.HIVEDEFAULTFILEFORMAT))) {
@@ -449,7 +447,7 @@
   protected List<FieldSchema> getColumns(ASTNode ast) throws SemanticException {
     return getColumns(ast, true);
   }
-  
+
   /**
    * Get the list of FieldSchema out of the ASTNode.
    */
@@ -553,11 +551,12 @@
     public Map<String, String> partSpec; // has to use LinkedHashMap to enforce order
     public Partition partHandle;
     public int numDynParts; // number of dynamic partition columns
+    private List<Partition> partitions; // involved partitions in TableScanOperator/FileSinkOperator
 
     public tableSpec(Hive db, HiveConf conf, ASTNode ast)
         throws SemanticException {
 
-      assert (ast.getToken().getType() == HiveParser.TOK_TAB);
+      assert (ast.getToken().getType() == HiveParser.TOK_TAB || ast.getToken().getType() == HiveParser.TOK_TABTYPE);
       int childIndex = 0;
       numDynParts = 0;
 
@@ -661,7 +660,7 @@
   public void setLineageInfo(LineageInfo linfo) {
     this.linfo = linfo;
   }
-  
+
   protected HashMap<String, String> extractPartitionSpecs(Tree partspec)
       throws SemanticException {
     HashMap<String, String> partSpec = new LinkedHashMap<String, String>();
@@ -672,5 +671,5 @@
     }
     return partSpec;
   }
-  
+
 }
Index: ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
===================================================================
--- ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java	(revision 1000592)
+++ ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java	(working copy)
@@ -43,7 +43,9 @@
 import org.apache.hadoop.hive.common.JavaUtils;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.conf.HiveConf.ConfVars;
+import org.apache.hadoop.hive.metastore.Warehouse;
 import org.apache.hadoop.hive.metastore.api.FieldSchema;
+import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.metastore.api.Order;
 import org.apache.hadoop.hive.ql.Context;
 import org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator;
@@ -691,6 +693,16 @@
         qbp.setDestLimit(ctx_1.dest, new Integer(ast.getChild(0).getText()));
         break;
 
+      case HiveParser.TOK_ANALYZE:
+        // Case of analyze command
+        String table_name = unescapeIdentifier(ast.getChild(0).getChild(0).getText());
+        qb.setTabAlias(table_name, table_name);
+        qb.getParseInfo().setIsAnalyzeCommand(true);
+        // Allow analyze the whole table and dynamic partitions
+        HiveConf.setVar(conf, HiveConf.ConfVars.DYNAMICPARTITIONINGMODE, "nonstrict");
+        HiveConf.setVar(conf, HiveConf.ConfVars.HIVEMAPREDMODE, "nonstrict");
+        break;
+
       case HiveParser.TOK_UNION:
         // currently, we dont support subq1 union subq2 - the user has to
         // explicitly say:
@@ -768,6 +780,11 @@
         }
 
         qb.getMetaData().setSrcForAlias(alias, tab);
+
+        if (qb.getParseInfo().isAnalyzeCommand()) {
+          tableSpec ts = new tableSpec(db, conf, (ASTNode) ast.getChild(0));
+          qb.getParseInfo().addTableSpec(alias, ts);
+        }
       }
 
       LOG.info("Get metadata for subqueries");
@@ -811,6 +828,12 @@
             // This is a partition
             qb.getMetaData().setDestForAlias(name, ts.partHandle);
           }
+          if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
+            // Set that variable to automatically collect stats during the MapReduce job
+            qb.getParseInfo().setIsInsertToTable(true);
+            // Add the table spec for the destination table.
+            qb.getParseInfo().addTableSpec(ts.tableName.toLowerCase(), ts);
+          }
           break;
         }
 
@@ -3295,6 +3318,7 @@
     Integer dest_type = qbm.getDestTypeForAlias(dest);
 
     Table dest_tab = null;     // destination table if any
+    Partition dest_part = null;// destination partition if any
     String queryTmpdir = null; // the intermediate destination directory
     Path dest_path = null; // the final destination directory
     TableDesc table_desc = null;
@@ -3402,8 +3426,7 @@
     }
     case QBMetaData.DEST_PARTITION: {
 
-      Partition dest_part = qbm.getDestPartitionForAlias(dest);
-
+      dest_part = qbm.getDestPartitionForAlias(dest);
       dest_tab = dest_part.getTable();
 
       dest_path = dest_part.getPath()[0];
@@ -3582,21 +3605,37 @@
 
     RowSchema fsRS = new RowSchema(vecCol);
 
-    Operator output = putOpInsertMap(
-        OperatorFactory.getAndMakeChild(
-            new FileSinkDesc(
-                queryTmpdir,
-                table_desc,
-                conf.getBoolVar(HiveConf.ConfVars.COMPRESSRESULT),
-                currentTableId,
-                rsCtx.isMultiFileSpray(),
-                rsCtx.getNumFiles(),
-                rsCtx.getTotalFiles(),
-                rsCtx.getPartnCols(),
-                dpCtx),
+    FileSinkDesc fileSinkDesc = new FileSinkDesc(
+      queryTmpdir,
+      table_desc,
+      conf.getBoolVar(HiveConf.ConfVars.COMPRESSRESULT),
+      currentTableId,
+      rsCtx.isMultiFileSpray(),
+      rsCtx.getNumFiles(),
+      rsCtx.getTotalFiles(),
+      rsCtx.getPartnCols(),
+      dpCtx);
+
+    // set the stats publishing/aggregating key prefix
+    // the same as directory name. The directory name
+    // can be changed in the optimizer  but the key should not be changed
+    // it should be the same as the MoveWork's sourceDir.
+    fileSinkDesc.setStatsAggPrefix(fileSinkDesc.getDirName());
+
+    if (dest_part != null) {
+      try {
+        String staticSpec = Warehouse.makePartName(dest_part.getSpec());
+        fileSinkDesc.setStaticSpec(staticSpec);
+      } catch (MetaException e) {
+        throw new SemanticException(e);
+      }
+    } else if (dpCtx != null) {
+      fileSinkDesc.setStaticSpec(dpCtx.getSPPath());
+    }
+
+    Operator output = putOpInsertMap(OperatorFactory.getAndMakeChild(fileSinkDesc,
             fsRS, input), inputRR);
 
-
     if (ltd != null && SessionState.get() != null) {
       SessionState.get().getLineageState()
         .mapDirToFop(ltd.getSourceDir(), (FileSinkOperator)output);
@@ -5159,7 +5198,7 @@
     // currently. It doesnt matter whether he has asked to do
     // map-side aggregation or not. Map side aggregation is turned off
     boolean optimizeMultiGroupBy = (getCommonDistinctExprs(qb, input) != null);
-    Operator curr = null;
+    Operator curr = input;
 
     // If there are multiple group-bys, map-side aggregation is turned off,
     // there are no filters
@@ -5531,7 +5570,10 @@
       }
 
       // Create the root of the operator tree
-      top = putOpInsertMap(OperatorFactory.get(new TableScanDesc(alias, vcList),
+      TableScanDesc tsDesc = new TableScanDesc(alias, vcList);
+      setupStats(tsDesc, qb.getParseInfo(), tab, alias);
+
+      top = putOpInsertMap(OperatorFactory.get(tsDesc,
           new RowSchema(rwsch.getColumnInfos())), rwsch);
 
       // Add this to the list of top operators - we always start from a table
@@ -5596,8 +5638,7 @@
       }
 
       // Check if input can be pruned
-      ts
-          .setInputPruning((sampleExprs == null || sampleExprs.size() == 0 || colsEqual));
+      ts.setInputPruning((sampleExprs == null || sampleExprs.size() == 0 || colsEqual));
 
       // check if input pruning is enough
       if ((sampleExprs == null || sampleExprs.size() == 0 || colsEqual)
@@ -5683,6 +5724,55 @@
     return output;
   }
 
+  private void setupStats(TableScanDesc tsDesc, QBParseInfo qbp, Table tab, String alias)
+      throws SemanticException {
+
+    if (!qbp.isAnalyzeCommand()) {
+      tsDesc.setGatherStats(false);
+    } else {
+      tsDesc.setGatherStats(true);
+
+      String tblName = tab.getTableName();
+    	tableSpec tblSpec = qbp.getTableSpec(alias);
+    	Map<String, String> partSpec = tblSpec.getPartSpec();
+
+    	if (partSpec != null) {
+    	  List<String> cols = new ArrayList<String>();
+    	  cols.addAll(partSpec.keySet());
+    	  tsDesc.setPartColumns(cols);
+    	}
+
+    	// Theoretically the key prefix could be any unique string shared
+    	// between TableScanOperator (when publishing) and StatsTask (when aggregating).
+    	// Here we use
+    	//       table_name + partitionSec
+    	// as the prefix for easy of read during explain and debugging.
+    	// Currently, partition spec can only be static partition.
+    	String k = tblName + Path.SEPARATOR;
+    	tsDesc.setStatsAggPrefix(k);
+
+    	// set up WritenEntity for replication
+    	outputs.add(new WriteEntity(tab));
+
+    	// add WriteEntity for each matching partition
+    	if (tab.isPartitioned()) {
+    	  if (partSpec == null) {
+    	    throw new SemanticException(ErrorMsg.NEED_PARTITION_SPECIFICATION.getMsg());
+    	  }
+    	  // get all partitions that matches with the partition spec
+    	  try {
+    	    List<Partition> partitions = db.getPartitions(tab, partSpec);
+    	    for (Partition partn : partitions) {
+    	      // inputs.add(new ReadEntity(partn)); // is this needed at all?
+    	      outputs.add(new WriteEntity(partn));
+    	    }
+    	  } catch (HiveException e) {
+    	    throw new SemanticException(e);
+    	  }
+    	}
+    }
+  }
+
   private Operator genPlan(QBExpr qbexpr) throws SemanticException {
     if (qbexpr.getOpcode() == QBExpr.Opcode.NULLOP) {
       return genPlan(qbexpr.getQB());
@@ -5988,7 +6078,6 @@
       fetchTask = (FetchTask) TaskFactory.get(fetch, conf);
       setFetchTask(fetchTask);
     } else {
-      new ArrayList<MoveWork>();
       for (LoadTableDesc ltd : loadTableWork) {
         Task<MoveWork> tsk = TaskFactory.get(new MoveWork(null, null, ltd, null, false),
             conf);
Index: ql/src/gen-javabean/org/apache/hadoop/hive/ql/plan/api/StageType.java
===================================================================
--- ql/src/gen-javabean/org/apache/hadoop/hive/ql/plan/api/StageType.java	(revision 1000592)
+++ ql/src/gen-javabean/org/apache/hadoop/hive/ql/plan/api/StageType.java	(working copy)
@@ -6,13 +6,11 @@
 package org.apache.hadoop.hive.ql.plan.api;
 
 
-import java.util.Set;
-import java.util.HashSet;
-import java.util.Collections;
-import org.apache.thrift.IntRangeSet;
+import java.util.HashMap;
 import java.util.Map;
-import java.util.HashMap;
 
+import org.apache.thrift.IntRangeSet;
+
 public class StageType {
   public static final int CONDITIONAL = 0;
   public static final int COPY = 1;
@@ -23,17 +21,19 @@
   public static final int FUNC = 6;
   public static final int MAPREDLOCAL = 7;
   public static final int MOVE = 8;
+  public static final int STATS = 9;
 
   public static final IntRangeSet VALID_VALUES = new IntRangeSet(
-    CONDITIONAL, 
-    COPY, 
-    DDL, 
-    MAPRED, 
-    EXPLAIN, 
-    FETCH, 
-    FUNC, 
-    MAPREDLOCAL, 
-    MOVE );
+    CONDITIONAL,
+    COPY,
+    DDL,
+    MAPRED,
+    EXPLAIN,
+    FETCH,
+    FUNC,
+    MAPREDLOCAL,
+    MOVE,
+    STATS);
 
   public static final Map<Integer, String> VALUES_TO_NAMES = new HashMap<Integer, String>() {{
     put(CONDITIONAL, "CONDITIONAL");
@@ -45,5 +45,6 @@
     put(FUNC, "FUNC");
     put(MAPREDLOCAL, "MAPREDLOCAL");
     put(MOVE, "MOVE");
+    put(STATS, "STATS");
   }};
 }
Index: ql/build.xml
===================================================================
--- ql/build.xml	(revision 1000592)
+++ ql/build.xml	(working copy)
@@ -47,6 +47,7 @@
     <pathelement location="${jasperc.test.jar}"/>
     <pathelement location="${jsp.test.jar}"/>
     <pathelement location="${common.jar}"/>
+    <pathelement location="${hive.root}/lib/derby.jar"/>
     <fileset dir="${hive.root}" includes="testlibs/*.jar"/>
     <fileset dir="${hadoop.root}/lib" includes="*.jar"/>
     <fileset dir="${hadoop.root}/lib" includes="jsp-2.1/*.jar"/>
@@ -62,7 +63,7 @@
 
   <target name="gen-test" depends="deploy-ant-tasks, test-conditions, test-init" >
     <taskdef name="qtestgen" classname="org.apache.hadoop.hive.ant.QTestGenTask"
-             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${hive.root}/lib/velocity-1.5.jar:${hive.root}/lib/commons-collections-3.2.1.jar:${hive.root}/lib/commons-lang-2.4.jar"/>
+             classpath="${build.dir.hive}/anttasks/hive-anttasks-${version}.jar:${hive.root}/lib/velocity-1.5.jar:${hive.root}/lib/commons-collections-3.2.1.jar:${hive.root}/lib/commons-lang-2.4.jar:${hive.root}/lib/derby.jar"/>
     
     <qtestgen outputDirectory="${test.build.src}/org/apache/hadoop/hive/ql/parse" 
               templatePath="${ql.test.template.dir}" template="TestParse.vm" 
