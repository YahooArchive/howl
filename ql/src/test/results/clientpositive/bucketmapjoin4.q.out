PREHOOK: query: drop table bucketmapjoin_hash_result_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_hash_result_2
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table bucketmapjoin_hash_result_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_hash_result_1
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table bucketmapjoin_tmp_result
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_tmp_result
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table srcbucket_mapjoin
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table srcbucket_mapjoin_part
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin_part
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table srcbucket_mapjoin_part_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin_part_2
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@srcbucket_mapjoin
PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin
PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@srcbucket_mapjoin_part
PREHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
PREHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part@ds=2008-04-08
PREHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
POSTHOOK: query: CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@srcbucket_mapjoin_part_2
PREHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
PREHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
PREHOOK: type: LOAD
POSTHOOK: query: load data local inpath '../data/files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')
POSTHOOK: type: LOAD
POSTHOOK: Output: default@srcbucket_mapjoin_part_2@ds=2008-04-08
PREHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@bucketmapjoin_hash_result_1
PREHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@bucketmapjoin_hash_result_2
PREHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
PREHOOK: type: CREATETABLE
POSTHOOK: query: create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: explain extended 
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
POSTHOOK: query: explain extended 
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST b))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
  Stage-3
  Stage-0 depends on stages: Stage-3, Stage-2
  Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            Common Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              outputColumnNames: _col0, _col1, _col3
              Position of Big Table: 0
              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: string
                      expr: _col3
                      type: string
                outputColumnNames: _col0, _col1, _col3
                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: string
                        expr: _col3
                        type: string
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
                    NumFilesPerFileSink: 1
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          bucket_count -1
                          columns key,value1,value2
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                          name bucketmapjoin_tmp_result
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          transient_lastDdlTime 1270505141
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: bucketmapjoin_tmp_result
                    TotalFiles: 1
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
          Alias -> Map Local Tables:
            b 
              Fetch Operator
                limit: -1
          Alias -> Map Local Operator Tree:
            b 
              TableScan
                alias: b
                Common Join Operator
                  condition map:
                       Inner Join 0 to 1
                  condition expressions:
                    0 {key} {value}
                    1 {value}
                  handleSkewJoin: false
                  keys:
                    0 [Column[key]]
                    1 [Column[key]]
                  outputColumnNames: _col0, _col1, _col3
                  Position of Big Table: 0
                  Select Operator
                    expressions:
                          expr: _col0
                          type: int
                          expr: _col1
                          type: string
                          expr: _col3
                          type: string
                    outputColumnNames: _col0, _col1, _col3
                    Select Operator
                      expressions:
                            expr: _col0
                            type: int
                            expr: _col1
                            type: string
                            expr: _col3
                            type: string
                      outputColumnNames: _col0, _col1, _col2
                      File Output Operator
                        compressed: false
                        GlobalTableId: 1
                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
                        NumFilesPerFileSink: 1
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            properties:
                              bucket_count -1
                              columns key,value1,value2
                              columns.types string:string:string
                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                              name bucketmapjoin_tmp_result
                              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                              serialization.format 1
                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                              transient_lastDdlTime 1270505141
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: bucketmapjoin_tmp_result
                        TotalFiles: 1
                        MultiFileSpray: false
          Bucket Mapjoin Context:
              Alias Bucket Base File Name Mapping:
                b {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
              Alias Bucket File Name Mapping:
                b {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
              Alias Bucket Output File Name Mapping:
                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
      Needs Tagging: false
      Path -> Alias:
        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [a]
      Path -> Partition:
        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
          Partition
            base file name: srcbucket_mapjoin
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
              name srcbucket_mapjoin
              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1270505140
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                name srcbucket_mapjoin
                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505140
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: srcbucket_mapjoin
            name: srcbucket_mapjoin

  Stage: Stage-4
    Conditional Operator

  Stage: Stage-3
    Move Operator
      files:
          hdfs directory: true
          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002
          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                name bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505141
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: bucketmapjoin_tmp_result
          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10001

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 
            Reduce Output Operator
              sort order: 
              Map-reduce partition columns:
                    expr: rand()
                    type: double
              tag: -1
              value expressions:
                    expr: key
                    type: string
                    expr: value1
                    type: string
                    expr: value2
                    type: string
      Needs Tagging: false
      Path -> Alias:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002]
      Path -> Partition:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10002 
          Partition
            base file name: 10002
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value1,value2
              columns.types string:string:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
              name bucketmapjoin_tmp_result
              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1270505141
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                name bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505141
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: bucketmapjoin_tmp_result
            name: bucketmapjoin_tmp_result
      Reduce Operator Tree:
        Extract
          File Output Operator
            compressed: false
            GlobalTableId: 0
            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-41_817_6161225466190369608/10000
            NumFilesPerFileSink: 1
            table:
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                properties:
                  bucket_count -1
                  columns key,value1,value2
                  columns.types string:string:string
                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                  name bucketmapjoin_tmp_result
                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  transient_lastDdlTime 1270505141
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: bucketmapjoin_tmp_result
            TotalFiles: 1
            MultiFileSpray: false


PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin
PREHOOK: Output: default@bucketmapjoin_tmp_result
POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-47_572_2716519961288565209/10000
POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-47_572_2716519961288565209/10000
464
PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: default@bucketmapjoin_hash_result_1
POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: default@bucketmapjoin_hash_result_1
PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin
PREHOOK: Output: default@bucketmapjoin_tmp_result
POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(b)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-58_635_263344841467156716/10000
POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-05-58_635_263344841467156716/10000
464
PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: default@bucketmapjoin_hash_result_2
POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: default@bucketmapjoin_hash_result_2
PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_hash_result_2
PREHOOK: Input: default@bucketmapjoin_hash_result_1
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-04_288_4499541346186910760/10000
POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_hash_result_2
POSTHOOK: Input: default@bucketmapjoin_hash_result_1
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-04_288_4499541346186910760/10000
0	0	0
PREHOOK: query: explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
POSTHOOK: query: explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF srcbucket_mapjoin a) (TOK_TABREF srcbucket_mapjoin b) (= (. (TOK_TABLE_OR_COL a) key) (. (TOK_TABLE_OR_COL b) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB bucketmapjoin_tmp_result)) (TOK_SELECT (TOK_HINTLIST (TOK_HINT TOK_MAPJOIN (TOK_HINTARGLIST a))) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) value)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL b) value)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-4 depends on stages: Stage-1 , consists of Stage-3, Stage-2
  Stage-3
  Stage-0 depends on stages: Stage-3, Stage-2
  Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        b 
          TableScan
            alias: b
            Common Join Operator
              condition map:
                   Inner Join 0 to 1
              condition expressions:
                0 {key} {value}
                1 {value}
              handleSkewJoin: false
              keys:
                0 [Column[key]]
                1 [Column[key]]
              outputColumnNames: _col0, _col1, _col3
              Position of Big Table: 1
              Select Operator
                expressions:
                      expr: _col0
                      type: int
                      expr: _col1
                      type: string
                      expr: _col3
                      type: string
                outputColumnNames: _col0, _col1, _col3
                Select Operator
                  expressions:
                        expr: _col0
                        type: int
                        expr: _col1
                        type: string
                        expr: _col3
                        type: string
                  outputColumnNames: _col0, _col1, _col2
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
                    NumFilesPerFileSink: 1
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          bucket_count -1
                          columns key,value1,value2
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                          name bucketmapjoin_tmp_result
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          transient_lastDdlTime 1270505141
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: bucketmapjoin_tmp_result
                    TotalFiles: 1
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
          Alias -> Map Local Tables:
            a 
              Fetch Operator
                limit: -1
          Alias -> Map Local Operator Tree:
            a 
              TableScan
                alias: a
                Common Join Operator
                  condition map:
                       Inner Join 0 to 1
                  condition expressions:
                    0 {key} {value}
                    1 {value}
                  handleSkewJoin: false
                  keys:
                    0 [Column[key]]
                    1 [Column[key]]
                  outputColumnNames: _col0, _col1, _col3
                  Position of Big Table: 1
                  Select Operator
                    expressions:
                          expr: _col0
                          type: int
                          expr: _col1
                          type: string
                          expr: _col3
                          type: string
                    outputColumnNames: _col0, _col1, _col3
                    Select Operator
                      expressions:
                            expr: _col0
                            type: int
                            expr: _col1
                            type: string
                            expr: _col3
                            type: string
                      outputColumnNames: _col0, _col1, _col2
                      File Output Operator
                        compressed: false
                        GlobalTableId: 1
                        directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
                        NumFilesPerFileSink: 1
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            properties:
                              bucket_count -1
                              columns key,value1,value2
                              columns.types string:string:string
                              file.inputformat org.apache.hadoop.mapred.TextInputFormat
                              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                              name bucketmapjoin_tmp_result
                              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                              serialization.format 1
                              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                              transient_lastDdlTime 1270505141
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: bucketmapjoin_tmp_result
                        TotalFiles: 1
                        MultiFileSpray: false
          Bucket Mapjoin Context:
              Alias Bucket Base File Name Mapping:
                a {srcbucket20.txt=[srcbucket20.txt], srcbucket21.txt=[srcbucket21.txt]}
              Alias Bucket File Name Mapping:
                a {file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt], file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt=[file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt]}
              Alias Bucket Output File Name Mapping:
                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket20.txt 0
                file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin/srcbucket21.txt 1
      Needs Tagging: false
      Path -> Alias:
        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin [b]
      Path -> Partition:
        file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin 
          Partition
            base file name: srcbucket_mapjoin
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
              name srcbucket_mapjoin
              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1270505140
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/srcbucket_mapjoin
                name srcbucket_mapjoin
                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505140
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: srcbucket_mapjoin
            name: srcbucket_mapjoin

  Stage: Stage-4
    Conditional Operator

  Stage: Stage-3
    Move Operator
      files:
          hdfs directory: true
          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002
          destination: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                name bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505141
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: bucketmapjoin_tmp_result
          tmp directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10001

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 
            Reduce Output Operator
              sort order: 
              Map-reduce partition columns:
                    expr: rand()
                    type: double
              tag: -1
              value expressions:
                    expr: key
                    type: string
                    expr: value1
                    type: string
                    expr: value2
                    type: string
      Needs Tagging: false
      Path -> Alias:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 [file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002]
      Path -> Partition:
        file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10002 
          Partition
            base file name: 10002
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value1,value2
              columns.types string:string:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
              name bucketmapjoin_tmp_result
              serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              transient_lastDdlTime 1270505141
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                name bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1270505141
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: bucketmapjoin_tmp_result
            name: bucketmapjoin_tmp_result
      Reduce Operator Tree:
        Extract
          File Output Operator
            compressed: false
            GlobalTableId: 0
            directory: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-07_187_7710258011545085783/10000
            NumFilesPerFileSink: 1
            table:
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                properties:
                  bucket_count -1
                  columns key,value1,value2
                  columns.types string:string:string
                  file.inputformat org.apache.hadoop.mapred.TextInputFormat
                  file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  location file:/data/users/njain/hive-trunk/build/ql/test/data/warehouse/bucketmapjoin_tmp_result
                  name bucketmapjoin_tmp_result
                  serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                  serialization.format 1
                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  transient_lastDdlTime 1270505141
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                name: bucketmapjoin_tmp_result
            TotalFiles: 1
            MultiFileSpray: false


PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin
PREHOOK: Output: default@bucketmapjoin_tmp_result
POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-12_917_4419238107961618871/10000
POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-12_917_4419238107961618871/10000
464
PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: default@bucketmapjoin_hash_result_1
POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: default@bucketmapjoin_hash_result_1
PREHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@srcbucket_mapjoin
PREHOOK: Output: default@bucketmapjoin_tmp_result
POSTHOOK: query: insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin b 
on a.key=b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcbucket_mapjoin
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: select count(1) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-24_098_3327514646758498260/10000
POSTHOOK: query: select count(1) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-24_098_3327514646758498260/10000
464
PREHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_tmp_result
PREHOOK: Output: default@bucketmapjoin_hash_result_2
POSTHOOK: query: insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_tmp_result
POSTHOOK: Output: default@bucketmapjoin_hash_result_2
PREHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
PREHOOK: type: QUERY
PREHOOK: Input: default@bucketmapjoin_hash_result_2
PREHOOK: Input: default@bucketmapjoin_hash_result_1
PREHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-29_679_7550371653184314434/10000
POSTHOOK: query: select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@bucketmapjoin_hash_result_2
POSTHOOK: Input: default@bucketmapjoin_hash_result_1
POSTHOOK: Output: file:/data/users/njain/hive-trunk/build/ql/scratchdir/hive_2010-04-05_15-06-29_679_7550371653184314434/10000
0	0	0
PREHOOK: query: drop table bucketmapjoin_hash_result_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_hash_result_2
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@bucketmapjoin_hash_result_2
PREHOOK: query: drop table bucketmapjoin_hash_result_1
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_hash_result_1
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@bucketmapjoin_hash_result_1
PREHOOK: query: drop table bucketmapjoin_tmp_result
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table bucketmapjoin_tmp_result
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@bucketmapjoin_tmp_result
PREHOOK: query: drop table srcbucket_mapjoin
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@srcbucket_mapjoin
PREHOOK: query: drop table srcbucket_mapjoin_part
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin_part
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@srcbucket_mapjoin_part
PREHOOK: query: drop table srcbucket_mapjoin_part_2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table srcbucket_mapjoin_part_2
POSTHOOK: type: DROPTABLE
POSTHOOK: Output: default@srcbucket_mapjoin_part_2
