query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
query: -- both input pruning and sample filter
EXPLAIN EXTENDED
INSERT OVERWRITE TABLE dest1 SELECT s.* 
FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 4 on key) s
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF srcbucket (TOK_TABLESAMPLE 1 4 (TOK_TABLE_OR_COL key)) s)) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest1)) (TOK_SELECT (TOK_SELEXPR (TOK_ALLCOLREF s)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-4 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        s 
          TableScan
            alias: s
            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: (((hash(key) & 2147483647) % 4) = 0)
                  type: boolean
              Filter Operator
                isSamplingPred: true
                predicate:
                    expr: (((hash(key) & 2147483647) % 4) = 0)
                    type: boolean
                Select Operator
                  expressions:
                        expr: key
                        type: int
                        expr: value
                        type: string
                  outputColumnNames: _col0, _col1
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/237880152/10002
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          name dest1
                          columns.types int:string
                          serialization.ddl struct dest1 { i32 key, string value}
                          serialization.format 1
                          columns key,value
                          bucket_count -1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/dest1
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: dest1
      Needs Tagging: false
      Path -> Alias:
        file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
      Path -> Partition:
        file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/srcbucket/srcbucket0.txt 
          Partition
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name srcbucket
                columns.types int:string
                bucket_field_name key
                serialization.ddl struct srcbucket { i32 key, string value}
                columns key,value
                serialization.format 1
                bucket_count 2
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/srcbucket
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: srcbucket

  Stage: Stage-4
    Conditional Operator
      list of dependent Tasks:
          Move Operator
            files:
                hdfs directory: true
                source: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/237880152/10002
                destination: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/871659719/10000
          Map Reduce
            Alias -> Map Operator Tree:
              file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/237880152/10002 
                  Reduce Output Operator
                    sort order: 
                    Map-reduce partition columns:
                          expr: rand()
                          type: double
                    tag: -1
                    value expressions:
                          expr: key
                          type: int
                          expr: value
                          type: string
            Needs Tagging: false
            Path -> Alias:
              file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/237880152/10002 
            Path -> Partition:
              file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/237880152/10002 
                Partition
                
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      name dest1
                      columns.types int:string
                      serialization.ddl struct dest1 { i32 key, string value}
                      serialization.format 1
                      columns key,value
                      bucket_count -1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      file.inputformat org.apache.hadoop.mapred.TextInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      location file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/dest1
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: dest1
            Reduce Operator Tree:
              Extract
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  directory: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/871659719/10000
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        name dest1
                        columns.types int:string
                        serialization.ddl struct dest1 { i32 key, string value}
                        serialization.format 1
                        columns key,value
                        bucket_count -1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
                        location file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/dest1
                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: dest1

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/871659719/10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name dest1
                columns.types int:string
                serialization.ddl struct dest1 { i32 key, string value}
                serialization.format 1
                columns key,value
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/test/data/warehouse/dest1
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: dest1
          tmp directory: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/871659719/10001


query: INSERT OVERWRITE TABLE dest1 SELECT s.* 
FROM srcbucket TABLESAMPLE (BUCKET 1 OUT OF 4 on key) s
Input: default/srcbucket
Output: default/dest1
query: SELECT dest1.* FROM dest1
Input: default/dest1
Output: file:/data/users/athusoo/commits/hive_trunk_ws1/build/ql/tmp/899553837/10000
468	val_469
272	val_273
448	val_449
440	val_441
296	val_297
428	val_429
356	val_357
128	val_129
0	val_1
240	val_241
408	val_409
476	val_477
48	val_49
424	val_425
488	val_489
128	val_129
468	val_469
224	val_225
344	val_345
4	val_5
56	val_57
304	val_305
264	val_265
196	val_197
20	val_21
492	val_493
360	val_361
68	val_69
16	val_17
492	val_493
376	val_377
120	val_121
132	val_133
388	val_389
184	val_185
284	val_285
352	val_353
328	val_329
480	val_481
480	val_481
392	val_393
476	val_477
252	val_253
264	val_265
48	val_49
336	val_337
340	val_341
484	val_485
260	val_261
164	val_165
104	val_105
80	val_81
140	val_141
212	val_213
308	val_309
416	val_417
364	val_365
20	val_21
52	val_53
40	val_41
8	val_9
168	val_169
384	val_385
324	val_325
404	val_405
260	val_261
328	val_329
404	val_405
384	val_385
76	val_77
116	val_117
104	val_105
32	val_33
132	val_133
192	val_193
356	val_357
352	val_353
52	val_53
160	val_161
76	val_77
412	val_413
16	val_17
204	val_205
216	val_217
196	val_197
12	val_13
384	val_385
60	val_61
52	val_53
404	val_405
300	val_301
0	val_1
268	val_269
392	val_393
104	val_105
436	val_437
156	val_157
172	val_173
244	val_245
284	val_285
164	val_165
136	val_137
432	val_433
496	val_497
144	val_145
408	val_409
152	val_153
348	val_349
292	val_293
52	val_53
152	val_153
256	val_257
292	val_293
412	val_413
40	val_41
100	val_101
156	val_157
228	val_229
248	val_249
244	val_245
276	val_277
196	val_197
440	val_441
100	val_101
308	val_309
468	val_469
152	val_153
76	val_77
300	val_301
244	val_245
484	val_484
224	val_224
128	val_128
152	val_152
252	val_252
292	val_292
208	val_208
396	val_396
0	val_0
128	val_128
316	val_316
20	val_20
92	val_92
72	val_72
4	val_4
280	val_280
208	val_208
356	val_356
192	val_192
176	val_176
216	val_216
176	val_176
332	val_332
180	val_180
284	val_284
12	val_12
260	val_260
404	val_404
384	val_384
272	val_272
84	val_84
348	val_348
8	val_8
208	val_208
348	val_348
24	val_24
172	val_172
496	val_496
0	val_0
468	val_468
100	val_100
96	val_96
120	val_120
404	val_404
436	val_436
156	val_156
468	val_468
308	val_308
196	val_196
288	val_288
316	val_316
0	val_0
364	val_364
72	val_72
224	val_224
392	val_392
272	val_272
452	val_452
396	val_396
336	val_336
168	val_168
472	val_472
160	val_160
76	val_76
492	val_492
228	val_228
64	val_64
468	val_468
76	val_76
368	val_368
296	val_296
216	val_216
344	val_344
116	val_116
256	val_256
480	val_480
288	val_288
244	val_244
128	val_128
432	val_432
316	val_316
280	val_280
80	val_80
44	val_44
104	val_104
348	val_348
424	val_424
12	val_12
396	val_396
164	val_164
164	val_164
424	val_424
480	val_480
24	val_24
104	val_104
200	val_200
360	val_360
248	val_248
444	val_444
120	val_120
468	val_468
460	val_460
480	val_480
136	val_136
172	val_172
384	val_384
256	val_256
384	val_384
492	val_492
100	val_100
348	val_348
344	val_344
84	val_84
28	val_28
448	val_448
152	val_152
348	val_348
400	val_400
200	val_200
